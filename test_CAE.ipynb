{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook provides output of running main.py\n",
    "\n",
    "# to run this notebook:\n",
    "# choose cohortney kernel for this notebook to run\n",
    "# first you need to install this kernel with\n",
    "# pip install ipykernel\n",
    "# python -m ipykernel install --user --name=cohortney\n",
    "\n",
    "# or just run the script from console)\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPTV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 550 K \n",
      "1 | decoder | Sequential | 550 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 10.94it/s, loss=55.6, val_loss=0.151, avg_val\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 19.11it/s, loss=55.6, val_loss=0.327, avg_val\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 11.78it/s, loss=32.1, val_loss=0.327, avg_val\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 20.27it/s, loss=32.1, val_loss=5.25, avg_val_\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 11.77it/s, loss=22, val_loss=5.25, avg_val_lo\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 20.50it/s, loss=22, val_loss=6.05, avg_val_lo\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=16.8, val_loss=6.05, avg_val_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=16.8, val_loss=5.73, avg_val_\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=13.6, val_loss=5.73, avg_val_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=13.6, val_loss=3.1, avg_val_l\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=11.4, val_loss=3.1, avg_val_l\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=11.4, val_loss=2.53, avg_val_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.80it/s, loss=9.87, val_loss=2.53, avg_val_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=9.87, val_loss=1.58, avg_val_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=1.13, val_loss=1.58, avg_val_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 20.74it/s, loss=1.13, val_loss=0.73, avg_val_\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.708, val_loss=0.73, avg_val\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=0.708, val_loss=0.629, avg_va\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.516, val_loss=0.629, avg_va\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=0.516, val_loss=0.314, avg_va\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.4, val_loss=0.314, avg_val\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.4, val_loss=0.344, avg_val\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.315, val_loss=0.344, avg_v\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.315, val_loss=0.202, avg_v\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.264, val_loss=0.202, avg_v\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.264, val_loss=0.223, avg_v\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.218, val_loss=0.223, avg_v\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.218, val_loss=0.139, avg_v\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.192, val_loss=0.139, avg_v\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.192, val_loss=0.162, avg_v\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.169, val_loss=0.162, avg_v\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.169, val_loss=0.13, avg_va\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 11.57it/s, loss=0.154, val_loss=0.13, avg_va\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 20.24it/s, loss=0.154, val_loss=0.129, avg_v\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.142, val_loss=0.129, avg_v\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.142, val_loss=0.118, avg_v\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.133, val_loss=0.118, avg_v\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.133, val_loss=0.117, avg_v\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.71it/s, loss=0.126, val_loss=0.117, avg_v\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 20.40it/s, loss=0.126, val_loss=0.112, avg_v\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=0.121, val_loss=0.112, avg_v\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=0.121, val_loss=0.111, avg_v\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.117, val_loss=0.111, avg_v\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 20.74it/s, loss=0.117, val_loss=0.107, avg_v\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.113, val_loss=0.107, avg_v\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.113, val_loss=0.107, avg_v\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.111, val_loss=0.107, avg_v\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.111, val_loss=0.105, avg_v\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.109, val_loss=0.105, avg_v\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.109, val_loss=0.105, avg_v\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.108, val_loss=0.105, avg_v\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 20.51it/s, loss=0.108, val_loss=0.103, avg_v\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=0.106, val_loss=0.103, avg_v\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.106, val_loss=0.103, avg_v\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.105, val_loss=0.103, avg_v\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=0.105, val_loss=0.102, avg_v\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=0.104, val_loss=0.102, avg_v\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=0.104, val_loss=0.102, avg_v\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.103, val_loss=0.102, avg_v\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.103, val_loss=0.101, avg_v\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.103, val_loss=0.101, avg_v\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.103, val_loss=0.101, avg_v\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.102, val_loss=0.101, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.102, val_loss=0.1, avg_val\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=0.102, val_loss=0.1, avg_val\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=0.102, val_loss=0.0998, avg_\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 11.51it/s, loss=0.101, val_loss=0.0998, avg_\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 20.13it/s, loss=0.101, val_loss=0.0995, avg_\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.101, val_loss=0.0995, avg_\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 20.48it/s, loss=0.101, val_loss=0.099, avg_v\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.1, val_loss=0.099, avg_val\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.1, val_loss=0.0986, avg_va\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0998, val_loss=0.0986, avg\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.0998, val_loss=0.0983, avg\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.0994, val_loss=0.0983, avg\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.0994, val_loss=0.0979, avg\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.099, val_loss=0.0979, avg_\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=0.099, val_loss=0.0975, avg_\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.0986, val_loss=0.0975, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=0.0986, val_loss=0.0972, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.0986, val_loss=0.0972, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of clusters: 27, 23, 35, 107, 26, 71\n",
      "\n",
      "preds: [5 5 4 5 5 3 2 1 0 5 5 5 4 1 2 4 1 3 3 2 3 3 3 5 2 1 5 3 5 2 3 5 0 5 5 3 3\n",
      " 5 1 3 3 3 3 2 5 3 2 3 2 5 1 3 5 2 5 5 1 5 1 5 0 3 4 0 5 4 3 3 2 3 2 3 5 3\n",
      " 3 2 4 2 3 3 2 5 0 5 5 1 3 2 5 5 3 5 1 3 5 3 3 5 5 4 3 3 5 0 5 4 2 2 3 0 3\n",
      " 2 2 3 2 5 3 5 2 3 0 5 3 3 5 2 5 5 5 3 1 2 5 0 4 5 3 5 3 3 3 4 3 5 1 3 3 3\n",
      " 5 3 3 2 5 3 3 3 0 3 2 5 3 3 4 3 5 0 3 0 0 4 0 5 3 4 1 4 5 3 3 3 3 2 3 5 5\n",
      " 3 5 4 4 3 3 5 5 3 4 4 5 3 3 5 3 2 3 3 3 4 3 1 0 3 5 3 2 3 3 2 0 3 5 3 3 2\n",
      " 4 3 0 3 3 3 2 3 5 3 5 3 1 3 3 3 3 3 1 2 0 5 3 2 5 3 1 5 0 3 1 4 1 4 1 3 3\n",
      " 3 0 3 4 0 1 4 0 5 4 5 3 3 3 0 1 5 0 0 4 5 3 2 3 1 5 0 2 0 5]\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 550 K \n",
      "1 | decoder | Sequential | 550 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.76it/s, loss=58.5, val_loss=0.153, avg_val\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=58.5, val_loss=0.329, avg_val\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=38.7, val_loss=0.329, avg_val\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=38.7, val_loss=1.66, avg_val_\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=26.7, val_loss=1.66, avg_val_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=26.7, val_loss=3.34, avg_val_\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=20.4, val_loss=3.34, avg_val_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=20.4, val_loss=3.37, avg_val_\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=16.5, val_loss=3.37, avg_val_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=16.5, val_loss=2.45, avg_val_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.75it/s, loss=13.9, val_loss=2.45, avg_val_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 20.44it/s, loss=13.9, val_loss=1.96, avg_val_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=12.1, val_loss=1.96, avg_val_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=12.1, val_loss=0.916, avg_val\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=1.64, val_loss=0.916, avg_val\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=1.64, val_loss=0.859, avg_val\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.915, val_loss=0.859, avg_va\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.915, val_loss=0.514, avg_va\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.623, val_loss=0.514, avg_va\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.623, val_loss=0.505, avg_va\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.445, val_loss=0.505, avg_v\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.445, val_loss=0.252, avg_v\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 11.91it/s, loss=0.355, val_loss=0.252, avg_v\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.355, val_loss=0.251, avg_v\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.276, val_loss=0.251, avg_v\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 20.60it/s, loss=0.276, val_loss=0.176, avg_v\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.232, val_loss=0.176, avg_v\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=0.232, val_loss=0.167, avg_v\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.193, val_loss=0.167, avg_v\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.193, val_loss=0.131, avg_v\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.92it/s, loss=0.167, val_loss=0.131, avg_v\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 20.77it/s, loss=0.167, val_loss=0.13, avg_va\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 11.50it/s, loss=0.145, val_loss=0.13, avg_va\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 20.06it/s, loss=0.145, val_loss=0.11, avg_va\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.133, val_loss=0.11, avg_va\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=0.133, val_loss=0.11, avg_va\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.77it/s, loss=0.122, val_loss=0.11, avg_va\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 20.54it/s, loss=0.122, val_loss=0.101, avg_v\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.114, val_loss=0.101, avg_v\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.114, val_loss=0.099, avg_v\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.108, val_loss=0.099, avg_v\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 20.60it/s, loss=0.108, val_loss=0.096, avg_v\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.103, val_loss=0.096, avg_v\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.103, val_loss=0.0939, avg_\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0997, val_loss=0.0939, avg\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 20.47it/s, loss=0.0997, val_loss=0.093, avg_\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0974, val_loss=0.093, avg_\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.0974, val_loss=0.0911, avg\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0951, val_loss=0.0911, avg\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 20.53it/s, loss=0.0951, val_loss=0.0909, avg\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 11.80it/s, loss=0.0936, val_loss=0.0909, avg\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.0936, val_loss=0.0895, avg\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.91it/s, loss=0.0922, val_loss=0.0895, avg\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=0.0922, val_loss=0.0891, avg\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.0913, val_loss=0.0891, avg\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=0.0913, val_loss=0.0886, avg\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0904, val_loss=0.0886, avg\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.0904, val_loss=0.088, avg_\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.0897, val_loss=0.088, avg_\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=0.0897, val_loss=0.0876, avg\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.0891, val_loss=0.0876, avg\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 20.60it/s, loss=0.0891, val_loss=0.0872, avg\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0885, val_loss=0.0872, avg\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.0885, val_loss=0.0869, avg\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.91it/s, loss=0.0881, val_loss=0.0869, avg\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.0881, val_loss=0.0865, avg\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 11.43it/s, loss=0.0877, val_loss=0.0865, avg\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 20.01it/s, loss=0.0877, val_loss=0.0862, avg\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0873, val_loss=0.0862, avg\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.0873, val_loss=0.0859, avg\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0869, val_loss=0.0859, avg\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=0.0869, val_loss=0.0856, avg\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0866, val_loss=0.0856, avg\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=0.0866, val_loss=0.0853, avg\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0863, val_loss=0.0853, avg\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 20.63it/s, loss=0.0863, val_loss=0.085, avg_\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.086, val_loss=0.085, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 20.43it/s, loss=0.086, val_loss=0.0848, avg_\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.0857, val_loss=0.0848, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.0857, val_loss=0.0845, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.48it/s, loss=0.0857, val_loss=0.0845, avg\n",
      "Sizes of clusters: 10, 127, 81, 20, 32, 19\n",
      "\n",
      "preds: [2 2 0 1 4 1 3 5 2 4 1 2 3 3 3 4 5 1 1 4 1 1 1 1 4 5 2 2 2 4 1 1 3 2 2 2 1\n",
      " 0 5 1 2 2 1 4 2 1 5 1 1 2 1 1 2 2 1 1 3 2 2 1 5 1 3 2 2 4 1 1 1 1 5 1 2 1\n",
      " 0 2 4 4 1 1 2 2 5 4 2 2 1 2 4 1 1 2 2 1 2 1 1 1 1 3 1 1 2 2 2 4 2 1 1 5 1\n",
      " 2 2 1 2 1 1 2 1 1 5 2 1 1 2 4 2 4 4 1 2 1 1 5 4 1 1 2 1 1 1 4 1 2 5 2 1 1\n",
      " 1 1 4 4 1 1 2 1 5 2 3 2 1 1 2 1 2 2 2 1 2 4 3 1 1 3 2 3 1 1 1 1 1 0 1 4 2\n",
      " 2 2 0 3 1 1 2 2 1 4 4 1 1 1 1 1 1 1 1 1 4 1 2 5 1 1 1 2 1 1 4 2 1 2 1 1 3\n",
      " 3 1 3 2 5 1 0 1 1 1 2 1 2 1 1 1 1 1 5 1 5 2 1 4 2 1 3 1 2 1 2 4 3 4 5 2 1\n",
      " 2 0 1 0 5 2 4 2 1 4 1 1 1 1 2 1 2 3 2 0 2 1 4 1 1 2 3 0 2 2]\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 550 K \n",
      "1 | decoder | Sequential | 550 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=65.5, val_loss=0.159, avg_val\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 20.63it/s, loss=65.5, val_loss=0.34, avg_val_\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=44.1, val_loss=0.34, avg_val_\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=44.1, val_loss=0.936, avg_val\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=30.2, val_loss=0.936, avg_val\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=30.2, val_loss=2.43, avg_val_\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=23, val_loss=2.43, avg_val_lo\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 20.47it/s, loss=23, val_loss=1.7, avg_val_los\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=18.5, val_loss=1.7, avg_val_l\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=18.5, val_loss=1.81, avg_val_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=15.5, val_loss=1.81, avg_val_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=15.5, val_loss=1.36, avg_val_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=13.5, val_loss=1.36, avg_val_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=13.5, val_loss=1.12, avg_val_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=1.65, val_loss=1.12, avg_val_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=1.65, val_loss=0.728, avg_val\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.757, val_loss=0.728, avg_va\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 20.63it/s, loss=0.757, val_loss=0.448, avg_va\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.506, val_loss=0.448, avg_va\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.506, val_loss=0.358, avg_va\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.39, val_loss=0.358, avg_va\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.39, val_loss=0.295, avg_va\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.308, val_loss=0.295, avg_v\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.308, val_loss=0.221, avg_v\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.78it/s, loss=0.255, val_loss=0.221, avg_v\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.255, val_loss=0.188, avg_v\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.21, val_loss=0.188, avg_va\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=0.21, val_loss=0.158, avg_va\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.182, val_loss=0.158, avg_v\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.182, val_loss=0.14, avg_va\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.159, val_loss=0.14, avg_va\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.159, val_loss=0.127, avg_v\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 11.53it/s, loss=0.147, val_loss=0.127, avg_v\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 20.16it/s, loss=0.147, val_loss=0.124, avg_v\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.134, val_loss=0.124, avg_v\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 20.47it/s, loss=0.134, val_loss=0.114, avg_v\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.126, val_loss=0.114, avg_v\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.126, val_loss=0.11, avg_va\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.119, val_loss=0.11, avg_va\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.119, val_loss=0.107, avg_v\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.114, val_loss=0.107, avg_v\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.114, val_loss=0.105, avg_v\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.111, val_loss=0.105, avg_v\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 20.73it/s, loss=0.111, val_loss=0.102, avg_v\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.108, val_loss=0.102, avg_v\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.108, val_loss=0.101, avg_v\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=0.105, val_loss=0.101, avg_v\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.105, val_loss=0.0996, avg_\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.103, val_loss=0.0996, avg_\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 20.59it/s, loss=0.103, val_loss=0.0982, avg_\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.101, val_loss=0.0982, avg_\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.101, val_loss=0.0972, avg_\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.1, val_loss=0.0972, avg_va\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.1, val_loss=0.0964, avg_va\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0989, val_loss=0.0964, avg\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 20.72it/s, loss=0.0989, val_loss=0.0956, avg\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.0979, val_loss=0.0956, avg\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.0979, val_loss=0.0948, avg\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0969, val_loss=0.0948, avg\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=0.0969, val_loss=0.0941, avg\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0961, val_loss=0.0941, avg\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=0.0961, val_loss=0.0935, avg\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.75it/s, loss=0.0953, val_loss=0.0935, avg\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 20.42it/s, loss=0.0953, val_loss=0.0928, avg\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0946, val_loss=0.0928, avg\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=0.0946, val_loss=0.0922, avg\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 11.54it/s, loss=0.0939, val_loss=0.0922, avg\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 20.12it/s, loss=0.0939, val_loss=0.0916, avg\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0933, val_loss=0.0916, avg\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=0.0933, val_loss=0.091, avg_\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.0926, val_loss=0.091, avg_\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=0.0926, val_loss=0.0904, avg\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.91it/s, loss=0.092, val_loss=0.0904, avg_\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 20.60it/s, loss=0.092, val_loss=0.0898, avg_\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 11.80it/s, loss=0.0914, val_loss=0.0898, avg\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.0914, val_loss=0.0893, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.0908, val_loss=0.0893, avg\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 20.71it/s, loss=0.0908, val_loss=0.0887, avg\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.76it/s, loss=0.0903, val_loss=0.0887, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.49it/s, loss=0.0903, val_loss=0.0882, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.33it/s, loss=0.0903, val_loss=0.0882, avg\n",
      "Sizes of clusters: 38, 141, 7, 53, 40, 10\n",
      "\n",
      "preds: [3 4 5 1 4 4 3 0 0 4 3 4 5 3 3 4 3 1 3 3 1 4 1 3 3 0 1 1 4 3 1 3 0 1 1 2 1\n",
      " 1 0 3 1 1 1 3 1 1 3 1 1 4 1 1 1 3 3 1 2 3 5 3 0 1 4 0 1 4 1 1 3 1 3 1 1 0\n",
      " 1 2 4 3 1 1 3 1 0 3 1 0 3 1 4 1 1 1 3 1 3 1 1 3 4 5 3 1 1 1 1 5 3 2 1 0 1\n",
      " 3 3 1 1 3 1 1 0 1 0 1 1 1 1 3 1 3 5 1 0 1 1 0 4 1 1 1 1 1 1 4 1 4 0 1 1 1\n",
      " 4 1 1 3 1 3 1 1 0 4 3 1 1 1 3 1 1 0 0 1 0 4 0 1 1 4 1 4 1 1 1 1 1 3 1 5 3\n",
      " 1 3 4 4 1 1 1 4 1 4 4 4 1 1 3 1 2 1 1 1 4 1 0 0 1 1 1 4 1 1 3 0 1 1 1 1 3\n",
      " 4 1 0 1 0 1 3 1 1 1 5 1 0 1 1 1 1 1 2 2 0 3 3 4 1 1 0 1 4 1 1 4 0 4 0 1 1\n",
      " 1 0 1 5 0 1 4 0 3 5 4 1 1 1 1 0 1 0 1 4 3 4 3 1 1 4 0 3 0 3]\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 550 K \n",
      "1 | decoder | Sequential | 550 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=66.6, val_loss=0.159, avg_val\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=66.6, val_loss=0.234, avg_val\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=38.9, val_loss=0.234, avg_val\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=38.9, val_loss=2.5, avg_val_l\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=26.7, val_loss=2.5, avg_val_l\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=26.7, val_loss=4.19, avg_val_\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=20.3, val_loss=4.19, avg_val_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=20.3, val_loss=3.74, avg_val_\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=16.4, val_loss=3.74, avg_val_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=16.4, val_loss=3.47, avg_val_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=13.8, val_loss=3.47, avg_val_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 20.42it/s, loss=13.8, val_loss=1.84, avg_val_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=11.9, val_loss=1.84, avg_val_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=11.9, val_loss=1.72, avg_val_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=1.49, val_loss=1.72, avg_val_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 20.41it/s, loss=1.49, val_loss=0.773, avg_val\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.71, val_loss=0.773, avg_val\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.71, val_loss=0.7, avg_val_l\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.494, val_loss=0.7, avg_val_\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.494, val_loss=0.369, avg_va\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.379, val_loss=0.369, avg_v\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.379, val_loss=0.307, avg_v\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.297, val_loss=0.307, avg_v\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 20.53it/s, loss=0.297, val_loss=0.257, avg_v\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.78it/s, loss=0.258, val_loss=0.257, avg_v\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 20.48it/s, loss=0.258, val_loss=0.182, avg_v\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.68it/s, loss=0.213, val_loss=0.182, avg_v\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 20.39it/s, loss=0.213, val_loss=0.173, avg_v\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=0.188, val_loss=0.173, avg_v\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 20.54it/s, loss=0.188, val_loss=0.143, avg_v\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.164, val_loss=0.143, avg_v\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 20.59it/s, loss=0.164, val_loss=0.136, avg_v\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 11.37it/s, loss=0.148, val_loss=0.136, avg_v\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 19.91it/s, loss=0.148, val_loss=0.121, avg_v\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.137, val_loss=0.121, avg_v\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.137, val_loss=0.119, avg_v\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.127, val_loss=0.119, avg_v\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.127, val_loss=0.112, avg_v\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.72it/s, loss=0.121, val_loss=0.112, avg_v\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 20.45it/s, loss=0.121, val_loss=0.109, avg_v\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.116, val_loss=0.109, avg_v\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.116, val_loss=0.107, avg_v\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.112, val_loss=0.107, avg_v\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=0.112, val_loss=0.105, avg_v\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.109, val_loss=0.105, avg_v\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.109, val_loss=0.103, avg_v\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.78it/s, loss=0.107, val_loss=0.103, avg_v\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 20.54it/s, loss=0.107, val_loss=0.102, avg_v\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.105, val_loss=0.102, avg_v\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.105, val_loss=0.101, avg_v\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.104, val_loss=0.101, avg_v\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 20.59it/s, loss=0.104, val_loss=0.1, avg_val\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.76it/s, loss=0.103, val_loss=0.1, avg_val\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 20.50it/s, loss=0.103, val_loss=0.0997, avg_\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.102, val_loss=0.0997, avg_\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.102, val_loss=0.0991, avg_\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.101, val_loss=0.0991, avg_\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.101, val_loss=0.0986, avg_\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.1, val_loss=0.0986, avg_va\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 20.68it/s, loss=0.1, val_loss=0.0981, avg_va\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=0.0995, val_loss=0.0981, avg\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 20.46it/s, loss=0.0995, val_loss=0.0976, avg\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.099, val_loss=0.0976, avg_\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=0.099, val_loss=0.0972, avg_\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.74it/s, loss=0.0985, val_loss=0.0972, avg\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 20.48it/s, loss=0.0985, val_loss=0.0968, avg\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 11.49it/s, loss=0.098, val_loss=0.0968, avg_\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 20.09it/s, loss=0.098, val_loss=0.0964, avg_\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.0975, val_loss=0.0964, avg\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=0.0975, val_loss=0.096, avg_\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.0971, val_loss=0.096, avg_\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 20.60it/s, loss=0.0971, val_loss=0.0956, avg\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0967, val_loss=0.0956, avg\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 20.63it/s, loss=0.0967, val_loss=0.0953, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.0963, val_loss=0.0953, avg\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 20.52it/s, loss=0.0963, val_loss=0.0949, avg\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.096, val_loss=0.0949, avg_\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.096, val_loss=0.0946, avg_\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.0956, val_loss=0.0946, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.53it/s, loss=0.0956, val_loss=0.0942, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.36it/s, loss=0.0956, val_loss=0.0942, avg\n",
      "Sizes of clusters: 43, 60, 122, 19, 22, 23\n",
      "\n",
      "preds: [1 1 5 2 1 2 5 4 0 0 1 0 3 4 3 3 4 2 2 5 2 2 2 0 5 4 1 2 1 5 2 1 0 1 1 2 2\n",
      " 1 4 2 2 2 2 5 1 2 5 2 1 1 2 2 1 5 1 2 4 0 0 2 4 2 3 4 0 3 2 2 1 2 5 2 1 2\n",
      " 1 5 3 5 2 2 1 1 0 1 1 4 0 5 1 2 2 1 4 2 1 2 2 2 1 3 2 2 1 0 1 0 5 1 2 4 2\n",
      " 1 5 2 1 1 2 1 1 2 0 1 2 2 2 5 1 0 0 2 4 1 2 0 3 2 2 2 2 2 2 3 2 0 4 0 2 2\n",
      " 1 2 0 5 2 2 2 2 4 2 3 1 2 2 1 2 1 0 2 2 0 3 0 2 2 3 2 3 1 2 2 2 2 4 2 0 1\n",
      " 1 0 3 3 2 2 1 1 2 1 0 1 2 2 0 2 1 2 2 2 3 2 4 0 2 1 2 5 2 2 5 0 2 2 2 2 5\n",
      " 3 2 0 2 0 2 5 2 2 2 0 2 2 2 2 2 2 2 4 1 0 1 1 5 1 2 4 2 0 2 2 1 4 1 4 2 2\n",
      " 2 0 2 0 4 2 0 0 1 3 0 2 2 2 0 2 1 0 0 3 1 2 5 2 2 0 4 5 0 1]\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 550 K \n",
      "1 | decoder | Sequential | 550 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=60.8, val_loss=0.168, avg_val\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 20.54it/s, loss=60.8, val_loss=0.437, avg_val\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 11.72it/s, loss=37.6, val_loss=0.437, avg_val\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 20.45it/s, loss=37.6, val_loss=4.98, avg_val_\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=25.9, val_loss=4.98, avg_val_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 20.62it/s, loss=25.9, val_loss=5.74, avg_val_\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=19.7, val_loss=5.74, avg_val_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=19.7, val_loss=5.89, avg_val_\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=15.9, val_loss=5.89, avg_val_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=15.9, val_loss=2.49, avg_val_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=13.3, val_loss=2.49, avg_val_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=13.3, val_loss=2.29, avg_val_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=11.5, val_loss=2.29, avg_val_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=11.5, val_loss=1.28, avg_val_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 11.87it/s, loss=1.67, val_loss=1.28, avg_val_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 20.49it/s, loss=1.67, val_loss=0.768, avg_val\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.678, val_loss=0.768, avg_va\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 20.66it/s, loss=0.678, val_loss=0.63, avg_val\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 11.90it/s, loss=0.441, val_loss=0.63, avg_val\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 20.70it/s, loss=0.441, val_loss=0.351, avg_va\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.62it/s, loss=0.323, val_loss=0.351, avg_v\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 20.27it/s, loss=0.323, val_loss=0.295, avg_v\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 11.88it/s, loss=0.258, val_loss=0.295, avg_v\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 20.69it/s, loss=0.258, val_loss=0.222, avg_v\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.83it/s, loss=0.218, val_loss=0.222, avg_v\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.218, val_loss=0.161, avg_v\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.71it/s, loss=0.185, val_loss=0.161, avg_v\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 20.35it/s, loss=0.185, val_loss=0.15, avg_va\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.75it/s, loss=0.17, val_loss=0.15, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 20.45it/s, loss=0.17, val_loss=0.139, avg_va\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.15, val_loss=0.139, avg_va\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 20.34it/s, loss=0.15, val_loss=0.131, avg_va\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 11.47it/s, loss=0.138, val_loss=0.131, avg_v\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 20.01it/s, loss=0.138, val_loss=0.117, avg_v\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.13, val_loss=0.117, avg_va\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.13, val_loss=0.114, avg_va\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.122, val_loss=0.114, avg_v\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=0.122, val_loss=0.11, avg_va\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.117, val_loss=0.11, avg_va\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 20.67it/s, loss=0.117, val_loss=0.108, avg_v\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.114, val_loss=0.108, avg_v\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 20.47it/s, loss=0.114, val_loss=0.106, avg_v\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.111, val_loss=0.106, avg_v\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 20.61it/s, loss=0.111, val_loss=0.105, avg_v\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.108, val_loss=0.105, avg_v\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 20.63it/s, loss=0.108, val_loss=0.103, avg_v\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.77it/s, loss=0.107, val_loss=0.103, avg_v\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 20.48it/s, loss=0.107, val_loss=0.103, avg_v\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.105, val_loss=0.103, avg_v\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 20.64it/s, loss=0.105, val_loss=0.102, avg_v\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.104, val_loss=0.102, avg_v\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 20.39it/s, loss=0.104, val_loss=0.101, avg_v\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.103, val_loss=0.101, avg_v\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.103, val_loss=0.101, avg_v\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.79it/s, loss=0.102, val_loss=0.101, avg_v\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 20.50it/s, loss=0.102, val_loss=0.1, avg_val\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.75it/s, loss=0.102, val_loss=0.1, avg_val\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 20.26it/s, loss=0.102, val_loss=0.1, avg_val\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.80it/s, loss=0.101, val_loss=0.1, avg_val\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.101, val_loss=0.0996, avg_\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.101, val_loss=0.0996, avg_\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 20.55it/s, loss=0.101, val_loss=0.0993, avg_\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.84it/s, loss=0.1, val_loss=0.0993, avg_va\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.1, val_loss=0.099, avg_val\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.78it/s, loss=0.1, val_loss=0.099, avg_val\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 20.49it/s, loss=0.1, val_loss=0.0986, avg_va\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 11.39it/s, loss=0.0996, val_loss=0.0986, avg\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 19.89it/s, loss=0.0996, val_loss=0.0983, avg\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 11.80it/s, loss=0.0993, val_loss=0.0983, avg\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 20.56it/s, loss=0.0993, val_loss=0.0981, avg\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.86it/s, loss=0.0989, val_loss=0.0981, avg\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 20.65it/s, loss=0.0989, val_loss=0.0977, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.89it/s, loss=0.0986, val_loss=0.0977, avg\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 20.53it/s, loss=0.0986, val_loss=0.0975, avg\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 11.81it/s, loss=0.0983, val_loss=0.0975, avg\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 20.53it/s, loss=0.0983, val_loss=0.0972, avg\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.85it/s, loss=0.098, val_loss=0.0972, avg_\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 20.57it/s, loss=0.098, val_loss=0.0969, avg_\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.82it/s, loss=0.0977, val_loss=0.0969, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.58it/s, loss=0.0977, val_loss=0.0967, avg\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 20.39it/s, loss=0.0977, val_loss=0.0967, avg\n",
      "Sizes of clusters: 27, 43, 30, 41, 86, 62\n",
      "\n",
      "preds: [5 1 5 5 5 1 3 0 1 2 3 5 2 3 2 2 0 1 4 3 4 1 4 5 3 0 5 4 5 3 4 3 1 4 5 0 4\n",
      " 5 0 1 4 4 4 3 5 4 3 1 3 5 0 4 5 5 3 5 0 5 0 5 0 4 2 1 5 2 4 4 3 4 2 4 5 4\n",
      " 3 3 2 3 4 4 3 5 1 5 5 0 5 3 5 5 1 3 0 4 5 4 4 4 5 2 1 4 5 5 5 5 3 3 4 0 4\n",
      " 3 3 4 3 3 4 4 3 4 1 5 4 1 5 3 4 5 5 3 0 3 4 1 2 4 4 5 4 4 4 2 4 5 0 1 4 4\n",
      " 5 1 1 3 5 5 4 5 0 1 2 5 4 4 2 4 5 1 1 1 1 2 1 3 4 2 1 2 3 1 4 1 4 2 4 5 3\n",
      " 4 5 2 2 4 4 4 5 4 2 2 5 4 4 5 4 3 1 4 4 2 1 0 1 1 3 4 5 4 1 3 1 4 5 5 4 2\n",
      " 2 5 1 4 4 4 3 4 5 4 5 4 0 4 4 4 4 4 0 3 1 3 4 2 5 4 0 4 2 4 0 5 0 2 0 1 4\n",
      " 4 1 4 5 0 1 2 1 5 2 5 4 4 4 1 0 5 1 1 2 5 0 3 4 0 5 0 3 1 3]\n",
      "\n",
      "Consistency: 0.4674\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/IPTV_Data' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext txt \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 1.2 M \n",
      "1 | decoder | Sequential | 1.2 M \n",
      "---------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 5/10 [00:00<00:00, 29.03it/s, loss=0.347, val_loss=0.00054, avg\n",
      "Epoch 0: 100%|█| 10/10 [00:00<00:00, 47.75it/s, loss=0.347, val_loss=0.000209, a\n",
      "Epoch 1:  50%|▌| 5/10 [00:00<00:00, 41.01it/s, loss=0.209, val_loss=0.000209, av\n",
      "Epoch 1: 100%|█| 10/10 [00:00<00:00, 59.43it/s, loss=0.209, val_loss=0.000501, a\n",
      "Epoch 2:  50%|▌| 5/10 [00:00<00:00, 44.91it/s, loss=0.149, val_loss=0.000501, av\n",
      "Epoch 2: 100%|█| 10/10 [00:00<00:00, 65.29it/s, loss=0.149, val_loss=0.000516, a\n",
      "Epoch 3:  50%|▌| 5/10 [00:00<00:00, 44.04it/s, loss=0.116, val_loss=0.000516, av\n",
      "Epoch 3: 100%|█| 10/10 [00:00<00:00, 63.31it/s, loss=0.116, val_loss=0.000322, a\n",
      "Epoch 4:  50%|▌| 5/10 [00:00<00:00, 41.39it/s, loss=0.0319, val_loss=0.000322, a\n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 59.46it/s, loss=0.0319, val_loss=0.000212, \n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 58.15it/s, loss=0.0319, val_loss=0.000212, \n",
      "Sizes of clusters: 2, 2, 8, 32, 3, 2\n",
      "\n",
      "preds: [3 3 3 3 3 3 3 3 2 3 4 3 4 1 3 3 3 3 3 0 5 4 3 3 3 2 3 1 3 3 2 3 2 3 3 3 3\n",
      " 3 2 2 5 3 3 2 0 2 3 3 3]\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 1.2 M \n",
      "1 | decoder | Sequential | 1.2 M \n",
      "---------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 5/10 [00:00<00:00, 43.52it/s, loss=0.391, val_loss=0.000485, av\n",
      "Epoch 0: 100%|█| 10/10 [00:00<00:00, 63.39it/s, loss=0.391, val_loss=0.00021, av\n",
      "Epoch 1:  50%|▌| 5/10 [00:00<00:00, 45.41it/s, loss=0.26, val_loss=0.00021, avg_\n",
      "Epoch 1: 100%|█| 10/10 [00:00<00:00, 62.29it/s, loss=0.26, val_loss=0.000466, av\n",
      "Epoch 2:  50%|▌| 5/10 [00:00<00:00, 46.38it/s, loss=0.185, val_loss=0.000466, av\n",
      "Epoch 2: 100%|█| 10/10 [00:00<00:00, 66.00it/s, loss=0.185, val_loss=0.00057, av\n",
      "Epoch 3:  50%|▌| 5/10 [00:00<00:00, 43.47it/s, loss=0.144, val_loss=0.00057, avg\n",
      "Epoch 3: 100%|█| 10/10 [00:00<00:00, 66.25it/s, loss=0.144, val_loss=0.000378, a\n",
      "Epoch 4:  50%|▌| 5/10 [00:00<00:00, 44.19it/s, loss=0.0488, val_loss=0.000378, a\n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 69.64it/s, loss=0.0488, val_loss=0.000238, \n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 67.77it/s, loss=0.0488, val_loss=0.000238, \n",
      "Sizes of clusters: 1, 7, 36, 2, 2, 1\n",
      "\n",
      "preds: [2 2 2 5 2 2 1 2 2 1 3 2 1 4 2 2 2 2 0 2 1 3 2 1 2 2 2 4 2 2 2 2 2 2 1 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2]\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 1.2 M \n",
      "1 | decoder | Sequential | 1.2 M \n",
      "---------------------------------------\n",
      "2.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 5/10 [00:00<00:00, 32.58it/s, loss=0.427, val_loss=0.000501, av\n",
      "Epoch 0: 100%|█| 10/10 [00:00<00:00, 47.84it/s, loss=0.427, val_loss=0.000256, a\n",
      "Epoch 1:  50%|▌| 5/10 [00:00<00:00, 36.90it/s, loss=0.26, val_loss=0.000256, avg\n",
      "Epoch 1: 100%|█| 10/10 [00:00<00:00, 58.49it/s, loss=0.26, val_loss=0.00115, avg\n",
      "Epoch 2:  50%|▌| 5/10 [00:00<00:00, 31.22it/s, loss=0.187, val_loss=0.00115, avg\n",
      "Epoch 2: 100%|█| 10/10 [00:00<00:00, 42.07it/s, loss=0.187, val_loss=0.000823, a\n",
      "Epoch 3:  50%|▌| 5/10 [00:00<00:00, 27.42it/s, loss=0.147, val_loss=0.000823, av\n",
      "Epoch 3: 100%|█| 10/10 [00:00<00:00, 47.01it/s, loss=0.147, val_loss=0.000423, a\n",
      "Epoch 4:  50%|▌| 5/10 [00:00<00:00, 43.97it/s, loss=0.0435, val_loss=0.000423, a\n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 52.12it/s, loss=0.0435, val_loss=0.000261, \n",
      "Epoch 4: 100%|█| 10/10 [00:00<00:00, 51.19it/s, loss=0.0435, val_loss=0.000261, \n",
      "Sizes of clusters: 42, 2, 1, 2, 1, 1\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0 2 0 0 4 0 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 5 0 0 0 0 0 0]\n",
      "\n",
      "Consistency: 0.5892\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/booking_tmp_tmp' \\\n",
    "    --verbose \\\n",
    "    --epochs 5 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 10 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 6 \\\n",
    "    --type 'booking2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  1.79it/s, loss=0.384, val_loss=5.79e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:04<00:02,  2.23it/s, loss=0.384, val_loss=5.79e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  7.44it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:04<00:01,  2.55it/s, loss=0.384, val_loss=5.79e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  7.39it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  2.84it/s, loss=0.384, val_loss=5.79e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:00<00:00,  7.31it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  2.85it/s, loss=0.384, val_loss=8.25e-5, av\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:03<00:02,  2.19it/s, loss=0.248, val_loss=8.25e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:02,  2.06it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:04<00:01,  2.19it/s, loss=0.248, val_loss=8.25e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:01<00:01,  2.25it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:05<00:00,  2.26it/s, loss=0.248, val_loss=8.25e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:05<00:00,  2.50it/s, loss=0.248, val_loss=8.25e-5, av\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:05<00:00,  2.41it/s, loss=0.248, val_loss=0.000898, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.85it/s, loss=0.184, val_loss=0.000898, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.43it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.23it/s, loss=0.184, val_loss=0.000898, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.37it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.51it/s, loss=0.184, val_loss=0.000898, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.52it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.74it/s, loss=0.184, val_loss=0.000898, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.55it/s, loss=0.184, val_loss=0.000398, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.76it/s, loss=0.0515, val_loss=0.000398, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.83it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  3.16it/s, loss=0.0515, val_loss=0.000398, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.57it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.39it/s, loss=0.0515, val_loss=0.000398, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.97it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.44it/s, loss=0.0515, val_loss=0.000398, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.27it/s, loss=0.0515, val_loss=0.000149, \u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:02<00:02,  2.82it/s, loss=0.0195, val_loss=0.000149, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.76it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  3.23it/s, loss=0.0195, val_loss=0.000149, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.64it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.47it/s, loss=0.0195, val_loss=0.000149, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.54it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.71it/s, loss=0.0195, val_loss=0.000149, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.53it/s, loss=0.0195, val_loss=8.31e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.67it/s, loss=0.00951, val_loss=8.31e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.98it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  2.94it/s, loss=0.00951, val_loss=8.31e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.11it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:04<00:00,  2.98it/s, loss=0.00951, val_loss=8.31e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  3.24it/s, loss=0.00951, val_loss=8.31e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  3.10it/s, loss=0.00951, val_loss=5.77e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:02<00:02,  2.79it/s, loss=0.00492, val_loss=5.77e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.13it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  3.21it/s, loss=0.00492, val_loss=5.77e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.15it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.54it/s, loss=0.00492, val_loss=5.77e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.69it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.83it/s, loss=0.00492, val_loss=5.77e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.63it/s, loss=0.00492, val_loss=4.19e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.76it/s, loss=0.00258, val_loss=4.19e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.17it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.17it/s, loss=0.00258, val_loss=4.19e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.10it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.51it/s, loss=0.00258, val_loss=4.19e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.52it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.78it/s, loss=0.00258, val_loss=4.19e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.59it/s, loss=0.00258, val_loss=4.41e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:03<00:02,  2.52it/s, loss=0.00133, val_loss=4.41e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.15it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  2.88it/s, loss=0.00133, val_loss=4.41e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.06it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.18it/s, loss=0.00133, val_loss=4.41e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.81it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.45it/s, loss=0.00133, val_loss=4.41e-5, \u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.29it/s, loss=0.00133, val_loss=4.55e-5, \u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.81it/s, loss=0.000727, val_loss=4.55e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.03it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.22it/s, loss=0.000727, val_loss=4.55e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.83it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.54it/s, loss=0.000727, val_loss=4.55e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.97it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.79it/s, loss=0.000727, val_loss=4.55e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.57it/s, loss=0.000727, val_loss=5.99e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.52it/s, loss=0.000727, val_loss=5.99e-5,\u001b[A\n",
      "Sizes of clusters: 391, 294\n",
      "\n",
      "preds: [1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1\n",
      " 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0\n",
      " 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0\n",
      " 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 0 0]\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  2.16it/s, loss=0.326, val_loss=5.78e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.69it/s, loss=0.326, val_loss=5.78e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  8.75it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:00,  3.04it/s, loss=0.326, val_loss=5.78e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  7.69it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:03<00:00,  3.33it/s, loss=0.326, val_loss=5.78e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:00<00:00,  7.49it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  3.31it/s, loss=0.326, val_loss=5.55e-5, av\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:03<00:02,  2.57it/s, loss=0.204, val_loss=5.55e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.22it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  2.98it/s, loss=0.204, val_loss=5.55e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.11it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.30it/s, loss=0.204, val_loss=5.55e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.61it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.57it/s, loss=0.204, val_loss=5.55e-5, av\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.40it/s, loss=0.204, val_loss=0.000202, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.81it/s, loss=0.149, val_loss=0.000202, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.13it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.23it/s, loss=0.149, val_loss=0.000202, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.21it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.57it/s, loss=0.149, val_loss=0.000202, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.80it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.86it/s, loss=0.149, val_loss=0.000202, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.149, val_loss=0.000164, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.89it/s, loss=0.0286, val_loss=0.000164, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.01it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  3.31it/s, loss=0.0286, val_loss=0.000164, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.61it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.54it/s, loss=0.0286, val_loss=0.000164, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.56it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.80it/s, loss=0.0286, val_loss=0.000164, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.61it/s, loss=0.0286, val_loss=7.7e-5, av\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:02<00:02,  2.92it/s, loss=0.0126, val_loss=7.7e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.96it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:02<00:01,  3.33it/s, loss=0.0126, val_loss=7.7e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.71it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.47it/s, loss=0.0126, val_loss=7.7e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.26it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.60it/s, loss=0.0126, val_loss=7.7e-5, av\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.42it/s, loss=0.0126, val_loss=4.96e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.89it/s, loss=0.00577, val_loss=4.96e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.11it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.26it/s, loss=0.00577, val_loss=4.96e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.24it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.55it/s, loss=0.00577, val_loss=4.96e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.91it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.84it/s, loss=0.00577, val_loss=4.96e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.00577, val_loss=3.16e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:02<00:02,  2.94it/s, loss=0.00284, val_loss=3.16e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.01it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:02<00:01,  3.36it/s, loss=0.00284, val_loss=3.16e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.01it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.68it/s, loss=0.00284, val_loss=3.16e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.58it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.80it/s, loss=0.00284, val_loss=3.16e-5, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.57it/s, loss=0.00284, val_loss=2.79e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.80it/s, loss=0.00146, val_loss=2.79e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.39it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.14it/s, loss=0.00146, val_loss=2.79e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.21it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.44it/s, loss=0.00146, val_loss=2.79e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.46it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.71it/s, loss=0.00146, val_loss=2.79e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.52it/s, loss=0.00146, val_loss=2.63e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:02<00:02,  2.90it/s, loss=0.000807, val_loss=2.63e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.37it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.29it/s, loss=0.000807, val_loss=2.63e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.74it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.62it/s, loss=0.000807, val_loss=2.63e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.56it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.91it/s, loss=0.000807, val_loss=2.63e-5,\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.71it/s, loss=0.000807, val_loss=2.75e-5,\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.78it/s, loss=0.000478, val_loss=2.75e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.47it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.21it/s, loss=0.000478, val_loss=2.75e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.35it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.54it/s, loss=0.000478, val_loss=2.75e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.39it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.73it/s, loss=0.000478, val_loss=2.75e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.55it/s, loss=0.000478, val_loss=3.11e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.50it/s, loss=0.000478, val_loss=3.11e-5,\u001b[A\n",
      "Sizes of clusters: 441, 244\n",
      "\n",
      "preds: [0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
      " 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0\n",
      " 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0\n",
      " 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0]\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:02<00:02,  2.46it/s, loss=0.264, val_loss=5.67e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:02<00:01,  3.03it/s, loss=0.264, val_loss=5.67e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  7.73it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:00,  3.35it/s, loss=0.264, val_loss=5.67e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  6.92it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:03<00:00,  3.59it/s, loss=0.264, val_loss=5.67e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:00<00:00,  6.38it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:03<00:00,  3.51it/s, loss=0.264, val_loss=0.000103, a\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:02<00:02,  2.74it/s, loss=0.163, val_loss=0.000103, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.05it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  3.15it/s, loss=0.163, val_loss=0.000103, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.07it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.43it/s, loss=0.163, val_loss=0.000103, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.96it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.68it/s, loss=0.163, val_loss=0.000103, a\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.50it/s, loss=0.163, val_loss=0.000399, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.88it/s, loss=0.121, val_loss=0.000399, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.34it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.30it/s, loss=0.121, val_loss=0.000399, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.16it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.62it/s, loss=0.121, val_loss=0.000399, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.48it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.88it/s, loss=0.121, val_loss=0.000399, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.121, val_loss=0.000263, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:03<00:02,  2.59it/s, loss=0.0301, val_loss=0.000263, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.97it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  2.95it/s, loss=0.0301, val_loss=0.000263, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.12it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.25it/s, loss=0.0301, val_loss=0.000263, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.68it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.46it/s, loss=0.0301, val_loss=0.000263, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.30it/s, loss=0.0301, val_loss=0.000118, \u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:02<00:02,  2.83it/s, loss=0.0152, val_loss=0.000118, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.73it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  3.26it/s, loss=0.0152, val_loss=0.000118, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.32it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.58it/s, loss=0.0152, val_loss=0.000118, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.61it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.86it/s, loss=0.0152, val_loss=0.000118, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.0152, val_loss=7.94e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.69it/s, loss=0.00915, val_loss=7.94e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.65it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.09it/s, loss=0.00915, val_loss=7.94e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.61it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.40it/s, loss=0.00915, val_loss=7.94e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.28it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.68it/s, loss=0.00915, val_loss=7.94e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.50it/s, loss=0.00915, val_loss=6.54e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:03<00:02,  2.18it/s, loss=0.00593, val_loss=6.54e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.85it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  2.55it/s, loss=0.00593, val_loss=6.54e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.83it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:04<00:00,  2.83it/s, loss=0.00593, val_loss=6.54e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.12it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.10it/s, loss=0.00593, val_loss=6.54e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  2.97it/s, loss=0.00593, val_loss=6.51e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.85it/s, loss=0.00426, val_loss=6.51e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.13it/s, loss=0.00426, val_loss=6.51e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.43it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.45it/s, loss=0.00426, val_loss=6.51e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.13it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.72it/s, loss=0.00426, val_loss=6.51e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.54it/s, loss=0.00426, val_loss=8.65e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:03<00:02,  2.19it/s, loss=0.0033, val_loss=8.65e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.68it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:04<00:01,  2.47it/s, loss=0.0033, val_loss=8.65e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.05it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:04<00:00,  2.71it/s, loss=0.0033, val_loss=8.65e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.90it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  2.96it/s, loss=0.0033, val_loss=8.65e-5, a\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  2.85it/s, loss=0.0033, val_loss=0.000112, \u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.83it/s, loss=0.00302, val_loss=0.000112, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.42it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.24it/s, loss=0.00302, val_loss=0.000112,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.23it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.51it/s, loss=0.00302, val_loss=0.000112,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.93it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.77it/s, loss=0.00302, val_loss=0.000112,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.59it/s, loss=0.00302, val_loss=0.000201,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.54it/s, loss=0.00302, val_loss=0.000201,\u001b[A\n",
      "Sizes of clusters: 445, 240\n",
      "\n",
      "preds: [0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0\n",
      " 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0\n",
      " 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  2.06it/s, loss=0.207, val_loss=5.74e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.54it/s, loss=0.207, val_loss=5.74e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  6.35it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:01,  2.76it/s, loss=0.207, val_loss=5.74e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  5.24it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  2.93it/s, loss=0.207, val_loss=5.74e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:01<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  2.86it/s, loss=0.207, val_loss=0.000222, a\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:02<00:02,  2.94it/s, loss=0.136, val_loss=0.000222, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.46it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:02<00:01,  3.37it/s, loss=0.136, val_loss=0.000222, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.26it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.68it/s, loss=0.136, val_loss=0.000222, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.93it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.92it/s, loss=0.136, val_loss=0.000222, a\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.55it/s, loss=0.136, val_loss=0.000446, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.85it/s, loss=0.103, val_loss=0.000446, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  3.88it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.12it/s, loss=0.103, val_loss=0.000446, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.05it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.42it/s, loss=0.103, val_loss=0.000446, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.54it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.67it/s, loss=0.103, val_loss=0.000446, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.50it/s, loss=0.103, val_loss=0.000172, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.79it/s, loss=0.0322, val_loss=0.000172, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.20it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  3.17it/s, loss=0.0322, val_loss=0.000172, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.56it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.50it/s, loss=0.0322, val_loss=0.000172, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.14it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.76it/s, loss=0.0322, val_loss=0.000172, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.57it/s, loss=0.0322, val_loss=8.45e-5, a\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.42it/s, loss=0.0147, val_loss=8.45e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.38it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  2.74it/s, loss=0.0147, val_loss=8.45e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.75it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.01it/s, loss=0.0147, val_loss=8.45e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.28it/s, loss=0.0147, val_loss=8.45e-5, a\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.14it/s, loss=0.0147, val_loss=5.04e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:03<00:02,  2.62it/s, loss=0.00721, val_loss=5.04e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.48it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.00it/s, loss=0.00721, val_loss=5.04e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.35it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.33it/s, loss=0.00721, val_loss=5.04e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.32it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.60it/s, loss=0.00721, val_loss=5.04e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  3.43it/s, loss=0.00721, val_loss=4.39e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:03<00:02,  2.64it/s, loss=0.004, val_loss=4.39e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:02,  2.93it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  2.80it/s, loss=0.004, val_loss=4.39e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.94it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.08it/s, loss=0.004, val_loss=4.39e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.65it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.32it/s, loss=0.004, val_loss=4.39e-5, av\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.17it/s, loss=0.004, val_loss=4.83e-5, av\u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.84it/s, loss=0.00273, val_loss=4.83e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.35it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.24it/s, loss=0.00273, val_loss=4.83e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.68it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.56it/s, loss=0.00273, val_loss=4.83e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.50it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.77it/s, loss=0.00273, val_loss=4.83e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.58it/s, loss=0.00273, val_loss=7.32e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:02<00:02,  2.84it/s, loss=0.00238, val_loss=7.32e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.90it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.21it/s, loss=0.00238, val_loss=7.32e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.16it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.35it/s, loss=0.00238, val_loss=7.32e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.40it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.57it/s, loss=0.00238, val_loss=7.32e-5, \u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.40it/s, loss=0.00238, val_loss=0.000129,\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:03<00:02,  2.30it/s, loss=0.00233, val_loss=0.000129, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.69it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  2.68it/s, loss=0.00233, val_loss=0.000129,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.50it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:04<00:00,  2.96it/s, loss=0.00233, val_loss=0.000129,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.83it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.23it/s, loss=0.00233, val_loss=0.000129,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.09it/s, loss=0.00233, val_loss=0.000196,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.06it/s, loss=0.00233, val_loss=0.000196,\u001b[A\n",
      "Sizes of clusters: 274, 411\n",
      "\n",
      "preds: [0 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1\n",
      " 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
      " 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
      " 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 1 1\n",
      " 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 1\n",
      " 1 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1\n",
      " 0 0 1 0 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  2.32it/s, loss=0.391, val_loss=5.75e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.72it/s, loss=0.391, val_loss=5.75e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:01,  3.41it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:01,  2.93it/s, loss=0.391, val_loss=5.75e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  3.07it/s, loss=0.391, val_loss=5.75e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:01<00:00,  4.36it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  2.94it/s, loss=0.391, val_loss=0.000107, a\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:04<00:03,  1.99it/s, loss=0.224, val_loss=0.000107, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.86it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:04<00:01,  2.33it/s, loss=0.224, val_loss=0.000107, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.55it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:04<00:00,  2.62it/s, loss=0.224, val_loss=0.000107, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.36it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  2.88it/s, loss=0.224, val_loss=0.000107, a\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:05<00:00,  2.69it/s, loss=0.224, val_loss=0.00106, av\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.81it/s, loss=0.164, val_loss=0.00106, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.35it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.23it/s, loss=0.164, val_loss=0.00106, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.88it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.51it/s, loss=0.164, val_loss=0.00106, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.28it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.80it/s, loss=0.164, val_loss=0.00106, av\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.61it/s, loss=0.164, val_loss=0.000426, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:03<00:02,  2.56it/s, loss=0.0293, val_loss=0.000426, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.86it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  2.96it/s, loss=0.0293, val_loss=0.000426, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.79it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.21it/s, loss=0.0293, val_loss=0.000426, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.12it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.24it/s, loss=0.0293, val_loss=0.000426, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.10it/s, loss=0.0293, val_loss=0.000141, \u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.60it/s, loss=0.013, val_loss=0.000141, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.64it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  2.96it/s, loss=0.013, val_loss=0.000141, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.04it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.27it/s, loss=0.013, val_loss=0.000141, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.90it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.53it/s, loss=0.013, val_loss=0.000141, a\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.35it/s, loss=0.013, val_loss=9.06e-5, av\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:03<00:02,  2.06it/s, loss=0.0065, val_loss=9.06e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  3.34it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:04<00:01,  2.24it/s, loss=0.0065, val_loss=9.06e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.04it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:04<00:00,  2.51it/s, loss=0.0065, val_loss=9.06e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.74it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:05<00:00,  2.72it/s, loss=0.0065, val_loss=9.06e-5, a\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:05<00:00,  2.61it/s, loss=0.0065, val_loss=5.24e-5, a\u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:03<00:02,  2.61it/s, loss=0.00382, val_loss=5.24e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.43it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  3.01it/s, loss=0.00382, val_loss=5.24e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.75it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.34it/s, loss=0.00382, val_loss=5.24e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.21it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.60it/s, loss=0.00382, val_loss=5.24e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.39it/s, loss=0.00382, val_loss=6.49e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:03<00:02,  2.57it/s, loss=0.00273, val_loss=6.49e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.86it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  2.84it/s, loss=0.00273, val_loss=6.49e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.21it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.12it/s, loss=0.00273, val_loss=6.49e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.08it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.29it/s, loss=0.00273, val_loss=6.49e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.12it/s, loss=0.00273, val_loss=0.000105,\u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:02<00:02,  2.81it/s, loss=0.00282, val_loss=0.000105, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.30it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.23it/s, loss=0.00282, val_loss=0.000105,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.15it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.56it/s, loss=0.00282, val_loss=0.000105,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.76it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.85it/s, loss=0.00282, val_loss=0.000105,\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.66it/s, loss=0.00282, val_loss=0.000241,\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:03<00:02,  2.47it/s, loss=0.00364, val_loss=0.000241, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  2.85it/s, loss=0.00364, val_loss=0.000241,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.55it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.16it/s, loss=0.00364, val_loss=0.000241,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.29it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.40it/s, loss=0.00364, val_loss=0.000241,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.16it/s, loss=0.00364, val_loss=0.00056, \u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.12it/s, loss=0.00364, val_loss=0.00056, \u001b[A\n",
      "Sizes of clusters: 447, 238\n",
      "\n",
      "preds: [1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1\n",
      " 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0\n",
      " 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0\n",
      " 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      "Consistency: 0.5276\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/booking_tmp_5000' \\\n",
    "    --verbose \\\n",
    "    --epochs 5 \\\n",
    "    --nruns 3 \\\n",
    "    --ext csv \\\n",
    "    --batch 10 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 6 \\\n",
    "    --type 'booking2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:02<00:02,  2.45it/s, loss=0.223, val_loss=5.58e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.87it/s, loss=0.223, val_loss=5.58e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:01,  3.59it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:01,  3.00it/s, loss=0.223, val_loss=5.58e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:01<00:00,  3.71it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  3.17it/s, loss=0.223, val_loss=5.58e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:01<00:00,  4.87it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  3.16it/s, loss=0.223, val_loss=8.02e-5, av\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:03<00:02,  2.21it/s, loss=0.135, val_loss=8.02e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.49it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  2.59it/s, loss=0.135, val_loss=8.02e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.31it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:04<00:00,  2.87it/s, loss=0.135, val_loss=8.02e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.60it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.08it/s, loss=0.135, val_loss=8.02e-5, av\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  2.95it/s, loss=0.135, val_loss=0.000381, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.96it/s, loss=0.0998, val_loss=0.000381, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.29it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  2.95it/s, loss=0.0998, val_loss=0.000381, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.64it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.13it/s, loss=0.0998, val_loss=0.000381, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.48it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.33it/s, loss=0.0998, val_loss=0.000381, \u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.17it/s, loss=0.0998, val_loss=0.000163, \u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.95it/s, loss=0.0247, val_loss=0.000163, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.48it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:02<00:01,  3.37it/s, loss=0.0247, val_loss=0.000163, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.71it/s, loss=0.0247, val_loss=0.000163, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.54it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.99it/s, loss=0.0247, val_loss=0.000163, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.78it/s, loss=0.0247, val_loss=9.06e-5, a\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.49it/s, loss=0.0124, val_loss=9.06e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.74it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  2.71it/s, loss=0.0124, val_loss=9.06e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.92it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:04<00:00,  2.90it/s, loss=0.0124, val_loss=9.06e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  5.13it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.17it/s, loss=0.0124, val_loss=9.06e-5, a\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.04it/s, loss=0.0124, val_loss=5.59e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.84it/s, loss=0.00703, val_loss=5.59e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.01it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.25it/s, loss=0.00703, val_loss=5.59e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.92it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.58it/s, loss=0.00703, val_loss=5.59e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.49it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.86it/s, loss=0.00703, val_loss=5.59e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.67it/s, loss=0.00703, val_loss=5.35e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:03<00:02,  2.18it/s, loss=0.00449, val_loss=5.35e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.24it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:04<00:01,  2.47it/s, loss=0.00449, val_loss=5.35e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.50it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:04<00:00,  2.75it/s, loss=0.00449, val_loss=5.35e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.54it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.02it/s, loss=0.00449, val_loss=5.35e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  2.86it/s, loss=0.00449, val_loss=5.15e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.74it/s, loss=0.00309, val_loss=5.15e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.48it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.05it/s, loss=0.00309, val_loss=5.15e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.89it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.16it/s, loss=0.00309, val_loss=5.15e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.23it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.18it/s, loss=0.00309, val_loss=5.15e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.04it/s, loss=0.00309, val_loss=6.1e-5, a\u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:02<00:02,  2.69it/s, loss=0.00233, val_loss=6.1e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.44it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.11it/s, loss=0.00233, val_loss=6.1e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.10it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.43it/s, loss=0.00233, val_loss=6.1e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.75it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.71it/s, loss=0.00233, val_loss=6.1e-5, a\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.53it/s, loss=0.00233, val_loss=8.15e-5, \u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.83it/s, loss=0.00196, val_loss=8.15e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.49it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.15it/s, loss=0.00196, val_loss=8.15e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.06it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.40it/s, loss=0.00196, val_loss=8.15e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.03it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.30it/s, loss=0.00196, val_loss=8.15e-5, \u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.09it/s, loss=0.00196, val_loss=0.000157,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.06it/s, loss=0.00196, val_loss=0.000157,\u001b[A\n",
      "Sizes of clusters: 1, 261, 423\n",
      "\n",
      "preds: [2 2 1 2 1 2 1 1 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1 1 2\n",
      " 2 2 2 2 1 1 1 1 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 2 1 1 1 1 2 1 2 2 2 1 2 1 2\n",
      " 2 2 2 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 1 2 2 1 2 2 1\n",
      " 1 2 2 2 2 2 1 2 2 1 2 2 1 2 1 2 1 1 2 1 1 1 2 2 1 1 2 1 1 1 2 2 1 1 2 2 2\n",
      " 1 1 2 2 1 2 2 1 1 1 2 2 2 2 2 2 1 1 1 2 2 2 2 1 1 1 1 2 2 1 2 2 2 1 1 2 2\n",
      " 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 1 1 2 2 1\n",
      " 1 2 1 2 2 1 1 2 2 1 2 1 1 2 1 2 2 2 1 1 1 2 1 2 1 2 2 2 2 1 2 1 2 2 1 2 1\n",
      " 2 2 2 1 2 2 2 1 2 2 1 2 2 1 1 2 2 1 1 2 2 2 1 2 1 1 2 2 1 2 1 1 2 1 2 2 1\n",
      " 2 2 2 2 2 1 1 2 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2\n",
      " 2 2 2 1 2 1 2 2 2 1 2 2 2 1 2 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 1 2 1 2 1 2 1 2 2 2 2 2 1 1 1 2 2 1 1 2 2 1 2 2 2 1 1 2 2 2 1 2 2 1\n",
      " 2 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 1 2 2 2 2 2 2 1 2 1 1 2 1 1 1 1 2\n",
      " 2 2 2 1 2 1 2 1 2 2 1 2 1 2 2 2 2 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 1 2 1 2 1\n",
      " 2 2 2 2 2 2 2 1 2 1 2 1 1 1 2 1 2 2 2 2 1 1 1 1 2 2 1 1 2 2 2 2 2 2 1 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 1 1 1 2 2 2 1 2 2 1 1 2 2 1 2 2 1 2 2 2\n",
      " 2 2 2 2 1 1 2 1 1 2 1 1 1 1 1 2 2 2 1 1 2 1 2 2 1 2 1 2 1 2 1 2 1 1 1 2 2\n",
      " 1 2 1 2 2 2 1 2 2 2 2 1 2 0 1 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 1 1 2 2 1 2\n",
      " 1 2 1 2 1 2 2 2 2 1 2 2 2 2 2 1 2 1 2]\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  1.97it/s, loss=0.286, val_loss=5.64e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:02,  2.43it/s, loss=0.286, val_loss=5.64e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  6.36it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:04<00:01,  2.75it/s, loss=0.286, val_loss=5.64e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  6.67it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  3.03it/s, loss=0.286, val_loss=5.64e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:00<00:00,  7.04it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  3.03it/s, loss=0.286, val_loss=7.95e-5, av\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:02<00:02,  2.92it/s, loss=0.165, val_loss=7.95e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.48it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:02<00:01,  3.33it/s, loss=0.165, val_loss=7.95e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.35it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.64it/s, loss=0.165, val_loss=7.95e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.40it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.92it/s, loss=0.165, val_loss=7.95e-5, av\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.72it/s, loss=0.165, val_loss=0.000388, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:02<00:02,  2.79it/s, loss=0.118, val_loss=0.000388, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.31it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  3.21it/s, loss=0.118, val_loss=0.000388, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.29it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:03<00:00,  3.55it/s, loss=0.118, val_loss=0.000388, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.85it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.84it/s, loss=0.118, val_loss=0.000388, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.118, val_loss=0.000195, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.80it/s, loss=0.0181, val_loss=0.000195, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.83it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  3.22it/s, loss=0.0181, val_loss=0.000195, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.82it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.52it/s, loss=0.0181, val_loss=0.000195, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.10it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.78it/s, loss=0.0181, val_loss=0.000195, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:03<00:00,  3.59it/s, loss=0.0181, val_loss=6.03e-5, a\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.66it/s, loss=0.00661, val_loss=6.03e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  3.78it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  2.92it/s, loss=0.00661, val_loss=6.03e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.98it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.25it/s, loss=0.00661, val_loss=6.03e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.70it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.49it/s, loss=0.00661, val_loss=6.03e-5, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.33it/s, loss=0.00661, val_loss=3.96e-5, \u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.79it/s, loss=0.00333, val_loss=3.96e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.01it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.15it/s, loss=0.00333, val_loss=3.96e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.47it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.43it/s, loss=0.00333, val_loss=3.96e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.59it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.70it/s, loss=0.00333, val_loss=3.96e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.52it/s, loss=0.00333, val_loss=3.52e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:02<00:02,  2.97it/s, loss=0.00178, val_loss=3.52e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.58it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:02<00:01,  3.35it/s, loss=0.00178, val_loss=3.52e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.99it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.69it/s, loss=0.00178, val_loss=3.52e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.33it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.90it/s, loss=0.00178, val_loss=3.52e-5, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.70it/s, loss=0.00178, val_loss=2.54e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.85it/s, loss=0.000992, val_loss=2.54e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.73it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.25it/s, loss=0.000992, val_loss=2.54e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.57it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.50it/s, loss=0.000992, val_loss=2.54e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.80it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.67it/s, loss=0.000992, val_loss=2.54e-5,\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.48it/s, loss=0.000992, val_loss=2.59e-5,\u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:02<00:02,  2.76it/s, loss=0.000563, val_loss=2.59e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.96it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.07it/s, loss=0.000563, val_loss=2.59e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.16it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.38it/s, loss=0.000563, val_loss=2.59e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.49it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.63it/s, loss=0.000563, val_loss=2.59e-5,\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.45it/s, loss=0.000563, val_loss=2.44e-5,\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.86it/s, loss=0.000338, val_loss=2.44e-5, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.29it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.28it/s, loss=0.000338, val_loss=2.44e-5,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.01it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.61it/s, loss=0.000338, val_loss=2.44e-5,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.75it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.89it/s, loss=0.000338, val_loss=2.44e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.70it/s, loss=0.000338, val_loss=2.72e-5,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.65it/s, loss=0.000338, val_loss=2.72e-5,\u001b[A\n",
      "Sizes of clusters: 201, 353, 131\n",
      "\n",
      "preds: [2 1 2 1 0 1 0 1 1 2 0 1 0 1 0 0 1 2 1 1 1 0 0 2 1 1 2 1 1 1 1 1 2 2 0 1 1\n",
      " 1 1 0 1 2 1 1 1 0 0 2 1 1 1 2 0 1 1 2 2 0 1 0 2 0 1 2 1 0 2 2 0 1 1 2 1 0\n",
      " 0 1 1 0 1 2 1 1 1 1 1 1 1 1 2 1 1 0 1 0 2 0 2 1 0 2 2 1 1 2 1 2 0 0 1 1 1\n",
      " 0 1 0 1 0 0 0 1 1 1 1 2 0 2 2 0 1 0 0 1 1 2 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1\n",
      " 2 0 1 1 1 1 1 2 1 1 0 0 2 1 2 1 0 2 2 1 2 1 2 1 0 1 0 2 0 0 1 2 1 1 2 0 1\n",
      " 1 1 0 0 0 0 1 0 2 2 1 1 1 0 2 2 2 1 1 1 1 0 2 1 1 0 1 1 2 2 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 0 0 0 1 1 2 1 2 1 1 2 1 1 0 1 0 0 2 1 1 1 2 0 1 1 1 1 1 1 0 2\n",
      " 1 1 0 0 1 0 1 1 1 1 2 0 1 1 1 1 1 1 1 1 1 2 2 2 1 0 1 0 1 1 0 1 0 1 1 1 2\n",
      " 1 1 1 0 1 2 0 1 1 1 2 1 1 1 0 1 2 0 0 0 0 0 0 1 1 1 0 0 2 1 2 1 1 1 2 0 0\n",
      " 2 1 0 0 1 1 0 1 1 2 1 2 2 0 1 2 1 1 2 1 1 0 1 0 0 1 1 2 1 0 1 2 2 2 0 1 0\n",
      " 2 0 2 2 2 0 1 0 2 0 1 1 0 0 0 1 1 1 0 2 1 2 1 0 1 0 0 1 1 1 0 1 1 1 1 2 1\n",
      " 0 1 0 1 1 1 1 0 0 1 1 1 2 0 1 2 1 2 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 1 1\n",
      " 0 0 1 1 1 2 2 1 1 1 0 1 1 1 0 0 1 2 1 0 1 0 1 2 0 0 1 1 0 2 0 1 2 1 2 0 0\n",
      " 1 0 1 0 1 2 1 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 2 1 1 0 0 1 1 1 2 1 1 0 0 1 1\n",
      " 1 0 1 1 0 2 1 1 1 0 1 0 2 0 1 1 1 1 2 0 1 1 2 1 0 1 2 1 1 0 0 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 0 1 0 1 1 1 1 0 2 0 2 1 2 1 2 1 1 0 1\n",
      " 1 1 1 1 2 0 2 1 1 1 2 1 0 2 0 1 2 1 1 2 2 0 1 0 2 2 1 0 0 1 1 1 2 1 0 0 2\n",
      " 1 1 2 2 1 0 1 1 0 1 0 0 2 2 1 0 2 1 1 0 1 0 1 0 0 0 2 0 2 0 0 1 0 0 2 1 1\n",
      " 1 0 0 1 0 0 0 2 1 1 0 1 2 1 1 2 1 1 1]\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:03<00:03,  2.29it/s, loss=0.278, val_loss=5.69e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.84it/s, loss=0.278, val_loss=5.69e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  5.67it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:01,  2.97it/s, loss=0.278, val_loss=5.69e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  5.64it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:03<00:00,  3.25it/s, loss=0.278, val_loss=5.69e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:01<00:00,  5.79it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  3.20it/s, loss=0.278, val_loss=0.000111, a\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:03<00:02,  2.49it/s, loss=0.172, val_loss=0.000111, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.96it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  2.85it/s, loss=0.172, val_loss=0.000111, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.98it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.14it/s, loss=0.172, val_loss=0.000111, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.01it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.42it/s, loss=0.172, val_loss=0.000111, a\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.25it/s, loss=0.172, val_loss=0.00054, av\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:03<00:02,  2.37it/s, loss=0.127, val_loss=0.00054, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.27it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  2.74it/s, loss=0.127, val_loss=0.00054, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.01it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:04<00:00,  2.89it/s, loss=0.127, val_loss=0.00054, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.15it/s, loss=0.127, val_loss=0.00054, av\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.02it/s, loss=0.127, val_loss=0.000223, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:03<00:02,  2.60it/s, loss=0.0316, val_loss=0.000223, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  3.99it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  2.87it/s, loss=0.0316, val_loss=0.000223, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.07it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:03<00:00,  3.19it/s, loss=0.0316, val_loss=0.000223, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.05it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.46it/s, loss=0.0316, val_loss=0.000223, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  3.30it/s, loss=0.0316, val_loss=0.000103, \u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.12it/s, loss=0.0137, val_loss=0.000103, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.47it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:04<00:01,  2.47it/s, loss=0.0137, val_loss=0.000103, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.63it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:04<00:00,  2.78it/s, loss=0.0137, val_loss=0.000103, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.10it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.03it/s, loss=0.0137, val_loss=0.000103, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  2.90it/s, loss=0.0137, val_loss=7.93e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:03<00:02,  2.66it/s, loss=0.00743, val_loss=7.93e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.45it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  2.87it/s, loss=0.00743, val_loss=7.93e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.85it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:04<00:00,  2.94it/s, loss=0.00743, val_loss=7.93e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  3.20it/s, loss=0.00743, val_loss=7.93e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  2.96it/s, loss=0.00743, val_loss=7.77e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:02<00:02,  2.78it/s, loss=0.00571, val_loss=7.77e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.64it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  3.21it/s, loss=0.00571, val_loss=7.77e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.37it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.54it/s, loss=0.00571, val_loss=7.77e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.73it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.81it/s, loss=0.00571, val_loss=7.77e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.62it/s, loss=0.00571, val_loss=0.000127,\u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:03<00:02,  2.64it/s, loss=0.00614, val_loss=0.000127, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.81it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  2.88it/s, loss=0.00614, val_loss=0.000127,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.12it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.19it/s, loss=0.00614, val_loss=0.000127,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.79it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.45it/s, loss=0.00614, val_loss=0.000127,\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.29it/s, loss=0.00614, val_loss=0.000222,\u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:03<00:02,  2.57it/s, loss=0.00726, val_loss=0.000222, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.53it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  2.99it/s, loss=0.00726, val_loss=0.000222,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  8.16it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.31it/s, loss=0.00726, val_loss=0.000222,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.68it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.59it/s, loss=0.00726, val_loss=0.000222,\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.42it/s, loss=0.00726, val_loss=0.000352,\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:03<00:02,  2.41it/s, loss=0.00772, val_loss=0.000352, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.99it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  2.65it/s, loss=0.00772, val_loss=0.000352,\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.19it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:04<00:00,  2.89it/s, loss=0.00772, val_loss=0.000352,\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  5.26it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.11it/s, loss=0.00772, val_loss=0.000352,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  2.97it/s, loss=0.00772, val_loss=0.000483,\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  2.94it/s, loss=0.00772, val_loss=0.000483,\u001b[A\n",
      "Sizes of clusters: 321, 196, 168\n",
      "\n",
      "preds: [0 0 0 2 2 1 0 0 2 0 0 2 2 1 0 2 0 2 2 0 2 2 0 1 1 0 2 1 2 0 2 1 2 2 1 2 0\n",
      " 2 2 0 2 1 2 0 0 0 2 0 0 1 1 0 0 1 0 2 2 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1\n",
      " 0 0 0 0 2 0 2 2 1 2 1 0 2 2 1 2 1 2 2 1 1 2 1 0 1 2 0 0 0 1 0 1 2 0 2 2 0\n",
      " 1 1 1 0 1 2 0 2 1 2 0 0 2 1 0 1 0 1 0 2 1 2 1 0 1 2 1 2 1 2 1 2 1 2 0 1 1\n",
      " 1 2 1 0 0 1 0 0 2 2 2 2 1 0 0 0 2 2 2 1 2 2 2 0 1 2 0 0 1 2 1 1 0 2 1 1 0\n",
      " 0 0 0 2 2 1 0 0 0 0 0 0 0 1 1 0 1 2 0 2 1 1 1 0 2 1 2 0 1 2 0 0 1 2 1 0 1\n",
      " 1 1 0 0 1 0 1 1 0 1 1 2 0 1 1 0 0 0 2 0 1 0 1 0 2 1 0 0 0 0 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 1 0 2 1 0 1 1 0 2 0 0 0 0 2 2 2 1 1 0 0 0 0 1 0 2 2 0 0 0 2\n",
      " 1 0 0 1 1 1 2 0 1 0 2 2 0 1 1 0 0 0 0 2 2 0 1 2 2 0 0 1 0 1 1 1 1 0 1 0 2\n",
      " 1 0 0 2 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 1 2 1 0 0 0 0 0 0 1 1 0 1 0 2 2 2 0\n",
      " 2 0 0 2 0 0 0 2 0 0 2 2 1 0 0 0 0 0 0 2 1 0 1 0 0 1 1 1 1 1 0 0 2 2 0 1 0\n",
      " 0 0 0 2 0 0 2 2 1 0 0 0 2 0 0 2 2 0 0 1 0 0 2 0 2 0 0 0 2 2 0 2 0 2 0 1 0\n",
      " 2 0 1 0 2 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 2 2 0 1 2 0 2 0 1 0 2 2 2\n",
      " 0 0 1 0 1 2 1 0 0 0 2 0 0 1 1 0 0 1 2 2 0 0 0 1 0 0 1 1 2 1 0 0 0 2 0 1 0\n",
      " 0 2 1 0 0 1 2 0 1 0 0 2 0 1 0 0 0 0 2 1 2 1 0 0 2 2 1 0 1 0 2 2 2 0 2 1 0\n",
      " 0 2 0 0 0 2 1 1 1 1 2 1 1 0 1 1 0 0 0 1 0 2 0 0 0 2 0 0 0 1 0 0 2 0 0 0 0\n",
      " 1 2 1 1 2 2 2 0 0 2 1 0 0 1 2 1 0 2 0 1 1 0 1 0 1 1 1 0 0 0 2 0 0 0 1 2 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 2 0 0 0 0 1 2 2 0 2 0 0 2 0 0 2 2 1 1 1 0 0 2 2 0 1\n",
      " 2 0 2 1 1 2 0 0 1 0 1 1 0 0 0 2 0 1 1]\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:02<00:02,  2.34it/s, loss=0.232, val_loss=5.63e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.84it/s, loss=0.232, val_loss=5.63e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:01,  4.65it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:00,  3.01it/s, loss=0.232, val_loss=5.63e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  4.17it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:04<00:00,  3.14it/s, loss=0.232, val_loss=5.63e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:01<00:00,  4.78it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  2.97it/s, loss=0.232, val_loss=0.00015, av\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:02<00:02,  2.67it/s, loss=0.142, val_loss=0.00015, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.30it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  3.02it/s, loss=0.142, val_loss=0.00015, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.33it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.26it/s, loss=0.142, val_loss=0.00015, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.35it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.45it/s, loss=0.142, val_loss=0.00015, av\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.29it/s, loss=0.142, val_loss=0.000315, a\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:03<00:02,  2.20it/s, loss=0.103, val_loss=0.000315, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.12it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  2.57it/s, loss=0.103, val_loss=0.000315, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.96it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:04<00:00,  2.88it/s, loss=0.103, val_loss=0.000315, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.45it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.14it/s, loss=0.103, val_loss=0.000315, a\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.01it/s, loss=0.103, val_loss=0.000174, a\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:03<00:02,  2.56it/s, loss=0.0214, val_loss=0.000174, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.15it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  2.80it/s, loss=0.0214, val_loss=0.000174, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:04<00:00,  2.84it/s, loss=0.0214, val_loss=0.000174, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  3.44it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  2.91it/s, loss=0.0214, val_loss=0.000174, \u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:05<00:00,  2.75it/s, loss=0.0214, val_loss=7.48e-5, a\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:03<00:02,  2.51it/s, loss=0.00812, val_loss=7.48e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  2.81it/s, loss=0.00812, val_loss=7.48e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.48it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.13it/s, loss=0.00812, val_loss=7.48e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.15it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.36it/s, loss=0.00812, val_loss=7.48e-5, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:04<00:00,  3.21it/s, loss=0.00812, val_loss=5.29e-5, \u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:02<00:02,  2.76it/s, loss=0.00405, val_loss=5.29e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.34it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  3.17it/s, loss=0.00405, val_loss=5.29e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.38it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:03<00:00,  3.41it/s, loss=0.00405, val_loss=5.29e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.68it/s, loss=0.00405, val_loss=5.29e-5, \u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:03<00:00,  3.50it/s, loss=0.00405, val_loss=3.65e-5, \u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:03<00:02,  2.44it/s, loss=0.00232, val_loss=3.65e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.81it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  2.83it/s, loss=0.00232, val_loss=3.65e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.32it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.12it/s, loss=0.00232, val_loss=3.65e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.84it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.38it/s, loss=0.00232, val_loss=3.65e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.23it/s, loss=0.00232, val_loss=3.02e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.88it/s, loss=0.00139, val_loss=3.02e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  7.94it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  3.29it/s, loss=0.00139, val_loss=3.02e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.22it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.48it/s, loss=0.00139, val_loss=3.02e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.01it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.72it/s, loss=0.00139, val_loss=3.02e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:03<00:00,  3.54it/s, loss=0.00139, val_loss=6.03e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:03<00:02,  2.60it/s, loss=0.011, val_loss=6.03e-5, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.31it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  2.80it/s, loss=0.011, val_loss=6.03e-5, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.03it/s, loss=0.011, val_loss=6.03e-5, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.16it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.14it/s, loss=0.011, val_loss=6.03e-5, av\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  2.97it/s, loss=0.011, val_loss=0.000737, a\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:02<00:02,  2.88it/s, loss=0.0167, val_loss=0.000737, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  3.16it/s, loss=0.0167, val_loss=0.000737, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  5.47it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:03<00:00,  3.50it/s, loss=0.0167, val_loss=0.000737, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.30it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.78it/s, loss=0.0167, val_loss=0.000737, \u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.59it/s, loss=0.0167, val_loss=0.000411, \u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:03<00:00,  3.54it/s, loss=0.0167, val_loss=0.000411, \u001b[A\n",
      "Sizes of clusters: 105, 285, 295\n",
      "\n",
      "preds: [2 1 2 1 2 2 1 2 0 0 2 1 1 1 2 0 0 1 1 1 2 2 0 1 2 2 2 0 1 2 1 0 0 2 1 2 2\n",
      " 2 1 1 2 0 2 2 1 0 1 1 2 2 0 1 0 1 1 1 1 2 0 2 2 2 1 0 2 1 0 2 0 1 1 0 2 0\n",
      " 2 0 2 2 1 2 0 2 2 1 1 1 1 2 1 2 0 0 0 2 2 0 1 2 2 1 0 2 1 2 1 2 1 2 0 2 1\n",
      " 0 1 1 1 0 2 2 1 2 1 2 1 0 2 1 1 1 1 2 1 1 2 2 2 1 1 1 2 1 2 1 2 1 2 2 2 2\n",
      " 2 2 1 2 2 1 1 1 2 2 2 2 2 2 1 1 2 1 0 2 1 2 0 1 1 1 2 0 2 1 0 2 2 0 1 0 0\n",
      " 1 2 2 2 1 2 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 0 1\n",
      " 2 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 1 2 1 2 1 1 2 1 2 2 2 2 1 1 1 1 1 2 2 0 2\n",
      " 1 1 1 2 2 0 0 1 2 2 2 1 2 1 1 1 2 1 1 2 1 1 2 2 2 0 0 0 1 1 1 2 1 1 2 2 1\n",
      " 1 2 2 2 1 1 1 0 0 1 2 1 2 1 2 2 2 0 1 0 0 0 2 0 2 1 2 1 1 1 2 1 1 1 1 2 2\n",
      " 1 2 2 1 2 2 1 1 2 2 0 0 2 2 2 2 1 1 1 1 0 2 0 1 2 2 1 2 1 1 2 2 2 1 2 2 0\n",
      " 0 1 1 1 2 2 0 2 1 2 2 0 1 2 2 2 2 2 2 1 1 0 2 2 2 1 1 1 2 2 1 2 1 0 0 1 2\n",
      " 2 2 0 1 1 2 1 2 2 2 1 0 0 2 2 1 2 2 2 0 2 1 1 1 0 2 0 1 2 2 1 2 2 0 0 1 2\n",
      " 2 1 1 1 2 2 0 0 2 1 2 2 2 2 1 2 2 2 0 2 2 2 2 1 1 0 1 2 1 1 1 2 2 2 2 0 2\n",
      " 0 0 1 0 1 1 2 1 1 1 0 1 2 1 2 1 1 0 2 2 1 1 2 2 1 2 1 2 1 1 2 1 2 2 2 2 1\n",
      " 2 1 1 1 0 1 0 2 2 2 2 1 2 1 1 2 2 2 1 1 0 1 2 1 1 1 0 2 1 2 2 1 0 2 1 1 2\n",
      " 1 0 1 1 0 2 1 0 2 2 2 1 1 2 1 1 1 2 1 1 0 1 1 1 0 2 1 2 1 2 1 1 1 2 2 1 1\n",
      " 1 1 1 1 2 0 1 2 2 2 2 2 0 2 2 0 2 0 1 1 1 1 2 1 1 2 0 2 1 2 1 2 1 1 1 2 2\n",
      " 1 1 1 0 2 0 0 2 1 1 2 2 2 0 2 2 2 1 1 0 1 1 2 2 2 1 1 2 2 0 2 2 1 2 2 2 2\n",
      " 2 0 2 1 0 2 2 1 1 2 1 0 1 2 0 2 2 2 0]\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 6.2 M \n",
      "1 | decoder | Sequential | 6.2 M \n",
      "---------------------------------------\n",
      "12.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 M    Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 7/14 [00:02<00:02,  2.34it/s, loss=0.279, val_loss=5.81e-5, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  64%|▋| 9/14 [00:03<00:01,  2.84it/s, loss=0.279, val_loss=5.81e-5, avg\u001b[A\n",
      "Validating:  29%|█████████▍                       | 2/7 [00:00<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 0:  79%|▊| 11/14 [00:03<00:00,  3.19it/s, loss=0.279, val_loss=5.81e-5, av\u001b[A\n",
      "Validating:  57%|██████████████████▊              | 4/7 [00:00<00:00,  6.40it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 13/14 [00:03<00:00,  3.46it/s, loss=0.279, val_loss=5.81e-5, av\u001b[A\n",
      "Validating:  86%|████████████████████████████▎    | 6/7 [00:00<00:00,  6.58it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 14/14 [00:04<00:00,  3.42it/s, loss=0.279, val_loss=0.000344, a\u001b[A\n",
      "Epoch 1:  57%|▌| 8/14 [00:02<00:02,  2.80it/s, loss=0.244, val_loss=0.000344, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  6.86it/s]\u001b[A\n",
      "Epoch 1:  71%|▋| 10/14 [00:03<00:01,  3.16it/s, loss=0.244, val_loss=0.000344, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  6.74it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 12/14 [00:03<00:00,  3.47it/s, loss=0.244, val_loss=0.000344, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  6.63it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:03<00:00,  3.70it/s, loss=0.244, val_loss=0.000344, a\u001b[A\n",
      "Epoch 1: 100%|█| 14/14 [00:04<00:00,  3.46it/s, loss=0.244, val_loss=0.00255, av\u001b[A\n",
      "Epoch 2:  57%|▌| 8/14 [00:03<00:02,  2.23it/s, loss=0.195, val_loss=0.00255, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.53it/s]\u001b[A\n",
      "Epoch 2:  71%|▋| 10/14 [00:03<00:01,  2.62it/s, loss=0.195, val_loss=0.00255, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.22it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 12/14 [00:04<00:00,  2.89it/s, loss=0.195, val_loss=0.00255, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.37it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.17it/s, loss=0.195, val_loss=0.00255, av\u001b[A\n",
      "Epoch 2: 100%|█| 14/14 [00:04<00:00,  3.04it/s, loss=0.195, val_loss=0.00037, av\u001b[A\n",
      "Epoch 3:  57%|▌| 8/14 [00:02<00:02,  2.77it/s, loss=0.103, val_loss=0.00037, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  3.79it/s]\u001b[A\n",
      "Epoch 3:  71%|▋| 10/14 [00:03<00:01,  2.91it/s, loss=0.103, val_loss=0.00037, av\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.15it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 12/14 [00:04<00:00,  2.99it/s, loss=0.103, val_loss=0.00037, av\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  3.29it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:04<00:00,  2.81it/s, loss=0.103, val_loss=0.00037, av\u001b[A\n",
      "Epoch 3: 100%|█| 14/14 [00:05<00:00,  2.66it/s, loss=0.103, val_loss=0.000129, a\u001b[A\n",
      "Epoch 4:  57%|▌| 8/14 [00:02<00:02,  2.89it/s, loss=0.0373, val_loss=0.000129, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  9.29it/s]\u001b[A\n",
      "Epoch 4:  71%|▋| 10/14 [00:03<00:01,  3.31it/s, loss=0.0373, val_loss=0.000129, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.11it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 12/14 [00:03<00:00,  3.58it/s, loss=0.0373, val_loss=0.000129, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.20it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.81it/s, loss=0.0373, val_loss=0.000129, \u001b[A\n",
      "Epoch 4: 100%|█| 14/14 [00:03<00:00,  3.62it/s, loss=0.0373, val_loss=6.91e-5, a\u001b[A\n",
      "Epoch 5:  57%|▌| 8/14 [00:03<00:02,  2.61it/s, loss=0.0171, val_loss=6.91e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  4.73it/s]\u001b[A\n",
      "Epoch 5:  71%|▋| 10/14 [00:03<00:01,  2.70it/s, loss=0.0171, val_loss=6.91e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:01,  3.93it/s]\u001b[A\n",
      "Epoch 5:  86%|▊| 12/14 [00:04<00:00,  2.90it/s, loss=0.0171, val_loss=6.91e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.09it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  2.98it/s, loss=0.0171, val_loss=6.91e-5, a\u001b[A\n",
      "Epoch 5: 100%|█| 14/14 [00:04<00:00,  2.82it/s, loss=0.0171, val_loss=5.09e-5, a\u001b[A\n",
      "Epoch 6:  57%|▌| 8/14 [00:02<00:02,  2.85it/s, loss=0.00808, val_loss=5.09e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.24it/s]\u001b[A\n",
      "Epoch 6:  71%|▋| 10/14 [00:03<00:01,  3.10it/s, loss=0.00808, val_loss=5.09e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.68it/s]\u001b[A\n",
      "Epoch 6:  86%|▊| 12/14 [00:03<00:00,  3.32it/s, loss=0.00808, val_loss=5.09e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  5.61it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:03<00:00,  3.56it/s, loss=0.00808, val_loss=5.09e-5, \u001b[A\n",
      "Epoch 6: 100%|█| 14/14 [00:04<00:00,  3.40it/s, loss=0.00808, val_loss=5.04e-5, \u001b[A\n",
      "Epoch 7:  57%|▌| 8/14 [00:02<00:02,  2.69it/s, loss=0.00393, val_loss=5.04e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.49it/s]\u001b[A\n",
      "Epoch 7:  71%|▋| 10/14 [00:03<00:01,  2.92it/s, loss=0.00393, val_loss=5.04e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.75it/s]\u001b[A\n",
      "Epoch 7:  86%|▊| 12/14 [00:03<00:00,  3.12it/s, loss=0.00393, val_loss=5.04e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.78it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.28it/s, loss=0.00393, val_loss=5.04e-5, \u001b[A\n",
      "Epoch 7: 100%|█| 14/14 [00:04<00:00,  3.12it/s, loss=0.00393, val_loss=5.77e-5, \u001b[A\n",
      "Epoch 8:  57%|▌| 8/14 [00:03<00:02,  2.61it/s, loss=0.00209, val_loss=5.77e-5, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:00,  8.67it/s]\u001b[A\n",
      "Epoch 8:  71%|▋| 10/14 [00:03<00:01,  3.01it/s, loss=0.00209, val_loss=5.77e-5, \u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  7.89it/s]\u001b[A\n",
      "Epoch 8:  86%|▊| 12/14 [00:03<00:00,  3.33it/s, loss=0.00209, val_loss=5.77e-5, \u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:00<00:00,  7.42it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:03<00:00,  3.61it/s, loss=0.00209, val_loss=5.77e-5, \u001b[A\n",
      "Epoch 8: 100%|█| 14/14 [00:04<00:00,  3.42it/s, loss=0.00209, val_loss=4.9e-5, a\u001b[A\n",
      "Epoch 9:  57%|▌| 8/14 [00:03<00:02,  2.52it/s, loss=0.00115, val_loss=4.9e-5, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:  14%|████▋                            | 1/7 [00:00<00:01,  5.36it/s]\u001b[A\n",
      "Epoch 9:  71%|▋| 10/14 [00:03<00:01,  2.85it/s, loss=0.00115, val_loss=4.9e-5, a\u001b[A\n",
      "Validating:  43%|██████████████▏                  | 3/7 [00:00<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 9:  86%|▊| 12/14 [00:04<00:00,  2.97it/s, loss=0.00115, val_loss=4.9e-5, a\u001b[A\n",
      "Validating:  71%|███████████████████████▌         | 5/7 [00:01<00:00,  4.53it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  3.09it/s, loss=0.00115, val_loss=4.9e-5, a\u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  2.95it/s, loss=0.00115, val_loss=5.07e-5, \u001b[A\n",
      "Epoch 9: 100%|█| 14/14 [00:04<00:00,  2.92it/s, loss=0.00115, val_loss=5.07e-5, \u001b[A\n",
      "Sizes of clusters: 171, 409, 105\n",
      "\n",
      "preds: [1 2 1 2 0 1 0 1 2 2 1 1 1 1 1 1 1 1 0 1 0 2 2 1 0 1 1 1 1 1 0 1 0 1 1 1 1\n",
      " 0 1 0 1 0 2 1 1 0 1 1 0 0 2 1 1 0 2 1 1 1 1 0 1 2 2 1 1 0 0 0 1 1 0 1 1 1\n",
      " 1 0 2 2 1 0 1 0 0 1 1 2 1 2 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0\n",
      " 1 1 2 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 0 0 2 1 0 1 1 1 1 2 1 0 0 1\n",
      " 1 1 1 0 1 1 1 0 1 2 0 1 1 2 2 0 1 1 2 0 0 2 1 2 0 0 1 2 1 1 1 1 2 0 0 2 1\n",
      " 1 0 1 1 2 0 2 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 0 0 2 1 0 1 1 1 1 2 1 1 1 0 1\n",
      " 1 2 1 1 1 0 1 0 2 1 1 2 1 2 1 1 1 1 0 0 1 0 0 0 1 1 1 2 1 1 1 0 0 1 0 1 2\n",
      " 1 2 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 1 1 0 2 2 0 1 1 2 1 0 2 1 1 1 1 1 1 1 1 1 1 2 0 1 1 1 1 1 1 1 2 1 1 1 2 1\n",
      " 0 1 1 1 1 1 1 1 1 1 2 1 1 0 1 1 1 0 1 1 1 2 2 0 0 1 0 1 1 0 1 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 0 2 1 1 1 2 2 1 1 1 0 0 2 1 2 1 1 1 1 1 1 2 1 2 0 2 1 0 0 0 1\n",
      " 0 0 1 1 1 1 1 2 1 1 2 1 1 2 2 1 0 1 0 2 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 2 1 1 0 1 0 1 1 1 2 0 1 1 1 1 1 0 1 0 1 0 1 0 2 0 1\n",
      " 1 1 0 1 2 1 1 0 1 1 2 0 2 1 1 0 0 0 0 0 0 2 1 0 0 1 2 1 1 0 0 1 1 1 2 1 0\n",
      " 2 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 2 1 1 1 1 1 2 2 2 2 1 1 2 2 0 0\n",
      " 0 1 1 1 2 1 0 1 1 1 0 2 1 2 1 1 0 1 0 2 0 0 0 0 2 1 1 2 1 0 0 1 1 0 1 0 2\n",
      " 0 0 0 2 0 1 0 2 1 1 1 2 1 1 1 1 1 1 1 0 1 2 1 0 0 0 1 2 1 0 1 1 2 2 2 1 1\n",
      " 1 0 1 1 1 0 0 0 1 2 1 1 0 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 2 2 0 0 1 0 1\n",
      " 2 1 1 1 2 2 0 0 1 1 2 1 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3954\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/booking_tmp' \\\n",
    "    --verbose \\\n",
    "    --epochs 5 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3 \\\n",
    "    --type 'booking2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 527 K \n",
      "1 | decoder | Sequential | 527 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 10.21it/s, loss=1.8e+04, val_loss=0.987, avg_\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 17.76it/s, loss=1.8e+04, val_loss=0.564, avg_\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 10.97it/s, loss=1.56e+04, val_loss=0.564, avg\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 18.57it/s, loss=1.56e+04, val_loss=1.07, avg_\n",
      "Epoch 2:  67%|▋| 4/6 [00:00<00:00, 14.26it/s, loss=1.12e+04, val_loss=1.07, avg_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 18.77it/s, loss=1.12e+04, val_loss=2.47, avg_\n",
      "Epoch 3:  67%|▋| 4/6 [00:00<00:00, 14.81it/s, loss=8.5e+03, val_loss=2.47, avg_v\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 18.90it/s, loss=8.5e+03, val_loss=8.85, avg_v\n",
      "Epoch 4:  67%|▋| 4/6 [00:00<00:00, 14.49it/s, loss=6.83e+03, val_loss=8.85, avg_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 18.76it/s, loss=6.83e+03, val_loss=14.7, avg_\n",
      "Epoch 5:  67%|▋| 4/6 [00:00<00:00, 14.77it/s, loss=5.72e+03, val_loss=14.7, avg_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 19.34it/s, loss=5.72e+03, val_loss=14.4, avg_\n",
      "Epoch 6:  67%|▋| 4/6 [00:00<00:00, 14.52it/s, loss=5.14e+03, val_loss=14.4, avg_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 18.98it/s, loss=5.14e+03, val_loss=8.77, avg_\n",
      "Epoch 7:  67%|▋| 4/6 [00:00<00:00, 14.84it/s, loss=1.71e+03, val_loss=8.77, avg_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 19.09it/s, loss=1.71e+03, val_loss=8.09, avg_\n",
      "Epoch 8:  67%|▋| 4/6 [00:00<00:00, 14.54it/s, loss=261, val_loss=8.09, avg_val_l\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 19.19it/s, loss=261, val_loss=7.94, avg_val_l\n",
      "Epoch 9:  67%|▋| 4/6 [00:00<00:00, 14.75it/s, loss=106, val_loss=7.94, avg_val_l\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 19.16it/s, loss=106, val_loss=6.39, avg_val_l\n",
      "Epoch 10:  67%|▋| 4/6 [00:00<00:00, 14.55it/s, loss=55.8, val_loss=6.39, avg_val\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 18.66it/s, loss=55.8, val_loss=6.24, avg_val\n",
      "Epoch 11:  67%|▋| 4/6 [00:00<00:00, 14.56it/s, loss=35, val_loss=6.24, avg_val_l\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 19.08it/s, loss=35, val_loss=8.12, avg_val_l\n",
      "Epoch 12:  67%|▋| 4/6 [00:00<00:00, 14.74it/s, loss=16.7, val_loss=8.12, avg_val\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 19.46it/s, loss=16.7, val_loss=9.37, avg_val\n",
      "Epoch 13:  67%|▋| 4/6 [00:00<00:00, 14.52it/s, loss=11, val_loss=9.37, avg_val_l\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 19.13it/s, loss=11, val_loss=8.93, avg_val_l\n",
      "Epoch 14:  67%|▋| 4/6 [00:00<00:00, 14.49it/s, loss=8.75, val_loss=8.93, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 19.14it/s, loss=8.75, val_loss=7.98, avg_val\n",
      "Epoch 15:  67%|▋| 4/6 [00:00<00:00, 14.66it/s, loss=6.12, val_loss=7.98, avg_val\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 19.22it/s, loss=6.12, val_loss=7.17, avg_val\n",
      "Epoch 16:  67%|▋| 4/6 [00:00<00:00, 14.18it/s, loss=4.27, val_loss=7.17, avg_val\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 18.58it/s, loss=4.27, val_loss=6.27, avg_val\n",
      "Epoch 17:  67%|▋| 4/6 [00:00<00:00, 14.91it/s, loss=3.36, val_loss=6.27, avg_val\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 18.77it/s, loss=3.36, val_loss=5.14, avg_val\n",
      "Epoch 18:  67%|▋| 4/6 [00:00<00:00, 14.90it/s, loss=2.75, val_loss=5.14, avg_val\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 19.36it/s, loss=2.75, val_loss=4.06, avg_val\n",
      "Epoch 19:  67%|▋| 4/6 [00:00<00:00, 14.61it/s, loss=2.18, val_loss=4.06, avg_val\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 19.27it/s, loss=2.18, val_loss=3.36, avg_val\n",
      "Epoch 20:  67%|▋| 4/6 [00:00<00:00, 14.73it/s, loss=1.76, val_loss=3.36, avg_val\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 18.91it/s, loss=1.76, val_loss=2.75, avg_val\n",
      "Epoch 21:  67%|▋| 4/6 [00:00<00:00, 14.78it/s, loss=1.51, val_loss=2.75, avg_val\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 19.33it/s, loss=1.51, val_loss=2.2, avg_val_\n",
      "Epoch 22:  67%|▋| 4/6 [00:00<00:00, 14.75it/s, loss=1.27, val_loss=2.2, avg_val_\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 19.16it/s, loss=1.27, val_loss=2.05, avg_val\n",
      "Epoch 23:  67%|▋| 4/6 [00:00<00:00, 15.04it/s, loss=1.02, val_loss=2.05, avg_val\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 19.54it/s, loss=1.02, val_loss=2.18, avg_val\n",
      "Epoch 24:  67%|▋| 4/6 [00:00<00:00, 14.68it/s, loss=0.831, val_loss=2.18, avg_va\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 19.34it/s, loss=0.831, val_loss=2.27, avg_va\n",
      "Epoch 25:  67%|▋| 4/6 [00:00<00:00, 15.06it/s, loss=0.704, val_loss=2.27, avg_va\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 19.43it/s, loss=0.704, val_loss=2.18, avg_va\n",
      "Epoch 26:  67%|▋| 4/6 [00:00<00:00, 15.11it/s, loss=0.602, val_loss=2.18, avg_va\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=0.602, val_loss=1.87, avg_va\n",
      "Epoch 27:  67%|▋| 4/6 [00:00<00:00, 14.85it/s, loss=0.523, val_loss=1.87, avg_va\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 18.99it/s, loss=0.523, val_loss=1.51, avg_va\n",
      "Epoch 28:  67%|▋| 4/6 [00:00<00:00, 14.54it/s, loss=0.482, val_loss=1.51, avg_va\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 18.81it/s, loss=0.482, val_loss=1.19, avg_va\n",
      "Epoch 29:  67%|▋| 4/6 [00:00<00:00, 14.56it/s, loss=0.459, val_loss=1.19, avg_va\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 19.17it/s, loss=0.459, val_loss=0.839, avg_v\n",
      "Epoch 30:  67%|▋| 4/6 [00:00<00:00, 14.90it/s, loss=0.428, val_loss=0.839, avg_v\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 19.17it/s, loss=0.428, val_loss=0.697, avg_v\n",
      "Epoch 31:  67%|▋| 4/6 [00:00<00:00, 15.11it/s, loss=0.392, val_loss=0.697, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 19.78it/s, loss=0.392, val_loss=0.606, avg_v\n",
      "Epoch 32:  67%|▋| 4/6 [00:00<00:00, 14.31it/s, loss=0.365, val_loss=0.606, avg_v\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 18.90it/s, loss=0.365, val_loss=0.495, avg_v\n",
      "Epoch 33:  67%|▋| 4/6 [00:00<00:00, 14.00it/s, loss=0.348, val_loss=0.495, avg_v\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 18.58it/s, loss=0.348, val_loss=0.47, avg_va\n",
      "Epoch 34:  67%|▋| 4/6 [00:00<00:00, 15.07it/s, loss=0.333, val_loss=0.47, avg_va\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 19.78it/s, loss=0.333, val_loss=0.459, avg_v\n",
      "Epoch 35:  67%|▋| 4/6 [00:00<00:00, 14.98it/s, loss=0.318, val_loss=0.459, avg_v\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 19.70it/s, loss=0.318, val_loss=0.501, avg_v\n",
      "Epoch 36:  67%|▋| 4/6 [00:00<00:00, 14.76it/s, loss=0.304, val_loss=0.501, avg_v\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 19.18it/s, loss=0.304, val_loss=0.705, avg_v\n",
      "Epoch 37:  67%|▋| 4/6 [00:00<00:00, 14.60it/s, loss=0.291, val_loss=0.705, avg_v\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 19.28it/s, loss=0.291, val_loss=0.921, avg_v\n",
      "Epoch 38:  67%|▋| 4/6 [00:00<00:00, 14.15it/s, loss=0.279, val_loss=0.921, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 18.74it/s, loss=0.279, val_loss=1.09, avg_va\n",
      "Epoch 39:  67%|▋| 4/6 [00:00<00:00, 14.56it/s, loss=0.269, val_loss=1.09, avg_va\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 19.19it/s, loss=0.269, val_loss=1.69, avg_va\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 18.97it/s, loss=0.269, val_loss=1.69, avg_va\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of clusters: 186, 58, 56\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1\n",
      " 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 1 1 1 1 2 1 1 0 2 2 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 2 1\n",
      " 2 1 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6633\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 527 K \n",
      "1 | decoder | Sequential | 527 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.29it/s, loss=1.19e+04, val_loss=0.655, avg\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=1.19e+04, val_loss=4.46, avg_\n",
      "Epoch 1:  67%|▋| 4/6 [00:00<00:00, 15.09it/s, loss=1.52e+04, val_loss=4.46, avg_\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=1.52e+04, val_loss=19.4, avg_\n",
      "Epoch 2:  67%|▋| 4/6 [00:00<00:00, 14.54it/s, loss=1.08e+04, val_loss=19.4, avg_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 19.14it/s, loss=1.08e+04, val_loss=13.7, avg_\n",
      "Epoch 3:  67%|▋| 4/6 [00:00<00:00, 15.12it/s, loss=8.25e+03, val_loss=13.7, avg_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 19.78it/s, loss=8.25e+03, val_loss=29, avg_va\n",
      "Epoch 4:  67%|▋| 4/6 [00:00<00:00, 14.97it/s, loss=6.64e+03, val_loss=29, avg_va\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 19.33it/s, loss=6.64e+03, val_loss=27.3, avg_\n",
      "Epoch 5:  67%|▋| 4/6 [00:00<00:00, 14.59it/s, loss=5.56e+03, val_loss=27.3, avg_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 19.17it/s, loss=5.56e+03, val_loss=35, avg_va\n",
      "Epoch 6:  67%|▋| 4/6 [00:00<00:00, 14.75it/s, loss=5.01e+03, val_loss=35, avg_va\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 19.42it/s, loss=5.01e+03, val_loss=52.3, avg_\n",
      "Epoch 7:  67%|▋| 4/6 [00:00<00:00, 14.69it/s, loss=1.48e+03, val_loss=52.3, avg_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 18.97it/s, loss=1.48e+03, val_loss=55.1, avg_\n",
      "Epoch 8:  67%|▋| 4/6 [00:00<00:00, 14.86it/s, loss=393, val_loss=55.1, avg_val_l\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 19.51it/s, loss=393, val_loss=34.9, avg_val_l\n",
      "Epoch 9:  67%|▋| 4/6 [00:00<00:00, 15.21it/s, loss=141, val_loss=34.9, avg_val_l\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 19.95it/s, loss=141, val_loss=24, avg_val_los\n",
      "Epoch 10:  67%|▋| 4/6 [00:00<00:00, 14.91it/s, loss=86.4, val_loss=24, avg_val_l\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 19.66it/s, loss=86.4, val_loss=26, avg_val_l\n",
      "Epoch 11:  67%|▋| 4/6 [00:00<00:00, 14.77it/s, loss=65.1, val_loss=26, avg_val_l\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=65.1, val_loss=27.8, avg_val\n",
      "Epoch 12:  67%|▋| 4/6 [00:00<00:00, 15.04it/s, loss=46.4, val_loss=27.8, avg_val\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 19.61it/s, loss=46.4, val_loss=31.6, avg_val\n",
      "Epoch 13:  67%|▋| 4/6 [00:00<00:00, 14.91it/s, loss=33.4, val_loss=31.6, avg_val\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 19.06it/s, loss=33.4, val_loss=40.7, avg_val\n",
      "Epoch 14:  67%|▋| 4/6 [00:00<00:00, 14.71it/s, loss=21.6, val_loss=40.7, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 19.39it/s, loss=21.6, val_loss=48.7, avg_val\n",
      "Epoch 15:  67%|▋| 4/6 [00:00<00:00, 14.53it/s, loss=14.5, val_loss=48.7, avg_val\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 18.84it/s, loss=14.5, val_loss=49.5, avg_val\n",
      "Epoch 16:  67%|▋| 4/6 [00:00<00:00, 13.49it/s, loss=11.8, val_loss=49.5, avg_val\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 17.97it/s, loss=11.8, val_loss=46.4, avg_val\n",
      "Epoch 17:  67%|▋| 4/6 [00:00<00:00, 14.79it/s, loss=9.22, val_loss=46.4, avg_val\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 19.47it/s, loss=9.22, val_loss=40.1, avg_val\n",
      "Epoch 18:  67%|▋| 4/6 [00:00<00:00, 14.62it/s, loss=6.23, val_loss=40.1, avg_val\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 19.15it/s, loss=6.23, val_loss=30, avg_val_l\n",
      "Epoch 19:  67%|▋| 4/6 [00:00<00:00, 15.20it/s, loss=4.27, val_loss=30, avg_val_l\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 19.91it/s, loss=4.27, val_loss=22, avg_val_l\n",
      "Epoch 20:  67%|▋| 4/6 [00:00<00:00, 14.89it/s, loss=3.37, val_loss=22, avg_val_l\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 19.63it/s, loss=3.37, val_loss=17.6, avg_val\n",
      "Epoch 21:  67%|▋| 4/6 [00:00<00:00, 14.95it/s, loss=2.87, val_loss=17.6, avg_val\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 19.65it/s, loss=2.87, val_loss=13.9, avg_val\n",
      "Epoch 22:  67%|▋| 4/6 [00:00<00:00, 15.18it/s, loss=2.42, val_loss=13.9, avg_val\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 19.92it/s, loss=2.42, val_loss=10.3, avg_val\n",
      "Epoch 23:  67%|▋| 4/6 [00:00<00:00, 14.74it/s, loss=1.85, val_loss=10.3, avg_val\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 19.06it/s, loss=1.85, val_loss=7.51, avg_val\n",
      "Epoch 24:  67%|▋| 4/6 [00:00<00:00, 14.45it/s, loss=1.26, val_loss=7.51, avg_val\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 19.05it/s, loss=1.26, val_loss=5.74, avg_val\n",
      "Epoch 25:  67%|▋| 4/6 [00:00<00:00, 14.70it/s, loss=0.911, val_loss=5.74, avg_va\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 19.35it/s, loss=0.911, val_loss=4, avg_val_l\n",
      "Epoch 26:  67%|▋| 4/6 [00:00<00:00, 14.78it/s, loss=0.825, val_loss=4, avg_val_l\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 19.13it/s, loss=0.825, val_loss=2.62, avg_va\n",
      "Epoch 27:  67%|▋| 4/6 [00:00<00:00, 14.55it/s, loss=0.742, val_loss=2.62, avg_va\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 18.75it/s, loss=0.742, val_loss=1.79, avg_va\n",
      "Epoch 28:  67%|▋| 4/6 [00:00<00:00, 14.37it/s, loss=0.586, val_loss=1.79, avg_va\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 18.68it/s, loss=0.586, val_loss=1.12, avg_va\n",
      "Epoch 29:  67%|▋| 4/6 [00:00<00:00, 15.03it/s, loss=0.475, val_loss=1.12, avg_va\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 19.32it/s, loss=0.475, val_loss=0.682, avg_v\n",
      "Epoch 30:  67%|▋| 4/6 [00:00<00:00, 15.05it/s, loss=0.43, val_loss=0.682, avg_va\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 19.68it/s, loss=0.43, val_loss=0.479, avg_va\n",
      "Epoch 31:  67%|▋| 4/6 [00:00<00:00, 14.27it/s, loss=0.389, val_loss=0.479, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 18.34it/s, loss=0.389, val_loss=0.381, avg_v\n",
      "Epoch 32:  67%|▋| 4/6 [00:00<00:00, 14.45it/s, loss=0.345, val_loss=0.381, avg_v\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 19.05it/s, loss=0.345, val_loss=0.305, avg_v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  67%|▋| 4/6 [00:00<00:00, 13.07it/s, loss=0.314, val_loss=0.305, avg_v\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 17.29it/s, loss=0.314, val_loss=0.266, avg_v\n",
      "Epoch 34:  67%|▋| 4/6 [00:00<00:00, 13.77it/s, loss=0.285, val_loss=0.266, avg_v\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 18.25it/s, loss=0.285, val_loss=0.245, avg_v\n",
      "Epoch 35:  67%|▋| 4/6 [00:00<00:00, 14.08it/s, loss=0.259, val_loss=0.245, avg_v\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 18.62it/s, loss=0.259, val_loss=0.234, avg_v\n",
      "Epoch 36:  67%|▋| 4/6 [00:00<00:00, 14.67it/s, loss=0.246, val_loss=0.234, avg_v\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 18.94it/s, loss=0.246, val_loss=0.228, avg_v\n",
      "Epoch 37:  67%|▋| 4/6 [00:00<00:00, 14.12it/s, loss=0.237, val_loss=0.228, avg_v\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 18.54it/s, loss=0.237, val_loss=0.213, avg_v\n",
      "Epoch 38:  67%|▋| 4/6 [00:00<00:00, 14.06it/s, loss=0.225, val_loss=0.213, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 18.24it/s, loss=0.225, val_loss=0.203, avg_v\n",
      "Epoch 39:  67%|▋| 4/6 [00:00<00:00, 15.12it/s, loss=0.214, val_loss=0.203, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 19.82it/s, loss=0.214, val_loss=0.202, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 19.60it/s, loss=0.214, val_loss=0.202, avg_v\n",
      "Sizes of clusters: 186, 58, 56\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1\n",
      " 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 1 1 1 1 2 1 1 0 2 2 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 2 1\n",
      " 2 1 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6633\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 527 K \n",
      "1 | decoder | Sequential | 527 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 11.51it/s, loss=1.28e+04, val_loss=0.404, avg\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 19.56it/s, loss=1.28e+04, val_loss=0.976, avg\n",
      "Epoch 1:  67%|▋| 4/6 [00:00<00:00, 13.87it/s, loss=1.28e+04, val_loss=0.976, avg\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 17.83it/s, loss=1.28e+04, val_loss=4.68, avg_\n",
      "Epoch 2:  67%|▋| 4/6 [00:00<00:00, 14.50it/s, loss=1.05e+04, val_loss=4.68, avg_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 19.17it/s, loss=1.05e+04, val_loss=20.6, avg_\n",
      "Epoch 3:  67%|▋| 4/6 [00:00<00:00, 14.42it/s, loss=7.95e+03, val_loss=20.6, avg_\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 18.66it/s, loss=7.95e+03, val_loss=32.1, avg_\n",
      "Epoch 4:  67%|▋| 4/6 [00:00<00:00, 15.03it/s, loss=6.44e+03, val_loss=32.1, avg_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=6.44e+03, val_loss=36.6, avg_\n",
      "Epoch 5:  67%|▋| 4/6 [00:00<00:00, 14.28it/s, loss=5.41e+03, val_loss=36.6, avg_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 18.59it/s, loss=5.41e+03, val_loss=81.4, avg_\n",
      "Epoch 6:  67%|▋| 4/6 [00:00<00:00, 14.04it/s, loss=4.88e+03, val_loss=81.4, avg_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 18.12it/s, loss=4.88e+03, val_loss=146, avg_v\n",
      "Epoch 7:  67%|▋| 4/6 [00:00<00:00, 14.46it/s, loss=2.12e+03, val_loss=146, avg_v\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 18.69it/s, loss=2.12e+03, val_loss=177, avg_v\n",
      "Epoch 8:  67%|▋| 4/6 [00:00<00:00, 14.60it/s, loss=490, val_loss=177, avg_val_lo\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 19.21it/s, loss=490, val_loss=155, avg_val_lo\n",
      "Epoch 9:  67%|▋| 4/6 [00:00<00:00, 14.06it/s, loss=170, val_loss=155, avg_val_lo\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 18.42it/s, loss=170, val_loss=108, avg_val_lo\n",
      "Epoch 10:  67%|▋| 4/6 [00:00<00:00, 13.71it/s, loss=132, val_loss=108, avg_val_l\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 18.25it/s, loss=132, val_loss=59.4, avg_val_\n",
      "Epoch 11:  67%|▋| 4/6 [00:00<00:00, 14.81it/s, loss=76.2, val_loss=59.4, avg_val\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=76.2, val_loss=25.6, avg_val\n",
      "Epoch 12:  67%|▋| 4/6 [00:00<00:00, 14.93it/s, loss=44.3, val_loss=25.6, avg_val\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 19.32it/s, loss=44.3, val_loss=15.4, avg_val\n",
      "Epoch 13:  67%|▋| 4/6 [00:00<00:00, 14.89it/s, loss=32.8, val_loss=15.4, avg_val\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 19.55it/s, loss=32.8, val_loss=17.4, avg_val\n",
      "Epoch 14:  67%|▋| 4/6 [00:00<00:00, 13.86it/s, loss=28.3, val_loss=17.4, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 17.42it/s, loss=28.3, val_loss=18.1, avg_val\n",
      "Epoch 15:  67%|▋| 4/6 [00:00<00:00, 14.25it/s, loss=22.1, val_loss=18.1, avg_val\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 18.63it/s, loss=22.1, val_loss=14.2, avg_val\n",
      "Epoch 16:  67%|▋| 4/6 [00:00<00:00, 13.24it/s, loss=14.7, val_loss=14.2, avg_val\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 17.66it/s, loss=14.7, val_loss=9.56, avg_val\n",
      "Epoch 17:  67%|▋| 4/6 [00:00<00:00, 14.35it/s, loss=9.44, val_loss=9.56, avg_val\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 18.62it/s, loss=9.44, val_loss=7.31, avg_val\n",
      "Epoch 18:  67%|▋| 4/6 [00:00<00:00, 14.51it/s, loss=7.12, val_loss=7.31, avg_val\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 18.67it/s, loss=7.12, val_loss=6.53, avg_val\n",
      "Epoch 19:  67%|▋| 4/6 [00:00<00:00, 13.97it/s, loss=6.14, val_loss=6.53, avg_val\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 17.97it/s, loss=6.14, val_loss=5.41, avg_val\n",
      "Epoch 20:  67%|▋| 4/6 [00:00<00:00, 14.48it/s, loss=4.88, val_loss=5.41, avg_val\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 19.11it/s, loss=4.88, val_loss=3.98, avg_val\n",
      "Epoch 21:  67%|▋| 4/6 [00:00<00:00, 14.57it/s, loss=3.32, val_loss=3.98, avg_val\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 18.82it/s, loss=3.32, val_loss=3.13, avg_val\n",
      "Epoch 22:  67%|▋| 4/6 [00:00<00:00, 14.45it/s, loss=2.19, val_loss=3.13, avg_val\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 18.67it/s, loss=2.19, val_loss=2.85, avg_val\n",
      "Epoch 23:  67%|▋| 4/6 [00:00<00:00, 13.96it/s, loss=1.74, val_loss=2.85, avg_val\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 18.45it/s, loss=1.74, val_loss=2.55, avg_val\n",
      "Epoch 24:  67%|▋| 4/6 [00:00<00:00, 15.15it/s, loss=1.52, val_loss=2.55, avg_val\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 19.44it/s, loss=1.52, val_loss=1.95, avg_val\n",
      "Epoch 25:  67%|▋| 4/6 [00:00<00:00, 14.61it/s, loss=1.18, val_loss=1.95, avg_val\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 18.46it/s, loss=1.18, val_loss=1.28, avg_val\n",
      "Epoch 26:  67%|▋| 4/6 [00:00<00:00, 14.08it/s, loss=0.8, val_loss=1.28, avg_val_\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 18.64it/s, loss=0.8, val_loss=0.892, avg_val\n",
      "Epoch 27:  67%|▋| 4/6 [00:00<00:00, 14.75it/s, loss=0.576, val_loss=0.892, avg_v\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 18.86it/s, loss=0.576, val_loss=0.778, avg_v\n",
      "Epoch 28:  67%|▋| 4/6 [00:00<00:00, 14.22it/s, loss=0.505, val_loss=0.778, avg_v\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 18.38it/s, loss=0.505, val_loss=0.709, avg_v\n",
      "Epoch 29:  67%|▋| 4/6 [00:00<00:00, 13.98it/s, loss=0.459, val_loss=0.709, avg_v\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 18.39it/s, loss=0.459, val_loss=0.569, avg_v\n",
      "Epoch 30:  67%|▋| 4/6 [00:00<00:00, 13.94it/s, loss=0.376, val_loss=0.569, avg_v\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 17.98it/s, loss=0.376, val_loss=0.444, avg_v\n",
      "Epoch 31:  67%|▋| 4/6 [00:00<00:00, 13.86it/s, loss=0.291, val_loss=0.444, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 18.34it/s, loss=0.291, val_loss=0.403, avg_v\n",
      "Epoch 32:  67%|▋| 4/6 [00:00<00:00, 13.80it/s, loss=0.243, val_loss=0.403, avg_v\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 17.78it/s, loss=0.243, val_loss=0.398, avg_v\n",
      "Epoch 33:  67%|▋| 4/6 [00:00<00:00, 12.35it/s, loss=0.224, val_loss=0.398, avg_v\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 16.55it/s, loss=0.224, val_loss=0.36, avg_va\n",
      "Epoch 34:  67%|▋| 4/6 [00:00<00:00, 14.35it/s, loss=0.206, val_loss=0.36, avg_va\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 19.00it/s, loss=0.206, val_loss=0.3, avg_val\n",
      "Epoch 35:  67%|▋| 4/6 [00:00<00:00, 13.92it/s, loss=0.183, val_loss=0.3, avg_val\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 18.45it/s, loss=0.183, val_loss=0.254, avg_v\n",
      "Epoch 36:  67%|▋| 4/6 [00:00<00:00, 14.33it/s, loss=0.163, val_loss=0.254, avg_v\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 18.76it/s, loss=0.163, val_loss=0.224, avg_v\n",
      "Epoch 37:  67%|▋| 4/6 [00:00<00:00, 13.94it/s, loss=0.152, val_loss=0.224, avg_v\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 18.42it/s, loss=0.152, val_loss=0.207, avg_v\n",
      "Epoch 38:  67%|▋| 4/6 [00:00<00:00, 14.04it/s, loss=0.145, val_loss=0.207, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 18.50it/s, loss=0.145, val_loss=0.194, avg_v\n",
      "Epoch 39:  67%|▋| 4/6 [00:00<00:00, 14.23it/s, loss=0.137, val_loss=0.194, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 18.56it/s, loss=0.137, val_loss=0.189, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 18.36it/s, loss=0.137, val_loss=0.189, avg_v\n",
      "Sizes of clusters: 186, 58, 56\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1\n",
      " 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 1 1 1 1 2 1 1 0 2 2 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 2 1\n",
      " 2 1 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6633\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 527 K \n",
      "1 | decoder | Sequential | 527 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 10.30it/s, loss=2.02e+04, val_loss=0.324, avg\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 18.07it/s, loss=2.02e+04, val_loss=9.89, avg_\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 10.74it/s, loss=1.84e+04, val_loss=9.89, avg_\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 18.47it/s, loss=1.84e+04, val_loss=8.02, avg_\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 10.95it/s, loss=1.35e+04, val_loss=8.02, avg_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 18.80it/s, loss=1.35e+04, val_loss=16, avg_va\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 10.92it/s, loss=1.03e+04, val_loss=16, avg_va\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 19.10it/s, loss=1.03e+04, val_loss=102, avg_v\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 10.78it/s, loss=8.36e+03, val_loss=102, avg_v\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 18.79it/s, loss=8.36e+03, val_loss=87.3, avg_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 10.81it/s, loss=6.98e+03, val_loss=87.3, avg_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 18.16it/s, loss=6.98e+03, val_loss=43.9, avg_\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 10.50it/s, loss=6.29e+03, val_loss=43.9, avg_\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 17.97it/s, loss=6.29e+03, val_loss=23.3, avg_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 10.57it/s, loss=2.58e+03, val_loss=23.3, avg_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 18.52it/s, loss=2.58e+03, val_loss=16, avg_va\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 10.40it/s, loss=417, val_loss=16, avg_val_los\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 18.20it/s, loss=417, val_loss=16.4, avg_val_l\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 10.79it/s, loss=203, val_loss=16.4, avg_val_l\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 18.49it/s, loss=203, val_loss=21.8, avg_val_l\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 10.66it/s, loss=93.3, val_loss=21.8, avg_val\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 18.16it/s, loss=93.3, val_loss=30, avg_val_l\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 10.84it/s, loss=52.5, val_loss=30, avg_val_l\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 18.51it/s, loss=52.5, val_loss=36.2, avg_val\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 10.46it/s, loss=39.7, val_loss=36.2, avg_val\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 18.12it/s, loss=39.7, val_loss=34.6, avg_val\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 11.23it/s, loss=30.3, val_loss=34.6, avg_val\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 19.33it/s, loss=30.3, val_loss=25.1, avg_val\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 10.87it/s, loss=20.8, val_loss=25.1, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 18.23it/s, loss=20.8, val_loss=13.5, avg_val\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 11.04it/s, loss=13.4, val_loss=13.5, avg_val\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 19.31it/s, loss=13.4, val_loss=5.34, avg_val\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00,  9.37it/s, loss=9.73, val_loss=5.34, avg_val\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 16.29it/s, loss=9.73, val_loss=2.1, avg_val_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 10.95it/s, loss=8.26, val_loss=2.1, avg_val_\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 19.04it/s, loss=8.26, val_loss=2.09, avg_val\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 11.43it/s, loss=7.06, val_loss=2.09, avg_val\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 19.93it/s, loss=7.06, val_loss=2.83, avg_val\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 11.30it/s, loss=5.42, val_loss=2.83, avg_val\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 18.69it/s, loss=5.42, val_loss=2.8, avg_val_\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00,  9.94it/s, loss=3.71, val_loss=2.8, avg_val_\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 17.32it/s, loss=3.71, val_loss=2.15, avg_val\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 10.97it/s, loss=2.45, val_loss=2.15, avg_val\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 19.09it/s, loss=2.45, val_loss=1.61, avg_val\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 10.93it/s, loss=1.79, val_loss=1.61, avg_val\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 18.94it/s, loss=1.79, val_loss=1.32, avg_val\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.42it/s, loss=1.49, val_loss=1.32, avg_val\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 19.82it/s, loss=1.49, val_loss=1.05, avg_val\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 11.38it/s, loss=1.3, val_loss=1.05, avg_val_\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 18.97it/s, loss=1.3, val_loss=0.787, avg_val\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 10.82it/s, loss=1.08, val_loss=0.787, avg_va\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 18.01it/s, loss=1.08, val_loss=0.6, avg_val_\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 10.99it/s, loss=0.854, val_loss=0.6, avg_val\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 19.24it/s, loss=0.854, val_loss=0.522, avg_v\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 11.23it/s, loss=0.689, val_loss=0.522, avg_v\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 19.56it/s, loss=0.689, val_loss=0.513, avg_v\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 10.74it/s, loss=0.591, val_loss=0.513, avg_v\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 18.47it/s, loss=0.591, val_loss=0.485, avg_v\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 11.40it/s, loss=0.529, val_loss=0.485, avg_v\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 19.91it/s, loss=0.529, val_loss=0.412, avg_v\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00, 11.54it/s, loss=0.472, val_loss=0.412, avg_v\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 19.61it/s, loss=0.472, val_loss=0.352, avg_v\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 10.56it/s, loss=0.421, val_loss=0.352, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 17.92it/s, loss=0.421, val_loss=0.341, avg_v\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.34it/s, loss=0.386, val_loss=0.341, avg_v\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 19.61it/s, loss=0.386, val_loss=0.346, avg_v\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00, 10.73it/s, loss=0.365, val_loss=0.346, avg_v\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 18.20it/s, loss=0.365, val_loss=0.333, avg_v\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 10.87it/s, loss=0.349, val_loss=0.333, avg_v\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 18.72it/s, loss=0.349, val_loss=0.31, avg_va\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 11.39it/s, loss=0.331, val_loss=0.31, avg_va\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 19.79it/s, loss=0.331, val_loss=0.299, avg_v\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 10.59it/s, loss=0.317, val_loss=0.299, avg_v\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 18.12it/s, loss=0.317, val_loss=0.3, avg_val\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 10.80it/s, loss=0.308, val_loss=0.3, avg_val\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 18.74it/s, loss=0.308, val_loss=0.298, avg_v\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 11.39it/s, loss=0.302, val_loss=0.298, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 19.37it/s, loss=0.302, val_loss=0.289, avg_v\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 10.85it/s, loss=0.294, val_loss=0.289, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 17.29it/s, loss=0.294, val_loss=0.283, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 17.03it/s, loss=0.294, val_loss=0.283, avg_v\n",
      "Sizes of clusters: 186, 58, 56\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1\n",
      " 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 1 1 1 1 2 1 1 0 2 2 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 2 1\n",
      " 2 1 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6633\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 527 K \n",
      "1 | decoder | Sequential | 527 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 3/6 [00:00<00:00, 10.82it/s, loss=1.74e+04, val_loss=0.399, avg\n",
      "Epoch 0: 100%|█| 6/6 [00:00<00:00, 18.89it/s, loss=1.74e+04, val_loss=0.373, avg\n",
      "Epoch 1:  50%|▌| 3/6 [00:00<00:00, 10.80it/s, loss=1.32e+04, val_loss=0.373, avg\n",
      "Epoch 1: 100%|█| 6/6 [00:00<00:00, 18.39it/s, loss=1.32e+04, val_loss=8.29, avg_\n",
      "Epoch 2:  50%|▌| 3/6 [00:00<00:00, 10.74it/s, loss=9.06e+03, val_loss=8.29, avg_\n",
      "Epoch 2: 100%|█| 6/6 [00:00<00:00, 18.68it/s, loss=9.06e+03, val_loss=36.9, avg_\n",
      "Epoch 3:  50%|▌| 3/6 [00:00<00:00, 11.47it/s, loss=6.9e+03, val_loss=36.9, avg_v\n",
      "Epoch 3: 100%|█| 6/6 [00:00<00:00, 19.93it/s, loss=6.9e+03, val_loss=59.9, avg_v\n",
      "Epoch 4:  50%|▌| 3/6 [00:00<00:00, 10.87it/s, loss=5.57e+03, val_loss=59.9, avg_\n",
      "Epoch 4: 100%|█| 6/6 [00:00<00:00, 18.48it/s, loss=5.57e+03, val_loss=55.5, avg_\n",
      "Epoch 5:  50%|▌| 3/6 [00:00<00:00, 11.09it/s, loss=4.65e+03, val_loss=55.5, avg_\n",
      "Epoch 5: 100%|█| 6/6 [00:00<00:00, 19.25it/s, loss=4.65e+03, val_loss=43, avg_va\n",
      "Epoch 6:  50%|▌| 3/6 [00:00<00:00, 11.40it/s, loss=4.19e+03, val_loss=43, avg_va\n",
      "Epoch 6: 100%|█| 6/6 [00:00<00:00, 19.89it/s, loss=4.19e+03, val_loss=44.3, avg_\n",
      "Epoch 7:  50%|▌| 3/6 [00:00<00:00, 10.95it/s, loss=1.09e+03, val_loss=44.3, avg_\n",
      "Epoch 7: 100%|█| 6/6 [00:00<00:00, 19.25it/s, loss=1.09e+03, val_loss=58, avg_va\n",
      "Epoch 8:  50%|▌| 3/6 [00:00<00:00, 11.30it/s, loss=200, val_loss=58, avg_val_los\n",
      "Epoch 8: 100%|█| 6/6 [00:00<00:00, 19.59it/s, loss=200, val_loss=81, avg_val_los\n",
      "Epoch 9:  50%|▌| 3/6 [00:00<00:00, 10.84it/s, loss=116, val_loss=81, avg_val_los\n",
      "Epoch 9: 100%|█| 6/6 [00:00<00:00, 18.94it/s, loss=116, val_loss=93.9, avg_val_l\n",
      "Epoch 10:  50%|▌| 3/6 [00:00<00:00, 11.07it/s, loss=65.9, val_loss=93.9, avg_val\n",
      "Epoch 10: 100%|█| 6/6 [00:00<00:00, 18.61it/s, loss=65.9, val_loss=89.4, avg_val\n",
      "Epoch 11:  50%|▌| 3/6 [00:00<00:00, 10.84it/s, loss=42.9, val_loss=89.4, avg_val\n",
      "Epoch 11: 100%|█| 6/6 [00:00<00:00, 18.66it/s, loss=42.9, val_loss=71.8, avg_val\n",
      "Epoch 12:  50%|▌| 3/6 [00:00<00:00, 11.06it/s, loss=35, val_loss=71.8, avg_val_l\n",
      "Epoch 12: 100%|█| 6/6 [00:00<00:00, 18.59it/s, loss=35, val_loss=54.1, avg_val_l\n",
      "Epoch 13:  50%|▌| 3/6 [00:00<00:00, 10.34it/s, loss=26.3, val_loss=54.1, avg_val\n",
      "Epoch 13: 100%|█| 6/6 [00:00<00:00, 17.80it/s, loss=26.3, val_loss=47.7, avg_val\n",
      "Epoch 14:  50%|▌| 3/6 [00:00<00:00, 11.21it/s, loss=18.4, val_loss=47.7, avg_val\n",
      "Epoch 14: 100%|█| 6/6 [00:00<00:00, 18.57it/s, loss=18.4, val_loss=43.2, avg_val\n",
      "Epoch 15:  50%|▌| 3/6 [00:00<00:00, 10.01it/s, loss=12.9, val_loss=43.2, avg_val\n",
      "Epoch 15: 100%|█| 6/6 [00:00<00:00, 17.09it/s, loss=12.9, val_loss=33.9, avg_val\n",
      "Epoch 16:  50%|▌| 3/6 [00:00<00:00, 10.20it/s, loss=8.74, val_loss=33.9, avg_val\n",
      "Epoch 16: 100%|█| 6/6 [00:00<00:00, 17.64it/s, loss=8.74, val_loss=27.5, avg_val\n",
      "Epoch 17:  50%|▌| 3/6 [00:00<00:00, 10.80it/s, loss=6.26, val_loss=27.5, avg_val\n",
      "Epoch 17: 100%|█| 6/6 [00:00<00:00, 18.48it/s, loss=6.26, val_loss=26, avg_val_l\n",
      "Epoch 18:  50%|▌| 3/6 [00:00<00:00, 10.98it/s, loss=5.17, val_loss=26, avg_val_l\n",
      "Epoch 18: 100%|█| 6/6 [00:00<00:00, 18.75it/s, loss=5.17, val_loss=23.7, avg_val\n",
      "Epoch 19:  50%|▌| 3/6 [00:00<00:00, 10.51it/s, loss=4.49, val_loss=23.7, avg_val\n",
      "Epoch 19: 100%|█| 6/6 [00:00<00:00, 17.94it/s, loss=4.49, val_loss=19, avg_val_l\n",
      "Epoch 20:  50%|▌| 3/6 [00:00<00:00, 11.04it/s, loss=3.36, val_loss=19, avg_val_l\n",
      "Epoch 20: 100%|█| 6/6 [00:00<00:00, 19.28it/s, loss=3.36, val_loss=14.7, avg_val\n",
      "Epoch 21:  50%|▌| 3/6 [00:00<00:00, 10.86it/s, loss=2.05, val_loss=14.7, avg_val\n",
      "Epoch 21: 100%|█| 6/6 [00:00<00:00, 18.97it/s, loss=2.05, val_loss=12.1, avg_val\n",
      "Epoch 22:  50%|▌| 3/6 [00:00<00:00, 11.25it/s, loss=1.43, val_loss=12.1, avg_val\n",
      "Epoch 22: 100%|█| 6/6 [00:00<00:00, 19.60it/s, loss=1.43, val_loss=9.85, avg_val\n",
      "Epoch 23:  50%|▌| 3/6 [00:00<00:00, 11.04it/s, loss=1.35, val_loss=9.85, avg_val\n",
      "Epoch 23: 100%|█| 6/6 [00:00<00:00, 19.21it/s, loss=1.35, val_loss=7.46, avg_val\n",
      "Epoch 24:  50%|▌| 3/6 [00:00<00:00, 10.49it/s, loss=1.16, val_loss=7.46, avg_val\n",
      "Epoch 24: 100%|█| 6/6 [00:00<00:00, 17.77it/s, loss=1.16, val_loss=5.67, avg_val\n",
      "Epoch 25:  50%|▌| 3/6 [00:00<00:00, 10.44it/s, loss=0.844, val_loss=5.67, avg_va\n",
      "Epoch 25: 100%|█| 6/6 [00:00<00:00, 18.15it/s, loss=0.844, val_loss=4.1, avg_val\n",
      "Epoch 26:  50%|▌| 3/6 [00:00<00:00, 11.23it/s, loss=0.624, val_loss=4.1, avg_val\n",
      "Epoch 26: 100%|█| 6/6 [00:00<00:00, 19.45it/s, loss=0.624, val_loss=2.62, avg_va\n",
      "Epoch 27:  50%|▌| 3/6 [00:00<00:00, 10.90it/s, loss=0.527, val_loss=2.62, avg_va\n",
      "Epoch 27: 100%|█| 6/6 [00:00<00:00, 19.09it/s, loss=0.527, val_loss=1.66, avg_va\n",
      "Epoch 28:  50%|▌| 3/6 [00:00<00:00, 11.25it/s, loss=0.461, val_loss=1.66, avg_va\n",
      "Epoch 28: 100%|█| 6/6 [00:00<00:00, 19.11it/s, loss=0.461, val_loss=1.18, avg_va\n",
      "Epoch 29:  50%|▌| 3/6 [00:00<00:00, 10.91it/s, loss=0.391, val_loss=1.18, avg_va\n",
      "Epoch 29: 100%|█| 6/6 [00:00<00:00, 18.76it/s, loss=0.391, val_loss=0.862, avg_v\n",
      "Epoch 30:  50%|▌| 3/6 [00:00<00:00,  9.86it/s, loss=0.345, val_loss=0.862, avg_v\n",
      "Epoch 30: 100%|█| 6/6 [00:00<00:00, 17.36it/s, loss=0.345, val_loss=0.609, avg_v\n",
      "Epoch 31:  50%|▌| 3/6 [00:00<00:00, 11.38it/s, loss=0.302, val_loss=0.609, avg_v\n",
      "Epoch 31: 100%|█| 6/6 [00:00<00:00, 19.60it/s, loss=0.302, val_loss=0.487, avg_v\n",
      "Epoch 32:  50%|▌| 3/6 [00:00<00:00, 11.26it/s, loss=0.26, val_loss=0.487, avg_va\n",
      "Epoch 32: 100%|█| 6/6 [00:00<00:00, 19.09it/s, loss=0.26, val_loss=0.425, avg_va\n",
      "Epoch 33:  50%|▌| 3/6 [00:00<00:00,  9.56it/s, loss=0.237, val_loss=0.425, avg_v\n",
      "Epoch 33: 100%|█| 6/6 [00:00<00:00, 16.56it/s, loss=0.237, val_loss=0.357, avg_v\n",
      "Epoch 34:  50%|▌| 3/6 [00:00<00:00, 10.13it/s, loss=0.226, val_loss=0.357, avg_v\n",
      "Epoch 34: 100%|█| 6/6 [00:00<00:00, 17.48it/s, loss=0.226, val_loss=0.301, avg_v\n",
      "Epoch 35:  50%|▌| 3/6 [00:00<00:00, 10.57it/s, loss=0.209, val_loss=0.301, avg_v\n",
      "Epoch 35: 100%|█| 6/6 [00:00<00:00, 18.49it/s, loss=0.209, val_loss=0.266, avg_v\n",
      "Epoch 36:  50%|▌| 3/6 [00:00<00:00, 11.25it/s, loss=0.192, val_loss=0.266, avg_v\n",
      "Epoch 36: 100%|█| 6/6 [00:00<00:00, 18.56it/s, loss=0.192, val_loss=0.245, avg_v\n",
      "Epoch 37:  50%|▌| 3/6 [00:00<00:00, 10.96it/s, loss=0.182, val_loss=0.245, avg_v\n",
      "Epoch 37: 100%|█| 6/6 [00:00<00:00, 18.10it/s, loss=0.182, val_loss=0.226, avg_v\n",
      "Epoch 38:  50%|▌| 3/6 [00:00<00:00, 10.44it/s, loss=0.176, val_loss=0.226, avg_v\n",
      "Epoch 38: 100%|█| 6/6 [00:00<00:00, 17.21it/s, loss=0.176, val_loss=0.215, avg_v\n",
      "Epoch 39:  50%|▌| 3/6 [00:00<00:00, 11.27it/s, loss=0.168, val_loss=0.215, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 19.44it/s, loss=0.168, val_loss=0.208, avg_v\n",
      "Epoch 39: 100%|█| 6/6 [00:00<00:00, 19.22it/s, loss=0.168, val_loss=0.208, avg_v\n",
      "Sizes of clusters: 186, 58, 56\n",
      "\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 1 2 2 1 1 2 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1\n",
      " 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 1 1 1 1 2 1 1 0 2 2 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 2 1\n",
      " 2 1 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6633\n",
      "\n",
      "Consistency: 1.0000\n",
      "Purity: 0.6633333333333334+-0.0\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K3_C1' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00,  9.35it/s, loss=266, val_loss=0.08, avg_val_\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 16.68it/s, loss=266, val_loss=0.08, avg_val\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 16.16it/s, loss=266, val_loss=0.113, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 10.32it/s, loss=136, val_loss=0.113, avg_val\u001b[A\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 17.78it/s, loss=136, val_loss=0.227, avg_va\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00,  9.99it/s, loss=8.92, val_loss=0.227, avg_va\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 17.54it/s, loss=8.92, val_loss=0.184, avg_v\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 10.42it/s, loss=2.34, val_loss=0.184, avg_va\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 18.26it/s, loss=2.34, val_loss=0.143, avg_v\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 10.39it/s, loss=0.911, val_loss=0.143, avg_v\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 18.20it/s, loss=0.911, val_loss=0.145, avg_\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 10.52it/s, loss=0.436, val_loss=0.145, avg_v\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 18.33it/s, loss=0.436, val_loss=0.14, avg_v\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00,  9.88it/s, loss=0.228, val_loss=0.14, avg_va\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 17.54it/s, loss=0.228, val_loss=0.0931, avg\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 10.29it/s, loss=0.118, val_loss=0.0931, avg_\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 18.10it/s, loss=0.118, val_loss=0.0728, avg\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 10.43it/s, loss=0.0705, val_loss=0.0728, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 18.28it/s, loss=0.0705, val_loss=0.0516, av\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 10.41it/s, loss=0.0483, val_loss=0.0516, avg\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 18.08it/s, loss=0.0483, val_loss=0.0558, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 10.60it/s, loss=0.037, val_loss=0.0558, avg\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 18.08it/s, loss=0.037, val_loss=0.041, avg\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 10.36it/s, loss=0.031, val_loss=0.041, avg_\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 17.95it/s, loss=0.031, val_loss=0.0401, av\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 10.59it/s, loss=0.0269, val_loss=0.0401, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 18.45it/s, loss=0.0269, val_loss=0.0343, a\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 10.48it/s, loss=0.0243, val_loss=0.0343, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 18.42it/s, loss=0.0243, val_loss=0.0322, a\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 10.51it/s, loss=0.0223, val_loss=0.0322, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 18.40it/s, loss=0.0223, val_loss=0.0295, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 10.74it/s, loss=0.0208, val_loss=0.0295, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 18.64it/s, loss=0.0208, val_loss=0.0278, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 10.38it/s, loss=0.0195, val_loss=0.0278, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 17.80it/s, loss=0.0195, val_loss=0.0257, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 10.19it/s, loss=0.0184, val_loss=0.0257, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 17.94it/s, loss=0.0184, val_loss=0.0244, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00,  9.99it/s, loss=0.0175, val_loss=0.0244, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 17.62it/s, loss=0.0175, val_loss=0.023, av\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00,  9.91it/s, loss=0.0167, val_loss=0.023, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 16.89it/s, loss=0.0167, val_loss=0.0218, a\u001b[A\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 10.29it/s, loss=0.0159, val_loss=0.0218, av\u001b[A\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 18.12it/s, loss=0.0159, val_loss=0.0208, a\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 10.62it/s, loss=0.0153, val_loss=0.0208, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 18.49it/s, loss=0.0153, val_loss=0.0198, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00,  9.86it/s, loss=0.0147, val_loss=0.0198, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 17.54it/s, loss=0.0147, val_loss=0.0189, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 10.71it/s, loss=0.0142, val_loss=0.0189, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 18.41it/s, loss=0.0142, val_loss=0.0182, a\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 10.25it/s, loss=0.0137, val_loss=0.0182, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 17.79it/s, loss=0.0137, val_loss=0.0175, a\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 10.53it/s, loss=0.0133, val_loss=0.0175, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 18.35it/s, loss=0.0133, val_loss=0.0168, a\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 10.53it/s, loss=0.0129, val_loss=0.0168, av\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 18.47it/s, loss=0.0129, val_loss=0.0163, a\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 10.21it/s, loss=0.0125, val_loss=0.0163, av\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 17.93it/s, loss=0.0125, val_loss=0.0158, a\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.05it/s, loss=0.0122, val_loss=0.0158, av\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 19.24it/s, loss=0.0122, val_loss=0.0153, a\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 10.40it/s, loss=0.0119, val_loss=0.0153, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 18.06it/s, loss=0.0119, val_loss=0.0149, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 10.55it/s, loss=0.0116, val_loss=0.0149, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 18.64it/s, loss=0.0116, val_loss=0.0145, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 10.14it/s, loss=0.0113, val_loss=0.0145, av\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 18.02it/s, loss=0.0113, val_loss=0.0142, a\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 10.45it/s, loss=0.011, val_loss=0.0142, avg\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 18.43it/s, loss=0.011, val_loss=0.0139, av\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 10.50it/s, loss=0.0108, val_loss=0.0139, av\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 18.55it/s, loss=0.0108, val_loss=0.0136, a\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00,  9.98it/s, loss=0.0106, val_loss=0.0136, av\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 17.64it/s, loss=0.0106, val_loss=0.0133, a\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 10.46it/s, loss=0.0103, val_loss=0.0133, av\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 18.32it/s, loss=0.0103, val_loss=0.013, av\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 10.57it/s, loss=0.0101, val_loss=0.013, avg\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 18.48it/s, loss=0.0101, val_loss=0.0128, a\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00,  9.78it/s, loss=0.00992, val_loss=0.0128, a\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 17.30it/s, loss=0.00992, val_loss=0.0125, \n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 10.24it/s, loss=0.00972, val_loss=0.0125, a\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 17.81it/s, loss=0.00972, val_loss=0.0123, \n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 10.43it/s, loss=0.00954, val_loss=0.0123, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 18.39it/s, loss=0.00954, val_loss=0.012, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 18.26it/s, loss=0.00954, val_loss=0.012, a\n",
      "Sizes of clusters: 381, 419\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9738\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 10.02it/s, loss=222, val_loss=0.0697, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 17.70it/s, loss=222, val_loss=0.0507, avg_v\n",
      "Epoch 1:  56%|▌| 9/16 [00:00<00:00, 11.69it/s, loss=114, val_loss=0.0507, avg_va\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 18.21it/s, loss=114, val_loss=0.0821, avg_v\n",
      "Epoch 2:  56%|▌| 9/16 [00:00<00:00, 11.33it/s, loss=9.58, val_loss=0.0821, avg_v\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 17.89it/s, loss=9.58, val_loss=0.137, avg_v\n",
      "Epoch 3:  56%|▌| 9/16 [00:00<00:00, 11.14it/s, loss=2.09, val_loss=0.137, avg_va\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 17.61it/s, loss=2.09, val_loss=0.13, avg_va\n",
      "Epoch 4:  56%|▌| 9/16 [00:00<00:00, 11.91it/s, loss=0.831, val_loss=0.13, avg_va\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 18.53it/s, loss=0.831, val_loss=0.114, avg_\n",
      "Epoch 5:  56%|▌| 9/16 [00:00<00:00, 11.37it/s, loss=0.351, val_loss=0.114, avg_v\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 17.56it/s, loss=0.351, val_loss=0.105, avg_\n",
      "Epoch 6:  56%|▌| 9/16 [00:00<00:00, 11.50it/s, loss=0.18, val_loss=0.105, avg_va\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 18.00it/s, loss=0.18, val_loss=0.078, avg_v\n",
      "Epoch 7:  56%|▌| 9/16 [00:00<00:00, 11.81it/s, loss=0.1, val_loss=0.078, avg_val\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 18.14it/s, loss=0.1, val_loss=0.0581, avg_v\u001b[A\n",
      "Epoch 8:  56%|▌| 9/16 [00:00<00:00, 11.29it/s, loss=0.06, val_loss=0.0581, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 17.49it/s, loss=0.06, val_loss=0.0445, avg_\u001b[A\n",
      "Epoch 9:  56%|▌| 9/16 [00:00<00:00, 11.37it/s, loss=0.0432, val_loss=0.0445, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 17.59it/s, loss=0.0432, val_loss=0.0366, av\u001b[A\n",
      "Epoch 10:  56%|▌| 9/16 [00:00<00:00, 11.51it/s, loss=0.0338, val_loss=0.0366, av\u001b[A\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 18.03it/s, loss=0.0338, val_loss=0.0344, a\n",
      "Epoch 11:  56%|▌| 9/16 [00:00<00:00, 11.66it/s, loss=0.0288, val_loss=0.0344, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 18.25it/s, loss=0.0288, val_loss=0.03, avg\n",
      "Epoch 12:  56%|▌| 9/16 [00:00<00:00, 11.30it/s, loss=0.0257, val_loss=0.03, avg_\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 17.73it/s, loss=0.0257, val_loss=0.0308, a\n",
      "Epoch 13:  56%|▌| 9/16 [00:00<00:00, 11.46it/s, loss=0.0238, val_loss=0.0308, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 17.96it/s, loss=0.0238, val_loss=0.028, av\n",
      "Epoch 14:  56%|▌| 9/16 [00:00<00:00, 11.61it/s, loss=0.0225, val_loss=0.028, avg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 18.15it/s, loss=0.0225, val_loss=0.0277, a\n",
      "Epoch 15:  56%|▌| 9/16 [00:00<00:00, 12.17it/s, loss=0.0213, val_loss=0.0277, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 19.00it/s, loss=0.0213, val_loss=0.027, av\n",
      "Epoch 16:  56%|▌| 9/16 [00:00<00:00, 11.83it/s, loss=0.0204, val_loss=0.027, avg\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 18.51it/s, loss=0.0204, val_loss=0.0264, a\n",
      "Epoch 17:  56%|▌| 9/16 [00:00<00:00, 11.64it/s, loss=0.0195, val_loss=0.0264, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 18.03it/s, loss=0.0195, val_loss=0.0262, a\n",
      "Epoch 18:  56%|▌| 9/16 [00:00<00:00, 11.26it/s, loss=0.0188, val_loss=0.0262, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 17.44it/s, loss=0.0188, val_loss=0.0259, a\n",
      "Epoch 19:  56%|▌| 9/16 [00:00<00:00, 11.70it/s, loss=0.0182, val_loss=0.0259, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 18.18it/s, loss=0.0182, val_loss=0.0255, a\n",
      "Epoch 20:  56%|▌| 9/16 [00:00<00:00, 11.92it/s, loss=0.0176, val_loss=0.0255, av\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 18.69it/s, loss=0.0176, val_loss=0.0247, a\n",
      "Epoch 21:  56%|▌| 9/16 [00:00<00:00, 11.37it/s, loss=0.0171, val_loss=0.0247, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 17.86it/s, loss=0.0171, val_loss=0.0237, a\n",
      "Epoch 22:  56%|▌| 9/16 [00:00<00:00, 11.53it/s, loss=0.0166, val_loss=0.0237, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 18.12it/s, loss=0.0166, val_loss=0.0223, a\n",
      "Epoch 23:  56%|▌| 9/16 [00:00<00:00, 11.60it/s, loss=0.0162, val_loss=0.0223, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 18.04it/s, loss=0.0162, val_loss=0.0209, a\n",
      "Epoch 24:  56%|▌| 9/16 [00:00<00:00, 11.63it/s, loss=0.0157, val_loss=0.0209, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 18.26it/s, loss=0.0157, val_loss=0.0195, a\n",
      "Epoch 25:  56%|▌| 9/16 [00:00<00:00, 11.16it/s, loss=0.0152, val_loss=0.0195, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 17.52it/s, loss=0.0152, val_loss=0.0185, a\n",
      "Epoch 26:  56%|▌| 9/16 [00:00<00:00, 11.33it/s, loss=0.0148, val_loss=0.0185, av\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 17.73it/s, loss=0.0148, val_loss=0.0177, a\n",
      "Epoch 27:  56%|▌| 9/16 [00:00<00:00, 11.86it/s, loss=0.0143, val_loss=0.0177, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 17.72it/s, loss=0.0143, val_loss=0.0172, a\u001b[A\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00,  9.55it/s, loss=0.0139, val_loss=0.0172, av\u001b[A\n",
      "Epoch 28:  75%|▊| 12/16 [00:00<00:00, 13.51it/s, loss=0.0139, val_loss=0.0172, a\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 16.72it/s, loss=0.0139, val_loss=0.0167, a\u001b[A\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 10.44it/s, loss=0.0135, val_loss=0.0167, av\u001b[A\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 18.35it/s, loss=0.0135, val_loss=0.0162, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 10.15it/s, loss=0.0131, val_loss=0.0162, av\n",
      "Epoch 30:  75%|▊| 12/16 [00:00<00:00, 14.69it/s, loss=0.0131, val_loss=0.0162, a\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 17.58it/s, loss=0.0131, val_loss=0.0156, a\u001b[A\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 10.09it/s, loss=0.0128, val_loss=0.0156, av\u001b[A\n",
      "Epoch 31:  75%|▊| 12/16 [00:00<00:00, 14.24it/s, loss=0.0128, val_loss=0.0156, a\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 17.03it/s, loss=0.0128, val_loss=0.015, av\u001b[A\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 10.59it/s, loss=0.0125, val_loss=0.015, avg\u001b[A\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 18.48it/s, loss=0.0125, val_loss=0.0144, a\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 10.49it/s, loss=0.0123, val_loss=0.0144, av\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 18.40it/s, loss=0.0123, val_loss=0.0138, a\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 10.52it/s, loss=0.012, val_loss=0.0138, avg\n",
      "Epoch 34:  75%|▊| 12/16 [00:00<00:00, 14.96it/s, loss=0.012, val_loss=0.0138, av\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 18.15it/s, loss=0.012, val_loss=0.0133, av\u001b[A\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 10.26it/s, loss=0.0118, val_loss=0.0133, av\u001b[A\n",
      "Epoch 35:  75%|▊| 12/16 [00:00<00:00, 14.44it/s, loss=0.0118, val_loss=0.0133, a\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 17.27it/s, loss=0.0118, val_loss=0.0129, a\u001b[A\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 10.11it/s, loss=0.0115, val_loss=0.0129, av\u001b[A\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 17.97it/s, loss=0.0115, val_loss=0.0125, a\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00,  9.76it/s, loss=0.0113, val_loss=0.0125, av\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 17.05it/s, loss=0.0113, val_loss=0.0122, a\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 10.25it/s, loss=0.011, val_loss=0.0122, avg\n",
      "Epoch 38:  75%|▊| 12/16 [00:00<00:00, 14.71it/s, loss=0.011, val_loss=0.0122, av\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 17.85it/s, loss=0.011, val_loss=0.012, avg\u001b[A\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00,  9.84it/s, loss=0.0108, val_loss=0.012, avg\u001b[A\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.21it/s, loss=0.0108, val_loss=0.0118, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.11it/s, loss=0.0108, val_loss=0.0118, a\n",
      "Sizes of clusters: 382, 418\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9750\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 10.56it/s, loss=321, val_loss=0.0464, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 18.55it/s, loss=321, val_loss=0.0834, avg_v\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 10.17it/s, loss=164, val_loss=0.0834, avg_va\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 18.03it/s, loss=164, val_loss=0.208, avg_va\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 10.65it/s, loss=15.3, val_loss=0.208, avg_va\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 18.63it/s, loss=15.3, val_loss=0.3, avg_val\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 10.13it/s, loss=2.18, val_loss=0.3, avg_val_\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 17.81it/s, loss=2.18, val_loss=0.257, avg_v\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 10.79it/s, loss=0.867, val_loss=0.257, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 18.23it/s, loss=0.867, val_loss=0.195, avg_\u001b[A\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 10.37it/s, loss=0.401, val_loss=0.195, avg_v\u001b[A\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 17.97it/s, loss=0.401, val_loss=0.146, avg_\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 10.06it/s, loss=0.184, val_loss=0.146, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 17.29it/s, loss=0.184, val_loss=0.0973, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 10.59it/s, loss=0.103, val_loss=0.0973, avg_\u001b[A\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 18.60it/s, loss=0.103, val_loss=0.0935, avg\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 10.50it/s, loss=0.0652, val_loss=0.0935, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 18.21it/s, loss=0.0652, val_loss=0.0615, av\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 10.30it/s, loss=0.0439, val_loss=0.0615, avg\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 18.20it/s, loss=0.0439, val_loss=0.0553, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 10.16it/s, loss=0.034, val_loss=0.0553, avg\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 18.00it/s, loss=0.034, val_loss=0.047, avg\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 10.12it/s, loss=0.0281, val_loss=0.047, avg\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 17.76it/s, loss=0.0281, val_loss=0.0396, a\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00,  9.84it/s, loss=0.0248, val_loss=0.0396, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 16.89it/s, loss=0.0248, val_loss=0.0386, a\u001b[A\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 10.58it/s, loss=0.0224, val_loss=0.0386, av\u001b[A\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 18.55it/s, loss=0.0224, val_loss=0.034, av\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 10.49it/s, loss=0.0206, val_loss=0.034, avg\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 18.56it/s, loss=0.0206, val_loss=0.0317, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 10.34it/s, loss=0.0193, val_loss=0.0317, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 18.15it/s, loss=0.0193, val_loss=0.0294, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 10.59it/s, loss=0.0181, val_loss=0.0294, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 18.63it/s, loss=0.0181, val_loss=0.0278, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 10.46it/s, loss=0.0172, val_loss=0.0278, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 18.30it/s, loss=0.0172, val_loss=0.0261, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 10.17it/s, loss=0.0164, val_loss=0.0261, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 17.50it/s, loss=0.0164, val_loss=0.025, av\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 10.41it/s, loss=0.0156, val_loss=0.025, avg\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 18.25it/s, loss=0.0156, val_loss=0.0237, a\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 10.28it/s, loss=0.015, val_loss=0.0237, avg\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 18.05it/s, loss=0.015, val_loss=0.0226, av\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 10.87it/s, loss=0.0144, val_loss=0.0226, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 18.82it/s, loss=0.0144, val_loss=0.0217, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 10.57it/s, loss=0.0139, val_loss=0.0217, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 18.60it/s, loss=0.0139, val_loss=0.0209, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 10.09it/s, loss=0.0134, val_loss=0.0209, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 17.75it/s, loss=0.0134, val_loss=0.0201, a\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00,  9.69it/s, loss=0.0129, val_loss=0.0201, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 17.14it/s, loss=0.0129, val_loss=0.0193, a\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 10.31it/s, loss=0.0125, val_loss=0.0193, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 17.94it/s, loss=0.0125, val_loss=0.0186, a\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 10.07it/s, loss=0.0122, val_loss=0.0186, av\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 17.89it/s, loss=0.0122, val_loss=0.018, av\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00,  9.97it/s, loss=0.0118, val_loss=0.018, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 17.08it/s, loss=0.0118, val_loss=0.0174, a\u001b[A\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00,  9.02it/s, loss=0.0115, val_loss=0.0174, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 16/16 [00:01<00:00, 15.70it/s, loss=0.0115, val_loss=0.0169, a\u001b[A\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 10.17it/s, loss=0.0112, val_loss=0.0169, av\u001b[A\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 17.66it/s, loss=0.0112, val_loss=0.0164, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00,  9.63it/s, loss=0.0109, val_loss=0.0164, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 16.77it/s, loss=0.0109, val_loss=0.0159, a\u001b[A\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00,  9.91it/s, loss=0.0106, val_loss=0.0159, av\u001b[A\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 17.49it/s, loss=0.0106, val_loss=0.0155, a\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 10.60it/s, loss=0.0103, val_loss=0.0155, av\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 18.54it/s, loss=0.0103, val_loss=0.0151, a\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00,  8.38it/s, loss=0.0101, val_loss=0.0151, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 16/16 [00:01<00:00, 14.63it/s, loss=0.0101, val_loss=0.0147, a\u001b[A\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00,  9.82it/s, loss=0.00988, val_loss=0.0147, a\u001b[A\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 17.16it/s, loss=0.00988, val_loss=0.0143, \n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00,  9.99it/s, loss=0.00967, val_loss=0.0143, a\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 17.74it/s, loss=0.00967, val_loss=0.014, a\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00,  9.98it/s, loss=0.00946, val_loss=0.014, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 17.37it/s, loss=0.00946, val_loss=0.0137, \u001b[A\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00,  9.02it/s, loss=0.00927, val_loss=0.0137, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 16/16 [00:01<00:00, 15.73it/s, loss=0.00927, val_loss=0.0134, \u001b[A\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 10.16it/s, loss=0.00909, val_loss=0.0134, a\u001b[A\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 17.76it/s, loss=0.00909, val_loss=0.0131, \n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00,  9.48it/s, loss=0.00893, val_loss=0.0131, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 16.79it/s, loss=0.00893, val_loss=0.0128, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 16.49it/s, loss=0.00893, val_loss=0.0128, \n",
      "Sizes of clusters: 400, 400\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 1.0000\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00,  9.92it/s, loss=233, val_loss=0.0743, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 17.25it/s, loss=233, val_loss=0.158, avg_va\n",
      "Epoch 1:  56%|▌| 9/16 [00:00<00:00, 11.38it/s, loss=121, val_loss=0.158, avg_val\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 17.83it/s, loss=121, val_loss=0.349, avg_va\n",
      "Epoch 2:  56%|▌| 9/16 [00:00<00:00, 10.93it/s, loss=12.4, val_loss=0.349, avg_va\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 17.15it/s, loss=12.4, val_loss=0.331, avg_v\n",
      "Epoch 3:  56%|▌| 9/16 [00:00<00:00, 10.76it/s, loss=2.78, val_loss=0.331, avg_va\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 17.10it/s, loss=2.78, val_loss=0.247, avg_v\n",
      "Epoch 4:  56%|▌| 9/16 [00:00<00:00, 11.54it/s, loss=1.12, val_loss=0.247, avg_va\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 18.02it/s, loss=1.12, val_loss=0.17, avg_va\n",
      "Epoch 5:  56%|▌| 9/16 [00:00<00:00, 11.40it/s, loss=0.502, val_loss=0.17, avg_va\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 17.95it/s, loss=0.502, val_loss=0.11, avg_v\n",
      "Epoch 6:  56%|▌| 9/16 [00:00<00:00, 11.73it/s, loss=0.239, val_loss=0.11, avg_va\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 18.34it/s, loss=0.239, val_loss=0.0721, avg\n",
      "Epoch 7:  56%|▌| 9/16 [00:00<00:00, 11.35it/s, loss=0.129, val_loss=0.0721, avg_\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 17.85it/s, loss=0.129, val_loss=0.0678, avg\n",
      "Epoch 8:  56%|▌| 9/16 [00:00<00:00, 11.21it/s, loss=0.0774, val_loss=0.0678, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 17.36it/s, loss=0.0774, val_loss=0.0612, av\u001b[A\n",
      "Epoch 9:  56%|▌| 9/16 [00:00<00:00, 11.93it/s, loss=0.0526, val_loss=0.0612, avg\u001b[A\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 18.51it/s, loss=0.0526, val_loss=0.0496, av\n",
      "Epoch 10:  56%|▌| 9/16 [00:00<00:00, 10.82it/s, loss=0.04, val_loss=0.0496, avg_\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 17.15it/s, loss=0.04, val_loss=0.0482, avg\n",
      "Epoch 11:  56%|▌| 9/16 [00:00<00:00, 11.57it/s, loss=0.0332, val_loss=0.0482, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 18.07it/s, loss=0.0332, val_loss=0.0429, a\n",
      "Epoch 12:  56%|▌| 9/16 [00:00<00:00, 11.34it/s, loss=0.0291, val_loss=0.0429, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 17.71it/s, loss=0.0291, val_loss=0.0392, a\n",
      "Epoch 13:  56%|▌| 9/16 [00:00<00:00, 11.34it/s, loss=0.0264, val_loss=0.0392, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 17.75it/s, loss=0.0264, val_loss=0.0375, a\n",
      "Epoch 14:  56%|▌| 9/16 [00:00<00:00, 11.18it/s, loss=0.0244, val_loss=0.0375, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 17.25it/s, loss=0.0244, val_loss=0.0344, a\u001b[A\n",
      "Epoch 15:  56%|▌| 9/16 [00:00<00:00, 11.52it/s, loss=0.0228, val_loss=0.0344, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 17.51it/s, loss=0.0228, val_loss=0.0321, a\u001b[A\n",
      "Epoch 16:  56%|▌| 9/16 [00:00<00:00, 11.38it/s, loss=0.0215, val_loss=0.0321, av\u001b[A\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 17.89it/s, loss=0.0215, val_loss=0.0301, a\n",
      "Epoch 17:  56%|▌| 9/16 [00:00<00:00, 11.55it/s, loss=0.0203, val_loss=0.0301, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 18.08it/s, loss=0.0203, val_loss=0.0285, a\n",
      "Epoch 18:  56%|▌| 9/16 [00:00<00:00, 11.66it/s, loss=0.0193, val_loss=0.0285, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 18.09it/s, loss=0.0193, val_loss=0.0268, a\n",
      "Epoch 19:  56%|▌| 9/16 [00:00<00:00, 11.56it/s, loss=0.0184, val_loss=0.0268, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 18.20it/s, loss=0.0184, val_loss=0.0254, a\n",
      "Epoch 20:  56%|▌| 9/16 [00:00<00:00, 11.48it/s, loss=0.0176, val_loss=0.0254, av\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 17.94it/s, loss=0.0176, val_loss=0.0241, a\n",
      "Epoch 21:  56%|▌| 9/16 [00:00<00:00, 11.56it/s, loss=0.0169, val_loss=0.0241, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 17.78it/s, loss=0.0169, val_loss=0.0229, a\n",
      "Epoch 22:  56%|▌| 9/16 [00:00<00:00, 11.18it/s, loss=0.0162, val_loss=0.0229, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 17.10it/s, loss=0.0162, val_loss=0.0218, a\u001b[A\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 10.56it/s, loss=0.0155, val_loss=0.0218, av\u001b[A\n",
      "Epoch 23:  88%|▉| 14/16 [00:00<00:00, 16.83it/s, loss=0.0155, val_loss=0.0218, a\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 17.94it/s, loss=0.0155, val_loss=0.0209, a\u001b[A\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00,  9.95it/s, loss=0.015, val_loss=0.0209, avg\u001b[A\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 17.60it/s, loss=0.015, val_loss=0.02, avg_\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 10.11it/s, loss=0.0144, val_loss=0.02, avg_\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 17.60it/s, loss=0.0144, val_loss=0.0192, a\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 10.52it/s, loss=0.0139, val_loss=0.0192, av\n",
      "Epoch 26:  88%|▉| 14/16 [00:00<00:00, 16.85it/s, loss=0.0139, val_loss=0.0192, a\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 18.17it/s, loss=0.0139, val_loss=0.0184, a\u001b[A\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 10.28it/s, loss=0.0134, val_loss=0.0184, av\u001b[A\n",
      "Epoch 27:  88%|▉| 14/16 [00:00<00:00, 16.60it/s, loss=0.0134, val_loss=0.0184, a\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 17.87it/s, loss=0.0134, val_loss=0.0177, a\u001b[A\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00,  9.93it/s, loss=0.013, val_loss=0.0177, avg\u001b[A\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 17.49it/s, loss=0.013, val_loss=0.0171, av\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 10.31it/s, loss=0.0126, val_loss=0.0171, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 18.13it/s, loss=0.0126, val_loss=0.0165, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 10.10it/s, loss=0.0122, val_loss=0.0165, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 17.37it/s, loss=0.0122, val_loss=0.0159, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00,  9.95it/s, loss=0.0118, val_loss=0.0159, av\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 17.29it/s, loss=0.0118, val_loss=0.0154, a\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 10.43it/s, loss=0.0115, val_loss=0.0154, av\n",
      "Epoch 32:  88%|▉| 14/16 [00:00<00:00, 16.94it/s, loss=0.0115, val_loss=0.0154, a\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 18.22it/s, loss=0.0115, val_loss=0.0149, a\u001b[A\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00,  9.77it/s, loss=0.0111, val_loss=0.0149, av\u001b[A\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 17.18it/s, loss=0.0111, val_loss=0.0144, a\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00,  9.95it/s, loss=0.0108, val_loss=0.0144, av\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 17.51it/s, loss=0.0108, val_loss=0.014, av\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 10.09it/s, loss=0.0105, val_loss=0.014, avg\n",
      "Epoch 35:  88%|▉| 14/16 [00:00<00:00, 16.12it/s, loss=0.0105, val_loss=0.014, av\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 17.50it/s, loss=0.0105, val_loss=0.0135, a\u001b[A\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00,  9.80it/s, loss=0.0102, val_loss=0.0135, av\u001b[A\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 17.34it/s, loss=0.0102, val_loss=0.0131, a\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00,  9.96it/s, loss=0.00995, val_loss=0.0131, a\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 17.66it/s, loss=0.00995, val_loss=0.0128, \n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 10.33it/s, loss=0.0097, val_loss=0.0128, av\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 18.09it/s, loss=0.0097, val_loss=0.0124, a\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 10.22it/s, loss=0.00945, val_loss=0.0124, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.97it/s, loss=0.00945, val_loss=0.0121, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.39it/s, loss=0.00945, val_loss=0.0121, \n",
      "Sizes of clusters: 394, 406\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9900\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 10.18it/s, loss=260, val_loss=0.0904, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 18.03it/s, loss=260, val_loss=0.141, avg_va\n",
      "Epoch 1:  56%|▌| 9/16 [00:00<00:00, 11.55it/s, loss=134, val_loss=0.141, avg_val\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 18.05it/s, loss=134, val_loss=0.292, avg_va\n",
      "Epoch 2:  56%|▌| 9/16 [00:00<00:00, 11.30it/s, loss=11.4, val_loss=0.292, avg_va\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 17.62it/s, loss=11.4, val_loss=0.331, avg_v\u001b[A\n",
      "Epoch 3:  56%|▌| 9/16 [00:00<00:00, 11.35it/s, loss=2.74, val_loss=0.331, avg_va\u001b[A\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 17.85it/s, loss=2.74, val_loss=0.223, avg_v\n",
      "Epoch 4:  56%|▌| 9/16 [00:00<00:00, 11.78it/s, loss=1.19, val_loss=0.223, avg_va\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 18.33it/s, loss=1.19, val_loss=0.171, avg_v\n",
      "Epoch 5:  56%|▌| 9/16 [00:00<00:00, 10.83it/s, loss=0.524, val_loss=0.171, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 16.84it/s, loss=0.524, val_loss=0.116, avg_\u001b[A\n",
      "Epoch 6:  56%|▌| 9/16 [00:00<00:00, 11.06it/s, loss=0.25, val_loss=0.116, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 17.26it/s, loss=0.25, val_loss=0.103, avg_v\u001b[A\n",
      "Epoch 7:  56%|▌| 9/16 [00:00<00:00, 11.51it/s, loss=0.134, val_loss=0.103, avg_v\u001b[A\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 17.99it/s, loss=0.134, val_loss=0.0645, avg\n",
      "Epoch 8:  56%|▌| 9/16 [00:00<00:00, 11.53it/s, loss=0.0746, val_loss=0.0645, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 17.97it/s, loss=0.0746, val_loss=0.055, avg\n",
      "Epoch 9:  56%|▌| 9/16 [00:00<00:00, 11.88it/s, loss=0.0477, val_loss=0.055, avg_\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 18.67it/s, loss=0.0477, val_loss=0.0489, av\n",
      "Epoch 10:  56%|▌| 9/16 [00:00<00:00, 11.56it/s, loss=0.036, val_loss=0.0489, avg\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 18.08it/s, loss=0.036, val_loss=0.0397, av\n",
      "Epoch 11:  56%|▌| 9/16 [00:00<00:00, 11.56it/s, loss=0.0292, val_loss=0.0397, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 18.07it/s, loss=0.0292, val_loss=0.0354, a\n",
      "Epoch 12:  56%|▌| 9/16 [00:00<00:00, 11.37it/s, loss=0.0255, val_loss=0.0354, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 17.81it/s, loss=0.0255, val_loss=0.0317, a\n",
      "Epoch 13:  56%|▌| 9/16 [00:00<00:00, 11.18it/s, loss=0.0232, val_loss=0.0317, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 17.55it/s, loss=0.0232, val_loss=0.0292, a\n",
      "Epoch 14:  56%|▌| 9/16 [00:00<00:00, 11.74it/s, loss=0.0213, val_loss=0.0292, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 18.37it/s, loss=0.0213, val_loss=0.0268, a\n",
      "Epoch 15:  56%|▌| 9/16 [00:00<00:00, 11.40it/s, loss=0.0199, val_loss=0.0268, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 17.98it/s, loss=0.0199, val_loss=0.0248, a\n",
      "Epoch 16:  56%|▌| 9/16 [00:00<00:00, 11.33it/s, loss=0.0189, val_loss=0.0248, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 17.72it/s, loss=0.0189, val_loss=0.0233, a\n",
      "Epoch 17:  56%|▌| 9/16 [00:00<00:00, 11.92it/s, loss=0.0179, val_loss=0.0233, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 18.59it/s, loss=0.0179, val_loss=0.022, av\n",
      "Epoch 18:  56%|▌| 9/16 [00:00<00:00, 11.69it/s, loss=0.0172, val_loss=0.022, avg\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 18.26it/s, loss=0.0172, val_loss=0.0209, a\n",
      "Epoch 19:  56%|▌| 9/16 [00:00<00:00, 11.73it/s, loss=0.0165, val_loss=0.0209, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 18.22it/s, loss=0.0165, val_loss=0.02, avg\u001b[A\n",
      "Epoch 20:  56%|▌| 9/16 [00:00<00:00, 11.41it/s, loss=0.0159, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 17.73it/s, loss=0.0159, val_loss=0.0192, a\n",
      "Epoch 21:  56%|▌| 9/16 [00:00<00:00, 11.73it/s, loss=0.0154, val_loss=0.0192, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 18.03it/s, loss=0.0154, val_loss=0.0185, a\n",
      "Epoch 22:  56%|▌| 9/16 [00:00<00:00, 11.57it/s, loss=0.0149, val_loss=0.0185, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 18.06it/s, loss=0.0149, val_loss=0.0179, a\n",
      "Epoch 23:  56%|▌| 9/16 [00:00<00:00, 11.62it/s, loss=0.0145, val_loss=0.0179, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 18.16it/s, loss=0.0145, val_loss=0.0173, a\n",
      "Epoch 24:  56%|▌| 9/16 [00:00<00:00, 10.56it/s, loss=0.0142, val_loss=0.0173, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 16.70it/s, loss=0.0142, val_loss=0.0167, a\n",
      "Epoch 25:  56%|▌| 9/16 [00:00<00:00, 11.75it/s, loss=0.0138, val_loss=0.0167, av\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 18.02it/s, loss=0.0138, val_loss=0.0161, a\u001b[A\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 10.14it/s, loss=0.0135, val_loss=0.0161, av\u001b[A\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 17.55it/s, loss=0.0135, val_loss=0.0155, a\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00,  9.66it/s, loss=0.0132, val_loss=0.0155, av\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 16.81it/s, loss=0.0132, val_loss=0.0149, a\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 10.21it/s, loss=0.013, val_loss=0.0149, avg\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 17.89it/s, loss=0.013, val_loss=0.0142, av\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00,  9.83it/s, loss=0.0127, val_loss=0.0142, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 17.34it/s, loss=0.0127, val_loss=0.0137, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 10.61it/s, loss=0.0123, val_loss=0.0137, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 18.28it/s, loss=0.0123, val_loss=0.0133, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00,  9.80it/s, loss=0.012, val_loss=0.0133, avg\n",
      "Epoch 31:  88%|▉| 14/16 [00:00<00:00, 15.65it/s, loss=0.012, val_loss=0.0133, av\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 16.97it/s, loss=0.012, val_loss=0.013, avg\u001b[A\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 10.39it/s, loss=0.0117, val_loss=0.013, avg\u001b[A\n",
      "Epoch 32:  88%|▉| 14/16 [00:00<00:00, 16.18it/s, loss=0.0117, val_loss=0.013, av\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 17.55it/s, loss=0.0117, val_loss=0.0129, a\u001b[A\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00,  9.84it/s, loss=0.0114, val_loss=0.0129, av\u001b[A\n",
      "Epoch 33:  88%|▉| 14/16 [00:00<00:00, 15.82it/s, loss=0.0114, val_loss=0.0129, a\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 16.99it/s, loss=0.0114, val_loss=0.0127, a\u001b[A\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 10.28it/s, loss=0.0112, val_loss=0.0127, av\u001b[A\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 18.07it/s, loss=0.0112, val_loss=0.0127, a\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 10.42it/s, loss=0.0109, val_loss=0.0127, av\n",
      "Epoch 35:  88%|▉| 14/16 [00:00<00:00, 16.87it/s, loss=0.0109, val_loss=0.0127, a\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 18.02it/s, loss=0.0109, val_loss=0.0126, a\u001b[A\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00,  9.91it/s, loss=0.0107, val_loss=0.0126, av\u001b[A\n",
      "Epoch 36:  88%|▉| 14/16 [00:00<00:00, 16.00it/s, loss=0.0107, val_loss=0.0126, a\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 17.26it/s, loss=0.0107, val_loss=0.0125, a\u001b[A\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 10.00it/s, loss=0.0106, val_loss=0.0125, av\u001b[A\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 17.39it/s, loss=0.0106, val_loss=0.0125, a\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00,  9.18it/s, loss=0.0104, val_loss=0.0125, av\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 16.15it/s, loss=0.0104, val_loss=0.0124, a\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 10.01it/s, loss=0.0103, val_loss=0.0124, av\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.70it/s, loss=0.0103, val_loss=0.0124, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 17.51it/s, loss=0.0103, val_loss=0.0124, a\n",
      "Sizes of clusters: 375, 425\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9613\n",
      "\n",
      "Consistency: 0.9519\n",
      "Purity: 0.9800000000000001+-0.013532368602724327\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K2_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 10.71it/s, loss=176, val_loss=0.0674, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 18.78it/s, loss=176, val_loss=0.376, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 10.87it/s, loss=9.57, val_loss=0.376, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 19.00it/s, loss=9.57, val_loss=0.362, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 10.80it/s, loss=1.35, val_loss=0.362, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 19.02it/s, loss=1.35, val_loss=0.17, avg_va\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 10.51it/s, loss=0.388, val_loss=0.17, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 18.39it/s, loss=0.388, val_loss=0.104, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 10.41it/s, loss=0.133, val_loss=0.104, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 18.33it/s, loss=0.133, val_loss=0.0537, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.02it/s, loss=0.0592, val_loss=0.0537, av\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.18it/s, loss=0.0592, val_loss=0.0537, av\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 19.42it/s, loss=0.0592, val_loss=0.0414, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 10.40it/s, loss=0.0348, val_loss=0.0414, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 18.34it/s, loss=0.0348, val_loss=0.0342, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.0261, val_loss=0.0342, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 18.55it/s, loss=0.0261, val_loss=0.0303, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 10.20it/s, loss=0.0226, val_loss=0.0303, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 18.07it/s, loss=0.0226, val_loss=0.027, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 10.33it/s, loss=0.0206, val_loss=0.027, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 18.18it/s, loss=0.0206, val_loss=0.0249, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 10.80it/s, loss=0.0192, val_loss=0.0249, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 18.85it/s, loss=0.0192, val_loss=0.0232, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 10.70it/s, loss=0.0181, val_loss=0.0232, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 18.86it/s, loss=0.0181, val_loss=0.0218, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 10.73it/s, loss=0.0172, val_loss=0.0218, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 18.91it/s, loss=0.0172, val_loss=0.0207, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 10.58it/s, loss=0.0164, val_loss=0.0207, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 18.59it/s, loss=0.0164, val_loss=0.0197, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 10.82it/s, loss=0.0156, val_loss=0.0197, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 19.05it/s, loss=0.0156, val_loss=0.0189, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 10.69it/s, loss=0.0149, val_loss=0.0189, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 18.89it/s, loss=0.0149, val_loss=0.0181, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.0143, val_loss=0.0181, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 18.53it/s, loss=0.0143, val_loss=0.0174, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 10.72it/s, loss=0.0137, val_loss=0.0174, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 18.86it/s, loss=0.0137, val_loss=0.0167, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 10.68it/s, loss=0.0132, val_loss=0.0167, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 18.65it/s, loss=0.0132, val_loss=0.0161, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 10.21it/s, loss=0.0127, val_loss=0.0161, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 18.11it/s, loss=0.0127, val_loss=0.0155, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 10.78it/s, loss=0.0122, val_loss=0.0155, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 18.72it/s, loss=0.0122, val_loss=0.015, av\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 10.74it/s, loss=0.0118, val_loss=0.015, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 18.74it/s, loss=0.0118, val_loss=0.0144, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 10.47it/s, loss=0.0114, val_loss=0.0144, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 18.34it/s, loss=0.0114, val_loss=0.0139, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 10.22it/s, loss=0.011, val_loss=0.0139, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 18.02it/s, loss=0.011, val_loss=0.0134, av\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 10.31it/s, loss=0.0106, val_loss=0.0134, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 18.15it/s, loss=0.0106, val_loss=0.013, av\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=0.0103, val_loss=0.013, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 18.48it/s, loss=0.0103, val_loss=0.0125, a\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 10.45it/s, loss=0.00996, val_loss=0.0125, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 18.19it/s, loss=0.00996, val_loss=0.0121, \u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 10.58it/s, loss=0.00965, val_loss=0.0121, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 18.70it/s, loss=0.00965, val_loss=0.0117, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 10.64it/s, loss=0.00936, val_loss=0.0117, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 18.72it/s, loss=0.00936, val_loss=0.0113, \u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 10.54it/s, loss=0.00909, val_loss=0.0113, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 17.65it/s, loss=0.00909, val_loss=0.011, a\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.00884, val_loss=0.011, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 18.80it/s, loss=0.00884, val_loss=0.0107, \u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 10.60it/s, loss=0.0086, val_loss=0.0107, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 18.72it/s, loss=0.0086, val_loss=0.0103, a\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.00837, val_loss=0.0103, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 19.10it/s, loss=0.00837, val_loss=0.01, av\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01,  9.99it/s, loss=0.00816, val_loss=0.01, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 17.70it/s, loss=0.00816, val_loss=0.00976,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.00796, val_loss=0.00976,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 18.50it/s, loss=0.00796, val_loss=0.0095, \u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 10.40it/s, loss=0.00778, val_loss=0.0095, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 18.28it/s, loss=0.00778, val_loss=0.00926,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 10.57it/s, loss=0.0076, val_loss=0.00926, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 18.62it/s, loss=0.0076, val_loss=0.00902, \u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 10.43it/s, loss=0.00744, val_loss=0.00902,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 18.49it/s, loss=0.00744, val_loss=0.0088, \u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 10.45it/s, loss=0.00728, val_loss=0.0088, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 18.40it/s, loss=0.00728, val_loss=0.00859,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 10.89it/s, loss=0.00714, val_loss=0.00859,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 19.19it/s, loss=0.00714, val_loss=0.00838,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 19.02it/s, loss=0.00714, val_loss=0.00838,\u001b[A\n",
      "Sizes of clusters: 256, 542, 402\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2\n",
      " 0 2 2 2 2 2 2 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 0 0 0 0 0 1 1 0 2 0 2 1\n",
      " 1 1 0 1 1 0 1 1 1 2 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 2 0 0 1 1 1 1 1 0 0\n",
      " 1 1 0 0 1 1 0 2 0 0 1 0 0 2 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 2 0 1 1 0 1 0 0 2 0 1 2 1 1 2 0 0 0 1\n",
      " 1 0 0 0 0 0 1 2 1 2 0 1 1 2 2 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 2 1 1 0\n",
      " 0 1 1 1 0 0 0 1 0 1 1 1 0 2 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 0 1 0 0 1 2 0 1\n",
      " 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 2 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 0 0 2 0 0 0 0 0 0 0 2 0 1 0 0 0 1 2 2 0 0 1 0 0 1 0 2 2 0 1 0 0\n",
      " 2 0 1 1 1 2 1 1 1 0 0 1 1 0 0 0 1 1 2 0 1 2 0 0 0 0 2 1 0 1 0 1 0 0 1 0 0\n",
      " 2 1 0 2 0 0 1 0 2 0 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 0\n",
      " 0 2 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 2 2 1 0 1 0 0 1 0 0 0\n",
      " 1 1 1 0 1 0 0 1 1 0 1 0 1 2 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.7600\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=166, val_loss=0.0497, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 18.39it/s, loss=166, val_loss=0.0764, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 10.47it/s, loss=13.8, val_loss=0.0764, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 17.99it/s, loss=13.8, val_loss=0.0884, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 10.51it/s, loss=1.77, val_loss=0.0884, avg_\u001b[A\n",
      "Epoch 2:  92%|▉| 22/24 [00:01<00:00, 17.92it/s, loss=1.77, val_loss=0.0884, avg_\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 18.50it/s, loss=1.77, val_loss=0.0916, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 10.47it/s, loss=0.506, val_loss=0.0916, avg\u001b[A\n",
      "Epoch 3:  92%|▉| 22/24 [00:01<00:00, 17.86it/s, loss=0.506, val_loss=0.0916, avg\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 18.46it/s, loss=0.506, val_loss=0.08, avg_v\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 10.57it/s, loss=0.177, val_loss=0.08, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 18.23it/s, loss=0.177, val_loss=0.0585, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=0.0776, val_loss=0.0585, av\u001b[A\n",
      "Epoch 5:  92%|▉| 22/24 [00:01<00:00, 17.92it/s, loss=0.0776, val_loss=0.0585, av\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 18.51it/s, loss=0.0776, val_loss=0.0412, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.0422, val_loss=0.0412, av\u001b[A\n",
      "Epoch 6:  92%|▉| 22/24 [00:01<00:00, 18.46it/s, loss=0.0422, val_loss=0.0412, av\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 19.10it/s, loss=0.0422, val_loss=0.0316, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 10.42it/s, loss=0.0302, val_loss=0.0316, av\u001b[A\n",
      "Epoch 7:  92%|▉| 22/24 [00:01<00:00, 17.78it/s, loss=0.0302, val_loss=0.0316, av\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 18.36it/s, loss=0.0302, val_loss=0.0286, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 10.33it/s, loss=0.0253, val_loss=0.0286, av\u001b[A\n",
      "Epoch 8:  92%|▉| 22/24 [00:01<00:00, 17.60it/s, loss=0.0253, val_loss=0.0286, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 18.26it/s, loss=0.0253, val_loss=0.0254, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 10.51it/s, loss=0.0223, val_loss=0.0254, av\u001b[A\n",
      "Epoch 9:  92%|▉| 22/24 [00:01<00:00, 17.89it/s, loss=0.0223, val_loss=0.0254, av\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 18.49it/s, loss=0.0223, val_loss=0.0231, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 10.72it/s, loss=0.0202, val_loss=0.0231, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 18.77it/s, loss=0.0202, val_loss=0.0213, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 10.75it/s, loss=0.0186, val_loss=0.0213, a\u001b[A\n",
      "Epoch 11:  92%|▉| 22/24 [00:01<00:00, 18.32it/s, loss=0.0186, val_loss=0.0213, a\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 18.99it/s, loss=0.0186, val_loss=0.0198, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 10.16it/s, loss=0.0172, val_loss=0.0198, a\u001b[A\n",
      "Epoch 12:  92%|▉| 22/24 [00:01<00:00, 17.28it/s, loss=0.0172, val_loss=0.0198, a\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 17.94it/s, loss=0.0172, val_loss=0.0184, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 10.07it/s, loss=0.0161, val_loss=0.0184, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 17.19it/s, loss=0.0161, val_loss=0.0172, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 10.62it/s, loss=0.0151, val_loss=0.0172, a\u001b[A\n",
      "Epoch 14:  92%|▉| 22/24 [00:01<00:00, 18.14it/s, loss=0.0151, val_loss=0.0172, a\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 18.74it/s, loss=0.0151, val_loss=0.0162, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 10.65it/s, loss=0.0142, val_loss=0.0162, a\u001b[A\n",
      "Epoch 15:  92%|▉| 22/24 [00:01<00:00, 18.14it/s, loss=0.0142, val_loss=0.0162, a\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 18.70it/s, loss=0.0142, val_loss=0.0153, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.0135, val_loss=0.0153, a\u001b[A\n",
      "Epoch 16:  92%|▉| 22/24 [00:01<00:00, 18.03it/s, loss=0.0135, val_loss=0.0153, a\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 18.71it/s, loss=0.0135, val_loss=0.0145, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 10.37it/s, loss=0.0128, val_loss=0.0145, a\u001b[A\n",
      "Epoch 17:  92%|▉| 22/24 [00:01<00:00, 17.54it/s, loss=0.0128, val_loss=0.0145, a\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 18.08it/s, loss=0.0128, val_loss=0.0138, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 10.10it/s, loss=0.0123, val_loss=0.0138, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 17.51it/s, loss=0.0123, val_loss=0.0132, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 10.44it/s, loss=0.0118, val_loss=0.0132, a\u001b[A\n",
      "Epoch 19:  92%|▉| 22/24 [00:01<00:00, 17.78it/s, loss=0.0118, val_loss=0.0132, a\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 18.35it/s, loss=0.0118, val_loss=0.0126, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01,  9.74it/s, loss=0.0113, val_loss=0.0126, a\u001b[A\n",
      "Epoch 20:  92%|▉| 22/24 [00:01<00:00, 16.64it/s, loss=0.0113, val_loss=0.0126, a\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 17.27it/s, loss=0.0113, val_loss=0.0121, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 10.30it/s, loss=0.0109, val_loss=0.0121, a\u001b[A\n",
      "Epoch 21:  92%|▉| 22/24 [00:01<00:00, 17.30it/s, loss=0.0109, val_loss=0.0121, a\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 18.03it/s, loss=0.0109, val_loss=0.0117, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 10.39it/s, loss=0.0105, val_loss=0.0117, a\u001b[A\n",
      "Epoch 22:  92%|▉| 22/24 [00:01<00:00, 17.41it/s, loss=0.0105, val_loss=0.0117, a\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 18.14it/s, loss=0.0105, val_loss=0.0112, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 10.44it/s, loss=0.0102, val_loss=0.0112, a\u001b[A\n",
      "Epoch 23:  92%|▉| 22/24 [00:01<00:00, 17.79it/s, loss=0.0102, val_loss=0.0112, a\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 18.37it/s, loss=0.0102, val_loss=0.0108, a\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 10.17it/s, loss=0.00984, val_loss=0.0108, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 17.83it/s, loss=0.00984, val_loss=0.0104, \u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 10.31it/s, loss=0.00955, val_loss=0.0104, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 18.06it/s, loss=0.00955, val_loss=0.0101, \u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 10.57it/s, loss=0.00927, val_loss=0.0101, \u001b[A\n",
      "Epoch 26:  92%|▉| 22/24 [00:01<00:00, 17.84it/s, loss=0.00927, val_loss=0.0101, \n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 18.57it/s, loss=0.00927, val_loss=0.00979,\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 10.24it/s, loss=0.00902, val_loss=0.00979,\u001b[A\n",
      "Epoch 27:  92%|▉| 22/24 [00:01<00:00, 17.43it/s, loss=0.00902, val_loss=0.00979,\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 18.10it/s, loss=0.00902, val_loss=0.0095, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 10.60it/s, loss=0.00879, val_loss=0.0095, \u001b[A\n",
      "Epoch 28:  92%|▉| 22/24 [00:01<00:00, 18.14it/s, loss=0.00879, val_loss=0.0095, \n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 18.71it/s, loss=0.00879, val_loss=0.00924,\u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01,  9.82it/s, loss=0.00857, val_loss=0.00924,\u001b[A\n",
      "Epoch 29:  92%|▉| 22/24 [00:01<00:00, 16.67it/s, loss=0.00857, val_loss=0.00924,\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 17.38it/s, loss=0.00857, val_loss=0.00899,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 10.40it/s, loss=0.00837, val_loss=0.00899,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 18.15it/s, loss=0.00837, val_loss=0.00877,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 10.06it/s, loss=0.00817, val_loss=0.00877,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 17.09it/s, loss=0.00817, val_loss=0.00855,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 10.35it/s, loss=0.008, val_loss=0.00855, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 18.24it/s, loss=0.008, val_loss=0.00836, a\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 10.20it/s, loss=0.00783, val_loss=0.00836,\u001b[A\n",
      "Epoch 33:  92%|▉| 22/24 [00:01<00:00, 17.14it/s, loss=0.00783, val_loss=0.00836,\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 17.99it/s, loss=0.00783, val_loss=0.00817,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 10.16it/s, loss=0.00767, val_loss=0.00817,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 17.96it/s, loss=0.00767, val_loss=0.00799,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 10.33it/s, loss=0.00753, val_loss=0.00799,\u001b[A\n",
      "Epoch 35:  92%|▉| 22/24 [00:01<00:00, 17.60it/s, loss=0.00753, val_loss=0.00799,\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 18.24it/s, loss=0.00753, val_loss=0.00782,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 10.62it/s, loss=0.00739, val_loss=0.00782,\u001b[A\n",
      "Epoch 36:  92%|▉| 22/24 [00:01<00:00, 17.92it/s, loss=0.00739, val_loss=0.00782,\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 18.75it/s, loss=0.00739, val_loss=0.00765,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01,  9.91it/s, loss=0.00726, val_loss=0.00765,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 17.40it/s, loss=0.00726, val_loss=0.00749,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 10.83it/s, loss=0.00714, val_loss=0.00749,\u001b[A\n",
      "Epoch 38:  92%|▉| 22/24 [00:01<00:00, 18.18it/s, loss=0.00714, val_loss=0.00749,\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 18.99it/s, loss=0.00714, val_loss=0.00734,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 10.75it/s, loss=0.00703, val_loss=0.00734,\u001b[A\n",
      "Epoch 39:  92%|▉| 22/24 [00:01<00:00, 18.10it/s, loss=0.00703, val_loss=0.00734,\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 18.90it/s, loss=0.00703, val_loss=0.0072, \u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 18.66it/s, loss=0.00703, val_loss=0.0072, \u001b[A\n",
      "Sizes of clusters: 355, 473, 372\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 2 2 0 2 2 2 2\n",
      " 2 2 2 2 1 2 2 2 2 2 2 0 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 1 1 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 1 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 1 0 0 2 2\n",
      " 1 2 2 0 2 2 2 2 1 2 2 1 1 2 2 2 2 2 2 2 2 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 2 1 2 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2\n",
      " 0 2 2 2 2 2 1 0 2 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 2 1 2 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 0 2 2 0\n",
      " 2 2 2 2 2 0 2 2 1 0 2 2 2 2 2 2 0 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 2 1 2 2 1 2 2 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 1 2 2 1 2 2 2 2\n",
      " 2 0 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2 0 2 2 2 2 2 0 0 0 2 0 1 1 1 0 2 0 0 1\n",
      " 1 1 0 1 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 2 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 2 1 0 0 1 0 0 0 1 1 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 2 0 0 0 0 0 0 0 0 1 1 0 1 0 0 2 0 1 2 0 0 2 0 0 0 1\n",
      " 0 2 0 0 0 0 1 0 1 2 0 1 1 2 2 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 1 0 2 0 1 0\n",
      " 0 0 1 0 0 0 0 1 2 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 1\n",
      " 0 1 0 2 0 0 0 0 1 1 0 1 0 2 0 1 2 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 2 0 1 0 0 1 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 2 0 1 0 0 0 0 0 0 2 0 0 1 2 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 2 0 0 1 0 1 2 1 0 1 2 0 0 0 0\n",
      " 0 1 2 2 0 1 0 0 2 0 1 0 1 0 2 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 2 0 0\n",
      " 0 2 1 0 0 0 0 0 0 2 0 0 0 2 1 1 0 2 1 1 0 0 0 1 0 0 2 2 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 1 0 0 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.7808\n",
      "============= RUN 3 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 10.76it/s, loss=181, val_loss=0.0507, avg_v\n",
      "Epoch 0:  58%|▌| 14/24 [00:01<00:00, 12.38it/s, loss=181, val_loss=0.0507, avg_v\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 18.68it/s, loss=181, val_loss=0.232, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 10.41it/s, loss=12.4, val_loss=0.232, avg_v\u001b[A\n",
      "Epoch 1:  75%|▊| 18/24 [00:01<00:00, 14.58it/s, loss=12.4, val_loss=0.232, avg_v\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 18.06it/s, loss=12.4, val_loss=0.161, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 10.90it/s, loss=1.52, val_loss=0.161, avg_v\u001b[A\n",
      "Epoch 2:  75%|▊| 18/24 [00:01<00:00, 15.78it/s, loss=1.52, val_loss=0.161, avg_v\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 19.08it/s, loss=1.52, val_loss=0.101, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 10.83it/s, loss=0.397, val_loss=0.101, avg_\u001b[A\n",
      "Epoch 3:  75%|▊| 18/24 [00:01<00:00, 15.67it/s, loss=0.397, val_loss=0.101, avg_\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 18.92it/s, loss=0.397, val_loss=0.0996, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.147, val_loss=0.0996, avg\u001b[A\n",
      "Epoch 4:  75%|▊| 18/24 [00:01<00:00, 15.24it/s, loss=0.147, val_loss=0.0996, avg\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 18.61it/s, loss=0.147, val_loss=0.0639, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.0584, val_loss=0.0639, av\u001b[A\n",
      "Epoch 5:  75%|▊| 18/24 [00:01<00:00, 15.74it/s, loss=0.0584, val_loss=0.0639, av\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 19.03it/s, loss=0.0584, val_loss=0.0385, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 10.24it/s, loss=0.0324, val_loss=0.0385, av\u001b[A\n",
      "Epoch 6:  75%|▊| 18/24 [00:01<00:00, 14.86it/s, loss=0.0324, val_loss=0.0385, av\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 18.04it/s, loss=0.0324, val_loss=0.0309, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 10.67it/s, loss=0.0238, val_loss=0.0309, av\u001b[A\n",
      "Epoch 7:  75%|▊| 18/24 [00:01<00:00, 15.46it/s, loss=0.0238, val_loss=0.0309, av\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 18.76it/s, loss=0.0238, val_loss=0.0286, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 10.73it/s, loss=0.0202, val_loss=0.0286, av\u001b[A\n",
      "Epoch 8:  75%|▊| 18/24 [00:01<00:00, 15.24it/s, loss=0.0202, val_loss=0.0286, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 18.79it/s, loss=0.0202, val_loss=0.0265, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.0184, val_loss=0.0265, av\u001b[A\n",
      "Epoch 9:  75%|▊| 18/24 [00:01<00:00, 15.28it/s, loss=0.0184, val_loss=0.0265, av\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 18.52it/s, loss=0.0184, val_loss=0.0251, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 10.93it/s, loss=0.0171, val_loss=0.0251, a\u001b[A\n",
      "Epoch 10:  75%|▊| 18/24 [00:01<00:00, 15.85it/s, loss=0.0171, val_loss=0.0251, a\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 19.24it/s, loss=0.0171, val_loss=0.0237, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.016, val_loss=0.0237, av\u001b[A\n",
      "Epoch 11:  75%|▊| 18/24 [00:01<00:00, 15.62it/s, loss=0.016, val_loss=0.0237, av\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 19.09it/s, loss=0.016, val_loss=0.0224, av\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 10.74it/s, loss=0.0151, val_loss=0.0224, a\u001b[A\n",
      "Epoch 12:  75%|▊| 18/24 [00:01<00:00, 15.61it/s, loss=0.0151, val_loss=0.0224, a\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 18.86it/s, loss=0.0151, val_loss=0.0211, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 10.83it/s, loss=0.0143, val_loss=0.0211, a\u001b[A\n",
      "Epoch 13:  75%|▊| 18/24 [00:01<00:00, 15.20it/s, loss=0.0143, val_loss=0.0211, a\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 18.76it/s, loss=0.0143, val_loss=0.0198, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 10.77it/s, loss=0.0136, val_loss=0.0198, a\u001b[A\n",
      "Epoch 14:  75%|▊| 18/24 [00:01<00:00, 15.47it/s, loss=0.0136, val_loss=0.0198, a\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 18.73it/s, loss=0.0136, val_loss=0.0187, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 10.61it/s, loss=0.013, val_loss=0.0187, av\u001b[A\n",
      "Epoch 15:  75%|▊| 18/24 [00:01<00:00, 15.29it/s, loss=0.013, val_loss=0.0187, av\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 18.66it/s, loss=0.013, val_loss=0.0177, av\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 10.12it/s, loss=0.0124, val_loss=0.0177, a\u001b[A\n",
      "Epoch 16:  75%|▊| 18/24 [00:01<00:00, 14.72it/s, loss=0.0124, val_loss=0.0177, a\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 17.96it/s, loss=0.0124, val_loss=0.0169, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 10.79it/s, loss=0.0119, val_loss=0.0169, a\u001b[A\n",
      "Epoch 17:  75%|▊| 18/24 [00:01<00:00, 15.58it/s, loss=0.0119, val_loss=0.0169, a\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 18.89it/s, loss=0.0119, val_loss=0.0161, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 10.76it/s, loss=0.0115, val_loss=0.0161, a\u001b[A\n",
      "Epoch 18:  75%|▊| 18/24 [00:01<00:00, 15.49it/s, loss=0.0115, val_loss=0.0161, a\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 18.84it/s, loss=0.0115, val_loss=0.0154, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 10.43it/s, loss=0.0111, val_loss=0.0154, a\u001b[A\n",
      "Epoch 19:  75%|▊| 18/24 [00:01<00:00, 14.97it/s, loss=0.0111, val_loss=0.0154, a\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 18.37it/s, loss=0.0111, val_loss=0.0148, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 10.01it/s, loss=0.0107, val_loss=0.0148, a\u001b[A\n",
      "Epoch 20:  75%|▊| 18/24 [00:01<00:00, 13.90it/s, loss=0.0107, val_loss=0.0148, a\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 16.96it/s, loss=0.0107, val_loss=0.0142, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 10.27it/s, loss=0.0104, val_loss=0.0142, a\u001b[A\n",
      "Epoch 21:  75%|▊| 18/24 [00:01<00:00, 14.47it/s, loss=0.0104, val_loss=0.0142, a\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 17.90it/s, loss=0.0104, val_loss=0.0136, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 10.81it/s, loss=0.0101, val_loss=0.0136, a\u001b[A\n",
      "Epoch 22:  75%|▊| 18/24 [00:01<00:00, 15.76it/s, loss=0.0101, val_loss=0.0136, a\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 19.07it/s, loss=0.0101, val_loss=0.0131, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 10.41it/s, loss=0.00983, val_loss=0.0131, \u001b[A\n",
      "Epoch 23:  75%|▊| 18/24 [00:01<00:00, 14.98it/s, loss=0.00983, val_loss=0.0131, \n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 18.34it/s, loss=0.00983, val_loss=0.0126, \u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 10.55it/s, loss=0.00958, val_loss=0.0126, \u001b[A\n",
      "Epoch 24:  75%|▊| 18/24 [00:01<00:00, 15.34it/s, loss=0.00958, val_loss=0.0126, \n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 18.56it/s, loss=0.00958, val_loss=0.0122, \u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 10.38it/s, loss=0.00935, val_loss=0.0122, \u001b[A\n",
      "Epoch 25:  75%|▊| 18/24 [00:01<00:00, 14.71it/s, loss=0.00935, val_loss=0.0122, \n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 18.15it/s, loss=0.00935, val_loss=0.0118, \u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.00914, val_loss=0.0118, \u001b[A\n",
      "Epoch 26:  75%|▊| 18/24 [00:01<00:00, 15.55it/s, loss=0.00914, val_loss=0.0118, \n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 19.01it/s, loss=0.00914, val_loss=0.0115, \u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.11it/s, loss=0.00895, val_loss=0.0115, \u001b[A\n",
      "Epoch 27:  75%|▊| 18/24 [00:01<00:00, 15.63it/s, loss=0.00895, val_loss=0.0115, \n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 19.24it/s, loss=0.00895, val_loss=0.0112, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 10.73it/s, loss=0.00877, val_loss=0.0112, \u001b[A\n",
      "Epoch 28:  75%|▊| 18/24 [00:01<00:00, 15.02it/s, loss=0.00877, val_loss=0.0112, \n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 18.49it/s, loss=0.00877, val_loss=0.0109, \u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01,  9.93it/s, loss=0.0086, val_loss=0.0109, a\u001b[A\n",
      "Epoch 29:  75%|▊| 18/24 [00:01<00:00, 14.00it/s, loss=0.0086, val_loss=0.0109, a\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 17.38it/s, loss=0.0086, val_loss=0.0106, a\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 10.32it/s, loss=0.00845, val_loss=0.0106, \u001b[A\n",
      "Epoch 30:  75%|▊| 18/24 [00:01<00:00, 14.65it/s, loss=0.00845, val_loss=0.0106, \n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 18.03it/s, loss=0.00845, val_loss=0.0103, \u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 10.22it/s, loss=0.00831, val_loss=0.0103, \u001b[A\n",
      "Epoch 31:  75%|▊| 18/24 [00:01<00:00, 14.86it/s, loss=0.00831, val_loss=0.0103, \n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 18.06it/s, loss=0.00831, val_loss=0.0101, \u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 10.51it/s, loss=0.00817, val_loss=0.0101, \u001b[A\n",
      "Epoch 32:  75%|▊| 18/24 [00:01<00:00, 14.75it/s, loss=0.00817, val_loss=0.0101, \n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 18.32it/s, loss=0.00817, val_loss=0.00987,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 10.45it/s, loss=0.00805, val_loss=0.00987,\u001b[A\n",
      "Epoch 33:  75%|▊| 18/24 [00:01<00:00, 14.74it/s, loss=0.00805, val_loss=0.00987,\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 18.08it/s, loss=0.00805, val_loss=0.00966,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 10.34it/s, loss=0.00794, val_loss=0.00966,\u001b[A\n",
      "Epoch 34:  75%|▊| 18/24 [00:01<00:00, 14.56it/s, loss=0.00794, val_loss=0.00966,\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 18.02it/s, loss=0.00794, val_loss=0.00945,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 10.76it/s, loss=0.00783, val_loss=0.00945,\u001b[A\n",
      "Epoch 35:  75%|▊| 18/24 [00:01<00:00, 15.47it/s, loss=0.00783, val_loss=0.00945,\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 18.91it/s, loss=0.00783, val_loss=0.00924,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 10.54it/s, loss=0.00773, val_loss=0.00924,\u001b[A\n",
      "Epoch 36:  75%|▊| 18/24 [00:01<00:00, 14.97it/s, loss=0.00773, val_loss=0.00924,\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 18.50it/s, loss=0.00773, val_loss=0.00905,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 10.32it/s, loss=0.00765, val_loss=0.00905,\u001b[A\n",
      "Epoch 37:  75%|▊| 18/24 [00:01<00:00, 14.57it/s, loss=0.00765, val_loss=0.00905,\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 18.03it/s, loss=0.00765, val_loss=0.00886,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 10.45it/s, loss=0.00756, val_loss=0.00886,\u001b[A\n",
      "Epoch 38:  75%|▊| 18/24 [00:01<00:00, 14.87it/s, loss=0.00756, val_loss=0.00886,\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 18.37it/s, loss=0.00756, val_loss=0.00868,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 10.24it/s, loss=0.00748, val_loss=0.00868,\u001b[A\n",
      "Epoch 39:  75%|▊| 18/24 [00:01<00:00, 14.46it/s, loss=0.00748, val_loss=0.00868,\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 17.97it/s, loss=0.00748, val_loss=0.00852,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 17.65it/s, loss=0.00748, val_loss=0.00852,\u001b[A\n",
      "Sizes of clusters: 401, 569, 230\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 1 1 2 2 2 2 2 1\n",
      " 1 2 2 1 2 1 2 1 1 2 1 1 2 2 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 1 1 1 2 1 1 2 2\n",
      " 1 2 1 2 2 1 2 2 1 1 1 1 2 2 2 2 1 1 2 1 2 2 1 2 1 1 1 2 2 2 1 2 1 2 2 1 1\n",
      " 2 1 2 2 1 1 2 2 2 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 2 2 2 2 2 2 1 1 2 2 1 2 2\n",
      " 1 2 2 2 1 2 1 2 1 2 2 2 2 2 2 2 1 1 1 2 1 1 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 2 1 2 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 1 2 2 1 2 1 1 2 2 2 2 1 1 1 1 2 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 2 1 1 2 2 1 2 2 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1\n",
      " 1 2 1 1 2 1 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 2 2 1 2 2 1 2 2 2 2 2 2 2 1 2\n",
      " 2 1 1 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2 1 1 1 2 1 1 2 2 2 2\n",
      " 2 2 1 2 2 1 1 1 2 2 2 2 1 2 1 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2 2 1 1 2 1 1 1\n",
      " 2 2 1 2 2 1 2 1 1 2 2 2 2 2 1 1 2 1 1 1 1 2 2 2 2 2 2 1 2 2 1 2 2 1 2 2 1\n",
      " 1 1 1 1 1 2 2 1 1 1 2 1 1 2 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8308\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  54%|▌| 13/24 [00:01<00:00, 11.33it/s, loss=212, val_loss=0.0661, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 18.52it/s, loss=212, val_loss=0.163, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 10.62it/s, loss=15.8, val_loss=0.163, avg_v\u001b[A\n",
      "Epoch 1:  83%|▊| 20/24 [00:01<00:00, 16.58it/s, loss=15.8, val_loss=0.163, avg_v\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 18.75it/s, loss=15.8, val_loss=0.209, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 10.00it/s, loss=2.04, val_loss=0.209, avg_v\u001b[A\n",
      "Epoch 2:  83%|▊| 20/24 [00:01<00:00, 15.74it/s, loss=2.04, val_loss=0.209, avg_v\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 17.71it/s, loss=2.04, val_loss=0.166, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 10.83it/s, loss=0.554, val_loss=0.166, avg_\u001b[A\n",
      "Epoch 3:  83%|▊| 20/24 [00:01<00:00, 17.11it/s, loss=0.554, val_loss=0.166, avg_\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 19.00it/s, loss=0.554, val_loss=0.0951, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 10.54it/s, loss=0.193, val_loss=0.0951, avg\u001b[A\n",
      "Epoch 4:  83%|▊| 20/24 [00:01<00:00, 16.36it/s, loss=0.193, val_loss=0.0951, avg\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 18.56it/s, loss=0.193, val_loss=0.0849, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 10.81it/s, loss=0.0826, val_loss=0.0849, av\u001b[A\n",
      "Epoch 5:  83%|▊| 20/24 [00:01<00:00, 17.15it/s, loss=0.0826, val_loss=0.0849, av\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 19.06it/s, loss=0.0826, val_loss=0.054, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.0455, val_loss=0.054, avg\u001b[A\n",
      "Epoch 6:  83%|▊| 20/24 [00:01<00:00, 17.19it/s, loss=0.0455, val_loss=0.054, avg\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 19.06it/s, loss=0.0455, val_loss=0.0435, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 10.45it/s, loss=0.0331, val_loss=0.0435, av\u001b[A\n",
      "Epoch 7:  83%|▊| 20/24 [00:01<00:00, 16.50it/s, loss=0.0331, val_loss=0.0435, av\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 18.33it/s, loss=0.0331, val_loss=0.0359, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 10.58it/s, loss=0.0275, val_loss=0.0359, av\u001b[A\n",
      "Epoch 8:  83%|▊| 20/24 [00:01<00:00, 16.33it/s, loss=0.0275, val_loss=0.0359, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 18.32it/s, loss=0.0275, val_loss=0.031, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 10.26it/s, loss=0.0244, val_loss=0.031, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 17.68it/s, loss=0.0244, val_loss=0.0279, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01,  9.96it/s, loss=0.0222, val_loss=0.0279, a\u001b[A\n",
      "Epoch 10:  83%|▊| 20/24 [00:01<00:00, 15.41it/s, loss=0.0222, val_loss=0.0279, a\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 17.35it/s, loss=0.0222, val_loss=0.0254, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01,  9.92it/s, loss=0.0204, val_loss=0.0254, a\u001b[A\n",
      "Epoch 11:  83%|▊| 20/24 [00:01<00:00, 15.68it/s, loss=0.0204, val_loss=0.0254, a\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 17.59it/s, loss=0.0204, val_loss=0.0233, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 10.73it/s, loss=0.019, val_loss=0.0233, av\u001b[A\n",
      "Epoch 12:  83%|▊| 20/24 [00:01<00:00, 16.92it/s, loss=0.019, val_loss=0.0233, av\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 18.90it/s, loss=0.019, val_loss=0.0215, av\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 10.58it/s, loss=0.0178, val_loss=0.0215, a\u001b[A\n",
      "Epoch 13:  83%|▊| 20/24 [00:01<00:00, 16.64it/s, loss=0.0178, val_loss=0.0215, a\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 18.52it/s, loss=0.0178, val_loss=0.0199, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 10.85it/s, loss=0.0167, val_loss=0.0199, a\u001b[A\n",
      "Epoch 14:  83%|▊| 20/24 [00:01<00:00, 17.12it/s, loss=0.0167, val_loss=0.0199, a\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 19.02it/s, loss=0.0167, val_loss=0.0186, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 10.74it/s, loss=0.0158, val_loss=0.0186, a\u001b[A\n",
      "Epoch 15:  83%|▊| 20/24 [00:01<00:00, 16.99it/s, loss=0.0158, val_loss=0.0186, a\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 18.94it/s, loss=0.0158, val_loss=0.0174, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 10.39it/s, loss=0.015, val_loss=0.0174, av\u001b[A\n",
      "Epoch 16:  83%|▊| 20/24 [00:01<00:00, 15.97it/s, loss=0.015, val_loss=0.0174, av\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 18.05it/s, loss=0.015, val_loss=0.0164, av\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 10.28it/s, loss=0.0143, val_loss=0.0164, a\u001b[A\n",
      "Epoch 17:  83%|▊| 20/24 [00:01<00:00, 16.34it/s, loss=0.0143, val_loss=0.0164, a\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 18.20it/s, loss=0.0143, val_loss=0.0155, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 10.12it/s, loss=0.0136, val_loss=0.0155, a\u001b[A\n",
      "Epoch 18:  83%|▊| 20/24 [00:01<00:00, 15.71it/s, loss=0.0136, val_loss=0.0155, a\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 17.76it/s, loss=0.0136, val_loss=0.0147, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.00it/s, loss=0.0131, val_loss=0.0147, a\u001b[A\n",
      "Epoch 19:  83%|▊| 20/24 [00:01<00:00, 17.29it/s, loss=0.0131, val_loss=0.0147, a\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 19.33it/s, loss=0.0131, val_loss=0.014, av\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 10.64it/s, loss=0.0126, val_loss=0.014, av\u001b[A\n",
      "Epoch 20:  83%|▊| 20/24 [00:01<00:00, 16.60it/s, loss=0.0126, val_loss=0.014, av\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 18.57it/s, loss=0.0126, val_loss=0.0133, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 10.54it/s, loss=0.0121, val_loss=0.0133, a\u001b[A\n",
      "Epoch 21:  83%|▊| 20/24 [00:01<00:00, 16.72it/s, loss=0.0121, val_loss=0.0133, a\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 18.63it/s, loss=0.0121, val_loss=0.0128, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.0117, val_loss=0.0128, a\u001b[A\n",
      "Epoch 22:  83%|▊| 20/24 [00:01<00:00, 16.52it/s, loss=0.0117, val_loss=0.0128, a\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 18.49it/s, loss=0.0117, val_loss=0.0123, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.0113, val_loss=0.0123, a\u001b[A\n",
      "Epoch 23:  83%|▊| 20/24 [00:01<00:00, 16.44it/s, loss=0.0113, val_loss=0.0123, a\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 18.50it/s, loss=0.0113, val_loss=0.0118, a\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 10.31it/s, loss=0.011, val_loss=0.0118, av\u001b[A\n",
      "Epoch 24:  83%|▊| 20/24 [00:01<00:00, 16.21it/s, loss=0.011, val_loss=0.0118, av\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 18.16it/s, loss=0.011, val_loss=0.0114, av\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 10.34it/s, loss=0.0107, val_loss=0.0114, a\u001b[A\n",
      "Epoch 25:  83%|▊| 20/24 [00:01<00:00, 15.89it/s, loss=0.0107, val_loss=0.0114, a\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 18.01it/s, loss=0.0107, val_loss=0.011, av\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 10.42it/s, loss=0.0104, val_loss=0.011, av\u001b[A\n",
      "Epoch 26:  83%|▊| 20/24 [00:01<00:00, 16.35it/s, loss=0.0104, val_loss=0.011, av\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 18.37it/s, loss=0.0104, val_loss=0.0106, a\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 10.10it/s, loss=0.0101, val_loss=0.0106, a\u001b[A\n",
      "Epoch 27:  83%|▊| 20/24 [00:01<00:00, 15.96it/s, loss=0.0101, val_loss=0.0106, a\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 17.86it/s, loss=0.0101, val_loss=0.0103, a\u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 10.23it/s, loss=0.00987, val_loss=0.0103, \u001b[A\n",
      "Epoch 28:  83%|▊| 20/24 [00:01<00:00, 15.81it/s, loss=0.00987, val_loss=0.0103, \n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 17.98it/s, loss=0.00987, val_loss=0.00996,\u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 10.12it/s, loss=0.00964, val_loss=0.00996,\u001b[A\n",
      "Epoch 29:  83%|▊| 20/24 [00:01<00:00, 15.92it/s, loss=0.00964, val_loss=0.00996,\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 17.85it/s, loss=0.00964, val_loss=0.00967,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 10.38it/s, loss=0.00942, val_loss=0.00967,\u001b[A\n",
      "Epoch 30:  83%|▊| 20/24 [00:01<00:00, 16.03it/s, loss=0.00942, val_loss=0.00967,\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 18.03it/s, loss=0.00942, val_loss=0.00941,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 10.65it/s, loss=0.00922, val_loss=0.00941,\u001b[A\n",
      "Epoch 31:  83%|▊| 20/24 [00:01<00:00, 16.60it/s, loss=0.00922, val_loss=0.00941,\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 18.68it/s, loss=0.00922, val_loss=0.00917,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.00903, val_loss=0.00917,\u001b[A\n",
      "Epoch 32:  83%|▊| 20/24 [00:01<00:00, 16.59it/s, loss=0.00903, val_loss=0.00917,\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 18.65it/s, loss=0.00903, val_loss=0.00894,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 10.47it/s, loss=0.00885, val_loss=0.00894,\u001b[A\n",
      "Epoch 33:  83%|▊| 20/24 [00:01<00:00, 16.15it/s, loss=0.00885, val_loss=0.00894,\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 18.19it/s, loss=0.00885, val_loss=0.00873,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 10.20it/s, loss=0.00868, val_loss=0.00873,\u001b[A\n",
      "Epoch 34:  83%|▊| 20/24 [00:01<00:00, 16.12it/s, loss=0.00868, val_loss=0.00873,\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 18.03it/s, loss=0.00868, val_loss=0.00854,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 10.29it/s, loss=0.00852, val_loss=0.00854,\u001b[A\n",
      "Epoch 35:  83%|▊| 20/24 [00:01<00:00, 16.25it/s, loss=0.00852, val_loss=0.00854,\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 18.17it/s, loss=0.00852, val_loss=0.00835,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 10.11it/s, loss=0.00836, val_loss=0.00835,\u001b[A\n",
      "Epoch 36:  83%|▊| 20/24 [00:01<00:00, 15.71it/s, loss=0.00836, val_loss=0.00835,\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 17.91it/s, loss=0.00836, val_loss=0.00817,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 10.29it/s, loss=0.00822, val_loss=0.00817,\u001b[A\n",
      "Epoch 37:  83%|▊| 20/24 [00:01<00:00, 16.35it/s, loss=0.00822, val_loss=0.00817,\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 18.17it/s, loss=0.00822, val_loss=0.008, a\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 10.44it/s, loss=0.00808, val_loss=0.008, a\u001b[A\n",
      "Epoch 38:  83%|▊| 20/24 [00:01<00:00, 16.55it/s, loss=0.00808, val_loss=0.008, a\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 18.51it/s, loss=0.00808, val_loss=0.00784,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 10.83it/s, loss=0.00794, val_loss=0.00784,\u001b[A\n",
      "Epoch 39:  83%|▊| 20/24 [00:01<00:00, 17.13it/s, loss=0.00794, val_loss=0.00784,\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 19.00it/s, loss=0.00794, val_loss=0.0077, \u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 18.88it/s, loss=0.00794, val_loss=0.0077, \u001b[A\n",
      "Sizes of clusters: 383, 413, 404\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 2 1 1 2 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 2\n",
      " 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 2 1 2 1 2 2\n",
      " 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 2 2 2 2 2 1 1 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 1 2 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2\n",
      " 2 2 1 2 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 1 1 2 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 1 2 2 2 2 2 2 1 2 1 1 1 2 2 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 1 2 2 1 2 2 1 1 1 2 2 1 2 1 2 2 2 2 1 2 2 2 2 2 1 2 1 2 1 2 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 1 2 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1\n",
      " 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8575\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 10.70it/s, loss=160, val_loss=0.0475, avg_v\n",
      "Epoch 0:  58%|▌| 14/24 [00:01<00:00, 12.40it/s, loss=160, val_loss=0.0475, avg_v\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 18.91it/s, loss=160, val_loss=0.355, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 10.58it/s, loss=9.49, val_loss=0.355, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 18.56it/s, loss=9.49, val_loss=0.38, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 10.59it/s, loss=1.38, val_loss=0.38, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 18.42it/s, loss=1.38, val_loss=0.139, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=0.417, val_loss=0.139, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 17.97it/s, loss=0.417, val_loss=0.0897, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 10.29it/s, loss=0.152, val_loss=0.0897, avg\u001b[A\n",
      "Epoch 4:  92%|▉| 22/24 [00:01<00:00, 17.45it/s, loss=0.152, val_loss=0.0897, avg\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 18.04it/s, loss=0.152, val_loss=0.0585, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 10.72it/s, loss=0.0669, val_loss=0.0585, av\u001b[A\n",
      "Epoch 5:  92%|▉| 22/24 [00:01<00:00, 17.98it/s, loss=0.0669, val_loss=0.0585, av\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 18.82it/s, loss=0.0669, val_loss=0.0473, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 10.77it/s, loss=0.0406, val_loss=0.0473, av\u001b[A\n",
      "Epoch 6:  92%|▉| 22/24 [00:01<00:00, 18.18it/s, loss=0.0406, val_loss=0.0473, av\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 18.92it/s, loss=0.0406, val_loss=0.0414, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 10.75it/s, loss=0.0301, val_loss=0.0414, av\u001b[A\n",
      "Epoch 7:  92%|▉| 22/24 [00:01<00:00, 18.40it/s, loss=0.0301, val_loss=0.0414, av\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 18.98it/s, loss=0.0301, val_loss=0.0379, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 10.56it/s, loss=0.0255, val_loss=0.0379, av\u001b[A\n",
      "Epoch 8:  92%|▉| 22/24 [00:01<00:00, 17.91it/s, loss=0.0255, val_loss=0.0379, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 18.59it/s, loss=0.0255, val_loss=0.034, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.0228, val_loss=0.034, avg\u001b[A\n",
      "Epoch 9:  92%|▉| 22/24 [00:01<00:00, 18.17it/s, loss=0.0228, val_loss=0.034, avg\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 18.76it/s, loss=0.0228, val_loss=0.0306, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 10.17it/s, loss=0.0207, val_loss=0.0306, a\u001b[A\n",
      "Epoch 10:  92%|▉| 22/24 [00:01<00:00, 17.12it/s, loss=0.0207, val_loss=0.0306, a\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 17.58it/s, loss=0.0207, val_loss=0.0278, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 10.47it/s, loss=0.019, val_loss=0.0278, av\u001b[A\n",
      "Epoch 11:  92%|▉| 22/24 [00:01<00:00, 17.70it/s, loss=0.019, val_loss=0.0278, av\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 18.36it/s, loss=0.019, val_loss=0.0254, av\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 10.32it/s, loss=0.0177, val_loss=0.0254, a\u001b[A\n",
      "Epoch 12:  92%|▉| 22/24 [00:01<00:00, 17.68it/s, loss=0.0177, val_loss=0.0254, a\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 18.25it/s, loss=0.0177, val_loss=0.0233, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.0165, val_loss=0.0233, a\u001b[A\n",
      "Epoch 13:  92%|▉| 22/24 [00:01<00:00, 17.96it/s, loss=0.0165, val_loss=0.0233, a\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 18.51it/s, loss=0.0165, val_loss=0.0214, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=0.0155, val_loss=0.0214, a\u001b[A\n",
      "Epoch 14:  92%|▉| 22/24 [00:01<00:00, 17.80it/s, loss=0.0155, val_loss=0.0214, a\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 18.49it/s, loss=0.0155, val_loss=0.0198, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 10.69it/s, loss=0.0146, val_loss=0.0198, a\u001b[A\n",
      "Epoch 15:  92%|▉| 22/24 [00:01<00:00, 17.96it/s, loss=0.0146, val_loss=0.0198, a\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 18.78it/s, loss=0.0146, val_loss=0.0185, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 10.21it/s, loss=0.0139, val_loss=0.0185, a\u001b[A\n",
      "Epoch 16:  92%|▉| 22/24 [00:01<00:00, 17.32it/s, loss=0.0139, val_loss=0.0185, a\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 18.01it/s, loss=0.0139, val_loss=0.0172, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 10.67it/s, loss=0.0132, val_loss=0.0172, a\u001b[A\n",
      "Epoch 17:  92%|▉| 22/24 [00:01<00:00, 17.99it/s, loss=0.0132, val_loss=0.0172, a\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 18.67it/s, loss=0.0132, val_loss=0.0162, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 10.33it/s, loss=0.0126, val_loss=0.0162, a\u001b[A\n",
      "Epoch 18:  92%|▉| 22/24 [00:01<00:00, 17.62it/s, loss=0.0126, val_loss=0.0162, a\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 18.21it/s, loss=0.0126, val_loss=0.0152, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 10.36it/s, loss=0.012, val_loss=0.0152, av\u001b[A\n",
      "Epoch 19:  92%|▉| 22/24 [00:01<00:00, 17.34it/s, loss=0.012, val_loss=0.0152, av\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 18.09it/s, loss=0.012, val_loss=0.0144, av\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 10.46it/s, loss=0.0116, val_loss=0.0144, a\u001b[A\n",
      "Epoch 20:  92%|▉| 22/24 [00:01<00:00, 17.92it/s, loss=0.0116, val_loss=0.0144, a\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 18.50it/s, loss=0.0116, val_loss=0.0137, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 10.70it/s, loss=0.0111, val_loss=0.0137, a\u001b[A\n",
      "Epoch 21:  92%|▉| 22/24 [00:01<00:00, 18.04it/s, loss=0.0111, val_loss=0.0137, a\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 18.77it/s, loss=0.0111, val_loss=0.013, av\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 10.73it/s, loss=0.0107, val_loss=0.013, av\u001b[A\n",
      "Epoch 22:  92%|▉| 22/24 [00:01<00:00, 18.15it/s, loss=0.0107, val_loss=0.013, av\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 18.86it/s, loss=0.0107, val_loss=0.0124, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 10.66it/s, loss=0.0103, val_loss=0.0124, a\u001b[A\n",
      "Epoch 23:  92%|▉| 22/24 [00:01<00:00, 17.92it/s, loss=0.0103, val_loss=0.0124, a\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 18.79it/s, loss=0.0103, val_loss=0.0119, a\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 10.52it/s, loss=0.01, val_loss=0.0119, avg\u001b[A\n",
      "Epoch 24:  92%|▉| 22/24 [00:01<00:00, 17.63it/s, loss=0.01, val_loss=0.0119, avg\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 18.02it/s, loss=0.01, val_loss=0.0114, avg\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 10.29it/s, loss=0.00969, val_loss=0.0114, \u001b[A\n",
      "Epoch 25:  92%|▉| 22/24 [00:01<00:00, 17.39it/s, loss=0.00969, val_loss=0.0114, \n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 18.15it/s, loss=0.00969, val_loss=0.0109, \u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 10.63it/s, loss=0.00939, val_loss=0.0109, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 18.65it/s, loss=0.00939, val_loss=0.0105, \u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 10.89it/s, loss=0.00912, val_loss=0.0105, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 18.70it/s, loss=0.00912, val_loss=0.0101, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 10.43it/s, loss=0.00886, val_loss=0.0101, \u001b[A\n",
      "Epoch 28:  92%|▉| 22/24 [00:01<00:00, 17.57it/s, loss=0.00886, val_loss=0.0101, \n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 18.38it/s, loss=0.00886, val_loss=0.00978,\u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 10.12it/s, loss=0.00863, val_loss=0.00978,\u001b[A\n",
      "Epoch 29:  92%|▉| 22/24 [00:01<00:00, 17.30it/s, loss=0.00863, val_loss=0.00978,\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 17.87it/s, loss=0.00863, val_loss=0.00945,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 10.51it/s, loss=0.0084, val_loss=0.00945, \u001b[A\n",
      "Epoch 30:  92%|▉| 22/24 [00:01<00:00, 17.93it/s, loss=0.0084, val_loss=0.00945, \n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 18.54it/s, loss=0.0084, val_loss=0.00916, \u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 10.44it/s, loss=0.00819, val_loss=0.00916,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 18.04it/s, loss=0.00819, val_loss=0.00888,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 10.23it/s, loss=0.008, val_loss=0.00888, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 17.85it/s, loss=0.008, val_loss=0.00863, a\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 10.22it/s, loss=0.00782, val_loss=0.00863,\u001b[A\n",
      "Epoch 33:  92%|▉| 22/24 [00:01<00:00, 17.31it/s, loss=0.00782, val_loss=0.00863,\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 18.09it/s, loss=0.00782, val_loss=0.00839,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 10.59it/s, loss=0.00764, val_loss=0.00839,\u001b[A\n",
      "Epoch 34:  92%|▉| 22/24 [00:01<00:00, 17.98it/s, loss=0.00764, val_loss=0.00839,\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 18.72it/s, loss=0.00764, val_loss=0.00817,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 10.57it/s, loss=0.00748, val_loss=0.00817,\u001b[A\n",
      "Epoch 35:  92%|▉| 22/24 [00:01<00:00, 18.04it/s, loss=0.00748, val_loss=0.00817,\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 18.67it/s, loss=0.00748, val_loss=0.00797,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 10.65it/s, loss=0.00733, val_loss=0.00797,\u001b[A\n",
      "Epoch 36:  92%|▉| 22/24 [00:01<00:00, 18.23it/s, loss=0.00733, val_loss=0.00797,\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 18.81it/s, loss=0.00733, val_loss=0.00778,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 10.65it/s, loss=0.00719, val_loss=0.00778,\u001b[A\n",
      "Epoch 37:  92%|▉| 22/24 [00:01<00:00, 17.98it/s, loss=0.00719, val_loss=0.00778,\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 18.57it/s, loss=0.00719, val_loss=0.0076, \u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 10.81it/s, loss=0.00706, val_loss=0.0076, \u001b[A\n",
      "Epoch 38:  92%|▉| 22/24 [00:01<00:00, 18.26it/s, loss=0.00706, val_loss=0.0076, \n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 19.03it/s, loss=0.00706, val_loss=0.00744,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 10.49it/s, loss=0.00693, val_loss=0.00744,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 18.33it/s, loss=0.00693, val_loss=0.00729,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 18.15it/s, loss=0.00693, val_loss=0.00729,\u001b[A\n",
      "Sizes of clusters: 364, 648, 188\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 2 2 2 2 2 1 1 1 2 2 2 2 1\n",
      " 1 1 2 1 1 1 1 1 1 2 1 1 2 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 1 2 2 2 2 1 1 2 2 2 2 1 1 2 1 1 2 1 1 1 1 2 1 2 2 1 2 1 2 1 1 1\n",
      " 2 1 2 2 1 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 1 2 2 2 2 1 2 1 1 2 2 1 2 1\n",
      " 1 2 2 2 2 2 1 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1\n",
      " 2 1 1 2 1 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1\n",
      " 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 0\n",
      " 1 2 1 1 2 2 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 1 2 1 1 2 1 2 2 2 2 1 2 2\n",
      " 2 1 1 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 1 1 2 2 1 2 2 2 1 2 1 2 1 2 2 2 2 2\n",
      " 2 1 2 2 2 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1\n",
      " 2 2 1 1 2 1 1 2 1 2 2 2 2 2 1 1 2 2 1 1 1 1 2 1 2 2 2 2 2 2 1 2 2 1 2 2 2\n",
      " 1 1 1 1 1 2 2 1 1 1 1 1 1 2 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.7892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.6877\r\n",
      "Purity: 0.8036666666666668+-0.03542441091802215\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K3_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  53%|▌| 17/32 [00:01<00:01, 11.06it/s, loss=143, val_loss=0.0663, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 32/32 [00:01<00:00, 18.40it/s, loss=143, val_loss=0.108, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 16/32 [00:01<00:01, 10.68it/s, loss=1.81, val_loss=0.108, avg_v\u001b[A\n",
      "Epoch 1:  62%|▋| 20/32 [00:01<00:00, 13.14it/s, loss=1.81, val_loss=0.108, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:01<00:00, 18.85it/s, loss=1.81, val_loss=0.0847, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 16/32 [00:01<00:01, 10.79it/s, loss=0.372, val_loss=0.0847, avg\u001b[A\n",
      "Epoch 2:  62%|▋| 20/32 [00:01<00:00, 13.03it/s, loss=0.372, val_loss=0.0847, avg\n",
      "Epoch 2: 100%|█| 32/32 [00:01<00:00, 18.87it/s, loss=0.372, val_loss=0.0804, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 16/32 [00:01<00:01, 10.41it/s, loss=0.119, val_loss=0.0804, avg\u001b[A\n",
      "Epoch 3:  69%|▋| 22/32 [00:01<00:00, 13.92it/s, loss=0.119, val_loss=0.0804, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:01<00:00, 18.45it/s, loss=0.119, val_loss=0.0753, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:01<00:01, 10.31it/s, loss=0.0604, val_loss=0.0753, av\u001b[A\n",
      "Epoch 4:  69%|▋| 22/32 [00:01<00:00, 13.36it/s, loss=0.0604, val_loss=0.0753, av\n",
      "Validating:  38%|████████████                    | 6/16 [00:00<00:00, 59.04it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 32/32 [00:01<00:00, 17.86it/s, loss=0.0604, val_loss=0.0696, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:01<00:01, 10.09it/s, loss=0.0442, val_loss=0.0696, av\u001b[A\n",
      "Epoch 5:  69%|▋| 22/32 [00:01<00:00, 13.27it/s, loss=0.0442, val_loss=0.0696, av\n",
      "Epoch 5: 100%|█| 32/32 [00:01<00:00, 17.75it/s, loss=0.0442, val_loss=0.062, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 16/32 [00:01<00:01, 10.48it/s, loss=0.0367, val_loss=0.062, avg\u001b[A\n",
      "Epoch 6:  69%|▋| 22/32 [00:01<00:00, 13.85it/s, loss=0.0367, val_loss=0.062, avg\n",
      "Epoch 6: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0367, val_loss=0.0535, av\u001b[A\n",
      "Epoch 7:  50%|▌| 16/32 [00:01<00:01, 10.42it/s, loss=0.0322, val_loss=0.0535, av\u001b[A\n",
      "Epoch 7:  69%|▋| 22/32 [00:01<00:00, 13.78it/s, loss=0.0322, val_loss=0.0535, av\n",
      "Epoch 7: 100%|█| 32/32 [00:01<00:00, 18.37it/s, loss=0.0322, val_loss=0.0473, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:01<00:01, 10.77it/s, loss=0.0288, val_loss=0.0473, av\u001b[A\n",
      "Epoch 8:  69%|▋| 22/32 [00:01<00:00, 14.21it/s, loss=0.0288, val_loss=0.0473, av\n",
      "Epoch 8: 100%|█| 32/32 [00:01<00:00, 18.94it/s, loss=0.0288, val_loss=0.0426, av\u001b[A\n",
      "Epoch 9:  50%|▌| 16/32 [00:01<00:01, 10.35it/s, loss=0.0263, val_loss=0.0426, av\u001b[A\n",
      "Epoch 9:  69%|▋| 22/32 [00:01<00:00, 13.71it/s, loss=0.0263, val_loss=0.0426, av\n",
      "Epoch 9: 100%|█| 32/32 [00:01<00:00, 18.29it/s, loss=0.0263, val_loss=0.0387, av\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.0242, val_loss=0.0387, a\u001b[A\n",
      "Epoch 10:  69%|▋| 22/32 [00:01<00:00, 14.23it/s, loss=0.0242, val_loss=0.0387, a\n",
      "Epoch 10: 100%|█| 32/32 [00:01<00:00, 18.79it/s, loss=0.0242, val_loss=0.0353, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:01<00:01, 10.86it/s, loss=0.0225, val_loss=0.0353, a\u001b[A\n",
      "Epoch 11:  69%|▋| 22/32 [00:01<00:00, 14.33it/s, loss=0.0225, val_loss=0.0353, a\n",
      "Epoch 11: 100%|█| 32/32 [00:01<00:00, 19.05it/s, loss=0.0225, val_loss=0.0323, a\u001b[A\n",
      "Epoch 12:  50%|▌| 16/32 [00:01<00:01, 10.56it/s, loss=0.0211, val_loss=0.0323, a\u001b[A\n",
      "Epoch 12:  69%|▋| 22/32 [00:01<00:00, 13.98it/s, loss=0.0211, val_loss=0.0323, a\n",
      "Epoch 12: 100%|█| 32/32 [00:01<00:00, 18.55it/s, loss=0.0211, val_loss=0.0298, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.0199, val_loss=0.0298, a\u001b[A\n",
      "Epoch 13:  69%|▋| 22/32 [00:01<00:00, 14.32it/s, loss=0.0199, val_loss=0.0298, a\n",
      "Epoch 13: 100%|█| 32/32 [00:01<00:00, 18.80it/s, loss=0.0199, val_loss=0.0277, a\u001b[A\n",
      "Epoch 14:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.0189, val_loss=0.0277, a\u001b[A\n",
      "Epoch 14:  69%|▋| 22/32 [00:01<00:00, 14.03it/s, loss=0.0189, val_loss=0.0277, a\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 18.54it/s, loss=0.0189, val_loss=0.0259, a\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01, 10.65it/s, loss=0.018, val_loss=0.0259, av\u001b[A\n",
      "Epoch 15:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.018, val_loss=0.0259, av\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 18.76it/s, loss=0.018, val_loss=0.0244, av\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01, 10.59it/s, loss=0.0172, val_loss=0.0244, a\u001b[A\n",
      "Epoch 16:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0172, val_loss=0.0244, a\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 18.55it/s, loss=0.0172, val_loss=0.023, av\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.59it/s, loss=0.0166, val_loss=0.023, av\u001b[A\n",
      "Epoch 17:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.0166, val_loss=0.023, av\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 18.63it/s, loss=0.0166, val_loss=0.0219, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.016, val_loss=0.0219, av\u001b[A\n",
      "Epoch 18:  69%|▋| 22/32 [00:01<00:00, 14.09it/s, loss=0.016, val_loss=0.0219, av\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 18.47it/s, loss=0.016, val_loss=0.0209, av\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.43it/s, loss=0.0154, val_loss=0.0209, a\u001b[A\n",
      "Epoch 19:  69%|▋| 22/32 [00:01<00:00, 13.95it/s, loss=0.0154, val_loss=0.0209, a\n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0154, val_loss=0.02, avg\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.76it/s, loss=0.015, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 20:  69%|▋| 22/32 [00:01<00:00, 14.19it/s, loss=0.015, val_loss=0.02, avg_\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.89it/s, loss=0.015, val_loss=0.0191, av\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01, 10.81it/s, loss=0.0145, val_loss=0.0191, a\u001b[A\n",
      "Epoch 21:  69%|▋| 22/32 [00:01<00:00, 14.47it/s, loss=0.0145, val_loss=0.0191, a\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 19.10it/s, loss=0.0145, val_loss=0.0184, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 10.77it/s, loss=0.0141, val_loss=0.0184, a\u001b[A\n",
      "Epoch 22:  69%|▋| 22/32 [00:01<00:00, 14.34it/s, loss=0.0141, val_loss=0.0184, a\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 18.96it/s, loss=0.0141, val_loss=0.0177, a\u001b[A\n",
      "Epoch 23:  50%|▌| 16/32 [00:01<00:01, 10.99it/s, loss=0.0137, val_loss=0.0177, a\u001b[A\n",
      "Epoch 23:  69%|▋| 22/32 [00:01<00:00, 14.66it/s, loss=0.0137, val_loss=0.0177, a\n",
      "Epoch 23: 100%|█| 32/32 [00:01<00:00, 19.36it/s, loss=0.0137, val_loss=0.0171, a\u001b[A\n",
      "Epoch 24:  50%|▌| 16/32 [00:01<00:01, 10.48it/s, loss=0.0134, val_loss=0.0171, a\u001b[A\n",
      "Epoch 24:  69%|▋| 22/32 [00:01<00:00, 14.03it/s, loss=0.0134, val_loss=0.0171, a\n",
      "Epoch 24: 100%|█| 32/32 [00:01<00:00, 18.54it/s, loss=0.0134, val_loss=0.0166, a\u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:01<00:01, 10.93it/s, loss=0.0131, val_loss=0.0166, a\u001b[A\n",
      "Epoch 25:  69%|▋| 22/32 [00:01<00:00, 14.45it/s, loss=0.0131, val_loss=0.0166, a\n",
      "Epoch 25: 100%|█| 32/32 [00:01<00:00, 19.18it/s, loss=0.0131, val_loss=0.0161, a\u001b[A\n",
      "Epoch 26:  50%|▌| 16/32 [00:01<00:01, 10.53it/s, loss=0.0128, val_loss=0.0161, a\u001b[A\n",
      "Epoch 26:  69%|▋| 22/32 [00:01<00:00, 14.07it/s, loss=0.0128, val_loss=0.0161, a\n",
      "Epoch 26: 100%|█| 32/32 [00:01<00:00, 18.63it/s, loss=0.0128, val_loss=0.0157, a\u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:01<00:01, 10.56it/s, loss=0.0125, val_loss=0.0157, a\u001b[A\n",
      "Epoch 27:  69%|▋| 22/32 [00:01<00:00, 13.88it/s, loss=0.0125, val_loss=0.0157, a\n",
      "Epoch 27: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0125, val_loss=0.0153, a\u001b[A\n",
      "Epoch 28:  50%|▌| 16/32 [00:01<00:01, 10.21it/s, loss=0.0122, val_loss=0.0153, a\u001b[A\n",
      "Epoch 28:  69%|▋| 22/32 [00:01<00:00, 13.57it/s, loss=0.0122, val_loss=0.0153, a\n",
      "Epoch 28: 100%|█| 32/32 [00:01<00:00, 18.00it/s, loss=0.0122, val_loss=0.0149, a\u001b[A\n",
      "Epoch 29:  50%|▌| 16/32 [00:01<00:01, 10.46it/s, loss=0.012, val_loss=0.0149, av\u001b[A\n",
      "Epoch 29:  69%|▋| 22/32 [00:01<00:00, 13.74it/s, loss=0.012, val_loss=0.0149, av\n",
      "Validating:  56%|██████████████████              | 9/16 [00:00<00:00, 80.97it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 32/32 [00:01<00:00, 18.20it/s, loss=0.012, val_loss=0.0146, av\u001b[A\n",
      "Epoch 30:  50%|▌| 16/32 [00:01<00:01, 10.16it/s, loss=0.0118, val_loss=0.0146, a\u001b[A\n",
      "Epoch 30:  69%|▋| 22/32 [00:01<00:00, 13.37it/s, loss=0.0118, val_loss=0.0146, a\n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 68.72it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 32/32 [00:01<00:00, 17.60it/s, loss=0.0118, val_loss=0.0143, a\u001b[A\n",
      "Epoch 31:  50%|▌| 16/32 [00:01<00:01, 10.37it/s, loss=0.0115, val_loss=0.0143, a\u001b[A\n",
      "Epoch 31:  69%|▋| 22/32 [00:01<00:00, 13.90it/s, loss=0.0115, val_loss=0.0143, a\n",
      "Epoch 31: 100%|█| 32/32 [00:01<00:00, 18.31it/s, loss=0.0115, val_loss=0.014, av\u001b[A\n",
      "Epoch 32:  50%|▌| 16/32 [00:01<00:01, 10.53it/s, loss=0.0113, val_loss=0.014, av\u001b[A\n",
      "Epoch 32:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.0113, val_loss=0.014, av\n",
      "Epoch 32: 100%|█| 32/32 [00:01<00:00, 18.63it/s, loss=0.0113, val_loss=0.0137, a\u001b[A\n",
      "Epoch 33:  50%|▌| 16/32 [00:01<00:01, 10.63it/s, loss=0.0111, val_loss=0.0137, a\u001b[A\n",
      "Epoch 33:  69%|▋| 22/32 [00:01<00:00, 14.28it/s, loss=0.0111, val_loss=0.0137, a\n",
      "Epoch 33: 100%|█| 32/32 [00:01<00:00, 18.77it/s, loss=0.0111, val_loss=0.0135, a\u001b[A\n",
      "Epoch 34:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.0109, val_loss=0.0135, a\u001b[A\n",
      "Epoch 34:  69%|▋| 22/32 [00:01<00:00, 13.88it/s, loss=0.0109, val_loss=0.0135, a\n",
      "Epoch 34: 100%|█| 32/32 [00:01<00:00, 18.41it/s, loss=0.0109, val_loss=0.0132, a\u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:01<00:01, 10.75it/s, loss=0.0108, val_loss=0.0132, a\u001b[A\n",
      "Epoch 35:  69%|▋| 22/32 [00:01<00:00, 14.28it/s, loss=0.0108, val_loss=0.0132, a\n",
      "Epoch 35: 100%|█| 32/32 [00:01<00:00, 18.93it/s, loss=0.0108, val_loss=0.013, av\u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:01<00:01, 10.74it/s, loss=0.0106, val_loss=0.013, av\u001b[A\n",
      "Epoch 36:  69%|▋| 22/32 [00:01<00:00, 14.26it/s, loss=0.0106, val_loss=0.013, av\n",
      "Epoch 36: 100%|█| 32/32 [00:01<00:00, 18.85it/s, loss=0.0106, val_loss=0.0127, a\u001b[A\n",
      "Epoch 37:  50%|▌| 16/32 [00:01<00:01, 10.65it/s, loss=0.0104, val_loss=0.0127, a\u001b[A\n",
      "Epoch 37:  69%|▋| 22/32 [00:01<00:00, 14.15it/s, loss=0.0104, val_loss=0.0127, a\n",
      "Epoch 37: 100%|█| 32/32 [00:01<00:00, 18.78it/s, loss=0.0104, val_loss=0.0125, a\u001b[A\n",
      "Epoch 38:  50%|▌| 16/32 [00:01<00:01, 10.79it/s, loss=0.0103, val_loss=0.0125, a\u001b[A\n",
      "Epoch 38:  69%|▋| 22/32 [00:01<00:00, 14.46it/s, loss=0.0103, val_loss=0.0125, a\n",
      "Epoch 38: 100%|█| 32/32 [00:01<00:00, 19.06it/s, loss=0.0103, val_loss=0.0123, a\u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:01<00:01, 10.61it/s, loss=0.0102, val_loss=0.0123, a\u001b[A\n",
      "Epoch 39:  69%|▋| 22/32 [00:01<00:00, 14.06it/s, loss=0.0102, val_loss=0.0123, a\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.67it/s, loss=0.0102, val_loss=0.0121, a\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.47it/s, loss=0.0102, val_loss=0.0121, a\u001b[A\n",
      "Sizes of clusters: 459, 450, 244, 447\n",
      "\n",
      "preds: [3 3 3 1 1 1 3 3 1 3 1 1 1 1 1 1 1 3 3 1 1 1 3 1 3 3 3 3 1 3 1 1 3 1 1 3 1\n",
      " 3 1 3 3 1 1 3 3 3 3 3 3 1 1 3 1 1 1 1 3 3 3 3 3 1 1 3 3 1 3 3 3 1 1 1 3 3\n",
      " 3 3 1 3 1 1 3 1 1 3 3 3 3 1 1 3 3 3 1 1 1 3 1 3 3 3 1 1 1 3 3 3 1 1 1 1 1\n",
      " 3 3 3 3 1 3 3 3 1 1 3 1 3 3 3 3 3 3 3 3 3 1 1 1 3 1 1 1 1 1 1 3 1 3 1 3 3\n",
      " 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 3 3 1 3 1 1 3 3 3 1 3 1 1 1 3 1 1 1 3 1 3 1\n",
      " 1 3 3 1 3 3 1 3 1 1 3 1 1 1 1 3 1 3 1 1 3 3 3 1 1 1 3 3 3 3 1 1 3 3 1 3 1\n",
      " 3 3 1 1 1 1 1 1 1 3 1 1 3 3 1 3 1 3 3 1 3 3 3 3 3 1 1 3 1 3 3 1 1 3 0 3 3\n",
      " 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 3 3 1 1 3 1 3 1 1 1 1 3 1 3 3 1 1 3 3 1 1 1\n",
      " 1 1 1 1 3 1 1 1 3 1 1 3 3 3 1 3 1 3 1 3 1 1 3 1 1 3 3 1 3 1 3 3 1 3 1 3 3\n",
      " 1 1 3 3 3 3 3 3 1 1 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 3 3 1 1 1 3 3 3 3 1 1 1\n",
      " 3 3 1 3 3 1 3 1 3 1 1 3 3 1 3 3 1 1 1 1 1 1 1 3 1 3 1 3 1 1 3 3 3 3 1 1 3\n",
      " 1 1 1 1 3 3 3 1 1 1 1 3 3 1 1 3 1 1 1 1 1 3 3 1 1 1 1 0 3 1 1 1 3 1 1 3 1\n",
      " 1 1 3 3 3 1 1 3 3 1 3 3 3 1 1 1 1 3 1 1 3 3 1 3 1 1 3 1 1 0 3 0 1 1 1 3 1\n",
      " 1 3 3 3 3 1 3 1 1 1 1 3 1 1 1 3 3 1 1 1 3 3 1 3 3 3 3 1 1 3 1 1 1 1 1 3 1\n",
      " 1 1 1 1 3 3 3 1 1 1 1 3 3 1 1 3 3 1 3 1 0 3 3 1 1 1 1 3 3 3 3 3 1 3 1 3 1\n",
      " 1 1 1 1 1 1 3 1 3 3 3 3 1 3 3 1 1 1 1 1 1 3 3 3 3 3 1 1 1 1 1 3 1 1 3 1 1\n",
      " 1 1 1 3 3 1 3 1 3 3 1 1 3 1 1 3 3 1 3 1 1 1 1 1 1 1 3 3 3 3 3 3 3 1 1 1 1\n",
      " 3 1 1 1 3 1 3 3 3 1 0 3 1 1 3 1 3 0 3 1 3 3 1 1 3 3 3 1 1 1 1 3 3 1 1 1 1\n",
      " 1 1 1 3 3 1 1 3 1 1 3 1 3 3 1 3 1 1 3 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 1 3 3\n",
      " 1 1 3 1 1 1 1 3 1 1 3 1 1 3 3 1 1 1 1 1 1 3 1 1 1 1 3 1 1 3 3 3 1 3 1 1 3\n",
      " 3 1 3 3 3 1 1 1 3 1 1 1 3 1 3 1 1 1 1 1 3 1 1 3 3 1 3 1 0 1 1 3 3 1 1 3 1\n",
      " 1 1 1 1 1 3 1 1 1 1 1 3 3 3 3 1 3 3 3 1 1 3 3 2 2 0 2 2 0 0 2 0 0 0 2 0 0\n",
      " 2 2 2 0 2 0 2 0 2 2 2 0 2 0 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 0 0 2\n",
      " 0 0 0 2 2 0 2 0 2 2 2 2 0 0 2 2 2 0 2 0 0 2 0 2 2 0 0 0 0 0 0 2 2 0 0 0 2\n",
      " 2 2 0 0 0 2 0 0 2 0 0 0 0 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0\n",
      " 2 2 2 0 0 2 2 0 2 2 2 2 2 0 0 2 2 2 0 2 2 2 0 2 0 0 0 0 2 2 0 2 0 2 2 2 2\n",
      " 2 0 0 2 0 0 2 2 2 0 2 0 2 2 0 2 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 0 0 0 0 2 2\n",
      " 2 2 0 2 2 2 0 2 0 0 2 0 0 2 2 0 0 2 2 0 2 2 2 2 0 2 2 0 0 2 2 0 2 0 2 2 0\n",
      " 2 2 0 0 2 0 2 2 0 2 2 2 0 2 2 2 2 0 2 2 0 0 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2\n",
      " 0 0 0 2 0 0 0 0 0 0 2 2 2 2 0 2 2 2 0 2 0 2 0 0 2 2 2 2 2 2 2 0 0 0 0 0 2\n",
      " 2 2 0 2 2 2 2 0 0 2 2 2 2 2 2 0 0 2 2 0 0 2 0 0 2 0 0 2 0 0 2 2 0 2 0 0 0\n",
      " 2 0 0 0 2 2 2 0 0 0 0 2 2 2 2 2 2 0 2 0 2 2 0 2 0 2 0 2 2 0 0 2 2 2 0 0 0\n",
      " 0 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 0 0 3 0 0 0 2 0 0 0 0 0 3 3 0 0 3 0 0 3 0\n",
      " 2 0 3 3 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 3 0 0 0 0 3 3 3 0 0 3 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 3 0 0 3 0 0 0 3 0 0 0 0 0 0 0 3 0 0 2\n",
      " 0 0 0 3 0 2 0 0 3 0 3 0 0 0 0 0 0 3 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 3 3 0 3\n",
      " 0 0 3 0 0 0 3 0 3 0 0 0 0 0 3 0 0 0 3 0 0 0 0 3 3 0 0 2 3 3 3 3 0 0 0 0 3\n",
      " 3 0 0 0 0 0 0 3 3 0 0 0 3 0 3 0 3 3 0 0 3 0 0 3 0 3 0 0 0 0 0 3 3 0 0 3 3\n",
      " 0 0 2 0 3 0 0 0 0 3 0 0 0 0 2 0 0 0 3 0 3 3 0 0 0 3 3 2 0 3 0 0 0 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 0 0 0 3 0 3 3\n",
      " 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 3 3 0 3 0 0 0 0 3 0 0 3 0 0 0 2 3 0 3 0 3 3\n",
      " 3 3 0 0 3 0 0 0 0 0 3 3 0 0 0 0 0 0 0 3 0 0 0 0 0 0 3 3 3 3 3 3 3 3 0 0 0\n",
      " 3 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 3 0 0 0 0 0 0 0 3 0 0 0 0 3 0\n",
      " 0 0 3 0 3 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5875\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  53%|▌| 17/32 [00:01<00:01, 10.95it/s, loss=115, val_loss=0.0969, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 32/32 [00:01<00:00, 18.21it/s, loss=115, val_loss=0.269, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 16/32 [00:01<00:01, 10.69it/s, loss=1.76, val_loss=0.269, avg_v\u001b[A\n",
      "Epoch 1:  62%|▋| 20/32 [00:01<00:00, 13.01it/s, loss=1.76, val_loss=0.269, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:01<00:00, 18.56it/s, loss=1.76, val_loss=0.143, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.307, val_loss=0.143, avg_\u001b[A\n",
      "Epoch 2:  62%|▋| 20/32 [00:01<00:00, 12.92it/s, loss=0.307, val_loss=0.143, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:01<00:00, 18.55it/s, loss=0.307, val_loss=0.0845, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 16/32 [00:01<00:01, 10.25it/s, loss=0.0884, val_loss=0.0845, av\u001b[A\n",
      "Epoch 3:  62%|▋| 20/32 [00:01<00:00, 12.59it/s, loss=0.0884, val_loss=0.0845, av\n",
      "Epoch 3: 100%|█| 32/32 [00:01<00:00, 18.18it/s, loss=0.0884, val_loss=0.0641, av\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.0425, val_loss=0.0641, av\u001b[A\n",
      "Epoch 4:  62%|▋| 20/32 [00:01<00:00, 12.69it/s, loss=0.0425, val_loss=0.0641, av\n",
      "Epoch 4: 100%|█| 32/32 [00:01<00:00, 18.26it/s, loss=0.0425, val_loss=0.0499, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:01<00:01, 10.17it/s, loss=0.0301, val_loss=0.0499, av\u001b[A\n",
      "Epoch 5:  62%|▋| 20/32 [00:01<00:00, 12.31it/s, loss=0.0301, val_loss=0.0499, av\n",
      "Epoch 5:  94%|▉| 30/32 [00:01<00:00, 17.23it/s, loss=0.0301, val_loss=0.0499, av\u001b[A\n",
      "Epoch 5: 100%|█| 32/32 [00:01<00:00, 17.87it/s, loss=0.0301, val_loss=0.041, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.0255, val_loss=0.041, avg\u001b[A\n",
      "Epoch 6:  62%|▋| 20/32 [00:01<00:00, 12.85it/s, loss=0.0255, val_loss=0.041, avg\n",
      "Epoch 6: 100%|█| 32/32 [00:01<00:00, 18.54it/s, loss=0.0255, val_loss=0.036, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.0226, val_loss=0.036, avg\u001b[A\n",
      "Epoch 7:  69%|▋| 22/32 [00:01<00:00, 13.47it/s, loss=0.0226, val_loss=0.036, avg\n",
      "Validating:  44%|██████████████                  | 7/16 [00:00<00:00, 64.56it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 32/32 [00:01<00:00, 17.91it/s, loss=0.0226, val_loss=0.0319, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:01<00:01, 10.70it/s, loss=0.0206, val_loss=0.0319, av\u001b[A\n",
      "Epoch 8:  69%|▋| 22/32 [00:01<00:00, 14.21it/s, loss=0.0206, val_loss=0.0319, av\n",
      "Epoch 8: 100%|█| 32/32 [00:01<00:00, 18.86it/s, loss=0.0206, val_loss=0.0287, av\u001b[A\n",
      "Epoch 9:  50%|▌| 16/32 [00:01<00:01, 10.12it/s, loss=0.019, val_loss=0.0287, avg\u001b[A\n",
      "Epoch 9:  69%|▋| 22/32 [00:01<00:00, 13.37it/s, loss=0.019, val_loss=0.0287, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:01<00:00, 17.92it/s, loss=0.019, val_loss=0.0262, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:01<00:01, 10.44it/s, loss=0.0177, val_loss=0.0262, a\u001b[A\n",
      "Epoch 10:  69%|▋| 22/32 [00:01<00:00, 13.80it/s, loss=0.0177, val_loss=0.0262, a\n",
      "Epoch 10: 100%|█| 32/32 [00:01<00:00, 18.31it/s, loss=0.0177, val_loss=0.0242, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:01<00:01,  9.85it/s, loss=0.0166, val_loss=0.0242, a\u001b[A\n",
      "Epoch 11:  69%|▋| 22/32 [00:01<00:00, 12.88it/s, loss=0.0166, val_loss=0.0242, a\n",
      "Epoch 11: 100%|█| 32/32 [00:01<00:00, 17.32it/s, loss=0.0166, val_loss=0.0225, a\u001b[A\n",
      "Epoch 12:  50%|▌| 16/32 [00:01<00:01, 10.07it/s, loss=0.0157, val_loss=0.0225, a\u001b[A\n",
      "Epoch 12:  69%|▋| 22/32 [00:01<00:00, 13.35it/s, loss=0.0157, val_loss=0.0225, a\n",
      "Epoch 12: 100%|█| 32/32 [00:01<00:00, 17.76it/s, loss=0.0157, val_loss=0.0211, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:01<00:01, 10.26it/s, loss=0.0149, val_loss=0.0211, a\u001b[A\n",
      "Epoch 13:  69%|▋| 22/32 [00:01<00:00, 13.58it/s, loss=0.0149, val_loss=0.0211, a\n",
      "Epoch 13: 100%|█| 32/32 [00:01<00:00, 18.09it/s, loss=0.0149, val_loss=0.0199, a\u001b[A\n",
      "Epoch 14:  50%|▌| 16/32 [00:01<00:01, 10.35it/s, loss=0.0142, val_loss=0.0199, a\u001b[A\n",
      "Epoch 14:  69%|▋| 22/32 [00:01<00:00, 13.89it/s, loss=0.0142, val_loss=0.0199, a\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 18.27it/s, loss=0.0142, val_loss=0.0189, a\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01,  9.90it/s, loss=0.0135, val_loss=0.0189, a\u001b[A\n",
      "Epoch 15:  69%|▋| 22/32 [00:01<00:00, 13.31it/s, loss=0.0135, val_loss=0.0189, a\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 17.44it/s, loss=0.0135, val_loss=0.018, av\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01, 10.60it/s, loss=0.013, val_loss=0.018, avg\u001b[A\n",
      "Epoch 16:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.013, val_loss=0.018, avg\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 18.75it/s, loss=0.013, val_loss=0.0172, av\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.82it/s, loss=0.0125, val_loss=0.0172, a\u001b[A\n",
      "Epoch 17:  69%|▋| 22/32 [00:01<00:00, 14.36it/s, loss=0.0125, val_loss=0.0172, a\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 19.05it/s, loss=0.0125, val_loss=0.0165, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.012, val_loss=0.0165, av\u001b[A\n",
      "Epoch 18:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.012, val_loss=0.0165, av\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 18.59it/s, loss=0.012, val_loss=0.0158, av\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.92it/s, loss=0.0116, val_loss=0.0158, a\u001b[A\n",
      "Epoch 19:  69%|▋| 22/32 [00:01<00:00, 14.55it/s, loss=0.0116, val_loss=0.0158, a\n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 19.17it/s, loss=0.0116, val_loss=0.0152, a\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.0112, val_loss=0.0152, a\u001b[A\n",
      "Epoch 20:  69%|▋| 22/32 [00:01<00:00, 13.88it/s, loss=0.0112, val_loss=0.0152, a\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.38it/s, loss=0.0112, val_loss=0.0146, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01, 10.42it/s, loss=0.0109, val_loss=0.0146, a\u001b[A\n",
      "Epoch 21:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.0109, val_loss=0.0146, a\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 18.43it/s, loss=0.0109, val_loss=0.0141, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 10.39it/s, loss=0.0106, val_loss=0.0141, a\u001b[A\n",
      "Epoch 22:  69%|▋| 22/32 [00:01<00:00, 13.66it/s, loss=0.0106, val_loss=0.0141, a\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 18.25it/s, loss=0.0106, val_loss=0.0136, a\u001b[A\n",
      "Epoch 23:  50%|▌| 16/32 [00:01<00:01, 10.18it/s, loss=0.0103, val_loss=0.0136, a\u001b[A\n",
      "Epoch 23:  69%|▋| 22/32 [00:01<00:00, 13.49it/s, loss=0.0103, val_loss=0.0136, a\n",
      "Epoch 23: 100%|█| 32/32 [00:01<00:00, 17.87it/s, loss=0.0103, val_loss=0.0132, a\u001b[A\n",
      "Epoch 24:  50%|▌| 16/32 [00:01<00:01, 10.05it/s, loss=0.01, val_loss=0.0132, avg\u001b[A\n",
      "Epoch 24:  69%|▋| 22/32 [00:01<00:00, 13.39it/s, loss=0.01, val_loss=0.0132, avg\n",
      "Epoch 24: 100%|█| 32/32 [00:01<00:00, 17.89it/s, loss=0.01, val_loss=0.0128, avg\u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.00977, val_loss=0.0128, \u001b[A\n",
      "Epoch 25:  69%|▋| 22/32 [00:01<00:00, 14.24it/s, loss=0.00977, val_loss=0.0128, \n",
      "Epoch 25: 100%|█| 32/32 [00:01<00:00, 18.77it/s, loss=0.00977, val_loss=0.0125, \u001b[A\n",
      "Epoch 26:  50%|▌| 16/32 [00:01<00:01, 10.60it/s, loss=0.00954, val_loss=0.0125, \u001b[A\n",
      "Epoch 26:  69%|▋| 22/32 [00:01<00:00, 14.27it/s, loss=0.00954, val_loss=0.0125, \n",
      "Epoch 26: 100%|█| 32/32 [00:01<00:00, 18.72it/s, loss=0.00954, val_loss=0.0121, \u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:01<00:01, 10.77it/s, loss=0.00932, val_loss=0.0121, \u001b[A\n",
      "Epoch 27:  69%|▋| 22/32 [00:01<00:00, 14.51it/s, loss=0.00932, val_loss=0.0121, \n",
      "Epoch 27: 100%|█| 32/32 [00:01<00:00, 19.01it/s, loss=0.00932, val_loss=0.0118, \u001b[A\n",
      "Epoch 28:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.00912, val_loss=0.0118, \u001b[A\n",
      "Epoch 28:  69%|▋| 22/32 [00:01<00:00, 13.55it/s, loss=0.00912, val_loss=0.0118, \n",
      "Epoch 28: 100%|█| 32/32 [00:01<00:00, 18.13it/s, loss=0.00912, val_loss=0.0115, \u001b[A\n",
      "Epoch 29:  50%|▌| 16/32 [00:01<00:01, 10.65it/s, loss=0.00894, val_loss=0.0115, \u001b[A\n",
      "Epoch 29:  69%|▋| 22/32 [00:01<00:00, 14.31it/s, loss=0.00894, val_loss=0.0115, \n",
      "Epoch 29: 100%|█| 32/32 [00:01<00:00, 18.78it/s, loss=0.00894, val_loss=0.0113, \u001b[A\n",
      "Epoch 30:  50%|▌| 16/32 [00:01<00:01, 10.72it/s, loss=0.00877, val_loss=0.0113, \u001b[A\n",
      "Epoch 30:  69%|▋| 22/32 [00:01<00:00, 14.24it/s, loss=0.00877, val_loss=0.0113, \n",
      "Epoch 30: 100%|█| 32/32 [00:01<00:00, 18.93it/s, loss=0.00877, val_loss=0.011, a\u001b[A\n",
      "Epoch 31:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.00861, val_loss=0.011, a\u001b[A\n",
      "Epoch 31:  69%|▋| 22/32 [00:01<00:00, 13.66it/s, loss=0.00861, val_loss=0.011, a\n",
      "Epoch 31: 100%|█| 32/32 [00:01<00:00, 18.21it/s, loss=0.00861, val_loss=0.0108, \u001b[A\n",
      "Epoch 32:  50%|▌| 16/32 [00:01<00:01, 10.86it/s, loss=0.00847, val_loss=0.0108, \u001b[A\n",
      "Epoch 32:  69%|▋| 22/32 [00:01<00:00, 14.56it/s, loss=0.00847, val_loss=0.0108, \n",
      "Epoch 32: 100%|█| 32/32 [00:01<00:00, 19.13it/s, loss=0.00847, val_loss=0.0106, \u001b[A\n",
      "Epoch 33:  50%|▌| 16/32 [00:01<00:01, 10.69it/s, loss=0.00833, val_loss=0.0106, \u001b[A\n",
      "Epoch 33:  69%|▋| 22/32 [00:01<00:00, 14.04it/s, loss=0.00833, val_loss=0.0106, \n",
      "Epoch 33: 100%|█| 32/32 [00:01<00:00, 18.57it/s, loss=0.00833, val_loss=0.0104, \u001b[A\n",
      "Epoch 34:  50%|▌| 16/32 [00:01<00:01, 10.26it/s, loss=0.0082, val_loss=0.0104, a\u001b[A\n",
      "Epoch 34:  69%|▋| 22/32 [00:01<00:00, 13.59it/s, loss=0.0082, val_loss=0.0104, a\n",
      "Epoch 34: 100%|█| 32/32 [00:01<00:00, 18.07it/s, loss=0.0082, val_loss=0.0102, a\u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:01<00:01, 10.17it/s, loss=0.00808, val_loss=0.0102, \u001b[A\n",
      "Epoch 35:  69%|▋| 22/32 [00:01<00:00, 13.45it/s, loss=0.00808, val_loss=0.0102, \n",
      "Epoch 35: 100%|█| 32/32 [00:01<00:00, 17.88it/s, loss=0.00808, val_loss=0.0101, \u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.00797, val_loss=0.0101, \u001b[A\n",
      "Epoch 36:  69%|▋| 22/32 [00:01<00:00, 14.08it/s, loss=0.00797, val_loss=0.0101, \n",
      "Epoch 36: 100%|█| 32/32 [00:01<00:00, 18.66it/s, loss=0.00797, val_loss=0.00989,\u001b[A\n",
      "Epoch 37:  50%|▌| 16/32 [00:01<00:01,  9.95it/s, loss=0.00787, val_loss=0.00989,\u001b[A\n",
      "Epoch 37:  69%|▋| 22/32 [00:01<00:00, 13.28it/s, loss=0.00787, val_loss=0.00989,\n",
      "Epoch 37: 100%|█| 32/32 [00:01<00:00, 17.69it/s, loss=0.00787, val_loss=0.00974,\u001b[A\n",
      "Epoch 38:  50%|▌| 16/32 [00:01<00:01, 10.45it/s, loss=0.00777, val_loss=0.00974,\u001b[A\n",
      "Epoch 38:  69%|▋| 22/32 [00:01<00:00, 13.90it/s, loss=0.00777, val_loss=0.00974,\n",
      "Epoch 38: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.00777, val_loss=0.0096, \u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.00768, val_loss=0.0096, \u001b[A\n",
      "Epoch 39:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.00768, val_loss=0.0096, \n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.61it/s, loss=0.00768, val_loss=0.00947,\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.47it/s, loss=0.00768, val_loss=0.00947,\u001b[A\n",
      "Sizes of clusters: 416, 485, 505, 194\n",
      "\n",
      "preds: [1 1 1 1 1 3 3 2 2 2 1 1 2 3 3 1 3 1 1 3 3 3 3 3 1 2 2 1 1 1 3 3 2 3 3 1 2\n",
      " 1 1 1 1 3 2 2 1 1 3 1 2 3 2 1 2 2 1 1 1 1 1 2 2 1 1 3 2 2 2 2 1 1 2 3 1 2\n",
      " 1 1 1 2 2 1 2 2 3 3 2 1 1 1 2 3 1 0 3 2 3 3 3 2 1 1 1 1 1 2 1 1 3 3 2 2 3\n",
      " 1 2 1 2 3 3 2 1 3 3 1 2 2 1 2 2 2 1 1 3 1 3 3 1 3 3 1 3 1 2 3 1 3 2 3 2 3\n",
      " 1 2 3 1 1 2 1 3 3 3 2 1 1 3 3 2 3 2 0 3 1 2 1 2 2 3 1 1 3 1 2 2 3 1 3 2 1\n",
      " 3 2 1 1 2 2 3 2 1 3 2 3 2 1 3 1 3 1 2 2 3 2 2 1 1 3 3 1 2 1 2 3 3 1 1 2 1\n",
      " 1 2 1 3 1 1 1 1 3 3 1 3 2 2 3 1 1 2 1 1 2 2 2 1 1 1 3 2 1 3 2 3 2 2 2 1 3\n",
      " 1 1 3 3 1 1 2 3 2 3 1 1 2 2 1 3 1 1 1 3 3 2 2 2 1 2 1 1 3 1 2 3 2 2 2 3 3\n",
      " 3 1 3 2 1 1 3 1 2 1 2 1 3 1 1 2 3 1 1 3 3 3 1 1 3 2 1 3 2 3 1 1 2 1 1 2 2\n",
      " 1 3 3 1 2 2 1 2 2 1 1 3 3 1 1 2 2 1 2 3 2 3 2 1 1 3 3 3 3 1 2 1 1 1 2 2 3\n",
      " 3 1 3 2 2 1 1 3 1 2 1 3 2 1 1 2 3 1 1 3 3 1 1 3 1 3 3 3 1 3 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 2 1 2 2 1 1 2 1 2 0 0\n",
      " 1 2 1 2 1 2 2 2 1 1 1 2 1 1 3 1 1 2 2 2 2 2 2 2 1 2 1 1 2 2 3 1 1 3 0 2 1\n",
      " 2 1 2 2 3 2 2 2 1 3 1 2 1 2 3 1 1 2 3 2 1 3 1 3 1 1 0 1 1 1 1 1 1 1 1 3 1\n",
      " 1 1 3 2 0 1 1 1 3 2 2 0 0 2 3 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 3 0 1 1 1 1\n",
      " 1 1 1 2 2 1 1 2 3 1 1 1 1 1 1 1 1 3 1 2 1 1 1 3 2 2 2 1 1 2 2 3 0 1 2 1 2\n",
      " 2 1 1 1 2 1 1 2 3 1 3 1 1 1 2 3 1 2 2 3 1 1 1 1 2 2 1 1 1 3 3 2 1 1 2 3 1\n",
      " 1 3 2 1 3 1 0 1 1 2 1 1 1 1 2 2 2 2 1 2 1 1 1 2 1 2 2 2 2 3 1 2 1 1 3 3 1\n",
      " 3 1 2 0 2 1 2 1 1 1 2 3 2 1 3 1 1 1 3 1 1 2 1 2 3 3 2 2 1 1 1 2 1 2 2 1 1\n",
      " 2 1 2 1 2 2 1 2 1 1 1 1 3 3 2 1 2 1 2 1 1 2 2 2 2 1 2 3 2 3 1 2 1 2 2 1 2\n",
      " 1 1 2 1 1 2 2 1 2 1 1 3 1 1 1 2 2 1 1 2 1 3 2 1 3 1 2 2 2 1 1 1 2 3 2 0 1\n",
      " 2 2 2 2 1 2 2 2 1 1 1 1 1 1 1 2 3 1 1 2 2 3 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 1 2 2 2 2 1 2 2 1 3 1 3 1 1 1 3 2 1 1 2 1 2 2 2 2 2 2 1 2 1 3 1 1 1 1 2\n",
      " 1 2 2 1 2 2 2 2 2 2 3 1 2 1 2 1 2 2 2 1 2 2 2 2 2 1 2 3 1 1 2 2 2 2 2 2 2\n",
      " 1 2 2 1 2 1 3 2 2 1 3 2 2 1 1 2 1 3 2 2 2 1 2 1 2 2 2 2 1 2 1 2 2 2 1 1 2\n",
      " 2 2 1 2 2 2 1 2 2 2 0 2 2 1 1 2 2 1 1 2 2 1 3 1 2 2 2 1 2 2 1 2 1 1 2 1 2\n",
      " 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 2 2 1 2 1 1 2 2 1 2 2 1 2 2 1 2 3 3 2 2 1\n",
      " 2 1 2 2 1 1 1 2 1 2 1 2 2 1 2 1 1 1 1 2 2 2 1 2 1 0 2 2 2 3 2 2 0 3 2 2 0\n",
      " 2 2 2 3 2 1 2 2 2 1 2 1 2 1 2 2 2 2 1 1 1 2 2 2 2 1 2 1 3 2 1 2 1 2 1 2 1\n",
      " 2 2 2 2 2 2 1 2 2 2 2 3 1 2 2 1 2 1 2 0 3 2 1 2 1 1 0 1 3 2 2 2 2 1 2 2 2\n",
      " 2 1 2 2 1 2 2 2 2 3 1 2 2 3 2 1 2 1 2 2 1 1 3 2 2 2 2 2 2 2 1 2 2 1 2 2 2\n",
      " 2 2 2 2 2 1 2 3 2 1 2 2 2 3 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2 0 3 1 2 2 1 2 2\n",
      " 2 1 1 3 2 2 2 1 2 2 1 3 1 2 2 2 2 1 2 2 1 1 1 2 2 2 2 2 2 1 2 2 1 3 1 2 2\n",
      " 2 2 2 2 2 1 2 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5981\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  53%|▌| 17/32 [00:01<00:01, 11.15it/s, loss=165, val_loss=0.0622, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 32/32 [00:01<00:00, 18.51it/s, loss=165, val_loss=0.186, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 16/32 [00:01<00:01, 10.78it/s, loss=3.13, val_loss=0.186, avg_v\u001b[A\n",
      "Epoch 1:  69%|▋| 22/32 [00:01<00:00, 14.51it/s, loss=3.13, val_loss=0.186, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:01<00:00, 18.98it/s, loss=3.13, val_loss=0.22, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 16/32 [00:01<00:01, 10.64it/s, loss=0.582, val_loss=0.22, avg_v\u001b[A\n",
      "Epoch 2:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.582, val_loss=0.22, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:01<00:00, 18.58it/s, loss=0.582, val_loss=0.118, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 16/32 [00:01<00:01, 10.28it/s, loss=0.139, val_loss=0.118, avg_\u001b[A\n",
      "Epoch 3:  69%|▋| 22/32 [00:01<00:00, 13.88it/s, loss=0.139, val_loss=0.118, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:01<00:00, 18.03it/s, loss=0.139, val_loss=0.061, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:01<00:01, 10.39it/s, loss=0.0541, val_loss=0.061, avg\u001b[A\n",
      "Epoch 4:  69%|▋| 22/32 [00:01<00:00, 13.84it/s, loss=0.0541, val_loss=0.061, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:01<00:00, 18.25it/s, loss=0.0541, val_loss=0.0459, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.0343, val_loss=0.0459, av\u001b[A\n",
      "Epoch 5:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.0343, val_loss=0.0459, av\n",
      "Epoch 5: 100%|█| 32/32 [00:01<00:00, 18.54it/s, loss=0.0343, val_loss=0.0377, av\u001b[A\n",
      "Epoch 6:  50%|▌| 16/32 [00:01<00:01, 10.44it/s, loss=0.0275, val_loss=0.0377, av\u001b[A\n",
      "Epoch 6:  69%|▋| 22/32 [00:01<00:00, 13.91it/s, loss=0.0275, val_loss=0.0377, av\n",
      "Epoch 6: 100%|█| 32/32 [00:01<00:00, 18.40it/s, loss=0.0275, val_loss=0.033, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 16/32 [00:01<00:01, 10.52it/s, loss=0.024, val_loss=0.033, avg_\u001b[A\n",
      "Epoch 7:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.024, val_loss=0.033, avg_\n",
      "Epoch 7: 100%|█| 32/32 [00:01<00:00, 18.57it/s, loss=0.024, val_loss=0.0291, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:01<00:01, 10.55it/s, loss=0.0218, val_loss=0.0291, av\u001b[A\n",
      "Epoch 8:  69%|▋| 22/32 [00:01<00:00, 14.15it/s, loss=0.0218, val_loss=0.0291, av\n",
      "Epoch 8: 100%|█| 32/32 [00:01<00:00, 18.60it/s, loss=0.0218, val_loss=0.0263, av\u001b[A\n",
      "Epoch 9:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.0201, val_loss=0.0263, av\u001b[A\n",
      "Epoch 9:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0201, val_loss=0.0263, av\n",
      "Epoch 9: 100%|█| 32/32 [00:01<00:00, 18.52it/s, loss=0.0201, val_loss=0.0241, av\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:01<00:01, 10.46it/s, loss=0.0188, val_loss=0.0241, a\u001b[A\n",
      "Epoch 10:  69%|▋| 22/32 [00:01<00:00, 13.74it/s, loss=0.0188, val_loss=0.0241, a\n",
      "Epoch 10: 100%|█| 32/32 [00:01<00:00, 18.22it/s, loss=0.0188, val_loss=0.0224, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.0176, val_loss=0.0224, a\u001b[A\n",
      "Epoch 11:  69%|▋| 22/32 [00:01<00:00, 14.18it/s, loss=0.0176, val_loss=0.0224, a\n",
      "Epoch 11: 100%|█| 32/32 [00:01<00:00, 18.70it/s, loss=0.0176, val_loss=0.021, av\u001b[A\n",
      "Epoch 12:  50%|▌| 16/32 [00:01<00:01, 10.44it/s, loss=0.0167, val_loss=0.021, av\u001b[A\n",
      "Epoch 12:  69%|▋| 22/32 [00:01<00:00, 13.97it/s, loss=0.0167, val_loss=0.021, av\n",
      "Epoch 12: 100%|█| 32/32 [00:01<00:00, 18.37it/s, loss=0.0167, val_loss=0.0197, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:01<00:01, 10.54it/s, loss=0.0158, val_loss=0.0197, a\u001b[A\n",
      "Epoch 13:  69%|▋| 22/32 [00:01<00:00, 14.03it/s, loss=0.0158, val_loss=0.0197, a\n",
      "Epoch 13: 100%|█| 32/32 [00:01<00:00, 18.66it/s, loss=0.0158, val_loss=0.0187, a\u001b[A\n",
      "Epoch 14:  50%|▌| 16/32 [00:01<00:01, 10.48it/s, loss=0.015, val_loss=0.0187, av\u001b[A\n",
      "Epoch 14:  69%|▋| 22/32 [00:01<00:00, 13.97it/s, loss=0.015, val_loss=0.0187, av\n",
      "Validating:  69%|████████████████████▋         | 11/16 [00:00<00:00, 101.42it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 18.25it/s, loss=0.015, val_loss=0.0179, av\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01,  9.96it/s, loss=0.0144, val_loss=0.0179, a\u001b[A\n",
      "Epoch 15:  69%|▋| 22/32 [00:01<00:00, 13.20it/s, loss=0.0144, val_loss=0.0179, a\n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 74.67it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 17.16it/s, loss=0.0144, val_loss=0.0171, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01,  9.89it/s, loss=0.0138, val_loss=0.0171, a\u001b[A\n",
      "Epoch 16:  69%|▋| 22/32 [00:01<00:00, 13.13it/s, loss=0.0138, val_loss=0.0171, a\n",
      "Validating:  62%|███████████████████▍           | 10/16 [00:00<00:00, 98.91it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 17.54it/s, loss=0.0138, val_loss=0.0164, a\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.11it/s, loss=0.0132, val_loss=0.0164, a\u001b[A\n",
      "Epoch 17:  69%|▋| 22/32 [00:01<00:00, 13.45it/s, loss=0.0132, val_loss=0.0164, a\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 17.96it/s, loss=0.0132, val_loss=0.0158, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01, 10.30it/s, loss=0.0127, val_loss=0.0158, a\u001b[A\n",
      "Epoch 18:  69%|▋| 22/32 [00:01<00:00, 13.64it/s, loss=0.0127, val_loss=0.0158, a\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 18.01it/s, loss=0.0127, val_loss=0.0153, a\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.0122, val_loss=0.0153, a\u001b[A\n",
      "Epoch 19:  69%|▋| 22/32 [00:01<00:00, 13.69it/s, loss=0.0122, val_loss=0.0153, a\n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 18.21it/s, loss=0.0122, val_loss=0.0148, a\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.0118, val_loss=0.0148, a\u001b[A\n",
      "Epoch 20:  69%|▋| 22/32 [00:01<00:00, 13.79it/s, loss=0.0118, val_loss=0.0148, a\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.32it/s, loss=0.0118, val_loss=0.0143, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.0114, val_loss=0.0143, a\u001b[A\n",
      "Epoch 21:  69%|▋| 22/32 [00:01<00:00, 13.97it/s, loss=0.0114, val_loss=0.0143, a\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 18.53it/s, loss=0.0114, val_loss=0.0139, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 10.46it/s, loss=0.0111, val_loss=0.0139, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  69%|▋| 22/32 [00:01<00:00, 13.35it/s, loss=0.0111, val_loss=0.0139, a\u001b[A\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 17.91it/s, loss=0.0111, val_loss=0.0135, a\u001b[A\n",
      "Epoch 23:  50%|▌| 16/32 [00:01<00:01, 10.60it/s, loss=0.0108, val_loss=0.0135, a\u001b[A\n",
      "Epoch 23:  69%|▋| 22/32 [00:01<00:00, 13.98it/s, loss=0.0108, val_loss=0.0135, a\n",
      "Epoch 23: 100%|█| 32/32 [00:01<00:00, 18.64it/s, loss=0.0108, val_loss=0.0131, a\u001b[A\n",
      "Epoch 24:  50%|▌| 16/32 [00:01<00:01, 10.21it/s, loss=0.0105, val_loss=0.0131, a\u001b[A\n",
      "Epoch 24:  69%|▋| 22/32 [00:01<00:00, 13.67it/s, loss=0.0105, val_loss=0.0131, a\n",
      "Epoch 24: 100%|█| 32/32 [00:01<00:00, 18.14it/s, loss=0.0105, val_loss=0.0127, a\u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:01<00:01, 10.54it/s, loss=0.0102, val_loss=0.0127, a\u001b[A\n",
      "Epoch 25:  69%|▋| 22/32 [00:01<00:00, 13.95it/s, loss=0.0102, val_loss=0.0127, a\n",
      "Epoch 25: 100%|█| 32/32 [00:01<00:00, 18.59it/s, loss=0.0102, val_loss=0.0123, a\u001b[A\n",
      "Epoch 26:  50%|▌| 16/32 [00:01<00:01, 10.47it/s, loss=0.00991, val_loss=0.0123, \u001b[A\n",
      "Epoch 26:  69%|▋| 22/32 [00:01<00:00, 13.71it/s, loss=0.00991, val_loss=0.0123, \n",
      "Validating:  44%|██████████████                  | 7/16 [00:00<00:00, 68.05it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 32/32 [00:01<00:00, 18.17it/s, loss=0.00991, val_loss=0.012, a\u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.00965, val_loss=0.012, a\u001b[A\n",
      "Epoch 27:  69%|▋| 22/32 [00:01<00:00, 14.35it/s, loss=0.00965, val_loss=0.012, a\n",
      "Epoch 27: 100%|█| 32/32 [00:01<00:00, 18.87it/s, loss=0.00965, val_loss=0.0116, \u001b[A\n",
      "Epoch 28:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.00941, val_loss=0.0116, \u001b[A\n",
      "Epoch 28:  69%|▋| 22/32 [00:01<00:00, 13.82it/s, loss=0.00941, val_loss=0.0116, \n",
      "Epoch 28: 100%|█| 32/32 [00:01<00:00, 18.53it/s, loss=0.00941, val_loss=0.0113, \u001b[A\n",
      "Epoch 29:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.00919, val_loss=0.0113, \u001b[A\n",
      "Epoch 29:  69%|▋| 22/32 [00:01<00:00, 14.10it/s, loss=0.00919, val_loss=0.0113, \n",
      "Epoch 29: 100%|█| 32/32 [00:01<00:00, 18.62it/s, loss=0.00919, val_loss=0.0111, \u001b[A\n",
      "Epoch 30:  50%|▌| 16/32 [00:01<00:01, 10.70it/s, loss=0.00899, val_loss=0.0111, \u001b[A\n",
      "Epoch 30:  69%|▋| 22/32 [00:01<00:00, 14.16it/s, loss=0.00899, val_loss=0.0111, \n",
      "Epoch 30: 100%|█| 32/32 [00:01<00:00, 18.85it/s, loss=0.00899, val_loss=0.0108, \u001b[A\n",
      "Epoch 31:  50%|▌| 16/32 [00:01<00:01, 10.46it/s, loss=0.0088, val_loss=0.0108, a\u001b[A\n",
      "Epoch 31:  69%|▋| 22/32 [00:01<00:00, 14.08it/s, loss=0.0088, val_loss=0.0108, a\n",
      "Epoch 31: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0088, val_loss=0.0105, a\u001b[A\n",
      "Epoch 32:  50%|▌| 16/32 [00:01<00:01, 10.66it/s, loss=0.00862, val_loss=0.0105, \u001b[A\n",
      "Epoch 32:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.00862, val_loss=0.0105, \n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 76.97it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 32/32 [00:01<00:00, 18.50it/s, loss=0.00862, val_loss=0.0103, \u001b[A\n",
      "Epoch 33:  50%|▌| 16/32 [00:01<00:01, 10.95it/s, loss=0.00846, val_loss=0.0103, \u001b[A\n",
      "Epoch 33:  69%|▋| 22/32 [00:01<00:00, 14.63it/s, loss=0.00846, val_loss=0.0103, \n",
      "Epoch 33: 100%|█| 32/32 [00:01<00:00, 19.22it/s, loss=0.00846, val_loss=0.0101, \u001b[A\n",
      "Epoch 34:  50%|▌| 16/32 [00:01<00:01, 10.64it/s, loss=0.00831, val_loss=0.0101, \u001b[A\n",
      "Epoch 34:  69%|▋| 22/32 [00:01<00:00, 14.18it/s, loss=0.00831, val_loss=0.0101, \n",
      "Epoch 34: 100%|█| 32/32 [00:01<00:00, 18.74it/s, loss=0.00831, val_loss=0.00987,\u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.00816, val_loss=0.00987,\u001b[A\n",
      "Epoch 35:  69%|▋| 22/32 [00:01<00:00, 14.22it/s, loss=0.00816, val_loss=0.00987,\n",
      "Epoch 35: 100%|█| 32/32 [00:01<00:00, 18.80it/s, loss=0.00816, val_loss=0.00967,\u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.00803, val_loss=0.00967,\u001b[A\n",
      "Epoch 36:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.00803, val_loss=0.00967,\n",
      "Epoch 36: 100%|█| 32/32 [00:01<00:00, 18.64it/s, loss=0.00803, val_loss=0.00948,\u001b[A\n",
      "Epoch 37:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.00791, val_loss=0.00948,\u001b[A\n",
      "Epoch 37:  69%|▋| 22/32 [00:01<00:00, 13.90it/s, loss=0.00791, val_loss=0.00948,\n",
      "Epoch 37: 100%|█| 32/32 [00:01<00:00, 18.27it/s, loss=0.00791, val_loss=0.00931,\u001b[A\n",
      "Epoch 38:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.00779, val_loss=0.00931,\u001b[A\n",
      "Epoch 38:  69%|▋| 22/32 [00:01<00:00, 14.07it/s, loss=0.00779, val_loss=0.00931,\n",
      "Epoch 38: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.00779, val_loss=0.00914,\u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.00768, val_loss=0.00914,\u001b[A\n",
      "Epoch 39:  69%|▋| 22/32 [00:01<00:00, 14.05it/s, loss=0.00768, val_loss=0.00914,\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.67it/s, loss=0.00768, val_loss=0.00899,\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.56it/s, loss=0.00768, val_loss=0.00899,\u001b[A\n",
      "Sizes of clusters: 516, 242, 630, 212\n",
      "\n",
      "preds: [3 3 1 3 1 3 3 1 3 1 3 3 1 3 3 3 3 1 1 3 3 3 3 3 1 1 1 1 1 1 3 3 2 3 3 3 3\n",
      " 1 1 1 1 3 3 1 1 1 3 1 1 3 1 3 3 1 1 1 3 1 1 1 1 1 3 3 1 1 1 1 1 1 1 3 1 1\n",
      " 1 1 3 1 1 3 1 3 3 3 1 1 1 3 1 3 3 2 3 1 3 3 3 2 1 1 1 3 3 2 1 1 3 3 3 1 3\n",
      " 1 2 1 1 3 3 1 1 3 3 1 1 1 1 1 1 1 1 1 3 1 3 3 3 1 3 1 3 3 1 3 3 3 1 3 1 3\n",
      " 3 1 3 3 3 3 3 3 3 3 1 1 3 3 3 2 3 1 2 3 3 1 1 1 3 3 3 3 3 1 1 1 3 3 3 1 1\n",
      " 3 1 1 3 1 1 3 1 3 3 1 3 1 3 3 3 3 1 1 3 1 1 1 3 3 3 3 1 1 1 3 3 3 1 3 1 3\n",
      " 1 1 3 3 1 1 3 3 3 3 3 3 1 1 3 1 3 1 3 3 1 1 1 1 1 3 3 1 3 3 1 3 1 1 2 1 3\n",
      " 3 1 3 3 3 3 1 3 1 3 3 3 1 3 3 3 3 1 3 3 3 1 3 3 1 1 3 3 1 1 3 3 1 1 1 3 3\n",
      " 3 3 3 1 1 1 3 1 1 1 1 3 3 3 3 1 3 1 3 3 3 3 3 1 3 2 1 3 1 3 3 3 1 1 3 1 1\n",
      " 1 3 3 3 1 1 1 1 1 1 1 3 3 3 3 3 1 3 3 3 1 3 3 1 1 3 3 3 3 3 1 3 1 1 1 3 3\n",
      " 3 1 3 1 1 3 1 3 1 3 3 3 1 1 1 1 3 1 3 3 3 3 3 3 1 3 3 3 3 3 0 0 0 0 2 0 0\n",
      " 1 0 0 0 0 0 0 2 0 2 2 0 0 2 1 0 2 2 0 0 2 0 0 1 0 2 1 0 0 2 2 2 0 0 1 0 2\n",
      " 0 2 0 0 0 2 2 0 0 0 0 0 0 0 2 0 2 0 1 1 0 0 2 0 1 2 0 2 2 0 0 0 2 0 2 0 1\n",
      " 0 0 0 0 0 2 0 2 2 2 0 2 0 2 2 0 0 2 0 2 0 0 2 0 0 0 0 2 2 0 2 1 2 1 1 0 2\n",
      " 1 0 2 2 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 1 0 0 0 0 0 2 0 2 0 2\n",
      " 2 2 2 0 1 2 0 1 0 0 2 0 2 0 0 2 0 0 1 1 2 0 0 0 0 0 2 0 1 0 0 0 2 2 0 2 1\n",
      " 0 2 2 0 0 0 0 2 0 0 0 0 0 0 1 0 0 2 0 2 2 2 0 2 0 2 0 0 0 0 0 0 0 2 2 2 2\n",
      " 0 1 1 1 0 2 0 2 0 2 0 0 2 0 0 0 0 0 0 2 0 0 1 2 0 0 2 1 2 0 2 0 0 0 2 1 2\n",
      " 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 1 2 2 0 0 0 0 0 0 2 2 1 1 0 0\n",
      " 0 2 0 0 2 2 2 0 0 0 0 0 0 0 0 1 2 2 2 0 0 0 0 1 0 1 0 2 2 0 0 0 0 0 1 2 0\n",
      " 0 2 0 0 0 1 2 0 0 2 1 0 0 0 0 2 1 0 0 1 0 2 0 0 0 2 0 2 0 0 2 0 0 1 2 0 0\n",
      " 2 0 2 0 0 0 0 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 1 0 0 0\n",
      " 0 0 2 0 0 0 0 2 0 0 0 0 0 2 1 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 2 2\n",
      " 2 2 0 0 2 0 0 2 0 2 0 0 2 0 2 0 0 0 2 0 2 2 2 2 2 2 0 2 1 2 2 0 0 1 1 1 2\n",
      " 2 0 1 2 0 0 2 2 2 0 2 0 0 0 2 2 0 2 2 0 2 0 0 0 2 0 0 0 0 0 2 2 0 2 2 0 2\n",
      " 2 0 0 2 0 0 2 2 2 0 0 2 2 2 1 0 0 1 2 0 2 0 2 2 0 2 0 2 2 0 0 2 0 0 0 2 0\n",
      " 0 2 2 2 0 2 0 0 2 2 2 2 2 2 2 2 0 0 0 2 1 2 0 0 0 0 2 2 0 2 2 2 2 2 2 2 0\n",
      " 0 2 0 0 2 2 0 0 2 2 0 1 2 2 0 2 0 0 0 0 0 2 2 0 2 0 0 2 2 1 0 2 2 2 2 2 2\n",
      " 2 0 0 0 0 2 0 2 2 2 0 2 2 0 2 0 0 1 2 0 2 0 2 0 2 2 0 0 2 2 2 0 2 0 0 0 0\n",
      " 0 2 0 0 0 0 2 0 2 2 0 2 2 0 0 0 0 2 2 0 2 0 2 0 0 0 0 2 0 2 2 2 2 0 2 2 0\n",
      " 2 0 0 0 0 0 0 2 0 2 0 2 0 0 2 0 2 0 0 0 2 2 0 2 2 2 0 0 0 2 0 0 0 2 0 0 2\n",
      " 0 0 0 0 2 0 0 2 2 2 2 0 0 0 2 0 2 2 2 2 0 0 2 0 2 0 2 0 2 2 0 2 0 2 2 2 2\n",
      " 0 0 2 2 0 0 2 0 0 0 2 2 2 0 0 0 2 2 2 2 0 2 0 0 0 0 2 0 1 2 2 2 2 2 2 2 0\n",
      " 0 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 0\n",
      " 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 1 2 2 2 0 2\n",
      " 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 2 2 0\n",
      " 0 0 0 2 2 2 2 0 0 1 0 2 0 2 0 2 2 2 2 2 1 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2\n",
      " 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 0 2 1 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 2 2 2 0 2 2\n",
      " 2 2 2 1 2 2 0 2 0 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2\n",
      " 2 2 2 0 2 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.6006\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  53%|▌| 17/32 [00:01<00:01, 10.78it/s, loss=136, val_loss=0.0784, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 32/32 [00:01<00:00, 18.03it/s, loss=136, val_loss=0.155, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 16/32 [00:01<00:01, 10.52it/s, loss=2.31, val_loss=0.155, avg_v\u001b[A\n",
      "Epoch 1:  69%|▋| 22/32 [00:01<00:00, 13.91it/s, loss=2.31, val_loss=0.155, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:01<00:00, 18.51it/s, loss=2.31, val_loss=0.207, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 16/32 [00:01<00:01, 10.66it/s, loss=0.422, val_loss=0.207, avg_\u001b[A\n",
      "Epoch 2:  69%|▋| 22/32 [00:01<00:00, 14.17it/s, loss=0.422, val_loss=0.207, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:01<00:00, 18.74it/s, loss=0.422, val_loss=0.0868, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 16/32 [00:01<00:01, 10.04it/s, loss=0.121, val_loss=0.0868, avg\u001b[A\n",
      "Epoch 3:  69%|▋| 22/32 [00:01<00:00, 13.29it/s, loss=0.121, val_loss=0.0868, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:01<00:00, 17.78it/s, loss=0.121, val_loss=0.0701, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.0595, val_loss=0.0701, av\u001b[A\n",
      "Epoch 4:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0595, val_loss=0.0701, av\n",
      "Epoch 4: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0595, val_loss=0.0538, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:01<00:01, 10.60it/s, loss=0.0418, val_loss=0.0538, av\u001b[A\n",
      "Epoch 5:  69%|▋| 22/32 [00:01<00:00, 13.93it/s, loss=0.0418, val_loss=0.0538, av\n",
      "Epoch 5: 100%|█| 32/32 [00:01<00:00, 18.66it/s, loss=0.0418, val_loss=0.0442, av\u001b[A\n",
      "Epoch 6:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.034, val_loss=0.0442, avg\u001b[A\n",
      "Epoch 6:  69%|▋| 22/32 [00:01<00:00, 13.79it/s, loss=0.034, val_loss=0.0442, avg\n",
      "Epoch 6: 100%|█| 32/32 [00:01<00:00, 18.35it/s, loss=0.034, val_loss=0.0359, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.0293, val_loss=0.0359, av\u001b[A\n",
      "Epoch 7:  69%|▋| 22/32 [00:01<00:00, 13.80it/s, loss=0.0293, val_loss=0.0359, av\n",
      "Epoch 7: 100%|█| 32/32 [00:01<00:00, 18.43it/s, loss=0.0293, val_loss=0.0306, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:01<00:01, 10.09it/s, loss=0.026, val_loss=0.0306, avg\u001b[A\n",
      "Epoch 8:  69%|▋| 22/32 [00:01<00:00, 13.48it/s, loss=0.026, val_loss=0.0306, avg\n",
      "Epoch 8: 100%|█| 32/32 [00:01<00:00, 17.88it/s, loss=0.026, val_loss=0.027, avg_\u001b[A\n",
      "Epoch 9:  50%|▌| 16/32 [00:01<00:01, 10.52it/s, loss=0.0236, val_loss=0.027, avg\u001b[A\n",
      "Epoch 9:  69%|▋| 22/32 [00:01<00:00, 14.11it/s, loss=0.0236, val_loss=0.027, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:01<00:00, 18.63it/s, loss=0.0236, val_loss=0.0245, av\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.0216, val_loss=0.0245, a\u001b[A\n",
      "Epoch 10:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.0216, val_loss=0.0245, a\n",
      "Epoch 10: 100%|█| 32/32 [00:01<00:00, 18.41it/s, loss=0.0216, val_loss=0.0226, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.02, val_loss=0.0226, avg\u001b[A\n",
      "Epoch 11:  69%|▋| 22/32 [00:01<00:00, 13.60it/s, loss=0.02, val_loss=0.0226, avg\n",
      "Epoch 11: 100%|█| 32/32 [00:01<00:00, 18.18it/s, loss=0.02, val_loss=0.0211, avg\u001b[A\n",
      "Epoch 12:  50%|▌| 16/32 [00:01<00:01, 10.19it/s, loss=0.0187, val_loss=0.0211, a\u001b[A\n",
      "Epoch 12:  69%|▋| 22/32 [00:01<00:00, 13.59it/s, loss=0.0187, val_loss=0.0211, a\n",
      "Epoch 12: 100%|█| 32/32 [00:01<00:00, 18.05it/s, loss=0.0187, val_loss=0.0197, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:01<00:01, 10.43it/s, loss=0.0175, val_loss=0.0197, a\u001b[A\n",
      "Epoch 13:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0175, val_loss=0.0197, a\n",
      "Epoch 13: 100%|█| 32/32 [00:01<00:00, 18.39it/s, loss=0.0175, val_loss=0.0185, a\u001b[A\n",
      "Epoch 14:  50%|▌| 16/32 [00:01<00:01, 10.57it/s, loss=0.0166, val_loss=0.0185, a\u001b[A\n",
      "Epoch 14:  69%|▋| 22/32 [00:01<00:00, 13.88it/s, loss=0.0166, val_loss=0.0185, a\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0166, val_loss=0.0174, a\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01, 10.05it/s, loss=0.0158, val_loss=0.0174, a\u001b[A\n",
      "Epoch 15:  69%|▋| 22/32 [00:01<00:00, 13.38it/s, loss=0.0158, val_loss=0.0174, a\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 17.80it/s, loss=0.0158, val_loss=0.0165, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01, 10.40it/s, loss=0.0152, val_loss=0.0165, a\u001b[A\n",
      "Epoch 16:  69%|▋| 22/32 [00:01<00:00, 13.71it/s, loss=0.0152, val_loss=0.0165, a\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 18.27it/s, loss=0.0152, val_loss=0.0158, a\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.55it/s, loss=0.0146, val_loss=0.0158, a\u001b[A\n",
      "Epoch 17:  69%|▋| 22/32 [00:01<00:00, 14.10it/s, loss=0.0146, val_loss=0.0158, a\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 18.58it/s, loss=0.0146, val_loss=0.0151, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01, 10.10it/s, loss=0.0141, val_loss=0.0151, a\u001b[A\n",
      "Epoch 18:  69%|▋| 22/32 [00:01<00:00, 13.38it/s, loss=0.0141, val_loss=0.0151, a\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 17.87it/s, loss=0.0141, val_loss=0.0145, a\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.40it/s, loss=0.0136, val_loss=0.0145, a\u001b[A\n",
      "Epoch 19:  69%|▋| 22/32 [00:01<00:00, 13.84it/s, loss=0.0136, val_loss=0.0145, a\n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 18.21it/s, loss=0.0136, val_loss=0.0139, a\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.43it/s, loss=0.0132, val_loss=0.0139, a\u001b[A\n",
      "Epoch 20:  69%|▋| 22/32 [00:01<00:00, 13.89it/s, loss=0.0132, val_loss=0.0139, a\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.41it/s, loss=0.0132, val_loss=0.0135, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.0129, val_loss=0.0135, a\u001b[A\n",
      "Epoch 21:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0129, val_loss=0.0135, a\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 18.53it/s, loss=0.0129, val_loss=0.0131, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 10.42it/s, loss=0.0125, val_loss=0.0131, a\u001b[A\n",
      "Epoch 22:  69%|▋| 22/32 [00:01<00:00, 13.91it/s, loss=0.0125, val_loss=0.0131, a\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 18.41it/s, loss=0.0125, val_loss=0.0127, a\u001b[A\n",
      "Epoch 23:  50%|▌| 16/32 [00:01<00:01, 10.29it/s, loss=0.0122, val_loss=0.0127, a\u001b[A\n",
      "Epoch 23:  69%|▋| 22/32 [00:01<00:00, 13.71it/s, loss=0.0122, val_loss=0.0127, a\n",
      "Epoch 23: 100%|█| 32/32 [00:01<00:00, 18.25it/s, loss=0.0122, val_loss=0.0123, a\u001b[A\n",
      "Epoch 24:  50%|▌| 16/32 [00:01<00:01, 10.06it/s, loss=0.012, val_loss=0.0123, av\u001b[A\n",
      "Epoch 24:  69%|▋| 22/32 [00:01<00:00, 13.21it/s, loss=0.012, val_loss=0.0123, av\n",
      "Epoch 24: 100%|█| 32/32 [00:01<00:00, 17.57it/s, loss=0.012, val_loss=0.012, avg\u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:01<00:01, 10.19it/s, loss=0.0117, val_loss=0.012, av\u001b[A\n",
      "Epoch 25:  69%|▋| 22/32 [00:01<00:00, 13.40it/s, loss=0.0117, val_loss=0.012, av\n",
      "Epoch 25: 100%|█| 32/32 [00:01<00:00, 17.93it/s, loss=0.0117, val_loss=0.0117, a\u001b[A\n",
      "Epoch 26:  50%|▌| 16/32 [00:01<00:01, 10.97it/s, loss=0.0115, val_loss=0.0117, a\u001b[A\n",
      "Epoch 26:  69%|▋| 22/32 [00:01<00:00, 14.71it/s, loss=0.0115, val_loss=0.0117, a\n",
      "Epoch 26: 100%|█| 32/32 [00:01<00:00, 19.30it/s, loss=0.0115, val_loss=0.0115, a\u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.0113, val_loss=0.0115, a\u001b[A\n",
      "Epoch 27:  69%|▋| 22/32 [00:01<00:00, 13.89it/s, loss=0.0113, val_loss=0.0115, a\n",
      "Epoch 27: 100%|█| 32/32 [00:01<00:00, 18.49it/s, loss=0.0113, val_loss=0.0113, a\u001b[A\n",
      "Epoch 28:  50%|▌| 16/32 [00:01<00:01, 10.56it/s, loss=0.0111, val_loss=0.0113, a\u001b[A\n",
      "Epoch 28:  69%|▋| 22/32 [00:01<00:00, 14.04it/s, loss=0.0111, val_loss=0.0113, a\n",
      "Epoch 28: 100%|█| 32/32 [00:01<00:00, 18.65it/s, loss=0.0111, val_loss=0.0111, a\u001b[A\n",
      "Epoch 29:  50%|▌| 16/32 [00:01<00:01, 10.45it/s, loss=0.0109, val_loss=0.0111, a\u001b[A\n",
      "Epoch 29:  69%|▋| 22/32 [00:01<00:00, 13.98it/s, loss=0.0109, val_loss=0.0111, a\n",
      "Epoch 29: 100%|█| 32/32 [00:01<00:00, 18.46it/s, loss=0.0109, val_loss=0.0109, a\u001b[A\n",
      "Epoch 30:  50%|▌| 16/32 [00:01<00:01, 10.54it/s, loss=0.0107, val_loss=0.0109, a\u001b[A\n",
      "Epoch 30:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.0107, val_loss=0.0109, a\n",
      "Epoch 30: 100%|█| 32/32 [00:01<00:00, 18.58it/s, loss=0.0107, val_loss=0.0107, a\u001b[A\n",
      "Epoch 31:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.0105, val_loss=0.0107, a\u001b[A\n",
      "Epoch 31:  69%|▋| 22/32 [00:01<00:00, 13.71it/s, loss=0.0105, val_loss=0.0107, a\n",
      "Epoch 31: 100%|█| 32/32 [00:01<00:00, 18.28it/s, loss=0.0105, val_loss=0.0105, a\u001b[A\n",
      "Epoch 32:  50%|▌| 16/32 [00:01<00:01, 10.60it/s, loss=0.0104, val_loss=0.0105, a\u001b[A\n",
      "Epoch 32:  69%|▋| 22/32 [00:01<00:00, 14.12it/s, loss=0.0104, val_loss=0.0105, a\n",
      "Epoch 32: 100%|█| 32/32 [00:01<00:00, 18.67it/s, loss=0.0104, val_loss=0.0103, a\u001b[A\n",
      "Epoch 33:  50%|▌| 16/32 [00:01<00:01, 10.61it/s, loss=0.0102, val_loss=0.0103, a\u001b[A\n",
      "Epoch 33:  69%|▋| 22/32 [00:01<00:00, 14.20it/s, loss=0.0102, val_loss=0.0103, a\n",
      "Epoch 33: 100%|█| 32/32 [00:01<00:00, 18.79it/s, loss=0.0102, val_loss=0.0101, a\u001b[A\n",
      "Epoch 34:  50%|▌| 16/32 [00:01<00:01, 10.63it/s, loss=0.0101, val_loss=0.0101, a\u001b[A\n",
      "Epoch 34:  69%|▋| 22/32 [00:01<00:00, 14.16it/s, loss=0.0101, val_loss=0.0101, a\n",
      "Epoch 34: 100%|█| 32/32 [00:01<00:00, 18.77it/s, loss=0.0101, val_loss=0.00994, \u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:01<00:01, 10.30it/s, loss=0.00993, val_loss=0.00994,\u001b[A\n",
      "Epoch 35:  69%|▋| 22/32 [00:01<00:00, 13.63it/s, loss=0.00993, val_loss=0.00994,\n",
      "Epoch 35: 100%|█| 32/32 [00:01<00:00, 18.22it/s, loss=0.00993, val_loss=0.00978,\u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.0098, val_loss=0.00978, \u001b[A\n",
      "Epoch 36:  69%|▋| 22/32 [00:01<00:00, 14.07it/s, loss=0.0098, val_loss=0.00978, \n",
      "Epoch 36: 100%|█| 32/32 [00:01<00:00, 18.51it/s, loss=0.0098, val_loss=0.00964, \u001b[A\n",
      "Epoch 37:  50%|▌| 16/32 [00:01<00:01, 10.66it/s, loss=0.00968, val_loss=0.00964,\u001b[A\n",
      "Epoch 37:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.00968, val_loss=0.00964,\n",
      "Epoch 37: 100%|█| 32/32 [00:01<00:00, 18.66it/s, loss=0.00968, val_loss=0.00951,\u001b[A\n",
      "Epoch 38:  50%|▌| 16/32 [00:01<00:01, 10.80it/s, loss=0.00956, val_loss=0.00951,\u001b[A\n",
      "Epoch 38:  69%|▋| 22/32 [00:01<00:00, 14.42it/s, loss=0.00956, val_loss=0.00951,\n",
      "Epoch 38: 100%|█| 32/32 [00:01<00:00, 19.00it/s, loss=0.00956, val_loss=0.00938,\u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:01<00:01, 10.42it/s, loss=0.00945, val_loss=0.00938,\u001b[A\n",
      "Epoch 39:  69%|▋| 22/32 [00:01<00:00, 13.67it/s, loss=0.00945, val_loss=0.00938,\n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 74.02it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 18.16it/s, loss=0.00945, val_loss=0.00926,\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 17.90it/s, loss=0.00945, val_loss=0.00926,\u001b[A\n",
      "Sizes of clusters: 323, 663, 262, 352\n",
      "\n",
      "preds: [3 3 3 3 1 3 3 1 3 1 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 1 1 3 1 3 3 3 1 3 3 3 3\n",
      " 3 3 3 3 3 3 1 3 1 3 3 1 3 1 3 3 1 3 3 3 1 3 1 1 3 3 3 3 1 1 3 3 3 1 3 3 3\n",
      " 3 3 3 1 1 1 1 3 3 3 1 3 3 3 1 3 3 1 3 1 3 3 3 1 3 3 3 3 3 2 3 1 3 3 3 1 3\n",
      " 3 1 1 1 3 3 1 3 3 3 3 1 1 3 1 1 1 3 3 3 3 3 3 3 3 3 1 3 3 1 3 3 3 1 3 1 3\n",
      " 3 1 3 3 1 3 3 3 3 3 1 3 3 3 3 1 3 1 1 3 3 1 3 3 3 3 3 3 3 3 1 1 3 3 3 1 3\n",
      " 3 3 3 3 3 1 3 1 1 3 1 3 1 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 1 3\n",
      " 3 1 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 1 3 1 1 1 1 1 3 1 3 1 3 3 1 3 1 3 1 3 3\n",
      " 3 1 3 3 3 3 1 3 1 3 1 3 1 3 1 3 3 3 1 3 3 1 3 3 3 1 3 1 3 3 3 3 1 1 1 3 3\n",
      " 3 3 3 1 3 3 3 3 1 3 1 3 3 3 3 1 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 1 3 3 3 1\n",
      " 3 3 3 3 3 1 3 1 1 3 3 3 3 3 1 3 1 3 3 3 1 3 3 3 3 3 3 3 3 1 1 3 3 3 1 3 3\n",
      " 3 3 3 1 1 3 1 3 3 3 3 3 1 3 3 3 3 1 3 3 3 1 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 2 0 0 0 0 0 2 0 0 2 0 0 2 0 0 0 0 1 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 0 0\n",
      " 0 0 0 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 1 0 2\n",
      " 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 2 0 0 1 0 0 2 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 2 0 0 0 0 2 2 2 2\n",
      " 0 0 2 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0 2\n",
      " 0 2 1 2 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 0 0 0 0 0 2 2 0\n",
      " 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 2 0 0\n",
      " 2 0 0 0 0 2 0 2 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 1 1 1 1 3 1 1 2 2 2\n",
      " 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 2 1 1 2 1 1 2 3 1 1 3 2 1 2\n",
      " 1 1 2 1 3 1 1 3 1 3 1 2 1 1 3 1 1 2 3 2 1 3 1 3 3 1 2 1 1 1 1 1 1 1 1 3 3\n",
      " 1 1 3 1 2 1 1 1 1 2 1 2 2 2 3 2 2 1 2 2 2 1 1 1 2 2 1 2 1 1 3 3 2 1 2 1 1\n",
      " 3 1 1 3 1 1 2 1 3 1 1 2 2 1 1 1 1 3 1 2 1 1 1 3 2 1 2 1 3 1 1 3 2 1 1 3 2\n",
      " 1 1 1 2 1 1 1 2 1 1 3 1 2 3 1 1 1 1 1 3 1 1 1 1 2 2 1 1 1 3 1 1 1 1 1 3 1\n",
      " 3 3 2 1 3 2 2 1 1 1 1 1 1 1 2 1 1 2 1 2 1 3 3 2 1 2 2 1 1 3 1 1 2 1 3 3 1\n",
      " 1 1 1 2 2 1 1 2 1 2 2 3 1 1 3 1 1 3 3 1 3 2 1 2 3 3 2 1 1 2 1 2 2 2 1 1 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 3 1 1 1 1 2 2 1 1 1 1 1 2 1 2 3 1 3 2 1 3 1 1 3 1\n",
      " 1 1 2 1 1 2 2 1 2 2 1 3 1 1 2 1 1 1 1 1 1 3 1 1 3 1 1 2 1 1 1 1 2 3 2 2 1\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 2 3 1 2 1 1 3 1 2 1 1 1 1 3 1 1 2 1 2 1 1 1\n",
      " 1 1 1 1 2 2 2 1 2 1 3 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2\n",
      " 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1\n",
      " 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2\n",
      " 2 2 2 1 1 1 1 2 2 3 2 1 2 1 2 1 1 1 1 1 3 3 1 2 1 1 1 2 1 2 1 1 2 1 1 1 2\n",
      " 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 1 2 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 3 1 1 1 2 1 1\n",
      " 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1\n",
      " 1 1 2 2 1 2 1 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.6431\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:01<00:01, 10.24it/s, loss=163, val_loss=0.0849, avg_v\n",
      "Epoch 0:  84%|▊| 27/32 [00:01<00:00, 16.30it/s, loss=163, val_loss=0.0849, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:01<00:00, 17.95it/s, loss=163, val_loss=0.289, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 16/32 [00:01<00:01, 10.26it/s, loss=3.8, val_loss=0.289, avg_va\u001b[A\n",
      "Epoch 1:  69%|▋| 22/32 [00:01<00:00, 13.69it/s, loss=3.8, val_loss=0.289, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:01<00:00, 18.16it/s, loss=3.8, val_loss=0.254, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 16/32 [00:01<00:01, 10.88it/s, loss=0.629, val_loss=0.254, avg_\u001b[A\n",
      "Epoch 2:  69%|▋| 22/32 [00:01<00:00, 14.54it/s, loss=0.629, val_loss=0.254, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:01<00:00, 19.16it/s, loss=0.629, val_loss=0.145, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 16/32 [00:01<00:01, 10.19it/s, loss=0.156, val_loss=0.145, avg_\u001b[A\n",
      "Epoch 3:  69%|▋| 22/32 [00:01<00:00, 13.36it/s, loss=0.156, val_loss=0.145, avg_\n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 73.37it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 32/32 [00:01<00:00, 17.64it/s, loss=0.156, val_loss=0.0661, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:01<00:01, 10.00it/s, loss=0.0623, val_loss=0.0661, av\u001b[A\n",
      "Epoch 4:  69%|▋| 22/32 [00:01<00:00, 13.15it/s, loss=0.0623, val_loss=0.0661, av\n",
      "Epoch 4: 100%|█| 32/32 [00:01<00:00, 17.65it/s, loss=0.0623, val_loss=0.0495, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:01<00:01, 10.34it/s, loss=0.0397, val_loss=0.0495, av\u001b[A\n",
      "Epoch 5:  69%|▋| 22/32 [00:01<00:00, 13.61it/s, loss=0.0397, val_loss=0.0495, av\n",
      "Epoch 5: 100%|█| 32/32 [00:01<00:00, 18.20it/s, loss=0.0397, val_loss=0.0422, av\u001b[A\n",
      "Epoch 6:  50%|▌| 16/32 [00:01<00:01, 10.04it/s, loss=0.0323, val_loss=0.0422, av\u001b[A\n",
      "Epoch 6:  69%|▋| 22/32 [00:01<00:00, 13.02it/s, loss=0.0323, val_loss=0.0422, av\n",
      "Epoch 6: 100%|█| 32/32 [00:01<00:00, 17.44it/s, loss=0.0323, val_loss=0.037, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.0287, val_loss=0.037, avg\u001b[A\n",
      "Epoch 7:  69%|▋| 22/32 [00:01<00:00, 13.90it/s, loss=0.0287, val_loss=0.037, avg\n",
      "Epoch 7: 100%|█| 32/32 [00:01<00:00, 18.41it/s, loss=0.0287, val_loss=0.0335, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.0262, val_loss=0.0335, av\u001b[A\n",
      "Epoch 8:  69%|▋| 22/32 [00:01<00:00, 14.30it/s, loss=0.0262, val_loss=0.0335, av\n",
      "Epoch 8: 100%|█| 32/32 [00:01<00:00, 18.53it/s, loss=0.0262, val_loss=0.0308, av\u001b[A\n",
      "Epoch 9:  50%|▌| 16/32 [00:01<00:01, 10.61it/s, loss=0.0241, val_loss=0.0308, av\u001b[A\n",
      "Epoch 9:  69%|▋| 22/32 [00:01<00:00, 14.28it/s, loss=0.0241, val_loss=0.0308, av\n",
      "Epoch 9: 100%|█| 32/32 [00:01<00:00, 18.80it/s, loss=0.0241, val_loss=0.0285, av\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:01<00:01, 10.85it/s, loss=0.0223, val_loss=0.0285, a\u001b[A\n",
      "Epoch 10:  69%|▋| 22/32 [00:01<00:00, 14.55it/s, loss=0.0223, val_loss=0.0285, a\n",
      "Epoch 10: 100%|█| 32/32 [00:01<00:00, 19.16it/s, loss=0.0223, val_loss=0.0265, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:01<00:01, 10.92it/s, loss=0.0207, val_loss=0.0265, a\u001b[A\n",
      "Epoch 11:  69%|▋| 22/32 [00:01<00:00, 14.43it/s, loss=0.0207, val_loss=0.0265, a\n",
      "Epoch 11: 100%|█| 32/32 [00:01<00:00, 19.14it/s, loss=0.0207, val_loss=0.0248, a\u001b[A\n",
      "Epoch 12:  50%|▌| 16/32 [00:01<00:01, 10.65it/s, loss=0.0193, val_loss=0.0248, a\u001b[A\n",
      "Epoch 12:  69%|▋| 22/32 [00:01<00:00, 14.20it/s, loss=0.0193, val_loss=0.0248, a\n",
      "Epoch 12: 100%|█| 32/32 [00:01<00:00, 18.74it/s, loss=0.0193, val_loss=0.0232, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:01<00:01, 10.63it/s, loss=0.0181, val_loss=0.0232, a\u001b[A\n",
      "Epoch 13:  69%|▋| 22/32 [00:01<00:00, 14.06it/s, loss=0.0181, val_loss=0.0232, a\n",
      "Epoch 13: 100%|█| 32/32 [00:01<00:00, 18.72it/s, loss=0.0181, val_loss=0.0218, a\u001b[A\n",
      "Epoch 14:  50%|▌| 16/32 [00:01<00:01, 10.70it/s, loss=0.0171, val_loss=0.0218, a\u001b[A\n",
      "Epoch 14:  69%|▋| 22/32 [00:01<00:00, 14.23it/s, loss=0.0171, val_loss=0.0218, a\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 18.80it/s, loss=0.0171, val_loss=0.0206, a\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.0162, val_loss=0.0206, a\u001b[A\n",
      "Epoch 15:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.0162, val_loss=0.0206, a\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 18.47it/s, loss=0.0162, val_loss=0.0194, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.0153, val_loss=0.0194, a\u001b[A\n",
      "Epoch 16:  69%|▋| 22/32 [00:01<00:00, 13.54it/s, loss=0.0153, val_loss=0.0194, a\n",
      "Validating:  50%|████████████████                | 8/16 [00:00<00:00, 73.69it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 17.92it/s, loss=0.0153, val_loss=0.0184, a\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.12it/s, loss=0.0146, val_loss=0.0184, a\u001b[A\n",
      "Epoch 17:  69%|▋| 22/32 [00:01<00:00, 13.46it/s, loss=0.0146, val_loss=0.0184, a\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 17.91it/s, loss=0.0146, val_loss=0.0175, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01, 10.58it/s, loss=0.014, val_loss=0.0175, av\u001b[A\n",
      "Epoch 18:  69%|▋| 22/32 [00:01<00:00, 14.21it/s, loss=0.014, val_loss=0.0175, av\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 18.67it/s, loss=0.014, val_loss=0.0168, av\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.59it/s, loss=0.0134, val_loss=0.0168, a\u001b[A\n",
      "Epoch 19:  69%|▋| 22/32 [00:01<00:00, 13.98it/s, loss=0.0134, val_loss=0.0168, a\n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 18.57it/s, loss=0.0134, val_loss=0.016, av\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.67it/s, loss=0.0129, val_loss=0.016, av\u001b[A\n",
      "Epoch 20:  69%|▋| 22/32 [00:01<00:00, 14.35it/s, loss=0.0129, val_loss=0.016, av\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.88it/s, loss=0.0129, val_loss=0.0154, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01, 10.41it/s, loss=0.0124, val_loss=0.0154, a\u001b[A\n",
      "Epoch 21:  69%|▋| 22/32 [00:01<00:00, 14.03it/s, loss=0.0124, val_loss=0.0154, a\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 18.46it/s, loss=0.0124, val_loss=0.0148, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 10.65it/s, loss=0.012, val_loss=0.0148, av\u001b[A\n",
      "Epoch 22:  69%|▋| 22/32 [00:01<00:00, 14.00it/s, loss=0.012, val_loss=0.0148, av\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 18.65it/s, loss=0.012, val_loss=0.0143, av\u001b[A\n",
      "Epoch 23:  50%|▌| 16/32 [00:01<00:01, 10.66it/s, loss=0.0116, val_loss=0.0143, a\u001b[A\n",
      "Epoch 23:  69%|▋| 22/32 [00:01<00:00, 14.29it/s, loss=0.0116, val_loss=0.0143, a\n",
      "Epoch 23: 100%|█| 32/32 [00:01<00:00, 18.86it/s, loss=0.0116, val_loss=0.0138, a\u001b[A\n",
      "Epoch 24:  50%|▌| 16/32 [00:01<00:01, 10.43it/s, loss=0.0112, val_loss=0.0138, a\u001b[A\n",
      "Epoch 24:  69%|▋| 22/32 [00:01<00:00, 13.89it/s, loss=0.0112, val_loss=0.0138, a\n",
      "Epoch 24: 100%|█| 32/32 [00:01<00:00, 18.39it/s, loss=0.0112, val_loss=0.0134, a\u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:01<00:01, 10.62it/s, loss=0.0109, val_loss=0.0134, a\u001b[A\n",
      "Epoch 25:  69%|▋| 22/32 [00:01<00:00, 14.17it/s, loss=0.0109, val_loss=0.0134, a\n",
      "Epoch 25: 100%|█| 32/32 [00:01<00:00, 18.56it/s, loss=0.0109, val_loss=0.013, av\u001b[A\n",
      "Epoch 26:  50%|▌| 16/32 [00:01<00:01, 10.56it/s, loss=0.0106, val_loss=0.013, av\u001b[A\n",
      "Epoch 26:  69%|▋| 22/32 [00:01<00:00, 14.01it/s, loss=0.0106, val_loss=0.013, av\n",
      "Epoch 26: 100%|█| 32/32 [00:01<00:00, 18.66it/s, loss=0.0106, val_loss=0.0126, a\u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:01<00:01, 10.66it/s, loss=0.0103, val_loss=0.0126, a\u001b[A\n",
      "Epoch 27:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.0103, val_loss=0.0126, a\n",
      "Validating:  38%|████████████                    | 6/16 [00:00<00:00, 43.04it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 32/32 [00:01<00:00, 17.99it/s, loss=0.0103, val_loss=0.0123, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  50%|▌| 16/32 [00:01<00:01, 10.49it/s, loss=0.01, val_loss=0.0123, avg\u001b[A\n",
      "Epoch 28:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.01, val_loss=0.0123, avg\n",
      "Epoch 28: 100%|█| 32/32 [00:01<00:00, 18.37it/s, loss=0.01, val_loss=0.0119, avg\u001b[A\n",
      "Epoch 29:  50%|▌| 16/32 [00:01<00:01, 10.05it/s, loss=0.00977, val_loss=0.0119, \u001b[A\n",
      "Epoch 29:  69%|▋| 22/32 [00:01<00:00, 13.09it/s, loss=0.00977, val_loss=0.0119, \n",
      "Epoch 29: 100%|█| 32/32 [00:01<00:00, 17.58it/s, loss=0.00977, val_loss=0.0116, \u001b[A\n",
      "Epoch 30:  50%|▌| 16/32 [00:01<00:01, 10.38it/s, loss=0.00953, val_loss=0.0116, \u001b[A\n",
      "Epoch 30:  69%|▋| 22/32 [00:01<00:00, 13.92it/s, loss=0.00953, val_loss=0.0116, \n",
      "Epoch 30: 100%|█| 32/32 [00:01<00:00, 18.37it/s, loss=0.00953, val_loss=0.0113, \u001b[A\n",
      "Epoch 31:  50%|▌| 16/32 [00:01<00:01, 10.26it/s, loss=0.00931, val_loss=0.0113, \u001b[A\n",
      "Epoch 31:  69%|▋| 22/32 [00:01<00:00, 13.66it/s, loss=0.00931, val_loss=0.0113, \n",
      "Epoch 31: 100%|█| 32/32 [00:01<00:00, 18.17it/s, loss=0.00931, val_loss=0.011, a\u001b[A\n",
      "Epoch 32:  50%|▌| 16/32 [00:01<00:01, 10.73it/s, loss=0.0091, val_loss=0.011, av\u001b[A\n",
      "Epoch 32:  69%|▋| 22/32 [00:01<00:00, 14.16it/s, loss=0.0091, val_loss=0.011, av\n",
      "Epoch 32: 100%|█| 32/32 [00:01<00:00, 18.83it/s, loss=0.0091, val_loss=0.0107, a\u001b[A\n",
      "Epoch 33:  50%|▌| 16/32 [00:01<00:01, 10.57it/s, loss=0.00891, val_loss=0.0107, \u001b[A\n",
      "Epoch 33:  69%|▋| 22/32 [00:01<00:00, 13.90it/s, loss=0.00891, val_loss=0.0107, \n",
      "Epoch 33: 100%|█| 32/32 [00:01<00:00, 18.51it/s, loss=0.00891, val_loss=0.0105, \u001b[A\n",
      "Epoch 34:  50%|▌| 16/32 [00:01<00:01, 10.03it/s, loss=0.00872, val_loss=0.0105, \u001b[A\n",
      "Epoch 34:  69%|▋| 22/32 [00:01<00:00, 13.32it/s, loss=0.00872, val_loss=0.0105, \n",
      "Epoch 34: 100%|█| 32/32 [00:01<00:00, 17.82it/s, loss=0.00872, val_loss=0.0103, \u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:01<00:01, 10.42it/s, loss=0.00855, val_loss=0.0103, \u001b[A\n",
      "Epoch 35:  69%|▋| 22/32 [00:01<00:00, 13.87it/s, loss=0.00855, val_loss=0.0103, \n",
      "Epoch 35: 100%|█| 32/32 [00:01<00:00, 18.26it/s, loss=0.00855, val_loss=0.01, av\u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:01<00:01, 10.50it/s, loss=0.00838, val_loss=0.01, av\u001b[A\n",
      "Epoch 36:  69%|▋| 22/32 [00:01<00:00, 13.99it/s, loss=0.00838, val_loss=0.01, av\n",
      "Epoch 36: 100%|█| 32/32 [00:01<00:00, 18.39it/s, loss=0.00838, val_loss=0.00982,\u001b[A\n",
      "Epoch 37:  50%|▌| 16/32 [00:01<00:01, 10.17it/s, loss=0.00822, val_loss=0.00982,\u001b[A\n",
      "Epoch 37:  69%|▋| 22/32 [00:01<00:00, 13.60it/s, loss=0.00822, val_loss=0.00982,\n",
      "Epoch 37: 100%|█| 32/32 [00:01<00:00, 17.99it/s, loss=0.00822, val_loss=0.00962,\u001b[A\n",
      "Epoch 38:  50%|▌| 16/32 [00:01<00:01, 10.51it/s, loss=0.00807, val_loss=0.00962,\u001b[A\n",
      "Epoch 38:  69%|▋| 22/32 [00:01<00:00, 13.79it/s, loss=0.00807, val_loss=0.00962,\n",
      "Validating:  44%|██████████████                  | 7/16 [00:00<00:00, 66.12it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 32/32 [00:01<00:00, 17.95it/s, loss=0.00807, val_loss=0.00943,\u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:01<00:01, 10.17it/s, loss=0.00793, val_loss=0.00943,\u001b[A\n",
      "Epoch 39:  69%|▋| 22/32 [00:01<00:00, 13.59it/s, loss=0.00793, val_loss=0.00943,\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 17.91it/s, loss=0.00793, val_loss=0.00925,\u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:01<00:00, 17.79it/s, loss=0.00793, val_loss=0.00925,\u001b[A\n",
      "Sizes of clusters: 425, 382, 234, 559\n",
      "\n",
      "preds: [3 3 1 3 0 3 0 3 3 3 0 3 1 0 0 3 0 3 3 0 0 3 0 0 3 3 3 3 0 3 0 0 3 0 0 3 0\n",
      " 3 0 3 3 0 3 3 3 3 0 3 3 0 1 3 3 3 0 0 0 3 3 3 3 0 0 0 3 3 3 1 3 0 1 0 1 1\n",
      " 3 3 3 3 0 3 3 0 0 0 3 3 3 0 0 0 0 1 0 1 0 3 3 1 1 3 0 0 0 1 3 3 0 0 3 3 0\n",
      " 3 1 0 3 3 0 3 3 0 0 3 3 3 3 3 3 3 3 3 0 3 0 0 0 3 0 0 0 0 0 0 3 0 3 3 3 0\n",
      " 0 3 0 3 0 3 0 0 0 0 3 0 0 0 0 1 0 3 1 0 0 3 3 3 3 3 0 0 0 3 0 0 0 3 0 3 0\n",
      " 0 1 3 0 3 3 0 3 0 0 3 0 3 0 0 3 0 3 0 3 3 1 1 0 0 0 0 3 2 3 3 0 3 3 0 3 3\n",
      " 3 3 0 0 0 0 0 3 3 0 0 0 1 3 0 3 0 3 3 3 3 3 3 3 3 3 0 3 0 0 3 0 0 1 2 3 0\n",
      " 3 0 0 0 0 0 1 0 0 0 0 0 1 3 0 0 3 0 3 0 0 3 3 0 0 3 3 3 3 3 3 0 2 3 3 0 0\n",
      " 0 0 0 1 3 0 0 0 2 0 0 0 0 3 0 2 0 3 0 0 0 0 3 0 3 1 3 0 3 0 0 3 3 3 0 3 3\n",
      " 0 0 3 3 1 3 1 3 3 0 3 0 0 3 3 0 3 3 3 0 3 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3\n",
      " 0 3 0 3 3 0 0 0 3 3 3 0 3 0 3 1 0 0 0 0 0 0 0 0 0 3 0 0 3 0 2 2 2 2 2 2 1\n",
      " 1 1 1 2 2 2 2 2 1 1 1 2 2 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 2 2 0 2 1 2 1\n",
      " 2 2 2 2 2 2 1 2 1 1 2 1 2 1 1 1 1 2 2 1 2 2 1 2 2 2 2 2 1 2 2 2 1 1 1 2 1\n",
      " 1 2 2 1 2 1 2 1 2 2 1 2 1 1 1 2 2 2 2 2 2 1 1 2 2 2 2 1 2 2 2 1 1 1 1 2 1\n",
      " 2 1 1 2 2 2 1 2 1 2 2 2 2 1 1 2 2 1 0 2 2 1 1 1 1 1 1 2 2 1 2 1 1 1 2 2 1\n",
      " 1 1 1 1 2 2 2 1 1 2 1 1 1 2 2 2 1 1 1 3 2 2 0 1 2 2 1 1 1 2 1 2 2 1 1 1 2\n",
      " 1 2 1 1 1 2 2 1 2 2 1 2 2 1 1 2 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 2 1 1 1 1\n",
      " 2 1 1 1 2 1 2 1 2 0 2 2 1 1 2 1 2 2 1 1 2 2 1 1 2 2 2 1 2 2 1 2 1 2 1 2 2\n",
      " 1 1 1 2 2 1 1 2 1 2 2 2 1 2 2 2 1 1 2 2 2 2 1 1 2 2 1 1 1 1 1 1 1 1 2 2 2\n",
      " 1 2 2 1 2 1 1 1 2 1 1 1 1 2 2 3 2 1 1 2 2 2 1 1 2 1 2 2 2 2 2 2 1 2 1 1 2\n",
      " 1 2 2 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 2 2 1 1 2 2 2 2 1 1 2 1 2 2 1 2 2 1\n",
      " 1 1 2 1 1 2 1 1 2 1 2 2 2 1 1 2 2 2 2 1 2 1 2 3 3 3 0 0 3 3 0 0 3 0 0 2 2\n",
      " 0 0 0 3 0 3 3 3 3 3 3 3 3 0 0 3 0 1 3 0 0 3 3 1 0 3 0 3 3 0 3 3 3 3 2 3 0\n",
      " 0 0 3 3 3 3 1 1 3 0 3 0 0 3 0 0 3 3 0 3 0 0 0 0 3 0 2 0 0 0 0 3 0 0 0 0 3\n",
      " 3 3 0 3 2 3 0 0 0 3 0 2 2 0 3 0 3 0 0 2 0 3 3 0 0 3 0 0 0 3 3 0 2 3 0 3 0\n",
      " 0 0 3 1 3 3 0 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0 0 0 3 3 3 0 3 3 3 3 2 3 3 3 3\n",
      " 3 0 3 0 3 0 3 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 3 3 3 0 0 0 0 3 0 3 0 0 3 3 3\n",
      " 3 0 3 3 0 0 2 3 0 0 0 0 0 0 0 0 3 1 3 3 3 3 0 0 0 1 3 0 3 0 3 0 0 0 0 0 0\n",
      " 0 3 3 2 2 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 1 3 0 0 0 0 2 3 3 0 0 0 0 0 3 0 3\n",
      " 3 0 3 3 0 3 0 3 0 0 3 0 0 3 1 3 3 0 0 0 0 3 0 3 1 3 0 0 3 0 0 0 1 3 3 1 3\n",
      " 3 3 3 0 0 2 0 0 3 0 3 0 0 0 0 3 3 0 3 3 0 0 3 0 0 0 3 0 3 0 3 3 3 0 3 2 0\n",
      " 0 3 3 3 0 2 0 0 0 0 0 0 3 3 0 1 0 0 0 0 3 3 0 2 0 3 0 0 0 0 3 0 3 0 0 0 0\n",
      " 3 0 0 3 2 3 0 3 1 0 0 0 0 3 3 0 3 3 1 3 3 3 3 1 1 1 1 1 3 1 3 0 1 3 3 1 1\n",
      " 0 3 1 1 3 3 3 1 1 1 0 1 1 3 0 3 3 3 1 0 1 1 3 3 3 3 1 3 1 3 3 1 3 3 3 3 3\n",
      " 1 3 3 3 1 3 0 1 3 1 0 1 1 3 3 3 3 3 1 3 3 1 1 0 3 1 1 3 3 3 3 3 3 1 3 3 3\n",
      " 3 3 3 1 1 3 3 1 1 3 1 3 3 3 3 1 3 1 3 3 3 0 3 1 1 3 3 0 1 3 3 3 3 1 1 3 1\n",
      " 3 3 1 3 3 3 1 3 1 1 3 3 3 3 1 3 3 3 1 3 3 0 1 1 1 3 3 3 1 1 1 3 3 3 3 3 1\n",
      " 1 3 1 3 3 3 0 1 1 3 3 3 1 3 1 3 1 1 3 3 1 3 3 1 3 1 3 3 3 3 3 2 1 3 3 1 1\n",
      " 1 1 3 3 1 3 3 1 1 3 1 3 1 3 3 1 3 3 1 3 3 1 1 1 3 1 1 3 0 1 3 3 3 3 3 3 0\n",
      " 1 3 1 3 1 3 1 3 3 3 3 3 3 3 1 3 1 3 1 1 3 1 3 1 3 3 1 3 3 3 3 3 3 1 3 1 1\n",
      " 3 1 3 3 3 3 1 1 3 3 1 1 3 3 1 1 1 3 1 1 3 3 3 1 3 3 1 3 3 3 3 1 3 1 3 1 1\n",
      " 1 1 3 1 3 0 3 3 1 3 1 1 1 3 3 1 0 3 3 1 3 1 3 3 3 3 1 1 1 1 3 3 1 1 3 3 3\n",
      " 1 3 3 0 1 1 1 3 1 3 3 3 3 1 3 1 3 3 3 1 1 3 1 3 3 1 3 3 1 3 1 1 3 3 3 1 3\n",
      " 3 1 1 1 1 3 3 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3571\r\n",
      "Purity: 0.5902499999999999+-0.03911042060627835\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K4_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 20/40 [00:01<00:01, 10.32it/s, loss=104, val_loss=0.0613, avg_v\n",
      "Epoch 0:  57%|▌| 23/40 [00:01<00:01, 11.76it/s, loss=104, val_loss=0.0613, avg_v\n",
      "Epoch 0:  82%|▊| 33/40 [00:02<00:00, 16.02it/s, loss=104, val_loss=0.0613, avg_v\u001b[A\n",
      "Epoch 0: 100%|█| 40/40 [00:02<00:00, 18.27it/s, loss=104, val_loss=0.354, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 20/40 [00:01<00:01, 10.50it/s, loss=0.578, val_loss=0.354, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  75%|▊| 30/40 [00:02<00:00, 14.90it/s, loss=0.578, val_loss=0.354, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 40/40 [00:02<00:00, 18.53it/s, loss=0.578, val_loss=0.105, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 20/40 [00:01<00:01, 10.52it/s, loss=0.0984, val_loss=0.105, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  75%|▊| 30/40 [00:02<00:00, 14.95it/s, loss=0.0984, val_loss=0.105, avg\u001b[A\n",
      "Epoch 2: 100%|█| 40/40 [00:02<00:00, 18.48it/s, loss=0.0984, val_loss=0.0467, av\u001b[A\n",
      "Epoch 3:  50%|▌| 20/40 [00:01<00:01, 10.47it/s, loss=0.035, val_loss=0.0467, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|▊| 32/40 [00:02<00:00, 15.86it/s, loss=0.035, val_loss=0.0467, avg\u001b[A\n",
      "Epoch 3: 100%|█| 40/40 [00:02<00:00, 18.52it/s, loss=0.035, val_loss=0.038, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 20/40 [00:01<00:01, 10.45it/s, loss=0.0233, val_loss=0.038, avg\u001b[A\n",
      "Epoch 4:  60%|▌| 24/40 [00:01<00:01, 12.28it/s, loss=0.0233, val_loss=0.038, avg\n",
      "Epoch 4:  90%|▉| 36/40 [00:02<00:00, 17.12it/s, loss=0.0233, val_loss=0.038, avg\u001b[A\n",
      "Epoch 4: 100%|█| 40/40 [00:02<00:00, 18.38it/s, loss=0.0233, val_loss=0.0334, av\u001b[A\n",
      "Epoch 5:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.0191, val_loss=0.0334, av\u001b[A\n",
      "Epoch 5:  60%|▌| 24/40 [00:01<00:01, 12.39it/s, loss=0.0191, val_loss=0.0334, av\n",
      "Epoch 5:  90%|▉| 36/40 [00:02<00:00, 17.40it/s, loss=0.0191, val_loss=0.0334, av\u001b[A\n",
      "Epoch 5: 100%|█| 40/40 [00:02<00:00, 18.51it/s, loss=0.0191, val_loss=0.0273, av\u001b[A\n",
      "Epoch 6:  50%|▌| 20/40 [00:01<00:01, 10.18it/s, loss=0.0166, val_loss=0.0273, av\u001b[A\n",
      "Epoch 6:  60%|▌| 24/40 [00:01<00:01, 12.07it/s, loss=0.0166, val_loss=0.0273, av\n",
      "Epoch 6:  90%|▉| 36/40 [00:02<00:00, 17.01it/s, loss=0.0166, val_loss=0.0273, av\u001b[A\n",
      "Epoch 6: 100%|█| 40/40 [00:02<00:00, 18.09it/s, loss=0.0166, val_loss=0.0232, av\u001b[A\n",
      "Epoch 7:  50%|▌| 20/40 [00:01<00:01, 10.16it/s, loss=0.0148, val_loss=0.0232, av\u001b[A\n",
      "Epoch 7:  60%|▌| 24/40 [00:02<00:01, 11.87it/s, loss=0.0148, val_loss=0.0232, av\n",
      "Epoch 7:  90%|▉| 36/40 [00:02<00:00, 16.82it/s, loss=0.0148, val_loss=0.0232, av\u001b[A\n",
      "Epoch 7: 100%|█| 40/40 [00:02<00:00, 17.95it/s, loss=0.0148, val_loss=0.0205, av\u001b[A\n",
      "Epoch 8:  50%|▌| 20/40 [00:01<00:01, 10.69it/s, loss=0.0134, val_loss=0.0205, av\u001b[A\n",
      "Epoch 8:  60%|▌| 24/40 [00:01<00:01, 12.53it/s, loss=0.0134, val_loss=0.0205, av\n",
      "Epoch 8:  90%|▉| 36/40 [00:02<00:00, 17.34it/s, loss=0.0134, val_loss=0.0205, av\u001b[A\n",
      "Epoch 8: 100%|█| 40/40 [00:02<00:00, 18.41it/s, loss=0.0134, val_loss=0.0183, av\u001b[A\n",
      "Epoch 9:  50%|▌| 20/40 [00:01<00:01, 10.17it/s, loss=0.0123, val_loss=0.0183, av\u001b[A\n",
      "Epoch 9:  60%|▌| 24/40 [00:02<00:01, 11.98it/s, loss=0.0123, val_loss=0.0183, av\n",
      "Epoch 9:  90%|▉| 36/40 [00:02<00:00, 16.90it/s, loss=0.0123, val_loss=0.0183, av\u001b[A\n",
      "Epoch 9: 100%|█| 40/40 [00:02<00:00, 18.03it/s, loss=0.0123, val_loss=0.0166, av\u001b[A\n",
      "Epoch 10:  50%|▌| 20/40 [00:01<00:01, 10.33it/s, loss=0.0114, val_loss=0.0166, a\u001b[A\n",
      "Epoch 10:  60%|▌| 24/40 [00:01<00:01, 12.15it/s, loss=0.0114, val_loss=0.0166, a\n",
      "Epoch 10:  90%|▉| 36/40 [00:02<00:00, 17.14it/s, loss=0.0114, val_loss=0.0166, a\u001b[A\n",
      "Epoch 10: 100%|█| 40/40 [00:02<00:00, 18.27it/s, loss=0.0114, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  50%|▌| 20/40 [00:01<00:01, 10.33it/s, loss=0.0107, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  60%|▌| 24/40 [00:01<00:01, 12.15it/s, loss=0.0107, val_loss=0.0152, a\n",
      "Epoch 11:  90%|▉| 36/40 [00:02<00:00, 17.09it/s, loss=0.0107, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.0107, val_loss=0.014, av\u001b[A\n",
      "Epoch 12:  50%|▌| 20/40 [00:01<00:01, 10.25it/s, loss=0.0101, val_loss=0.014, av\u001b[A\n",
      "Epoch 12:  60%|▌| 24/40 [00:01<00:01, 12.08it/s, loss=0.0101, val_loss=0.014, av\n",
      "Epoch 12:  90%|▉| 36/40 [00:02<00:00, 16.96it/s, loss=0.0101, val_loss=0.014, av\u001b[A\n",
      "Epoch 12: 100%|█| 40/40 [00:02<00:00, 18.13it/s, loss=0.0101, val_loss=0.013, av\u001b[A\n",
      "Epoch 13:  50%|▌| 20/40 [00:01<00:01, 10.60it/s, loss=0.00954, val_loss=0.013, a\u001b[A\n",
      "Epoch 13:  60%|▌| 24/40 [00:01<00:01, 12.40it/s, loss=0.00954, val_loss=0.013, a\n",
      "Epoch 13:  90%|▉| 36/40 [00:02<00:00, 17.31it/s, loss=0.00954, val_loss=0.013, a\u001b[A\n",
      "Epoch 13: 100%|█| 40/40 [00:02<00:00, 18.50it/s, loss=0.00954, val_loss=0.0122, \u001b[A\n",
      "Epoch 14:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.00907, val_loss=0.0122, \u001b[A\n",
      "Epoch 14:  60%|▌| 24/40 [00:01<00:01, 12.52it/s, loss=0.00907, val_loss=0.0122, \n",
      "Epoch 14:  90%|▉| 36/40 [00:02<00:00, 17.61it/s, loss=0.00907, val_loss=0.0122, \u001b[A\n",
      "Epoch 14: 100%|█| 40/40 [00:02<00:00, 18.71it/s, loss=0.00907, val_loss=0.0115, \u001b[A\n",
      "Epoch 15:  50%|▌| 20/40 [00:01<00:01, 10.60it/s, loss=0.00865, val_loss=0.0115, \u001b[A\n",
      "Epoch 15:  60%|▌| 24/40 [00:01<00:01, 12.50it/s, loss=0.00865, val_loss=0.0115, \n",
      "Epoch 15:  90%|▉| 36/40 [00:02<00:00, 17.54it/s, loss=0.00865, val_loss=0.0115, \u001b[A\n",
      "Epoch 15: 100%|█| 40/40 [00:02<00:00, 18.64it/s, loss=0.00865, val_loss=0.0109, \u001b[A\n",
      "Epoch 16:  50%|▌| 20/40 [00:01<00:01, 10.84it/s, loss=0.00828, val_loss=0.0109, \u001b[A\n",
      "Epoch 16:  60%|▌| 24/40 [00:01<00:01, 12.80it/s, loss=0.00828, val_loss=0.0109, \n",
      "Epoch 16:  90%|▉| 36/40 [00:02<00:00, 17.93it/s, loss=0.00828, val_loss=0.0109, \u001b[A\n",
      "Epoch 16: 100%|█| 40/40 [00:02<00:00, 19.09it/s, loss=0.00828, val_loss=0.0103, \u001b[A\n",
      "Epoch 17:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.00794, val_loss=0.0103, \u001b[A\n",
      "Epoch 17:  60%|▌| 24/40 [00:01<00:01, 12.14it/s, loss=0.00794, val_loss=0.0103, \n",
      "Epoch 17:  90%|▉| 36/40 [00:02<00:00, 17.00it/s, loss=0.00794, val_loss=0.0103, \u001b[A\n",
      "Epoch 17: 100%|█| 40/40 [00:02<00:00, 18.26it/s, loss=0.00794, val_loss=0.00986,\u001b[A\n",
      "Epoch 18:  50%|▌| 20/40 [00:01<00:01, 10.73it/s, loss=0.00764, val_loss=0.00986,\u001b[A\n",
      "Epoch 18:  60%|▌| 24/40 [00:01<00:01, 12.66it/s, loss=0.00764, val_loss=0.00986,\n",
      "Epoch 18:  90%|▉| 36/40 [00:02<00:00, 17.75it/s, loss=0.00764, val_loss=0.00986,\u001b[A\n",
      "Epoch 18: 100%|█| 40/40 [00:02<00:00, 18.85it/s, loss=0.00764, val_loss=0.00943,\u001b[A\n",
      "Epoch 19:  50%|▌| 20/40 [00:01<00:01, 10.40it/s, loss=0.00737, val_loss=0.00943,\u001b[A\n",
      "Epoch 19:  60%|▌| 24/40 [00:01<00:01, 12.36it/s, loss=0.00737, val_loss=0.00943,\n",
      "Epoch 19:  90%|▉| 36/40 [00:02<00:00, 17.32it/s, loss=0.00737, val_loss=0.00943,\u001b[A\n",
      "Epoch 19: 100%|█| 40/40 [00:02<00:00, 18.40it/s, loss=0.00737, val_loss=0.00905,\u001b[A\n",
      "Epoch 20:  50%|▌| 20/40 [00:01<00:01, 10.75it/s, loss=0.00712, val_loss=0.00905,\u001b[A\n",
      "Epoch 20:  60%|▌| 24/40 [00:01<00:01, 12.59it/s, loss=0.00712, val_loss=0.00905,\n",
      "Epoch 20:  90%|▉| 36/40 [00:02<00:00, 17.75it/s, loss=0.00712, val_loss=0.00905,\u001b[A\n",
      "Epoch 20: 100%|█| 40/40 [00:02<00:00, 18.85it/s, loss=0.00712, val_loss=0.00871,\u001b[A\n",
      "Epoch 21:  50%|▌| 20/40 [00:01<00:01, 10.62it/s, loss=0.0069, val_loss=0.00871, \u001b[A\n",
      "Epoch 21:  60%|▌| 24/40 [00:01<00:01, 12.58it/s, loss=0.0069, val_loss=0.00871, \n",
      "Epoch 21:  90%|▉| 36/40 [00:02<00:00, 17.70it/s, loss=0.0069, val_loss=0.00871, \u001b[A\n",
      "Epoch 21: 100%|█| 40/40 [00:02<00:00, 18.79it/s, loss=0.0069, val_loss=0.00839, \u001b[A\n",
      "Epoch 22:  50%|▌| 20/40 [00:01<00:01, 10.60it/s, loss=0.0067, val_loss=0.00839, \u001b[A\n",
      "Epoch 22:  60%|▌| 24/40 [00:01<00:01, 12.44it/s, loss=0.0067, val_loss=0.00839, \n",
      "Epoch 22:  90%|▉| 36/40 [00:02<00:00, 17.20it/s, loss=0.0067, val_loss=0.00839, \u001b[A\n",
      "Epoch 22: 100%|█| 40/40 [00:02<00:00, 18.46it/s, loss=0.0067, val_loss=0.00811, \u001b[A\n",
      "Epoch 23:  50%|▌| 20/40 [00:01<00:01, 10.77it/s, loss=0.00651, val_loss=0.00811,\u001b[A\n",
      "Epoch 23:  60%|▌| 24/40 [00:01<00:01, 12.67it/s, loss=0.00651, val_loss=0.00811,\n",
      "Epoch 23:  90%|▉| 36/40 [00:02<00:00, 17.60it/s, loss=0.00651, val_loss=0.00811,\u001b[A\n",
      "Epoch 23: 100%|█| 40/40 [00:02<00:00, 18.79it/s, loss=0.00651, val_loss=0.00786,\u001b[A\n",
      "Epoch 24:  50%|▌| 20/40 [00:01<00:01, 10.67it/s, loss=0.00634, val_loss=0.00786,\u001b[A\n",
      "Epoch 24:  60%|▌| 24/40 [00:01<00:01, 12.58it/s, loss=0.00634, val_loss=0.00786,\n",
      "Epoch 24:  90%|▉| 36/40 [00:02<00:00, 17.61it/s, loss=0.00634, val_loss=0.00786,\u001b[A\n",
      "Epoch 24: 100%|█| 40/40 [00:02<00:00, 18.85it/s, loss=0.00634, val_loss=0.00763,\u001b[A\n",
      "Epoch 25:  50%|▌| 20/40 [00:01<00:01, 10.85it/s, loss=0.00619, val_loss=0.00763,\u001b[A\n",
      "Epoch 25:  60%|▌| 24/40 [00:01<00:01, 12.69it/s, loss=0.00619, val_loss=0.00763,\n",
      "Epoch 25:  90%|▉| 36/40 [00:02<00:00, 17.88it/s, loss=0.00619, val_loss=0.00763,\u001b[A\n",
      "Epoch 25: 100%|█| 40/40 [00:02<00:00, 19.04it/s, loss=0.00619, val_loss=0.00742,\u001b[A\n",
      "Epoch 26:  50%|▌| 20/40 [00:01<00:01, 10.68it/s, loss=0.00605, val_loss=0.00742,\u001b[A\n",
      "Epoch 26:  60%|▌| 24/40 [00:01<00:01, 12.60it/s, loss=0.00605, val_loss=0.00742,\n",
      "Epoch 26:  90%|▉| 36/40 [00:02<00:00, 17.74it/s, loss=0.00605, val_loss=0.00742,\u001b[A\n",
      "Epoch 26: 100%|█| 40/40 [00:02<00:00, 18.83it/s, loss=0.00605, val_loss=0.00723,\u001b[A\n",
      "Epoch 27:  50%|▌| 20/40 [00:01<00:01, 10.36it/s, loss=0.00592, val_loss=0.00723,\u001b[A\n",
      "Epoch 27:  60%|▌| 24/40 [00:01<00:01, 12.16it/s, loss=0.00592, val_loss=0.00723,\n",
      "Epoch 27:  90%|▉| 36/40 [00:02<00:00, 16.85it/s, loss=0.00592, val_loss=0.00723,\u001b[A\n",
      "Epoch 27: 100%|█| 40/40 [00:02<00:00, 18.10it/s, loss=0.00592, val_loss=0.00705,\u001b[A\n",
      "Epoch 28:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.0058, val_loss=0.00705, \u001b[A\n",
      "Epoch 28:  60%|▌| 24/40 [00:01<00:01, 12.58it/s, loss=0.0058, val_loss=0.00705, \n",
      "Epoch 28:  90%|▉| 36/40 [00:02<00:00, 17.54it/s, loss=0.0058, val_loss=0.00705, \u001b[A\n",
      "Epoch 28: 100%|█| 40/40 [00:02<00:00, 18.72it/s, loss=0.0058, val_loss=0.00688, \u001b[A\n",
      "Epoch 29:  50%|▌| 20/40 [00:01<00:01, 10.58it/s, loss=0.00569, val_loss=0.00688,\u001b[A\n",
      "Epoch 29:  60%|▌| 24/40 [00:01<00:01, 12.47it/s, loss=0.00569, val_loss=0.00688,\n",
      "Epoch 29:  90%|▉| 36/40 [00:02<00:00, 17.56it/s, loss=0.00569, val_loss=0.00688,\u001b[A\n",
      "Epoch 29: 100%|█| 40/40 [00:02<00:00, 18.66it/s, loss=0.00569, val_loss=0.00673,\u001b[A\n",
      "Epoch 30:  50%|▌| 20/40 [00:01<00:01, 10.59it/s, loss=0.00559, val_loss=0.00673,\u001b[A\n",
      "Epoch 30:  60%|▌| 24/40 [00:01<00:01, 12.48it/s, loss=0.00559, val_loss=0.00673,\n",
      "Epoch 30:  90%|▉| 36/40 [00:02<00:00, 17.62it/s, loss=0.00559, val_loss=0.00673,\u001b[A\n",
      "Epoch 30: 100%|█| 40/40 [00:02<00:00, 18.74it/s, loss=0.00559, val_loss=0.00659,\u001b[A\n",
      "Epoch 31:  50%|▌| 20/40 [00:01<00:01, 10.50it/s, loss=0.0055, val_loss=0.00659, \u001b[A\n",
      "Epoch 31:  60%|▌| 24/40 [00:01<00:01, 12.40it/s, loss=0.0055, val_loss=0.00659, \n",
      "Epoch 31: 100%|█| 40/40 [00:02<00:00, 18.58it/s, loss=0.0055, val_loss=0.00647, \u001b[A\n",
      "Epoch 32:  50%|▌| 20/40 [00:01<00:01, 10.32it/s, loss=0.00541, val_loss=0.00647,\u001b[A\n",
      "Epoch 32:  60%|▌| 24/40 [00:01<00:01, 12.13it/s, loss=0.00541, val_loss=0.00647,\n",
      "Epoch 32:  90%|▉| 36/40 [00:02<00:00, 16.97it/s, loss=0.00541, val_loss=0.00647,\u001b[A\n",
      "Epoch 32: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.00541, val_loss=0.00635,\u001b[A\n",
      "Epoch 33:  50%|▌| 20/40 [00:01<00:01, 10.36it/s, loss=0.00534, val_loss=0.00635,\u001b[A\n",
      "Epoch 33:  60%|▌| 24/40 [00:01<00:01, 12.20it/s, loss=0.00534, val_loss=0.00635,\n",
      "Epoch 33:  90%|▉| 36/40 [00:02<00:00, 17.10it/s, loss=0.00534, val_loss=0.00635,\u001b[A\n",
      "Epoch 33: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.00534, val_loss=0.00623,\u001b[A\n",
      "Epoch 34:  50%|▌| 20/40 [00:01<00:01, 10.59it/s, loss=0.00526, val_loss=0.00623,\u001b[A\n",
      "Epoch 34:  60%|▌| 24/40 [00:01<00:01, 12.42it/s, loss=0.00526, val_loss=0.00623,\n",
      "Epoch 34:  90%|▉| 36/40 [00:02<00:00, 17.43it/s, loss=0.00526, val_loss=0.00623,\u001b[A\n",
      "Epoch 34: 100%|█| 40/40 [00:02<00:00, 18.60it/s, loss=0.00526, val_loss=0.00613,\u001b[A\n",
      "Epoch 35:  50%|▌| 20/40 [00:01<00:01, 10.86it/s, loss=0.0052, val_loss=0.00613, \u001b[A\n",
      "Epoch 35:  60%|▌| 24/40 [00:01<00:01, 12.84it/s, loss=0.0052, val_loss=0.00613, \n",
      "Epoch 35:  90%|▉| 36/40 [00:02<00:00, 17.97it/s, loss=0.0052, val_loss=0.00613, \u001b[A\n",
      "Epoch 35: 100%|█| 40/40 [00:02<00:00, 19.17it/s, loss=0.0052, val_loss=0.00603, \u001b[A\n",
      "Epoch 36:  50%|▌| 20/40 [00:01<00:01, 10.69it/s, loss=0.00513, val_loss=0.00603,\u001b[A\n",
      "Epoch 36:  60%|▌| 24/40 [00:01<00:01, 12.58it/s, loss=0.00513, val_loss=0.00603,\n",
      "Epoch 36:  90%|▉| 36/40 [00:02<00:00, 17.68it/s, loss=0.00513, val_loss=0.00603,\u001b[A\n",
      "Epoch 36: 100%|█| 40/40 [00:02<00:00, 18.80it/s, loss=0.00513, val_loss=0.00593,\u001b[A\n",
      "Epoch 37:  50%|▌| 20/40 [00:01<00:01, 10.11it/s, loss=0.00508, val_loss=0.00593,\u001b[A\n",
      "Epoch 37:  60%|▌| 24/40 [00:02<00:01, 11.89it/s, loss=0.00508, val_loss=0.00593,\n",
      "Validating:  35%|███████████▏                    | 7/20 [00:00<00:00, 66.62it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 40/40 [00:02<00:00, 17.74it/s, loss=0.00508, val_loss=0.00584,\u001b[A\n",
      "Epoch 38:  50%|▌| 20/40 [00:01<00:01, 10.27it/s, loss=0.00502, val_loss=0.00584,\u001b[A\n",
      "Epoch 38:  60%|▌| 24/40 [00:01<00:01, 12.05it/s, loss=0.00502, val_loss=0.00584,\n",
      "Epoch 38:  90%|▉| 36/40 [00:02<00:00, 16.94it/s, loss=0.00502, val_loss=0.00584,\u001b[A\n",
      "Epoch 38: 100%|█| 40/40 [00:02<00:00, 18.15it/s, loss=0.00502, val_loss=0.00576,\u001b[A\n",
      "Epoch 39:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.00497, val_loss=0.00576,\u001b[A\n",
      "Epoch 39:  60%|▌| 24/40 [00:01<00:01, 12.33it/s, loss=0.00497, val_loss=0.00576,\n",
      "Epoch 39:  90%|▉| 36/40 [00:02<00:00, 17.37it/s, loss=0.00497, val_loss=0.00576,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.49it/s, loss=0.00497, val_loss=0.00568,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.40it/s, loss=0.00497, val_loss=0.00568,\u001b[A\n",
      "Sizes of clusters: 678, 293, 435, 166, 428\n",
      "\n",
      "preds: [4 0 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 4 0 0 2 0 0 0 0 0 0 4 0 0 0 2\n",
      " 4 0 0 4 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 4 4 0 0 2 4 4 0 0 0 0 0 4\n",
      " 0 4 4 0 0 4 0 1 4 0 0 0 0 0 0 0 0 1 0 4 4 0 4 4 0 0 0 4 0 0 2 0 4 0 0 0 0\n",
      " 4 0 4 2 0 0 0 4 0 4 0 2 0 4 0 0 4 2 0 0 0 0 4 4 0 0 0 0 0 0 0 4 2 0 4 4 4\n",
      " 0 4 0 0 0 0 1 0 4 0 0 0 0 4 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0\n",
      " 0 0 4 4 4 0 0 0 0 0 1 0 4 0 0 0 4 2 1 0 0 0 0 0 0 1 0 4 0 0 0 0 0 4 4 0 4\n",
      " 0 0 2 0 0 4 0 0 4 4 0 0 0 0 0 4 0 2 0 0 0 4 0 2 1 0 0 0 4 0 0 0 0 1 4 2 0\n",
      " 0 2 2 4 4 2 0 2 0 0 4 0 4 4 0 0 0 0 0 4 0 0 0 0 4 0 4 4 4 0 2 0 0 0 0 4 0\n",
      " 0 0 0 0 4 0 4 0 0 4 0 0 4 0 4 0 0 0 4 0 0 3 0 0 0 1 4 0 0 0 0 4 0 0 0 4 0\n",
      " 0 4 0 0 0 4 0 0 4 0 0 0 0 0 0 0 1 0 0 0 4 4 0 0 0 0 0 0 0 0 4 0 0 4 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 4 0 0 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 2 0 2 2 4 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 0 2 0 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 0 1 4 4 4 1 4 0 1 1 1 1 3 0\n",
      " 4 1 4 0 0 4 4 4 0 3 4 0 1 4 4 4 1 4 0 4 1 4 0 0 4 1 0 3 4 0 4 4 4 0 0 4 1\n",
      " 0 0 0 3 1 0 4 3 0 0 0 4 1 3 4 1 4 4 1 0 1 1 0 4 2 0 0 1 4 1 4 3 0 4 1 0 0\n",
      " 1 0 4 4 0 0 1 3 1 4 1 4 1 1 4 4 0 1 3 0 0 0 1 4 4 4 1 4 1 3 0 0 1 4 4 4 4\n",
      " 0 0 4 4 0 1 4 3 0 3 4 4 1 1 3 4 0 0 4 4 0 4 4 4 0 4 4 0 4 4 1 0 4 3 0 4 4\n",
      " 1 4 0 0 0 0 0 0 0 0 0 4 1 3 0 0 4 1 2 4 4 3 4 4 0 2 1 4 4 4 0 0 4 0 3 4 4\n",
      " 4 4 0 4 0 4 1 1 4 0 4 4 0 4 4 4 3 4 4 4 1 0 0 1 0 0 2 4 1 0 4 0 0 4 0 1 0\n",
      " 0 4 0 0 4 0 4 3 4 0 4 1 4 3 4 3 4 4 4 4 4 0 1 3 4 1 4 0 4 4 4 3 3 3 1 0 4\n",
      " 3 0 0 4 2 3 0 0 0 0 1 0 0 4 0 4 0 0 3 0 4 3 4 4 1 1 3 0 4 0 4 0 0 4 0 4 1\n",
      " 3 1 0 3 1 4 4 4 3 4 1 4 4 1 0 4 0 0 4 4 1 0 0 1 0 4 0 1 0 4 4 0 0 1 0 0 0\n",
      " 4 3 4 4 1 0 4 4 2 4 0 1 4 4 0 4 4 0 0 0 0 4 4 1 4 4 3 4 0 3 0 4 1 0 4 4 4\n",
      " 0 4 0 4 4 1 3 4 0 4 4 0 0 3 3 0 4 4 4 4 0 0 0 0 0 0 4 0 4 4 0 4 0 4 4 4 0\n",
      " 4 0 0 0 0 0 4 4 0 0 0 4 4 2 0 4 2 4 0 4 0 2 0 0 4 4 4 0 0 0 0 0 0 0 0 0 4\n",
      " 0 2 0 4 0 0 4 4 0 0 4 2 4 0 0 4 2 4 0 4 4 4 4 4 4 0 0 0 0 2 2 0 2 2 0 2 4\n",
      " 0 0 0 0 4 4 0 1 0 4 0 0 0 0 4 0 0 2 4 4 4 4 0 0 0 4 0 0 2 0 0 0 4 0 0 2 4\n",
      " 4 4 0 0 4 2 4 0 0 0 2 4 0 4 0 0 4 0 0 0 0 1 1 0 0 4 2 0 4 4 0 0 0 0 0 0 0\n",
      " 2 2 0 4 1 0 0 2 4 4 0 0 4 4 0 4 0 0 2 0 0 0 0 4 0 0 0 0 0 0 0 0 0 2 0 0 4\n",
      " 0 2 0 0 0 2 4 4 4 4 4 0 0 0 4 0 0 0 0 0 2 0 2 1 0 2 4 2 4 2 0 0 0 2 0 1 4\n",
      " 4 0 4 0 4 0 4 0 2 0 0 4 4 0 4 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 1 0 4\n",
      " 4 0 4 0 0 4 4 2 2 4 0 0 4 0 0 4 0 1 4 4 0 0 0 0 2 0 0 0 1 0 0 0 4 4 0 0 0\n",
      " 0 0 0 4 4 0 2 4 0 0 0 4 4 0 0 0 0 0 0 0 0 4 0 0 0 0 2 4 0 4 4 4 2 0 0 1 4\n",
      " 0 0 4 0 4 2 0 0 0 2 0 0 0 0 4 2 0 0 0 0 0 4 4 0 0 0 4 0 4 0 4 2 0 4 0 0 0\n",
      " 0 0 4 0 0 4 0 4 4 3 3 3 1 3 3 4 1 3 1 3 1 3 1 4 4 1 1 1 1 3 3 1 3 3 1 3 4\n",
      " 1 1 3 3 3 4 1 1 3 1 4 1 3 1 1 1 3 3 4 1 1 4 1 1 4 1 1 3 1 1 1 1 1 1 3 3 4\n",
      " 4 1 1 3 4 1 3 3 4 1 4 3 1 3 1 3 1 1 1 4 1 1 1 3 3 1 3 4 1 3 1 1 1 3 3 4 1\n",
      " 4 3 4 1 3 1 1 4 1 1 3 3 3 1 1 1 3 1 3 1 0 4 4 3 1 3 1 1 1 1 1 1 1 1 1 3 4\n",
      " 4 3 1 3 3 3 0 1 4 4 4 4 1 4 1 3 1 3 1 1 3 4 1 1 4 4 4 4 1 0 1 3 1 3 3 4 3\n",
      " 4 4 4 1 1 3 3 3 3 1 1 1 1 1 1 1 1 4 1 4 4 3 1 3 1 1 1 3 1 1 3 1 1 4 1 1 1\n",
      " 3 1 3 3 3 1 4 4 1 1 4 1 3 1 3 3 1 3 1 3 1 3 1 1 1 1 4 1 1 3 0 1 1 0 3 3 1\n",
      " 1 1 1 0 1 4 3 3 3 1 1 3 3 1 1 1 3 3 1 1 0 3 4 1 1 3 1 3 3 1 3 1 0 1 1 3 1\n",
      " 3 3 3 3 3 1 1 3 1 1 3 1 3 1 1 0 1 4 1 1 3 3 3 4 3 1 4 1 1 1 1 4 1 1 3 3 3\n",
      " 0 1 3 3 3 1 4 3 1 3 1 1 1 3 3 1 4 1 1 3 1 1 3 4 1 3 1 1 1 1 4 1 1 1 3 1 0\n",
      " 1 1 1 1 1 1 3 1 3 1 1 4 1 3 1 3 3 1 4 1 1 1 1 1 1 1 3 1 1 4 3 3 1 1 1 3 3\n",
      " 4 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5665\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 20/40 [00:01<00:01, 10.63it/s, loss=103, val_loss=0.0695, avg_v\n",
      "Epoch 0:  55%|▌| 22/40 [00:01<00:01, 11.62it/s, loss=103, val_loss=0.0695, avg_v\n",
      "Epoch 0:  80%|▊| 32/40 [00:02<00:00, 15.97it/s, loss=103, val_loss=0.0695, avg_v\u001b[A\n",
      "Epoch 0: 100%|█| 40/40 [00:02<00:00, 18.76it/s, loss=103, val_loss=0.2, avg_val_\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|▌| 20/40 [00:01<00:01, 10.59it/s, loss=0.885, val_loss=0.2, avg_va\u001b[A\n",
      "Epoch 1:  78%|▊| 31/40 [00:01<00:00, 15.58it/s, loss=0.885, val_loss=0.2, avg_va\n",
      "Validating:  55%|█████████████████              | 11/20 [00:00<00:00, 88.26it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 40/40 [00:02<00:00, 18.70it/s, loss=0.885, val_loss=0.128, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 20/40 [00:01<00:01, 10.60it/s, loss=0.171, val_loss=0.128, avg_\u001b[A\n",
      "Epoch 2:  55%|▌| 22/40 [00:01<00:01, 11.61it/s, loss=0.171, val_loss=0.128, avg_\n",
      "Epoch 2:  82%|▊| 33/40 [00:02<00:00, 16.46it/s, loss=0.171, val_loss=0.128, avg_\u001b[A\n",
      "Epoch 2: 100%|█| 40/40 [00:02<00:00, 18.76it/s, loss=0.171, val_loss=0.0634, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 20/40 [00:01<00:01, 10.34it/s, loss=0.0502, val_loss=0.0634, av\u001b[A\n",
      "Epoch 3:  55%|▌| 22/40 [00:01<00:01, 11.33it/s, loss=0.0502, val_loss=0.0634, av\n",
      "Epoch 3:  82%|▊| 33/40 [00:02<00:00, 15.83it/s, loss=0.0502, val_loss=0.0634, av\u001b[A\n",
      "Epoch 3: 100%|█| 40/40 [00:02<00:00, 18.15it/s, loss=0.0502, val_loss=0.0421, av\u001b[A\n",
      "Epoch 4:  50%|▌| 20/40 [00:01<00:01, 10.29it/s, loss=0.0289, val_loss=0.0421, av\u001b[A\n",
      "Epoch 4:  55%|▌| 22/40 [00:01<00:01, 11.25it/s, loss=0.0289, val_loss=0.0421, av\n",
      "Epoch 4:  82%|▊| 33/40 [00:02<00:00, 16.01it/s, loss=0.0289, val_loss=0.0421, av\u001b[A\n",
      "Epoch 4: 100%|█| 40/40 [00:02<00:00, 18.20it/s, loss=0.0289, val_loss=0.0344, av\u001b[A\n",
      "Epoch 5:  50%|▌| 20/40 [00:01<00:01, 10.91it/s, loss=0.0232, val_loss=0.0344, av\u001b[A\n",
      "Epoch 5:  55%|▌| 22/40 [00:01<00:01, 11.96it/s, loss=0.0232, val_loss=0.0344, av\n",
      "Epoch 5:  82%|▊| 33/40 [00:01<00:00, 16.95it/s, loss=0.0232, val_loss=0.0344, av\u001b[A\n",
      "Epoch 5: 100%|█| 40/40 [00:02<00:00, 19.26it/s, loss=0.0232, val_loss=0.0292, av\u001b[A\n",
      "Epoch 6:  50%|▌| 20/40 [00:01<00:01, 10.62it/s, loss=0.0202, val_loss=0.0292, av\u001b[A\n",
      "Epoch 6:  55%|▌| 22/40 [00:01<00:01, 11.64it/s, loss=0.0202, val_loss=0.0292, av\n",
      "Epoch 6:  82%|▊| 33/40 [00:01<00:00, 16.51it/s, loss=0.0202, val_loss=0.0292, av\u001b[A\n",
      "Epoch 6: 100%|█| 40/40 [00:02<00:00, 18.76it/s, loss=0.0202, val_loss=0.0256, av\u001b[A\n",
      "Epoch 7:  50%|▌| 20/40 [00:01<00:01, 10.80it/s, loss=0.0181, val_loss=0.0256, av\u001b[A\n",
      "Epoch 7:  55%|▌| 22/40 [00:01<00:01, 11.84it/s, loss=0.0181, val_loss=0.0256, av\n",
      "Epoch 7:  82%|▊| 33/40 [00:01<00:00, 16.72it/s, loss=0.0181, val_loss=0.0256, av\u001b[A\n",
      "Epoch 7: 100%|█| 40/40 [00:02<00:00, 19.06it/s, loss=0.0181, val_loss=0.0229, av\u001b[A\n",
      "Epoch 8:  50%|▌| 20/40 [00:01<00:01, 10.91it/s, loss=0.0165, val_loss=0.0229, av\u001b[A\n",
      "Epoch 8:  55%|▌| 22/40 [00:01<00:01, 11.95it/s, loss=0.0165, val_loss=0.0229, av\n",
      "Epoch 8:  82%|▊| 33/40 [00:01<00:00, 16.88it/s, loss=0.0165, val_loss=0.0229, av\u001b[A\n",
      "Epoch 8: 100%|█| 40/40 [00:02<00:00, 19.22it/s, loss=0.0165, val_loss=0.0208, av\u001b[A\n",
      "Epoch 9:  50%|▌| 20/40 [00:01<00:01, 10.58it/s, loss=0.0151, val_loss=0.0208, av\u001b[A\n",
      "Epoch 9:  55%|▌| 22/40 [00:01<00:01, 11.56it/s, loss=0.0151, val_loss=0.0208, av\n",
      "Epoch 9:  82%|▊| 33/40 [00:02<00:00, 16.34it/s, loss=0.0151, val_loss=0.0208, av\u001b[A\n",
      "Epoch 9: 100%|█| 40/40 [00:02<00:00, 18.70it/s, loss=0.0151, val_loss=0.019, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 20/40 [00:01<00:01, 10.30it/s, loss=0.014, val_loss=0.019, avg\u001b[A\n",
      "Epoch 10:  55%|▌| 22/40 [00:01<00:01, 11.25it/s, loss=0.014, val_loss=0.019, avg\n",
      "Epoch 10:  82%|▊| 33/40 [00:02<00:00, 15.98it/s, loss=0.014, val_loss=0.019, avg\u001b[A\n",
      "Epoch 10: 100%|█| 40/40 [00:02<00:00, 18.24it/s, loss=0.014, val_loss=0.0175, av\u001b[A\n",
      "Epoch 11:  50%|▌| 20/40 [00:01<00:01, 10.54it/s, loss=0.013, val_loss=0.0175, av\u001b[A\n",
      "Epoch 11:  55%|▌| 22/40 [00:01<00:01, 11.45it/s, loss=0.013, val_loss=0.0175, av\n",
      "Epoch 11:  82%|▊| 33/40 [00:02<00:00, 16.10it/s, loss=0.013, val_loss=0.0175, av\u001b[A\n",
      "Epoch 11: 100%|█| 40/40 [00:02<00:00, 18.51it/s, loss=0.013, val_loss=0.0162, av\u001b[A\n",
      "Epoch 12:  50%|▌| 20/40 [00:02<00:02,  9.59it/s, loss=0.0122, val_loss=0.0162, a\u001b[A\n",
      "Epoch 12:  55%|▌| 22/40 [00:02<00:01, 10.49it/s, loss=0.0122, val_loss=0.0162, a\n",
      "Epoch 12:  82%|▊| 33/40 [00:02<00:00, 14.75it/s, loss=0.0122, val_loss=0.0162, a\u001b[A\n",
      "Epoch 12: 100%|█| 40/40 [00:02<00:00, 17.02it/s, loss=0.0122, val_loss=0.0151, a\u001b[A\n",
      "Epoch 13:  50%|▌| 20/40 [00:01<00:01, 10.43it/s, loss=0.0115, val_loss=0.0151, a\u001b[A\n",
      "Epoch 13:  55%|▌| 22/40 [00:01<00:01, 11.42it/s, loss=0.0115, val_loss=0.0151, a\n",
      "Epoch 13:  82%|▊| 33/40 [00:02<00:00, 16.15it/s, loss=0.0115, val_loss=0.0151, a\u001b[A\n",
      "Epoch 13: 100%|█| 40/40 [00:02<00:00, 18.41it/s, loss=0.0115, val_loss=0.0141, a\u001b[A\n",
      "Epoch 14:  50%|▌| 20/40 [00:02<00:02,  9.86it/s, loss=0.0108, val_loss=0.0141, a\u001b[A\n",
      "Epoch 14:  55%|▌| 22/40 [00:02<00:01, 10.72it/s, loss=0.0108, val_loss=0.0141, a\n",
      "Epoch 14:  82%|▊| 33/40 [00:02<00:00, 15.18it/s, loss=0.0108, val_loss=0.0141, a\u001b[A\n",
      "Epoch 14: 100%|█| 40/40 [00:02<00:00, 17.43it/s, loss=0.0108, val_loss=0.0133, a\u001b[A\n",
      "Epoch 15:  50%|▌| 20/40 [00:01<00:01, 10.44it/s, loss=0.0102, val_loss=0.0133, a\u001b[A\n",
      "Epoch 15:  55%|▌| 22/40 [00:01<00:01, 11.40it/s, loss=0.0102, val_loss=0.0133, a\n",
      "Epoch 15:  82%|▊| 33/40 [00:02<00:00, 16.10it/s, loss=0.0102, val_loss=0.0133, a\u001b[A\n",
      "Epoch 15: 100%|█| 40/40 [00:02<00:00, 18.36it/s, loss=0.0102, val_loss=0.0125, a\u001b[A\n",
      "Epoch 16:  50%|▌| 20/40 [00:01<00:01, 10.16it/s, loss=0.00969, val_loss=0.0125, \u001b[A\n",
      "Epoch 16:  55%|▌| 22/40 [00:01<00:01, 11.12it/s, loss=0.00969, val_loss=0.0125, \n",
      "Epoch 16:  82%|▊| 33/40 [00:02<00:00, 15.71it/s, loss=0.00969, val_loss=0.0125, \u001b[A\n",
      "Epoch 16: 100%|█| 40/40 [00:02<00:00, 18.04it/s, loss=0.00969, val_loss=0.0118, \u001b[A\n",
      "Epoch 17:  50%|▌| 20/40 [00:01<00:01, 10.28it/s, loss=0.00922, val_loss=0.0118, \u001b[A\n",
      "Epoch 17:  55%|▌| 22/40 [00:01<00:01, 11.16it/s, loss=0.00922, val_loss=0.0118, \n",
      "Epoch 17:  82%|▊| 33/40 [00:02<00:00, 15.71it/s, loss=0.00922, val_loss=0.0118, \u001b[A\n",
      "Epoch 17: 100%|█| 40/40 [00:02<00:00, 17.93it/s, loss=0.00922, val_loss=0.0112, \u001b[A\n",
      "Epoch 18:  50%|▌| 20/40 [00:01<00:01, 10.05it/s, loss=0.00879, val_loss=0.0112, \u001b[A\n",
      "Epoch 18:  55%|▌| 22/40 [00:02<00:01, 10.92it/s, loss=0.00879, val_loss=0.0112, \n",
      "Epoch 18:  82%|▊| 33/40 [00:02<00:00, 15.46it/s, loss=0.00879, val_loss=0.0112, \u001b[A\n",
      "Epoch 18: 100%|█| 40/40 [00:02<00:00, 17.77it/s, loss=0.00879, val_loss=0.0107, \u001b[A\n",
      "Epoch 19:  50%|▌| 20/40 [00:02<00:02,  9.87it/s, loss=0.00841, val_loss=0.0107, \u001b[A\n",
      "Epoch 19:  55%|▌| 22/40 [00:02<00:01, 10.73it/s, loss=0.00841, val_loss=0.0107, \n",
      "Epoch 19:  82%|▊| 33/40 [00:02<00:00, 15.30it/s, loss=0.00841, val_loss=0.0107, \u001b[A\n",
      "Epoch 19: 100%|█| 40/40 [00:02<00:00, 17.47it/s, loss=0.00841, val_loss=0.0102, \u001b[A\n",
      "Epoch 20:  50%|▌| 20/40 [00:01<00:01, 10.66it/s, loss=0.00805, val_loss=0.0102, \u001b[A\n",
      "Epoch 20:  55%|▌| 22/40 [00:01<00:01, 11.60it/s, loss=0.00805, val_loss=0.0102, \n",
      "Epoch 20:  82%|▊| 33/40 [00:01<00:00, 16.52it/s, loss=0.00805, val_loss=0.0102, \u001b[A\n",
      "Epoch 20: 100%|█| 40/40 [00:02<00:00, 18.80it/s, loss=0.00805, val_loss=0.00975,\u001b[A\n",
      "Epoch 21:  50%|▌| 20/40 [00:01<00:01, 10.81it/s, loss=0.00773, val_loss=0.00975,\u001b[A\n",
      "Epoch 21:  55%|▌| 22/40 [00:01<00:01, 11.72it/s, loss=0.00773, val_loss=0.00975,\n",
      "Epoch 21:  82%|▊| 33/40 [00:01<00:00, 16.66it/s, loss=0.00773, val_loss=0.00975,\u001b[A\n",
      "Epoch 21: 100%|█| 40/40 [00:02<00:00, 18.92it/s, loss=0.00773, val_loss=0.00935,\u001b[A\n",
      "Epoch 22:  50%|▌| 20/40 [00:01<00:01, 10.68it/s, loss=0.00743, val_loss=0.00935,\u001b[A\n",
      "Epoch 22:  55%|▌| 22/40 [00:01<00:01, 11.70it/s, loss=0.00743, val_loss=0.00935,\n",
      "Epoch 22:  82%|▊| 33/40 [00:01<00:00, 16.53it/s, loss=0.00743, val_loss=0.00935,\u001b[A\n",
      "Epoch 22: 100%|█| 40/40 [00:02<00:00, 18.85it/s, loss=0.00743, val_loss=0.00898,\u001b[A\n",
      "Epoch 23:  50%|▌| 20/40 [00:01<00:01, 10.07it/s, loss=0.00716, val_loss=0.00898,\u001b[A\n",
      "Epoch 23:  55%|▌| 22/40 [00:01<00:01, 11.03it/s, loss=0.00716, val_loss=0.00898,\n",
      "Epoch 23:  82%|▊| 33/40 [00:02<00:00, 15.58it/s, loss=0.00716, val_loss=0.00898,\u001b[A\n",
      "Epoch 23: 100%|█| 40/40 [00:02<00:00, 17.92it/s, loss=0.00716, val_loss=0.00864,\u001b[A\n",
      "Epoch 24:  50%|▌| 20/40 [00:02<00:02,  9.80it/s, loss=0.00692, val_loss=0.00864,\u001b[A\n",
      "Epoch 24:  55%|▌| 22/40 [00:02<00:01, 10.69it/s, loss=0.00692, val_loss=0.00864,\n",
      "Epoch 24:  82%|▊| 33/40 [00:02<00:00, 15.25it/s, loss=0.00692, val_loss=0.00864,\u001b[A\n",
      "Epoch 24: 100%|█| 40/40 [00:02<00:00, 17.38it/s, loss=0.00692, val_loss=0.00833,\u001b[A\n",
      "Epoch 25:  50%|▌| 20/40 [00:01<00:01, 10.64it/s, loss=0.00669, val_loss=0.00833,\u001b[A\n",
      "Epoch 25:  55%|▌| 22/40 [00:01<00:01, 11.59it/s, loss=0.00669, val_loss=0.00833,\n",
      "Epoch 25: 100%|█| 40/40 [00:02<00:00, 18.76it/s, loss=0.00669, val_loss=0.00805,\u001b[A\n",
      "Epoch 26:  50%|▌| 20/40 [00:01<00:01, 10.57it/s, loss=0.00649, val_loss=0.00805,\u001b[A\n",
      "Epoch 26:  55%|▌| 22/40 [00:01<00:01, 11.58it/s, loss=0.00649, val_loss=0.00805,\n",
      "Epoch 26:  82%|▊| 33/40 [00:02<00:00, 16.28it/s, loss=0.00649, val_loss=0.00805,\u001b[A\n",
      "Epoch 26: 100%|█| 40/40 [00:02<00:00, 18.67it/s, loss=0.00649, val_loss=0.0078, \u001b[A\n",
      "Epoch 27:  50%|▌| 20/40 [00:01<00:01, 10.46it/s, loss=0.00631, val_loss=0.0078, \u001b[A\n",
      "Epoch 27:  55%|▌| 22/40 [00:01<00:01, 11.39it/s, loss=0.00631, val_loss=0.0078, \n",
      "Epoch 27:  82%|▊| 33/40 [00:02<00:00, 15.83it/s, loss=0.00631, val_loss=0.0078, \u001b[A\n",
      "Epoch 27: 100%|█| 40/40 [00:02<00:00, 18.31it/s, loss=0.00631, val_loss=0.00757,\u001b[A\n",
      "Epoch 28:  50%|▌| 20/40 [00:01<00:01, 10.45it/s, loss=0.00614, val_loss=0.00757,\u001b[A\n",
      "Epoch 28:  55%|▌| 22/40 [00:01<00:01, 11.45it/s, loss=0.00614, val_loss=0.00757,\n",
      "Epoch 28:  82%|▊| 33/40 [00:02<00:00, 16.11it/s, loss=0.00614, val_loss=0.00757,\u001b[A\n",
      "Epoch 28: 100%|█| 40/40 [00:02<00:00, 18.53it/s, loss=0.00614, val_loss=0.00736,\u001b[A\n",
      "Epoch 29:  50%|▌| 20/40 [00:01<00:01, 10.73it/s, loss=0.00599, val_loss=0.00736,\u001b[A\n",
      "Epoch 29:  55%|▌| 22/40 [00:01<00:01, 11.68it/s, loss=0.00599, val_loss=0.00736,\n",
      "Epoch 29:  82%|▊| 33/40 [00:01<00:00, 16.61it/s, loss=0.00599, val_loss=0.00736,\u001b[A\n",
      "Epoch 29: 100%|█| 40/40 [00:02<00:00, 18.89it/s, loss=0.00599, val_loss=0.00717,\u001b[A\n",
      "Epoch 30:  50%|▌| 20/40 [00:01<00:01, 10.77it/s, loss=0.00585, val_loss=0.00717,\u001b[A\n",
      "Epoch 30:  55%|▌| 22/40 [00:01<00:01, 11.77it/s, loss=0.00585, val_loss=0.00717,\n",
      "Epoch 30:  82%|▊| 33/40 [00:01<00:00, 16.67it/s, loss=0.00585, val_loss=0.00717,\u001b[A\n",
      "Epoch 30: 100%|█| 40/40 [00:02<00:00, 18.94it/s, loss=0.00585, val_loss=0.00699,\u001b[A\n",
      "Epoch 31:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00572, val_loss=0.00699,\u001b[A\n",
      "Epoch 31:  55%|▌| 22/40 [00:01<00:01, 11.47it/s, loss=0.00572, val_loss=0.00699,\n",
      "Epoch 31:  82%|▊| 33/40 [00:02<00:00, 16.20it/s, loss=0.00572, val_loss=0.00699,\u001b[A\n",
      "Epoch 31: 100%|█| 40/40 [00:02<00:00, 18.52it/s, loss=0.00572, val_loss=0.00682,\u001b[A\n",
      "Epoch 32:  50%|▌| 20/40 [00:02<00:02,  9.98it/s, loss=0.00561, val_loss=0.00682,\u001b[A\n",
      "Epoch 32:  55%|▌| 22/40 [00:02<00:01, 10.85it/s, loss=0.00561, val_loss=0.00682,\n",
      "Epoch 32:  82%|▊| 33/40 [00:02<00:00, 15.15it/s, loss=0.00561, val_loss=0.00682,\u001b[A\n",
      "Epoch 32: 100%|█| 40/40 [00:02<00:00, 17.41it/s, loss=0.00561, val_loss=0.00667,\u001b[A\n",
      "Epoch 33:  50%|▌| 20/40 [00:01<00:01, 10.41it/s, loss=0.00551, val_loss=0.00667,\u001b[A\n",
      "Epoch 33:  55%|▌| 22/40 [00:01<00:01, 11.38it/s, loss=0.00551, val_loss=0.00667,\n",
      "Epoch 33: 100%|█| 40/40 [00:02<00:00, 18.40it/s, loss=0.00551, val_loss=0.00654,\u001b[A\n",
      "Epoch 34:  50%|▌| 20/40 [00:01<00:01, 10.55it/s, loss=0.00541, val_loss=0.00654,\u001b[A\n",
      "Epoch 34:  55%|▌| 22/40 [00:01<00:01, 11.54it/s, loss=0.00541, val_loss=0.00654,\n",
      "Epoch 34:  82%|▊| 33/40 [00:02<00:00, 16.40it/s, loss=0.00541, val_loss=0.00654,\u001b[A\n",
      "Epoch 34: 100%|█| 40/40 [00:02<00:00, 18.61it/s, loss=0.00541, val_loss=0.00641,\u001b[A\n",
      "Epoch 35:  50%|▌| 20/40 [00:01<00:01, 10.68it/s, loss=0.00533, val_loss=0.00641,\u001b[A\n",
      "Epoch 35:  55%|▌| 22/40 [00:01<00:01, 11.66it/s, loss=0.00533, val_loss=0.00641,\n",
      "Epoch 35:  82%|▊| 33/40 [00:02<00:00, 16.44it/s, loss=0.00533, val_loss=0.00641,\u001b[A\n",
      "Epoch 35: 100%|█| 40/40 [00:02<00:00, 18.83it/s, loss=0.00533, val_loss=0.0063, \u001b[A\n",
      "Epoch 36:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.00526, val_loss=0.0063, \u001b[A\n",
      "Epoch 36:  55%|▌| 22/40 [00:01<00:01, 11.33it/s, loss=0.00526, val_loss=0.0063, \n",
      "Epoch 36:  82%|▊| 33/40 [00:02<00:00, 16.03it/s, loss=0.00526, val_loss=0.0063, \u001b[A\n",
      "Epoch 36: 100%|█| 40/40 [00:02<00:00, 18.35it/s, loss=0.00526, val_loss=0.0062, \u001b[A\n",
      "Epoch 37:  50%|▌| 20/40 [00:01<00:01, 10.20it/s, loss=0.00519, val_loss=0.0062, \u001b[A\n",
      "Epoch 37:  55%|▌| 22/40 [00:01<00:01, 11.11it/s, loss=0.00519, val_loss=0.0062, \n",
      "Epoch 37:  82%|▊| 33/40 [00:02<00:00, 15.79it/s, loss=0.00519, val_loss=0.0062, \u001b[A\n",
      "Epoch 37: 100%|█| 40/40 [00:02<00:00, 18.05it/s, loss=0.00519, val_loss=0.0061, \u001b[A\n",
      "Epoch 38:  50%|▌| 20/40 [00:01<00:01, 10.50it/s, loss=0.00513, val_loss=0.0061, \u001b[A\n",
      "Epoch 38:  55%|▌| 22/40 [00:01<00:01, 11.46it/s, loss=0.00513, val_loss=0.0061, \n",
      "Epoch 38:  82%|▊| 33/40 [00:02<00:00, 16.28it/s, loss=0.00513, val_loss=0.0061, \u001b[A\n",
      "Epoch 38: 100%|█| 40/40 [00:02<00:00, 18.54it/s, loss=0.00513, val_loss=0.00601,\u001b[A\n",
      "Epoch 39:  50%|▌| 20/40 [00:01<00:01, 10.24it/s, loss=0.00507, val_loss=0.00601,\u001b[A\n",
      "Epoch 39:  55%|▌| 22/40 [00:01<00:01, 11.19it/s, loss=0.00507, val_loss=0.00601,\n",
      "Epoch 39:  82%|▊| 33/40 [00:02<00:00, 15.88it/s, loss=0.00507, val_loss=0.00601,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.18it/s, loss=0.00507, val_loss=0.00593,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.12it/s, loss=0.00507, val_loss=0.00593,\u001b[A\n",
      "Sizes of clusters: 340, 813, 166, 136, 545\n",
      "\n",
      "preds: [4 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 2 1 1 1 1 1 4 1 1 1 1 1 4 1 1 1 4 1 1 4 1\n",
      " 4 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 4 4 1 1 4 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 4 1 1 4 4 4 1 1 1 4 1 4 1 4 1 4 1 2 1 1 1 1 4 1 1 1 1 4 1 4 1 4 1 1 1 4 1\n",
      " 1 1 1 1 1 1 1 4 1 1 1 1 1 4 1 4 4 1 1 1 1 1 1 1 1 1 1 1 4 1 1 4 1 4 1 4 1\n",
      " 4 1 1 1 1 1 1 4 1 1 1 4 1 1 1 1 1 4 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 4 1 1\n",
      " 1 1 4 1 1 4 1 4 1 4 1 1 4 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 4 1 1 4 4 1 4 4 1\n",
      " 4 1 4 4 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 2 4 1 1 1 1 1 1\n",
      " 1 1 1 1 4 1 4 1 1 2 1 4 4 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 4 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      " 0 3 0 0 0 0 0 0 3 0 0 0 0 0 0 3 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 0 0 0 0 0 3 0 0 0 0 0 0 3 0 0 0 0 3 3 0 0 0 0 3 0 0 3 0 0 0\n",
      " 3 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 3 3 0 0 0 0 0\n",
      " 3 0 0 0 0 0 3 3 0 0 3 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 3 0 0 3 0 3 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 3 0 3 0 3 0 3 0\n",
      " 0 0 0 0 0 3 0 0 3 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 0 0 0 3 3 0 0 0 3 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 3 0 0 0 0 0 2 4 1 1 4 4 1 4 1 4 4 1 4 1\n",
      " 1 1 1 1 1 4 1 1 1 2 4 1 1 1 4 1 1 1 4 1 1 1 1 4 4 4 1 2 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 4 4 1 1 4 4 4 1 1 4 1 1 1 1 1 4 1 4 1 4 1 1 1 1 1 1 1 1 1 1\n",
      " 1 4 1 1 1 1 1 1 1 1 1 4 1 1 1 1 4 1 4 4 1 1 1 1 1 1 2 1 1 2 1 1 2 1 4 1 1\n",
      " 1 1 1 1 4 4 1 4 1 2 1 1 1 2 2 1 1 1 4 1 1 4 1 1 1 1 1 1 1 1 1 1 1 2 1 1 4\n",
      " 1 1 1 1 1 4 1 1 4 1 1 1 4 4 4 1 1 1 1 1 1 4 1 1 1 4 1 1 1 4 1 4 4 1 4 1 1\n",
      " 1 1 1 4 4 1 4 1 1 1 1 1 4 4 1 4 2 1 1 1 1 1 1 1 4 1 1 4 1 4 1 1 1 1 4 1 2\n",
      " 1 4 1 1 1 1 1 4 1 4 1 4 1 1 1 4 4 1 4 1 1 1 2 4 1 1 1 1 1 1 1 2 4 1 1 4 1\n",
      " 4 1 1 1 1 4 4 1 1 4 1 1 1 1 1 4 1 1 4 4 1 4 4 4 1 4 4 1 2 1 1 1 4 1 1 1 4\n",
      " 4 1 4 2 4 4 1 4 2 1 1 1 1 4 4 1 1 1 1 1 4 1 1 1 4 1 1 4 1 1 1 1 1 1 4 4 4\n",
      " 1 2 1 1 1 4 1 4 1 4 1 1 1 4 1 1 1 4 4 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 4\n",
      " 1 1 1 4 1 1 1 1 1 4 1 4 1 4 2 4 4 4 4 4 4 1 1 4 1 4 4 4 4 4 4 4 4 4 4 4 1\n",
      " 4 4 4 1 4 4 4 4 4 4 4 4 4 4 1 4 1 4 1 2 4 4 4 1 4 4 4 1 4 1 1 1 4 4 1 1 2\n",
      " 1 1 1 4 4 1 4 4 1 1 4 1 4 4 1 4 1 4 1 2 4 2 4 4 4 1 1 1 1 4 4 4 1 4 1 1 4\n",
      " 4 4 1 1 4 4 1 2 1 4 1 1 4 4 2 1 1 1 4 4 4 4 4 1 4 4 2 4 1 1 1 1 4 1 4 1 4\n",
      " 4 4 1 1 4 2 4 1 1 4 4 4 1 4 1 4 4 1 4 4 1 4 2 4 1 4 1 4 4 4 4 1 1 1 1 2 1\n",
      " 4 4 4 4 2 4 4 4 4 4 1 4 2 4 1 4 4 1 1 1 1 1 4 1 4 4 4 1 4 4 1 1 4 1 1 4 4\n",
      " 1 4 4 1 2 4 4 4 4 4 4 4 1 4 4 4 1 4 1 1 1 1 4 4 1 1 4 4 4 1 4 1 4 1 1 2 4\n",
      " 4 1 1 4 4 4 4 4 4 1 4 2 4 1 4 4 1 1 4 4 4 4 1 2 4 4 1 4 1 4 4 4 1 1 2 1 4\n",
      " 4 1 1 1 4 2 4 1 4 4 4 1 4 4 1 4 4 2 1 4 4 4 4 1 1 1 1 1 2 4 4 1 4 4 1 1 1\n",
      " 4 1 4 4 4 4 4 4 1 1 1 4 4 4 1 4 4 4 1 1 4 4 4 4 1 1 1 4 1 4 2 4 1 1 4 2 4\n",
      " 4 4 4 4 4 1 4 1 1 1 4 1 4 1 4 4 1 1 4 4 1 4 4 1 4 1 4 4 4 1 4 4 2 4 4 4 4\n",
      " 4 4 4 4 1 4 1 4 4 3 3 3 2 2 3 1 1 4 4 3 2 3 2 4 1 1 1 3 3 2 4 3 2 4 4 3 4\n",
      " 2 2 4 3 4 1 2 2 4 3 4 3 3 1 3 1 3 2 2 2 2 4 1 2 1 4 2 4 3 4 1 4 1 3 2 4 3\n",
      " 2 4 2 2 4 3 2 4 4 3 2 4 4 4 2 4 4 2 3 4 2 1 2 1 2 2 1 3 4 4 1 2 3 2 3 4 3\n",
      " 4 4 2 2 3 2 1 4 2 3 1 4 4 1 3 1 2 4 2 2 1 2 4 2 4 3 3 3 2 4 4 3 3 4 3 3 2\n",
      " 1 4 1 4 4 4 4 2 4 2 4 4 1 4 3 4 1 4 1 4 2 4 3 1 1 3 1 1 1 1 2 2 4 4 2 4 2\n",
      " 2 3 4 3 2 4 1 4 3 4 2 3 1 1 1 4 4 4 1 4 1 3 2 1 2 3 4 3 2 4 4 2 2 4 3 1 4\n",
      " 2 4 2 2 4 2 2 4 2 2 4 2 2 1 4 4 2 4 1 1 2 4 2 4 3 3 2 2 1 2 1 4 2 2 4 4 2\n",
      " 2 1 1 4 2 4 4 2 3 1 2 4 3 4 4 3 2 2 1 3 4 1 1 2 4 3 2 2 3 2 3 3 1 1 3 3 2\n",
      " 3 4 4 2 3 4 4 2 4 4 4 1 4 4 2 4 4 4 2 4 2 4 4 1 3 4 1 4 4 3 2 4 2 4 4 3 3\n",
      " 1 4 4 3 1 2 4 2 2 3 2 4 2 1 4 2 4 2 3 4 2 4 4 1 2 4 1 4 2 4 2 1 4 4 4 4 1\n",
      " 1 4 2 2 2 3 4 4 3 1 3 2 1 2 3 1 4 4 4 4 4 2 4 4 3 1 2 2 3 1 2 2 2 2 3 2 3\n",
      " 4 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5455\n",
      "============= RUN 3 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 20/40 [00:01<00:01, 10.46it/s, loss=107, val_loss=0.0491, avg_v\n",
      "Epoch 0:  55%|▌| 22/40 [00:01<00:01, 11.40it/s, loss=107, val_loss=0.0491, avg_v\n",
      "Epoch 0:  82%|▊| 33/40 [00:02<00:00, 16.21it/s, loss=107, val_loss=0.0491, avg_v\u001b[A\n",
      "Epoch 0: 100%|█| 40/40 [00:02<00:00, 18.50it/s, loss=107, val_loss=0.119, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 20/40 [00:01<00:01, 10.76it/s, loss=0.98, val_loss=0.119, avg_v\u001b[A\n",
      "Epoch 1:  55%|▌| 22/40 [00:01<00:01, 11.75it/s, loss=0.98, val_loss=0.119, avg_v\n",
      "Epoch 1:  82%|▊| 33/40 [00:01<00:00, 16.67it/s, loss=0.98, val_loss=0.119, avg_v\u001b[A\n",
      "Epoch 1: 100%|█| 40/40 [00:02<00:00, 18.96it/s, loss=0.98, val_loss=0.107, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 20/40 [00:02<00:02,  9.88it/s, loss=0.156, val_loss=0.107, avg_\u001b[A\n",
      "Epoch 2:  55%|▌| 22/40 [00:02<00:01, 10.82it/s, loss=0.156, val_loss=0.107, avg_\n",
      "Epoch 2:  82%|▊| 33/40 [00:02<00:00, 15.41it/s, loss=0.156, val_loss=0.107, avg_\u001b[A\n",
      "Epoch 2: 100%|█| 40/40 [00:02<00:00, 17.57it/s, loss=0.156, val_loss=0.062, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 20/40 [00:01<00:01, 10.74it/s, loss=0.0516, val_loss=0.062, avg\u001b[A\n",
      "Epoch 3:  55%|▌| 22/40 [00:01<00:01, 11.68it/s, loss=0.0516, val_loss=0.062, avg\n",
      "Epoch 3:  82%|▊| 33/40 [00:02<00:00, 16.45it/s, loss=0.0516, val_loss=0.062, avg\u001b[A\n",
      "Epoch 3: 100%|█| 40/40 [00:02<00:00, 18.84it/s, loss=0.0516, val_loss=0.0384, av\u001b[A\n",
      "Epoch 4:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.0318, val_loss=0.0384, av\u001b[A\n",
      "Epoch 4:  55%|▌| 22/40 [00:01<00:01, 11.42it/s, loss=0.0318, val_loss=0.0384, av\n",
      "Epoch 4:  82%|▊| 33/40 [00:02<00:00, 16.22it/s, loss=0.0318, val_loss=0.0384, av\u001b[A\n",
      "Epoch 4: 100%|█| 40/40 [00:02<00:00, 18.49it/s, loss=0.0318, val_loss=0.031, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.0252, val_loss=0.031, avg\u001b[A\n",
      "Epoch 5:  55%|▌| 22/40 [00:01<00:01, 11.58it/s, loss=0.0252, val_loss=0.031, avg\n",
      "Epoch 5:  82%|▊| 33/40 [00:02<00:00, 16.43it/s, loss=0.0252, val_loss=0.031, avg\u001b[A\n",
      "Epoch 5: 100%|█| 40/40 [00:02<00:00, 18.69it/s, loss=0.0252, val_loss=0.0263, av\u001b[A\n",
      "Epoch 6:  50%|▌| 20/40 [00:01<00:01, 10.35it/s, loss=0.0213, val_loss=0.0263, av\u001b[A\n",
      "Epoch 6:  55%|▌| 22/40 [00:01<00:01, 11.34it/s, loss=0.0213, val_loss=0.0263, av\n",
      "Epoch 6:  82%|▊| 33/40 [00:02<00:00, 16.07it/s, loss=0.0213, val_loss=0.0263, av\u001b[A\n",
      "Epoch 6: 100%|█| 40/40 [00:02<00:00, 18.24it/s, loss=0.0213, val_loss=0.0227, av\u001b[A\n",
      "Epoch 7:  50%|▌| 20/40 [00:01<00:01, 10.75it/s, loss=0.0186, val_loss=0.0227, av\u001b[A\n",
      "Epoch 7:  55%|▌| 22/40 [00:01<00:01, 11.71it/s, loss=0.0186, val_loss=0.0227, av\n",
      "Epoch 7:  82%|▊| 33/40 [00:01<00:00, 16.58it/s, loss=0.0186, val_loss=0.0227, av\u001b[A\n",
      "Epoch 7: 100%|█| 40/40 [00:02<00:00, 18.92it/s, loss=0.0186, val_loss=0.0199, av\u001b[A\n",
      "Epoch 8:  50%|▌| 20/40 [00:01<00:01, 10.41it/s, loss=0.0165, val_loss=0.0199, av\u001b[A\n",
      "Epoch 8:  55%|▌| 22/40 [00:01<00:01, 11.37it/s, loss=0.0165, val_loss=0.0199, av\n",
      "Epoch 8:  82%|▊| 33/40 [00:02<00:00, 16.08it/s, loss=0.0165, val_loss=0.0199, av\u001b[A\n",
      "Epoch 8: 100%|█| 40/40 [00:02<00:00, 18.43it/s, loss=0.0165, val_loss=0.0177, av\u001b[A\n",
      "Epoch 9:  50%|▌| 20/40 [00:01<00:01, 10.69it/s, loss=0.0148, val_loss=0.0177, av\u001b[A\n",
      "Epoch 9:  55%|▌| 22/40 [00:01<00:01, 11.72it/s, loss=0.0148, val_loss=0.0177, av\n",
      "Epoch 9:  82%|▊| 33/40 [00:01<00:00, 16.55it/s, loss=0.0148, val_loss=0.0177, av\u001b[A\n",
      "Epoch 9: 100%|█| 40/40 [00:02<00:00, 18.87it/s, loss=0.0148, val_loss=0.016, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 20/40 [00:01<00:01, 10.38it/s, loss=0.0134, val_loss=0.016, av\u001b[A\n",
      "Epoch 10:  55%|▌| 22/40 [00:01<00:01, 11.26it/s, loss=0.0134, val_loss=0.016, av\n",
      "Validating:  25%|████████                        | 5/20 [00:00<00:00, 42.65it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 40/40 [00:02<00:00, 17.66it/s, loss=0.0134, val_loss=0.0147, a\u001b[A\n",
      "Epoch 11:  50%|▌| 20/40 [00:01<00:01, 10.68it/s, loss=0.0123, val_loss=0.0147, a\u001b[A\n",
      "Epoch 11:  55%|▌| 22/40 [00:01<00:01, 11.61it/s, loss=0.0123, val_loss=0.0147, a\n",
      "Epoch 11:  82%|▊| 33/40 [00:02<00:00, 16.46it/s, loss=0.0123, val_loss=0.0147, a\u001b[A\n",
      "Epoch 11: 100%|█| 40/40 [00:02<00:00, 18.78it/s, loss=0.0123, val_loss=0.0135, a\u001b[A\n",
      "Epoch 12:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.0114, val_loss=0.0135, a\u001b[A\n",
      "Epoch 12:  55%|▌| 22/40 [00:01<00:01, 11.38it/s, loss=0.0114, val_loss=0.0135, a\n",
      "Epoch 12:  82%|▊| 33/40 [00:02<00:00, 16.09it/s, loss=0.0114, val_loss=0.0135, a\u001b[A\n",
      "Epoch 12: 100%|█| 40/40 [00:02<00:00, 18.42it/s, loss=0.0114, val_loss=0.0125, a\u001b[A\n",
      "Epoch 13:  50%|▌| 20/40 [00:01<00:01, 10.91it/s, loss=0.0106, val_loss=0.0125, a\u001b[A\n",
      "Epoch 13:  55%|▌| 22/40 [00:01<00:01, 11.89it/s, loss=0.0106, val_loss=0.0125, a\n",
      "Epoch 13:  82%|▊| 33/40 [00:01<00:00, 16.69it/s, loss=0.0106, val_loss=0.0125, a\u001b[A\n",
      "Epoch 13: 100%|█| 40/40 [00:02<00:00, 19.10it/s, loss=0.0106, val_loss=0.0116, a\u001b[A\n",
      "Epoch 14:  50%|▌| 20/40 [00:01<00:01, 10.80it/s, loss=0.00987, val_loss=0.0116, \u001b[A\n",
      "Epoch 14:  55%|▌| 22/40 [00:01<00:01, 11.82it/s, loss=0.00987, val_loss=0.0116, \n",
      "Epoch 14:  82%|▊| 33/40 [00:01<00:00, 16.73it/s, loss=0.00987, val_loss=0.0116, \u001b[A\n",
      "Epoch 14: 100%|█| 40/40 [00:02<00:00, 19.07it/s, loss=0.00987, val_loss=0.0109, \u001b[A\n",
      "Epoch 15:  50%|▌| 20/40 [00:01<00:01, 10.59it/s, loss=0.00929, val_loss=0.0109, \u001b[A\n",
      "Epoch 15:  55%|▌| 22/40 [00:01<00:01, 11.47it/s, loss=0.00929, val_loss=0.0109, \n",
      "Epoch 15:  82%|▊| 33/40 [00:02<00:00, 16.28it/s, loss=0.00929, val_loss=0.0109, \u001b[A\n",
      "Epoch 15: 100%|█| 40/40 [00:02<00:00, 18.54it/s, loss=0.00929, val_loss=0.0103, \u001b[A\n",
      "Epoch 16:  50%|▌| 20/40 [00:01<00:01, 10.40it/s, loss=0.00878, val_loss=0.0103, \u001b[A\n",
      "Epoch 16:  55%|▌| 22/40 [00:01<00:01, 11.33it/s, loss=0.00878, val_loss=0.0103, \n",
      "Epoch 16:  82%|▊| 33/40 [00:02<00:00, 16.09it/s, loss=0.00878, val_loss=0.0103, \u001b[A\n",
      "Epoch 16: 100%|█| 40/40 [00:02<00:00, 18.34it/s, loss=0.00878, val_loss=0.0097, \u001b[A\n",
      "Epoch 17:  50%|▌| 20/40 [00:01<00:01, 10.16it/s, loss=0.00834, val_loss=0.0097, \u001b[A\n",
      "Epoch 17:  55%|▌| 22/40 [00:01<00:01, 11.10it/s, loss=0.00834, val_loss=0.0097, \n",
      "Epoch 17:  82%|▊| 33/40 [00:02<00:00, 15.79it/s, loss=0.00834, val_loss=0.0097, \u001b[A\n",
      "Epoch 17: 100%|█| 40/40 [00:02<00:00, 18.04it/s, loss=0.00834, val_loss=0.00918,\u001b[A\n",
      "Epoch 18:  50%|▌| 20/40 [00:01<00:01, 10.32it/s, loss=0.00795, val_loss=0.00918,\u001b[A\n",
      "Epoch 18:  55%|▌| 22/40 [00:01<00:01, 11.27it/s, loss=0.00795, val_loss=0.00918,\n",
      "Epoch 18:  82%|▊| 33/40 [00:02<00:00, 16.00it/s, loss=0.00795, val_loss=0.00918,\u001b[A\n",
      "Epoch 18: 100%|█| 40/40 [00:02<00:00, 18.26it/s, loss=0.00795, val_loss=0.00874,\u001b[A\n",
      "Epoch 19:  50%|▌| 20/40 [00:01<00:01, 10.39it/s, loss=0.00761, val_loss=0.00874,\u001b[A\n",
      "Epoch 19:  55%|▌| 22/40 [00:01<00:01, 11.39it/s, loss=0.00761, val_loss=0.00874,\n",
      "Epoch 19:  82%|▊| 33/40 [00:02<00:00, 16.09it/s, loss=0.00761, val_loss=0.00874,\u001b[A\n",
      "Epoch 19: 100%|█| 40/40 [00:02<00:00, 18.30it/s, loss=0.00761, val_loss=0.00835,\u001b[A\n",
      "Epoch 20:  50%|▌| 20/40 [00:01<00:01, 10.38it/s, loss=0.00731, val_loss=0.00835,\u001b[A\n",
      "Epoch 20:  55%|▌| 22/40 [00:01<00:01, 11.37it/s, loss=0.00731, val_loss=0.00835,\n",
      "Epoch 20:  82%|▊| 33/40 [00:02<00:00, 16.14it/s, loss=0.00731, val_loss=0.00835,\u001b[A\n",
      "Epoch 20: 100%|█| 40/40 [00:02<00:00, 18.40it/s, loss=0.00731, val_loss=0.008, a\u001b[A\n",
      "Epoch 21:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.00705, val_loss=0.008, a\u001b[A\n",
      "Epoch 21:  55%|▌| 22/40 [00:01<00:01, 11.35it/s, loss=0.00705, val_loss=0.008, a\n",
      "Epoch 21:  82%|▊| 33/40 [00:02<00:00, 16.01it/s, loss=0.00705, val_loss=0.008, a\u001b[A\n",
      "Epoch 21: 100%|█| 40/40 [00:02<00:00, 18.34it/s, loss=0.00705, val_loss=0.00769,\u001b[A\n",
      "Epoch 22:  50%|▌| 20/40 [00:02<00:02, 10.00it/s, loss=0.00681, val_loss=0.00769,\u001b[A\n",
      "Epoch 22:  55%|▌| 22/40 [00:02<00:01, 10.89it/s, loss=0.00681, val_loss=0.00769,\n",
      "Epoch 22:  82%|▊| 33/40 [00:02<00:00, 15.42it/s, loss=0.00681, val_loss=0.00769,\u001b[A\n",
      "Epoch 22: 100%|█| 40/40 [00:02<00:00, 17.68it/s, loss=0.00681, val_loss=0.00741,\u001b[A\n",
      "Epoch 23:  50%|▌| 20/40 [00:01<00:01, 10.44it/s, loss=0.0066, val_loss=0.00741, \u001b[A\n",
      "Epoch 23:  55%|▌| 22/40 [00:01<00:01, 11.41it/s, loss=0.0066, val_loss=0.00741, \n",
      "Epoch 23:  82%|▊| 33/40 [00:02<00:00, 16.09it/s, loss=0.0066, val_loss=0.00741, \u001b[A\n",
      "Epoch 23: 100%|█| 40/40 [00:02<00:00, 18.42it/s, loss=0.0066, val_loss=0.00715, \u001b[A\n",
      "Epoch 24:  50%|▌| 20/40 [00:01<00:01, 10.33it/s, loss=0.00642, val_loss=0.00715,\u001b[A\n",
      "Epoch 24:  55%|▌| 22/40 [00:01<00:01, 11.24it/s, loss=0.00642, val_loss=0.00715,\n",
      "Epoch 24:  82%|▊| 33/40 [00:02<00:00, 15.89it/s, loss=0.00642, val_loss=0.00715,\u001b[A\n",
      "Epoch 24: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.00642, val_loss=0.00693,\u001b[A\n",
      "Epoch 25:  50%|▌| 20/40 [00:01<00:01, 10.35it/s, loss=0.00625, val_loss=0.00693,\u001b[A\n",
      "Epoch 25:  55%|▌| 22/40 [00:01<00:01, 11.26it/s, loss=0.00625, val_loss=0.00693,\n",
      "Epoch 25:  82%|▊| 33/40 [00:02<00:00, 16.04it/s, loss=0.00625, val_loss=0.00693,\u001b[A\n",
      "Epoch 25: 100%|█| 40/40 [00:02<00:00, 18.28it/s, loss=0.00625, val_loss=0.00672,\u001b[A\n",
      "Epoch 26:  50%|▌| 20/40 [00:01<00:01, 10.65it/s, loss=0.0061, val_loss=0.00672, \u001b[A\n",
      "Epoch 26:  55%|▌| 22/40 [00:01<00:01, 11.63it/s, loss=0.0061, val_loss=0.00672, \n",
      "Epoch 26:  82%|▊| 33/40 [00:02<00:00, 16.28it/s, loss=0.0061, val_loss=0.00672, \u001b[A\n",
      "Epoch 26: 100%|█| 40/40 [00:02<00:00, 18.65it/s, loss=0.0061, val_loss=0.00655, \u001b[A\n",
      "Epoch 27:  50%|▌| 20/40 [00:01<00:01, 10.29it/s, loss=0.00597, val_loss=0.00655,\u001b[A\n",
      "Epoch 27:  55%|▌| 22/40 [00:01<00:01, 11.28it/s, loss=0.00597, val_loss=0.00655,\n",
      "Epoch 27:  82%|▊| 33/40 [00:02<00:00, 15.45it/s, loss=0.00597, val_loss=0.00655,\u001b[A\n",
      "Epoch 27: 100%|█| 40/40 [00:02<00:00, 17.83it/s, loss=0.00597, val_loss=0.00639,\u001b[A\n",
      "Epoch 28:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.00585, val_loss=0.00639,\u001b[A\n",
      "Epoch 28:  55%|▌| 22/40 [00:01<00:01, 11.54it/s, loss=0.00585, val_loss=0.00639,\n",
      "Epoch 28:  82%|▊| 33/40 [00:02<00:00, 16.37it/s, loss=0.00585, val_loss=0.00639,\u001b[A\n",
      "Epoch 28: 100%|█| 40/40 [00:02<00:00, 18.67it/s, loss=0.00585, val_loss=0.00626,\u001b[A\n",
      "Epoch 29:  50%|▌| 20/40 [00:01<00:01, 10.44it/s, loss=0.00574, val_loss=0.00626,\u001b[A\n",
      "Epoch 29:  55%|▌| 22/40 [00:01<00:01, 11.40it/s, loss=0.00574, val_loss=0.00626,\n",
      "Epoch 29:  82%|▊| 33/40 [00:02<00:00, 16.08it/s, loss=0.00574, val_loss=0.00626,\u001b[A\n",
      "Epoch 29: 100%|█| 40/40 [00:02<00:00, 18.43it/s, loss=0.00574, val_loss=0.00613,\u001b[A\n",
      "Epoch 30:  50%|▌| 20/40 [00:01<00:01, 10.84it/s, loss=0.00564, val_loss=0.00613,\u001b[A\n",
      "Epoch 30:  55%|▌| 22/40 [00:01<00:01, 11.88it/s, loss=0.00564, val_loss=0.00613,\n",
      "Epoch 30:  82%|▊| 33/40 [00:01<00:00, 16.78it/s, loss=0.00564, val_loss=0.00613,\u001b[A\n",
      "Epoch 30: 100%|█| 40/40 [00:02<00:00, 19.09it/s, loss=0.00564, val_loss=0.00601,\u001b[A\n",
      "Epoch 31:  50%|▌| 20/40 [00:01<00:01, 10.74it/s, loss=0.00554, val_loss=0.00601,\u001b[A\n",
      "Epoch 31:  55%|▌| 22/40 [00:01<00:01, 11.62it/s, loss=0.00554, val_loss=0.00601,\n",
      "Epoch 31:  82%|▊| 33/40 [00:02<00:00, 16.46it/s, loss=0.00554, val_loss=0.00601,\u001b[A\n",
      "Epoch 31: 100%|█| 40/40 [00:02<00:00, 16.78it/s, loss=0.00554, val_loss=0.00589,\u001b[A\n",
      "Epoch 32:  50%|▌| 20/40 [00:01<00:01, 10.53it/s, loss=0.00544, val_loss=0.00589,\u001b[A\n",
      "Epoch 32:  55%|▌| 22/40 [00:01<00:01, 11.42it/s, loss=0.00544, val_loss=0.00589,\n",
      "Epoch 32:  82%|▊| 33/40 [00:02<00:00, 16.14it/s, loss=0.00544, val_loss=0.00589,\u001b[A\n",
      "Epoch 32: 100%|█| 40/40 [00:02<00:00, 18.49it/s, loss=0.00544, val_loss=0.00578,\u001b[A\n",
      "Epoch 33:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.00535, val_loss=0.00578,\u001b[A\n",
      "Epoch 33:  55%|▌| 22/40 [00:01<00:01, 11.37it/s, loss=0.00535, val_loss=0.00578,\n",
      "Epoch 33:  82%|▊| 33/40 [00:02<00:00, 16.10it/s, loss=0.00535, val_loss=0.00578,\u001b[A\n",
      "Epoch 33: 100%|█| 40/40 [00:02<00:00, 18.43it/s, loss=0.00535, val_loss=0.00569,\u001b[A\n",
      "Epoch 34:  50%|▌| 20/40 [00:01<00:01, 10.69it/s, loss=0.00527, val_loss=0.00569,\u001b[A\n",
      "Epoch 34:  55%|▌| 22/40 [00:01<00:01, 11.71it/s, loss=0.00527, val_loss=0.00569,\n",
      "Epoch 34:  82%|▊| 33/40 [00:01<00:00, 16.56it/s, loss=0.00527, val_loss=0.00569,\u001b[A\n",
      "Epoch 34: 100%|█| 40/40 [00:02<00:00, 18.84it/s, loss=0.00527, val_loss=0.0056, \u001b[A\n",
      "Epoch 35:  50%|▌| 20/40 [00:01<00:01, 10.33it/s, loss=0.0052, val_loss=0.0056, a\u001b[A\n",
      "Epoch 35:  55%|▌| 22/40 [00:01<00:01, 11.26it/s, loss=0.0052, val_loss=0.0056, a\n",
      "Epoch 35:  82%|▊| 33/40 [00:02<00:00, 15.97it/s, loss=0.0052, val_loss=0.0056, a\u001b[A\n",
      "Epoch 35: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.0052, val_loss=0.00552, \u001b[A\n",
      "Epoch 36:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.00513, val_loss=0.00552,\u001b[A\n",
      "Epoch 36:  55%|▌| 22/40 [00:01<00:01, 11.34it/s, loss=0.00513, val_loss=0.00552,\n",
      "Epoch 36:  82%|▊| 33/40 [00:02<00:00, 15.82it/s, loss=0.00513, val_loss=0.00552,\u001b[A\n",
      "Epoch 36: 100%|█| 40/40 [00:02<00:00, 18.11it/s, loss=0.00513, val_loss=0.00545,\u001b[A\n",
      "Epoch 37:  50%|▌| 20/40 [00:01<00:01, 10.30it/s, loss=0.00507, val_loss=0.00545,\u001b[A\n",
      "Epoch 37:  55%|▌| 22/40 [00:01<00:01, 11.26it/s, loss=0.00507, val_loss=0.00545,\n",
      "Epoch 37:  82%|▊| 33/40 [00:02<00:00, 15.83it/s, loss=0.00507, val_loss=0.00545,\u001b[A\n",
      "Epoch 37: 100%|█| 40/40 [00:02<00:00, 18.24it/s, loss=0.00507, val_loss=0.00538,\u001b[A\n",
      "Epoch 38:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00501, val_loss=0.00538,\u001b[A\n",
      "Epoch 38:  55%|▌| 22/40 [00:01<00:01, 11.46it/s, loss=0.00501, val_loss=0.00538,\n",
      "Epoch 38:  82%|▊| 33/40 [00:02<00:00, 16.19it/s, loss=0.00501, val_loss=0.00538,\u001b[A\n",
      "Epoch 38: 100%|█| 40/40 [00:02<00:00, 18.54it/s, loss=0.00501, val_loss=0.00531,\u001b[A\n",
      "Epoch 39:  50%|▌| 20/40 [00:01<00:01, 10.34it/s, loss=0.00496, val_loss=0.00531,\u001b[A\n",
      "Epoch 39:  55%|▌| 22/40 [00:01<00:01, 11.28it/s, loss=0.00496, val_loss=0.00531,\n",
      "Epoch 39:  82%|▊| 33/40 [00:02<00:00, 16.03it/s, loss=0.00496, val_loss=0.00531,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.30it/s, loss=0.00496, val_loss=0.00525,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.21it/s, loss=0.00496, val_loss=0.00525,\u001b[A\n",
      "Sizes of clusters: 307, 189, 745, 355, 404\n",
      "\n",
      "preds: [2 2 4 2 4 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2\n",
      " 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 4 4 2 4 4 2 2 2 2 2 4 2 4 2 2 2 2\n",
      " 2 4 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 2 4 2 2 2 2 4 2 2 4 2 4 2 2 2 2\n",
      " 2 2 2 2 4 4 2 4 2 2 2 2 2 2 2 4 4 0 2 2 2 2 2 4 2 2 2 4 2 4 2 2 2 2 2 2 4\n",
      " 2 4 2 2 2 2 2 2 4 2 2 2 2 2 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2\n",
      " 4 2 2 2 4 2 2 4 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2 2 2 4 2 2 4\n",
      " 2 2 2 2 2 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2\n",
      " 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2\n",
      " 2 2 2 2 2 2 2 2 2 4 2 4 2 2 4 2 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2\n",
      " 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 4 2 2 4 2 2 4 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 4 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 3 0 3 0 3 3 3 2 0 0 0 0 0 0 3 2 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 3 3 0 0 0 0 0 3 0 0 0 0 3 0 0 3 3 3 0 0 0\n",
      " 0 0 0 3 0 0 0 0 3 0 0 3 0 0 0 0 2 3 3 2 3 0 0 0 3 0 0 0 0 0 0 0 0 2 0 0 3\n",
      " 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 0 0 0 3 0 2 0 0 3 0\n",
      " 4 3 0 0 0 0 0 0 2 0 0 2 2 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 3 3 0 0 0 0\n",
      " 3 0 0 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 3 3 0 0 0 3 0 0 0 0 0 0 3 0 0 0 3 0 0\n",
      " 0 0 0 0 0 0 2 0 0 0 3 0 0 3 0 0 0 2 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0\n",
      " 0 0 0 0 3 0 0 2 3 0 3 3 0 3 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 0 0 0 0 3 0 0 2 0 3 2 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 3\n",
      " 0 0 3 3 0 0 2 3 2 0 0 2 0 0 0 0 3 0 0 0 0 3 0 0 0 0 0 3 0 2 0 3 2 0 0 0 0\n",
      " 3 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 3 2 0 3 0 0 0 4 3 3 3 4 3 2 4 4 1 3 1 2\n",
      " 2 4 3 2 4 4 4 2 2 1 4 2 3 4 4 3 3 3 2 3 3 4 2 3 3 3 2 1 3 4 2 2 4 2 2 3 3\n",
      " 2 3 3 4 4 2 3 1 4 2 2 4 3 1 3 3 2 2 3 2 4 3 2 4 2 2 4 4 3 3 4 1 2 4 4 2 2\n",
      " 3 2 3 3 2 2 3 1 3 2 3 3 3 3 4 4 4 3 1 4 2 2 3 2 3 3 3 3 4 1 2 2 1 3 4 3 4\n",
      " 2 3 3 3 2 3 2 1 2 1 3 4 4 1 1 4 2 4 2 4 2 4 4 2 3 4 2 2 4 4 4 4 3 1 2 2 4\n",
      " 3 4 2 3 4 4 4 4 4 2 2 2 3 1 4 3 2 4 4 2 3 1 2 4 2 2 4 4 4 3 4 4 4 2 1 3 4\n",
      " 4 2 2 3 2 3 3 3 4 2 3 3 2 3 3 2 1 4 4 2 3 2 4 4 2 2 4 4 3 2 3 2 2 2 4 3 2\n",
      " 2 3 2 2 3 3 3 1 3 4 3 4 3 1 3 1 4 2 3 3 3 2 1 1 3 3 4 4 3 4 3 1 1 3 4 4 3\n",
      " 1 4 2 2 4 1 2 2 4 4 3 3 2 3 4 4 2 2 1 4 4 1 3 4 3 3 1 2 0 2 3 2 4 4 3 4 3\n",
      " 1 4 4 1 4 2 2 4 1 3 4 4 4 4 3 2 2 2 3 3 4 4 2 4 2 3 2 4 2 3 4 2 2 4 4 4 2\n",
      " 3 1 3 4 3 4 4 3 4 3 3 3 3 3 2 2 3 4 2 2 4 4 3 4 3 3 1 1 3 3 2 3 3 2 3 3 3\n",
      " 2 2 2 4 2 3 1 2 4 4 4 4 2 1 1 4 2 2 2 2 2 2 2 4 2 4 2 4 2 4 4 2 4 2 2 2 4\n",
      " 2 4 4 2 2 2 2 2 2 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 2 2 2 4 2 2 2 4 2 2 2 2\n",
      " 2 4 2 2 2 4 2 2 2 4 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 4 2 2 4 2 2\n",
      " 4 4 4 2 2 2 4 2 2 2 2 2 4 2 2 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2\n",
      " 2 2 4 4 2 4 4 4 2 4 4 2 2 2 2 2 2 2 2 4 2 4 2 2 4 2 2 2 2 2 4 2 2 2 2 2 4\n",
      " 2 2 2 2 2 4 4 4 2 2 4 4 2 2 4 2 4 2 4 4 2 2 2 4 2 2 2 2 2 4 4 2 4 4 4 2 2\n",
      " 4 4 4 2 2 2 2 2 2 2 2 4 2 2 2 4 2 2 4 4 2 2 4 2 2 4 2 4 2 2 4 2 4 2 2 2 2\n",
      " 2 2 2 4 2 4 2 4 4 4 2 2 2 2 2 2 2 2 3 4 4 4 2 2 4 4 2 4 2 4 2 2 4 4 2 4 4\n",
      " 2 4 3 2 4 2 2 4 4 2 4 4 2 4 2 2 2 2 3 2 2 2 4 2 2 4 2 2 2 4 2 2 2 2 4 2 4\n",
      " 2 4 2 2 2 2 4 2 4 2 4 2 2 4 2 4 4 4 4 2 2 2 4 2 4 4 2 2 4 2 4 2 2 2 2 2 2\n",
      " 2 4 2 4 2 4 2 2 4 2 4 2 2 4 2 4 4 2 4 2 2 2 2 4 2 4 2 2 2 2 2 4 2 2 4 4 4\n",
      " 4 4 2 2 4 4 4 4 2 1 1 1 1 3 1 3 4 3 3 1 1 1 1 4 4 3 3 1 1 3 4 1 3 4 3 1 4\n",
      " 1 1 4 1 3 2 1 1 4 3 4 1 1 4 1 4 1 3 3 1 1 4 3 1 3 3 1 1 1 3 4 3 3 1 4 4 3\n",
      " 3 3 1 4 4 1 3 3 3 1 1 4 3 3 1 4 3 1 1 3 1 4 1 3 3 4 1 3 3 3 3 1 1 3 1 4 1\n",
      " 3 3 3 1 1 1 3 4 1 3 2 4 4 4 1 4 4 3 3 3 4 3 3 3 3 1 3 1 1 3 3 1 1 3 1 1 1\n",
      " 3 1 2 4 4 4 3 1 3 3 3 4 3 4 1 3 3 3 4 3 4 4 1 4 3 3 4 3 3 4 1 3 3 3 3 2 3\n",
      " 3 1 3 1 1 4 3 4 1 3 1 3 4 3 4 2 3 4 4 3 3 1 1 4 1 1 3 1 1 3 4 1 1 4 1 3 4\n",
      " 3 3 3 1 4 1 3 3 1 1 3 1 3 4 3 4 1 4 4 2 1 4 1 4 1 0 1 1 3 1 4 3 1 3 1 3 1\n",
      " 1 4 3 3 1 4 4 3 1 3 1 1 1 4 2 3 1 1 3 1 3 3 4 1 3 1 1 3 1 1 1 1 4 3 1 1 1\n",
      " 1 4 3 3 1 3 3 1 3 3 3 3 4 2 1 3 3 4 1 3 3 3 3 3 1 3 3 3 3 1 1 2 3 3 4 1 1\n",
      " 4 3 4 1 2 1 4 3 1 1 1 3 1 2 3 1 3 3 1 1 1 2 3 4 1 3 4 3 1 3 3 3 2 3 3 4 4\n",
      " 3 3 1 1 4 1 3 1 1 3 1 3 4 3 1 3 4 3 4 3 3 1 3 3 3 3 3 1 1 3 1 3 1 1 1 1 1\n",
      " 3 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5370\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 20/40 [00:01<00:01, 10.43it/s, loss=103, val_loss=0.0881, avg_v\n",
      "Epoch 0:  55%|▌| 22/40 [00:01<00:01, 11.33it/s, loss=103, val_loss=0.0881, avg_v\n",
      "Epoch 0:  82%|▊| 33/40 [00:02<00:00, 16.11it/s, loss=103, val_loss=0.0881, avg_v\u001b[A\n",
      "Epoch 0: 100%|█| 40/40 [00:02<00:00, 18.34it/s, loss=103, val_loss=0.16, avg_val\u001b[A\n",
      "Epoch 1:  50%|▌| 20/40 [00:01<00:01, 10.25it/s, loss=0.687, val_loss=0.16, avg_v\u001b[A\n",
      "Epoch 1:  55%|▌| 22/40 [00:01<00:01, 11.20it/s, loss=0.687, val_loss=0.16, avg_v\n",
      "Epoch 1:  82%|▊| 33/40 [00:02<00:00, 15.66it/s, loss=0.687, val_loss=0.16, avg_v\u001b[A\n",
      "Epoch 1: 100%|█| 40/40 [00:02<00:00, 18.06it/s, loss=0.687, val_loss=0.108, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 20/40 [00:02<00:02,  9.93it/s, loss=0.122, val_loss=0.108, avg_\u001b[A\n",
      "Epoch 2:  55%|▌| 22/40 [00:02<00:01, 10.80it/s, loss=0.122, val_loss=0.108, avg_\n",
      "Epoch 2:  82%|▊| 33/40 [00:02<00:00, 15.14it/s, loss=0.122, val_loss=0.108, avg_\u001b[A\n",
      "Epoch 2: 100%|█| 40/40 [00:02<00:00, 17.45it/s, loss=0.122, val_loss=0.0659, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 20/40 [00:01<00:01, 10.17it/s, loss=0.0399, val_loss=0.0659, av\u001b[A\n",
      "Epoch 3:  55%|▌| 22/40 [00:01<00:01, 11.04it/s, loss=0.0399, val_loss=0.0659, av\n",
      "Epoch 3:  82%|▊| 33/40 [00:02<00:00, 15.46it/s, loss=0.0399, val_loss=0.0659, av\u001b[A\n",
      "Epoch 3: 100%|█| 40/40 [00:02<00:00, 17.77it/s, loss=0.0399, val_loss=0.0412, av\u001b[A\n",
      "Epoch 4:  50%|▌| 20/40 [00:01<00:01, 10.25it/s, loss=0.0238, val_loss=0.0412, av\u001b[A\n",
      "Epoch 4:  55%|▌| 22/40 [00:01<00:01, 11.09it/s, loss=0.0238, val_loss=0.0412, av\n",
      "Epoch 4:  82%|▊| 33/40 [00:02<00:00, 15.59it/s, loss=0.0238, val_loss=0.0412, av\u001b[A\n",
      "Epoch 4: 100%|█| 40/40 [00:02<00:00, 17.98it/s, loss=0.0238, val_loss=0.0317, av\u001b[A\n",
      "Epoch 5:  50%|▌| 20/40 [00:01<00:01, 10.29it/s, loss=0.0181, val_loss=0.0317, av\u001b[A\n",
      "Epoch 5:  55%|▌| 22/40 [00:01<00:01, 11.18it/s, loss=0.0181, val_loss=0.0317, av\n",
      "Epoch 5:  82%|▊| 33/40 [00:02<00:00, 15.90it/s, loss=0.0181, val_loss=0.0317, av\u001b[A\n",
      "Epoch 5: 100%|█| 40/40 [00:02<00:00, 18.12it/s, loss=0.0181, val_loss=0.0249, av\u001b[A\n",
      "Epoch 6:  50%|▌| 20/40 [00:01<00:01, 10.38it/s, loss=0.0151, val_loss=0.0249, av\u001b[A\n",
      "Epoch 6:  55%|▌| 22/40 [00:01<00:01, 11.27it/s, loss=0.0151, val_loss=0.0249, av\n",
      "Epoch 6:  82%|▊| 33/40 [00:02<00:00, 15.86it/s, loss=0.0151, val_loss=0.0249, av\u001b[A\n",
      "Epoch 6: 100%|█| 40/40 [00:02<00:00, 18.05it/s, loss=0.0151, val_loss=0.0205, av\u001b[A\n",
      "Epoch 7:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.013, val_loss=0.0205, avg\u001b[A\n",
      "Epoch 7:  55%|▌| 22/40 [00:01<00:01, 11.37it/s, loss=0.013, val_loss=0.0205, avg\n",
      "Epoch 7: 100%|█| 40/40 [00:02<00:00, 18.41it/s, loss=0.013, val_loss=0.0175, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 20/40 [00:01<00:01, 10.24it/s, loss=0.0114, val_loss=0.0175, av\u001b[A\n",
      "Epoch 8:  55%|▌| 22/40 [00:01<00:01, 11.19it/s, loss=0.0114, val_loss=0.0175, av\n",
      "Epoch 8:  82%|▊| 33/40 [00:02<00:00, 15.91it/s, loss=0.0114, val_loss=0.0175, av\u001b[A\n",
      "Epoch 8: 100%|█| 40/40 [00:02<00:00, 18.15it/s, loss=0.0114, val_loss=0.0152, av\u001b[A\n",
      "Epoch 9:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.0103, val_loss=0.0152, av\u001b[A\n",
      "Epoch 9:  55%|▌| 22/40 [00:01<00:01, 11.44it/s, loss=0.0103, val_loss=0.0152, av\n",
      "Epoch 9:  82%|▊| 33/40 [00:02<00:00, 16.05it/s, loss=0.0103, val_loss=0.0152, av\u001b[A\n",
      "Epoch 9: 100%|█| 40/40 [00:02<00:00, 18.42it/s, loss=0.0103, val_loss=0.0134, av\u001b[A\n",
      "Epoch 10:  50%|▌| 20/40 [00:01<00:01, 10.57it/s, loss=0.00936, val_loss=0.0134, \u001b[A\n",
      "Epoch 10:  55%|▌| 22/40 [00:01<00:01, 11.57it/s, loss=0.00936, val_loss=0.0134, \n",
      "Epoch 10:  82%|▊| 33/40 [00:02<00:00, 16.43it/s, loss=0.00936, val_loss=0.0134, \u001b[A\n",
      "Epoch 10: 100%|█| 40/40 [00:02<00:00, 18.72it/s, loss=0.00936, val_loss=0.0121, \u001b[A\n",
      "Epoch 11:  50%|▌| 20/40 [00:01<00:01, 10.73it/s, loss=0.00863, val_loss=0.0121, \u001b[A\n",
      "Epoch 11:  55%|▌| 22/40 [00:01<00:01, 11.68it/s, loss=0.00863, val_loss=0.0121, \n",
      "Epoch 11:  82%|▊| 33/40 [00:02<00:00, 16.45it/s, loss=0.00863, val_loss=0.0121, \u001b[A\n",
      "Epoch 11: 100%|█| 40/40 [00:02<00:00, 18.90it/s, loss=0.00863, val_loss=0.0111, \u001b[A\n",
      "Epoch 12:  50%|▌| 20/40 [00:01<00:01, 10.57it/s, loss=0.00805, val_loss=0.0111, \u001b[A\n",
      "Epoch 12:  55%|▌| 22/40 [00:01<00:01, 11.57it/s, loss=0.00805, val_loss=0.0111, \n",
      "Epoch 12:  82%|▊| 33/40 [00:02<00:00, 16.31it/s, loss=0.00805, val_loss=0.0111, \u001b[A\n",
      "Epoch 12: 100%|█| 40/40 [00:02<00:00, 18.73it/s, loss=0.00805, val_loss=0.0104, \u001b[A\n",
      "Epoch 13:  50%|▌| 20/40 [00:01<00:01, 10.01it/s, loss=0.00757, val_loss=0.0104, \u001b[A\n",
      "Epoch 13:  55%|▌| 22/40 [00:02<00:01, 10.92it/s, loss=0.00757, val_loss=0.0104, \n",
      "Epoch 13:  82%|▊| 33/40 [00:02<00:00, 15.53it/s, loss=0.00757, val_loss=0.0104, \u001b[A\n",
      "Epoch 13: 100%|█| 40/40 [00:02<00:00, 17.78it/s, loss=0.00757, val_loss=0.00974,\u001b[A\n",
      "Epoch 14:  50%|▌| 20/40 [00:01<00:01, 10.08it/s, loss=0.00717, val_loss=0.00974,\u001b[A\n",
      "Epoch 14:  55%|▌| 22/40 [00:01<00:01, 11.00it/s, loss=0.00717, val_loss=0.00974,\n",
      "Epoch 14:  82%|▊| 33/40 [00:02<00:00, 15.11it/s, loss=0.00717, val_loss=0.00974,\u001b[A\n",
      "Epoch 14: 100%|█| 40/40 [00:02<00:00, 17.46it/s, loss=0.00717, val_loss=0.009, a\u001b[A\n",
      "Epoch 15:  50%|▌| 20/40 [00:01<00:01, 10.30it/s, loss=0.00681, val_loss=0.009, a\u001b[A\n",
      "Epoch 15:  55%|▌| 22/40 [00:01<00:01, 11.20it/s, loss=0.00681, val_loss=0.009, a\n",
      "Epoch 15:  82%|▊| 33/40 [00:02<00:00, 15.66it/s, loss=0.00681, val_loss=0.009, a\u001b[A\n",
      "Epoch 15: 100%|█| 40/40 [00:02<00:00, 18.04it/s, loss=0.00681, val_loss=0.00825,\u001b[A\n",
      "Epoch 16:  50%|▌| 20/40 [00:01<00:01, 10.27it/s, loss=0.00651, val_loss=0.00825,\u001b[A\n",
      "Epoch 16:  55%|▌| 22/40 [00:01<00:01, 11.23it/s, loss=0.00651, val_loss=0.00825,\n",
      "Epoch 16:  82%|▊| 33/40 [00:02<00:00, 15.97it/s, loss=0.00651, val_loss=0.00825,\u001b[A\n",
      "Epoch 16: 100%|█| 40/40 [00:02<00:00, 18.21it/s, loss=0.00651, val_loss=0.00761,\u001b[A\n",
      "Epoch 17:  50%|▌| 20/40 [00:01<00:01, 10.63it/s, loss=0.00624, val_loss=0.00761,\u001b[A\n",
      "Epoch 17:  55%|▌| 22/40 [00:01<00:01, 11.52it/s, loss=0.00624, val_loss=0.00761,\n",
      "Epoch 17:  82%|▊| 33/40 [00:02<00:00, 16.36it/s, loss=0.00624, val_loss=0.00761,\u001b[A\n",
      "Epoch 17: 100%|█| 40/40 [00:02<00:00, 18.69it/s, loss=0.00624, val_loss=0.00714,\u001b[A\n",
      "Epoch 18:  50%|▌| 20/40 [00:01<00:01, 10.77it/s, loss=0.006, val_loss=0.00714, a\u001b[A\n",
      "Epoch 18:  55%|▌| 22/40 [00:01<00:01, 11.71it/s, loss=0.006, val_loss=0.00714, a\n",
      "Epoch 18:  82%|▊| 33/40 [00:02<00:00, 16.49it/s, loss=0.006, val_loss=0.00714, a\u001b[A\n",
      "Epoch 18: 100%|█| 40/40 [00:02<00:00, 18.95it/s, loss=0.006, val_loss=0.00684, a\u001b[A\n",
      "Epoch 19:  50%|▌| 20/40 [00:01<00:01, 10.66it/s, loss=0.00577, val_loss=0.00684,\u001b[A\n",
      "Epoch 19:  55%|▌| 22/40 [00:01<00:01, 11.64it/s, loss=0.00577, val_loss=0.00684,\n",
      "Epoch 19:  82%|▊| 33/40 [00:01<00:00, 16.56it/s, loss=0.00577, val_loss=0.00684,\u001b[A\n",
      "Epoch 19: 100%|█| 40/40 [00:02<00:00, 18.86it/s, loss=0.00577, val_loss=0.00662,\u001b[A\n",
      "Epoch 20:  50%|▌| 20/40 [00:01<00:01, 10.83it/s, loss=0.00558, val_loss=0.00662,\u001b[A\n",
      "Epoch 20:  55%|▌| 22/40 [00:01<00:01, 11.86it/s, loss=0.00558, val_loss=0.00662,\n",
      "Epoch 20:  82%|▊| 33/40 [00:01<00:00, 16.78it/s, loss=0.00558, val_loss=0.00662,\u001b[A\n",
      "Epoch 20: 100%|█| 40/40 [00:02<00:00, 19.04it/s, loss=0.00558, val_loss=0.00641,\u001b[A\n",
      "Epoch 21:  50%|▌| 20/40 [00:01<00:01, 10.60it/s, loss=0.00543, val_loss=0.00641,\u001b[A\n",
      "Epoch 21:  55%|▌| 22/40 [00:01<00:01, 11.62it/s, loss=0.00543, val_loss=0.00641,\n",
      "Epoch 21:  82%|▊| 33/40 [00:02<00:00, 16.49it/s, loss=0.00543, val_loss=0.00641,\u001b[A\n",
      "Epoch 21: 100%|█| 40/40 [00:02<00:00, 18.73it/s, loss=0.00543, val_loss=0.00622,\u001b[A\n",
      "Epoch 22:  50%|▌| 20/40 [00:01<00:01, 10.11it/s, loss=0.0053, val_loss=0.00622, \u001b[A\n",
      "Epoch 22:  55%|▌| 22/40 [00:01<00:01, 11.04it/s, loss=0.0053, val_loss=0.00622, \n",
      "Epoch 22:  82%|▊| 33/40 [00:02<00:00, 15.61it/s, loss=0.0053, val_loss=0.00622, \u001b[A\n",
      "Epoch 22: 100%|█| 40/40 [00:02<00:00, 17.91it/s, loss=0.0053, val_loss=0.00607, \u001b[A\n",
      "Epoch 23:  50%|▌| 20/40 [00:01<00:01, 10.15it/s, loss=0.0052, val_loss=0.00607, \u001b[A\n",
      "Epoch 23:  55%|▌| 22/40 [00:01<00:01, 11.03it/s, loss=0.0052, val_loss=0.00607, \n",
      "Epoch 23:  82%|▊| 33/40 [00:02<00:00, 15.54it/s, loss=0.0052, val_loss=0.00607, \u001b[A\n",
      "Epoch 23: 100%|█| 40/40 [00:02<00:00, 17.84it/s, loss=0.0052, val_loss=0.00593, \u001b[A\n",
      "Epoch 24:  50%|▌| 20/40 [00:02<00:02,  9.83it/s, loss=0.0051, val_loss=0.00593, \u001b[A\n",
      "Epoch 24:  55%|▌| 22/40 [00:02<00:01, 10.71it/s, loss=0.0051, val_loss=0.00593, \n",
      "Epoch 24:  82%|▊| 33/40 [00:02<00:00, 15.25it/s, loss=0.0051, val_loss=0.00593, \u001b[A\n",
      "Epoch 24: 100%|█| 40/40 [00:02<00:00, 17.42it/s, loss=0.0051, val_loss=0.00579, \u001b[A\n",
      "Epoch 25:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.00502, val_loss=0.00579,\u001b[A\n",
      "Epoch 25:  55%|▌| 22/40 [00:01<00:01, 11.44it/s, loss=0.00502, val_loss=0.00579,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  82%|▊| 33/40 [00:02<00:00, 16.11it/s, loss=0.00502, val_loss=0.00579,\u001b[A\n",
      "Epoch 25: 100%|█| 40/40 [00:02<00:00, 18.44it/s, loss=0.00502, val_loss=0.00566,\u001b[A\n",
      "Epoch 26:  50%|▌| 20/40 [00:01<00:01, 10.74it/s, loss=0.00496, val_loss=0.00566,\u001b[A\n",
      "Epoch 26:  55%|▌| 22/40 [00:01<00:01, 11.76it/s, loss=0.00496, val_loss=0.00566,\n",
      "Epoch 26:  82%|▊| 33/40 [00:01<00:00, 16.68it/s, loss=0.00496, val_loss=0.00566,\u001b[A\n",
      "Epoch 26: 100%|█| 40/40 [00:02<00:00, 18.93it/s, loss=0.00496, val_loss=0.00554,\u001b[A\n",
      "Epoch 27:  50%|▌| 20/40 [00:01<00:01, 10.55it/s, loss=0.0049, val_loss=0.00554, \u001b[A\n",
      "Epoch 27:  55%|▌| 22/40 [00:01<00:01, 11.56it/s, loss=0.0049, val_loss=0.00554, \n",
      "Epoch 27:  82%|▊| 33/40 [00:02<00:00, 16.29it/s, loss=0.0049, val_loss=0.00554, \u001b[A\n",
      "Epoch 27: 100%|█| 40/40 [00:02<00:00, 18.62it/s, loss=0.0049, val_loss=0.00544, \u001b[A\n",
      "Epoch 28:  50%|▌| 20/40 [00:01<00:01, 10.83it/s, loss=0.00485, val_loss=0.00544,\u001b[A\n",
      "Epoch 28:  55%|▌| 22/40 [00:01<00:01, 11.85it/s, loss=0.00485, val_loss=0.00544,\n",
      "Epoch 28:  82%|▊| 33/40 [00:01<00:00, 16.67it/s, loss=0.00485, val_loss=0.00544,\u001b[A\n",
      "Epoch 28: 100%|█| 40/40 [00:02<00:00, 19.10it/s, loss=0.00485, val_loss=0.00537,\u001b[A\n",
      "Epoch 29:  50%|▌| 20/40 [00:01<00:01, 10.85it/s, loss=0.0048, val_loss=0.00537, \u001b[A\n",
      "Epoch 29:  55%|▌| 22/40 [00:01<00:01, 11.81it/s, loss=0.0048, val_loss=0.00537, \n",
      "Epoch 29:  82%|▊| 33/40 [00:01<00:00, 16.65it/s, loss=0.0048, val_loss=0.00537, \u001b[A\n",
      "Epoch 29: 100%|█| 40/40 [00:02<00:00, 19.09it/s, loss=0.0048, val_loss=0.00531, \u001b[A\n",
      "Epoch 30:  50%|▌| 20/40 [00:01<00:01, 10.36it/s, loss=0.00476, val_loss=0.00531,\u001b[A\n",
      "Epoch 30:  55%|▌| 22/40 [00:01<00:01, 11.34it/s, loss=0.00476, val_loss=0.00531,\n",
      "Epoch 30:  82%|▊| 33/40 [00:02<00:00, 16.08it/s, loss=0.00476, val_loss=0.00531,\u001b[A\n",
      "Epoch 30: 100%|█| 40/40 [00:02<00:00, 18.34it/s, loss=0.00476, val_loss=0.00526,\u001b[A\n",
      "Epoch 31:  50%|▌| 20/40 [00:01<00:01, 10.41it/s, loss=0.00473, val_loss=0.00526,\u001b[A\n",
      "Epoch 31:  55%|▌| 22/40 [00:01<00:01, 11.31it/s, loss=0.00473, val_loss=0.00526,\n",
      "Epoch 31:  82%|▊| 33/40 [00:02<00:00, 16.06it/s, loss=0.00473, val_loss=0.00526,\u001b[A\n",
      "Epoch 31: 100%|█| 40/40 [00:02<00:00, 18.31it/s, loss=0.00473, val_loss=0.00523,\u001b[A\n",
      "Epoch 32:  50%|▌| 20/40 [00:01<00:01, 10.33it/s, loss=0.0047, val_loss=0.00523, \u001b[A\n",
      "Epoch 32:  55%|▌| 22/40 [00:01<00:01, 11.29it/s, loss=0.0047, val_loss=0.00523, \n",
      "Epoch 32:  82%|▊| 33/40 [00:02<00:00, 15.87it/s, loss=0.0047, val_loss=0.00523, \u001b[A\n",
      "Epoch 32: 100%|█| 40/40 [00:02<00:00, 18.18it/s, loss=0.0047, val_loss=0.00519, \u001b[A\n",
      "Epoch 33:  50%|▌| 20/40 [00:02<00:02,  9.89it/s, loss=0.00467, val_loss=0.00519,\u001b[A\n",
      "Epoch 33:  55%|▌| 22/40 [00:02<00:01, 10.83it/s, loss=0.00467, val_loss=0.00519,\n",
      "Epoch 33:  82%|▊| 33/40 [00:02<00:00, 15.32it/s, loss=0.00467, val_loss=0.00519,\u001b[A\n",
      "Epoch 33: 100%|█| 40/40 [00:02<00:00, 17.48it/s, loss=0.00467, val_loss=0.00516,\u001b[A\n",
      "Epoch 34:  50%|▌| 20/40 [00:02<00:02,  9.82it/s, loss=0.00464, val_loss=0.00516,\u001b[A\n",
      "Epoch 34:  55%|▌| 22/40 [00:02<00:01, 10.66it/s, loss=0.00464, val_loss=0.00516,\n",
      "Epoch 34:  82%|▊| 33/40 [00:02<00:00, 14.87it/s, loss=0.00464, val_loss=0.00516,\u001b[A\n",
      "Epoch 34: 100%|█| 40/40 [00:02<00:00, 17.19it/s, loss=0.00464, val_loss=0.00515,\u001b[A\n",
      "Epoch 35:  50%|▌| 20/40 [00:01<00:01, 10.31it/s, loss=0.00462, val_loss=0.00515,\u001b[A\n",
      "Epoch 35:  55%|▌| 22/40 [00:01<00:01, 11.25it/s, loss=0.00462, val_loss=0.00515,\n",
      "Epoch 35:  82%|▊| 33/40 [00:02<00:00, 15.91it/s, loss=0.00462, val_loss=0.00515,\u001b[A\n",
      "Epoch 35: 100%|█| 40/40 [00:02<00:00, 18.24it/s, loss=0.00462, val_loss=0.00515,\u001b[A\n",
      "Epoch 36:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.0046, val_loss=0.00515, \u001b[A\n",
      "Epoch 36:  55%|▌| 22/40 [00:01<00:01, 11.39it/s, loss=0.0046, val_loss=0.00515, \n",
      "Epoch 36:  82%|▊| 33/40 [00:02<00:00, 16.08it/s, loss=0.0046, val_loss=0.00515, \u001b[A\n",
      "Epoch 36: 100%|█| 40/40 [00:02<00:00, 18.42it/s, loss=0.0046, val_loss=0.00513, \u001b[A\n",
      "Epoch 37:  50%|▌| 20/40 [00:01<00:01, 10.62it/s, loss=0.00459, val_loss=0.00513,\u001b[A\n",
      "Epoch 37:  55%|▌| 22/40 [00:01<00:01, 11.57it/s, loss=0.00459, val_loss=0.00513,\n",
      "Epoch 37:  82%|▊| 33/40 [00:02<00:00, 16.05it/s, loss=0.00459, val_loss=0.00513,\u001b[A\n",
      "Epoch 37: 100%|█| 40/40 [00:02<00:00, 18.50it/s, loss=0.00459, val_loss=0.00505,\u001b[A\n",
      "Epoch 38:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00456, val_loss=0.00505,\u001b[A\n",
      "Epoch 38:  55%|▌| 22/40 [00:01<00:01, 11.40it/s, loss=0.00456, val_loss=0.00505,\n",
      "Epoch 38:  82%|▊| 33/40 [00:02<00:00, 15.91it/s, loss=0.00456, val_loss=0.00505,\u001b[A\n",
      "Epoch 38: 100%|█| 40/40 [00:02<00:00, 18.33it/s, loss=0.00456, val_loss=0.00491,\u001b[A\n",
      "Epoch 39:  50%|▌| 20/40 [00:01<00:01, 10.50it/s, loss=0.00452, val_loss=0.00491,\u001b[A\n",
      "Epoch 39:  55%|▌| 22/40 [00:01<00:01, 11.49it/s, loss=0.00452, val_loss=0.00491,\n",
      "Epoch 39:  82%|▊| 33/40 [00:02<00:00, 16.19it/s, loss=0.00452, val_loss=0.00491,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.55it/s, loss=0.00452, val_loss=0.00475,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.45it/s, loss=0.00452, val_loss=0.00475,\u001b[A\n",
      "Sizes of clusters: 400, 438, 271, 707, 184\n",
      "\n",
      "preds: [1 3 1 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 1 3 3 3 3\n",
      " 1 3 3 1 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3 3 1 1 3 3 3 1 1 3 3 3 3 3 1\n",
      " 3 1 1 3 3 1 3 2 1 3 3 3 3 3 3 3 3 2 3 1 1 3 1 3 3 3 3 1 3 3 3 3 1 3 3 3 3\n",
      " 1 3 1 3 3 3 3 1 3 1 3 3 3 1 3 3 1 3 3 3 3 3 1 1 3 3 3 3 3 3 3 1 3 3 3 1 1\n",
      " 3 1 3 3 3 3 1 3 1 3 3 3 3 1 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 1 1 1 3 3 3 3 3 2 3 1 3 3 3 3 3 1 3 3 3 3 3 3 1 3 1 3 3 3 3 3 1 1 3 1\n",
      " 3 3 3 3 3 1 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 1 3 3 1 3 3 3 1 3 3 3 3 2 1 3 3\n",
      " 3 3 3 1 1 3 3 3 3 3 1 3 3 1 3 3 3 3 3 1 3 3 3 3 1 3 3 1 1 3 3 3 3 3 3 1 3\n",
      " 3 3 3 3 1 3 1 3 3 1 3 3 1 3 1 3 3 3 1 3 3 2 3 3 3 1 1 3 3 3 3 1 3 3 3 3 3\n",
      " 3 1 3 3 3 1 3 3 1 3 3 3 3 3 3 3 1 3 3 3 1 1 3 3 3 3 3 3 3 3 1 3 3 1 3 3 3\n",
      " 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 1 3 3 3 3 1 3 3 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 1 1 2 2 1 3 2 2 2 2 4 3\n",
      " 1 2 1 3 3 1 1 1 3 4 1 3 2 1 1 1 2 1 3 1 2 1 3 3 2 2 3 4 1 3 1 1 1 3 3 1 2\n",
      " 3 1 1 2 2 3 1 4 1 1 3 1 2 4 1 2 1 1 2 3 2 2 3 1 3 3 1 2 1 2 1 4 3 1 2 3 3\n",
      " 2 3 1 1 3 3 2 2 2 1 2 2 2 2 1 1 3 2 4 3 3 3 2 1 1 1 2 1 2 4 3 3 4 1 1 1 1\n",
      " 3 1 1 1 1 2 1 4 3 4 1 1 2 2 4 1 3 3 1 1 3 1 1 1 1 1 1 3 1 1 2 3 1 4 3 1 1\n",
      " 2 1 3 1 3 3 3 3 1 3 3 1 2 4 3 1 1 2 3 1 1 4 1 1 3 3 2 1 1 2 3 3 1 3 4 1 1\n",
      " 1 1 3 2 3 1 2 2 1 3 1 1 3 2 1 1 4 1 1 1 2 3 3 2 3 3 3 1 2 3 1 3 3 1 3 2 0\n",
      " 3 2 3 3 1 1 1 4 1 1 1 2 2 4 1 4 1 1 2 1 1 3 4 4 1 2 1 3 1 1 1 4 4 2 2 1 1\n",
      " 4 3 3 1 3 4 3 3 3 3 2 1 3 1 3 1 3 3 4 3 1 4 2 1 2 2 4 3 1 3 1 3 1 1 1 1 2\n",
      " 4 2 1 4 2 1 1 1 4 1 2 1 1 2 1 1 3 3 1 1 2 3 3 2 3 1 3 2 3 1 1 3 3 2 1 3 3\n",
      " 1 4 1 1 2 3 1 1 3 2 1 2 1 2 3 1 1 1 1 3 3 1 1 2 1 1 4 2 1 2 3 1 2 3 1 1 1\n",
      " 3 1 3 1 1 2 4 1 3 1 1 3 3 4 4 3 1 1 1 1 3 3 3 3 3 3 1 3 1 1 3 1 3 1 1 1 3\n",
      " 1 3 3 3 3 3 1 1 3 3 3 1 1 3 3 1 3 1 3 3 3 3 3 3 1 1 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 1 3 3 1 1 3 3 1 3 1 3 3 1 3 1 3 3 1 3 1 1 1 3 3 3 3 3 3 3 3 3 3 3 1\n",
      " 3 3 3 3 1 1 3 1 3 1 3 3 3 3 3 3 3 3 1 1 1 1 3 3 3 1 3 3 3 3 3 3 1 3 3 3 1\n",
      " 1 1 3 3 1 3 1 3 3 3 3 1 3 1 3 3 1 3 3 3 3 2 1 3 3 1 3 3 1 1 3 3 3 3 3 3 3\n",
      " 3 3 3 1 1 3 3 3 1 1 3 3 3 1 3 1 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 1\n",
      " 3 3 3 3 3 3 1 1 1 1 1 3 3 3 1 3 3 3 3 3 3 3 3 1 3 3 1 3 1 3 3 3 3 3 3 1 1\n",
      " 1 3 1 3 1 3 1 3 3 3 3 3 1 3 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 1 3 1\n",
      " 1 3 1 3 3 3 1 3 3 1 3 3 1 3 3 1 3 1 1 1 3 3 3 3 3 3 3 3 1 3 3 3 1 1 3 3 3\n",
      " 3 3 3 1 1 3 3 3 3 3 3 1 1 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 3 1 1 1 3 3 3 1 1\n",
      " 3 3 1 3 1 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 1 1 3 3 3 1 3 1 3 1 3 3 1 3 3 3\n",
      " 3 3 1 3 3 1 3 1 1 4 4 4 4 4 4 1 1 4 2 4 2 4 4 1 1 2 2 4 4 4 4 4 4 2 2 4 1\n",
      " 2 4 2 4 2 1 4 4 2 2 1 4 4 1 4 2 4 4 1 2 2 1 2 4 1 2 4 4 4 2 2 2 2 4 4 2 2\n",
      " 1 2 2 4 1 4 4 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 4 4 2 4 1 2 2 2 4 4 4 4 1 4\n",
      " 2 2 1 2 4 2 2 1 4 2 2 2 2 1 4 2 4 2 4 2 3 1 2 4 2 4 2 4 4 2 2 4 4 2 4 4 2\n",
      " 1 4 1 2 2 2 1 4 2 1 2 1 2 1 4 2 2 2 2 2 4 1 4 1 1 2 1 1 2 3 2 4 2 4 4 1 4\n",
      " 1 2 2 4 2 2 2 2 4 2 4 2 2 2 2 1 2 1 2 2 1 4 2 2 2 4 2 4 4 2 2 2 2 1 4 2 1\n",
      " 4 2 4 4 2 2 1 2 4 4 2 4 4 2 2 2 4 2 1 2 2 2 4 2 4 4 2 4 2 4 3 2 2 1 4 2 4\n",
      " 4 1 2 1 4 1 2 4 4 2 4 4 4 1 1 2 4 4 2 4 1 2 1 4 2 4 2 4 4 2 4 4 3 2 4 4 4\n",
      " 4 2 2 4 4 2 2 4 2 2 2 2 4 1 2 1 2 1 4 2 4 2 2 1 4 2 1 2 2 4 4 1 2 2 2 4 4\n",
      " 3 2 2 4 2 2 1 4 4 4 4 2 2 2 2 2 1 2 4 4 4 1 2 1 2 2 1 2 2 2 1 2 1 2 4 1 3\n",
      " 2 2 4 4 2 4 2 2 4 2 4 1 1 4 4 2 2 2 1 2 2 4 2 2 2 2 4 4 4 1 4 4 2 2 4 4 4\n",
      " 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.6025\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 20/40 [00:01<00:01, 10.45it/s, loss=191, val_loss=0.0419, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  72%|▋| 29/40 [00:02<00:00, 14.34it/s, loss=191, val_loss=0.0419, avg_v\u001b[A\n",
      "Epoch 0: 100%|█| 40/40 [00:02<00:00, 18.15it/s, loss=191, val_loss=0.272, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 20/40 [00:01<00:01, 10.24it/s, loss=1.12, val_loss=0.272, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|▊| 32/40 [00:02<00:00, 15.53it/s, loss=1.12, val_loss=0.272, avg_v\u001b[A\n",
      "Epoch 1: 100%|█| 40/40 [00:02<00:00, 18.18it/s, loss=1.12, val_loss=0.121, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.172, val_loss=0.121, avg_\u001b[A\n",
      "Epoch 2:  60%|▌| 24/40 [00:01<00:01, 12.47it/s, loss=0.172, val_loss=0.121, avg_\n",
      "Epoch 2:  90%|▉| 36/40 [00:02<00:00, 17.45it/s, loss=0.172, val_loss=0.121, avg_\u001b[A\n",
      "Epoch 2: 100%|█| 40/40 [00:02<00:00, 18.58it/s, loss=0.172, val_loss=0.0666, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 20/40 [00:01<00:01, 10.34it/s, loss=0.0576, val_loss=0.0666, av\u001b[A\n",
      "Epoch 3:  60%|▌| 24/40 [00:01<00:01, 12.19it/s, loss=0.0576, val_loss=0.0666, av\n",
      "Epoch 3:  90%|▉| 36/40 [00:02<00:00, 16.88it/s, loss=0.0576, val_loss=0.0666, av\u001b[A\n",
      "Epoch 3: 100%|█| 40/40 [00:02<00:00, 18.10it/s, loss=0.0576, val_loss=0.0488, av\u001b[A\n",
      "Epoch 4:  50%|▌| 20/40 [00:01<00:01, 10.18it/s, loss=0.0353, val_loss=0.0488, av\u001b[A\n",
      "Epoch 4:  60%|▌| 24/40 [00:02<00:01, 11.93it/s, loss=0.0353, val_loss=0.0488, av\n",
      "Epoch 4:  90%|▉| 36/40 [00:02<00:00, 16.76it/s, loss=0.0353, val_loss=0.0488, av\u001b[A\n",
      "Epoch 4: 100%|█| 40/40 [00:02<00:00, 17.99it/s, loss=0.0353, val_loss=0.038, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 20/40 [00:01<00:01, 10.74it/s, loss=0.0285, val_loss=0.038, avg\u001b[A\n",
      "Epoch 5:  60%|▌| 24/40 [00:01<00:01, 12.59it/s, loss=0.0285, val_loss=0.038, avg\n",
      "Epoch 5:  90%|▉| 36/40 [00:02<00:00, 17.64it/s, loss=0.0285, val_loss=0.038, avg\u001b[A\n",
      "Epoch 5: 100%|█| 40/40 [00:02<00:00, 18.81it/s, loss=0.0285, val_loss=0.0317, av\u001b[A\n",
      "Epoch 6:  50%|▌| 20/40 [00:01<00:01, 10.71it/s, loss=0.0248, val_loss=0.0317, av\u001b[A\n",
      "Epoch 6:  60%|▌| 24/40 [00:01<00:01, 12.65it/s, loss=0.0248, val_loss=0.0317, av\n",
      "Epoch 6:  90%|▉| 36/40 [00:02<00:00, 17.74it/s, loss=0.0248, val_loss=0.0317, av\u001b[A\n",
      "Epoch 6: 100%|█| 40/40 [00:02<00:00, 18.86it/s, loss=0.0248, val_loss=0.0275, av\u001b[A\n",
      "Epoch 7:  50%|▌| 20/40 [00:01<00:01, 10.54it/s, loss=0.0221, val_loss=0.0275, av\u001b[A\n",
      "Epoch 7:  60%|▌| 24/40 [00:01<00:01, 12.35it/s, loss=0.0221, val_loss=0.0275, av\n",
      "Epoch 7:  90%|▉| 36/40 [00:02<00:00, 17.02it/s, loss=0.0221, val_loss=0.0275, av\u001b[A\n",
      "Epoch 7: 100%|█| 40/40 [00:02<00:00, 18.21it/s, loss=0.0221, val_loss=0.0244, av\u001b[A\n",
      "Epoch 8:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.02, val_loss=0.0244, avg_\u001b[A\n",
      "Epoch 8:  60%|▌| 24/40 [00:01<00:01, 12.18it/s, loss=0.02, val_loss=0.0244, avg_\n",
      "Epoch 8:  90%|▉| 36/40 [00:02<00:00, 17.22it/s, loss=0.02, val_loss=0.0244, avg_\u001b[A\n",
      "Epoch 8: 100%|█| 40/40 [00:02<00:00, 18.32it/s, loss=0.02, val_loss=0.0221, avg_\u001b[A\n",
      "Epoch 9:  50%|▌| 20/40 [00:01<00:01, 10.29it/s, loss=0.0184, val_loss=0.0221, av\u001b[A\n",
      "Epoch 9:  60%|▌| 24/40 [00:01<00:01, 12.12it/s, loss=0.0184, val_loss=0.0221, av\n",
      "Epoch 9:  90%|▉| 36/40 [00:02<00:00, 17.01it/s, loss=0.0184, val_loss=0.0221, av\u001b[A\n",
      "Epoch 9: 100%|█| 40/40 [00:02<00:00, 18.21it/s, loss=0.0184, val_loss=0.0203, av\u001b[A\n",
      "Epoch 10:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.0171, val_loss=0.0203, a\u001b[A\n",
      "Epoch 10:  60%|▌| 24/40 [00:01<00:01, 12.34it/s, loss=0.0171, val_loss=0.0203, a\n",
      "Epoch 10:  90%|▉| 36/40 [00:02<00:00, 17.37it/s, loss=0.0171, val_loss=0.0203, a\u001b[A\n",
      "Epoch 10: 100%|█| 40/40 [00:02<00:00, 18.44it/s, loss=0.0171, val_loss=0.0187, a\u001b[A\n",
      "Epoch 11:  50%|▌| 20/40 [00:01<00:01, 10.48it/s, loss=0.016, val_loss=0.0187, av\u001b[A\n",
      "Epoch 11:  60%|▌| 24/40 [00:01<00:01, 12.38it/s, loss=0.016, val_loss=0.0187, av\n",
      "Epoch 11:  90%|▉| 36/40 [00:02<00:00, 17.43it/s, loss=0.016, val_loss=0.0187, av\u001b[A\n",
      "Epoch 11: 100%|█| 40/40 [00:02<00:00, 18.52it/s, loss=0.016, val_loss=0.0175, av\u001b[A\n",
      "Epoch 12:  50%|▌| 20/40 [00:01<00:01, 10.30it/s, loss=0.015, val_loss=0.0175, av\u001b[A\n",
      "Epoch 12:  60%|▌| 24/40 [00:01<00:01, 12.23it/s, loss=0.015, val_loss=0.0175, av\n",
      "Epoch 12:  90%|▉| 36/40 [00:02<00:00, 17.14it/s, loss=0.015, val_loss=0.0175, av\u001b[A\n",
      "Epoch 12: 100%|█| 40/40 [00:02<00:00, 18.30it/s, loss=0.015, val_loss=0.0163, av\u001b[A\n",
      "Epoch 13:  50%|▌| 20/40 [00:01<00:01, 10.61it/s, loss=0.0141, val_loss=0.0163, a\u001b[A\n",
      "Epoch 13:  60%|▌| 24/40 [00:01<00:01, 12.49it/s, loss=0.0141, val_loss=0.0163, a\n",
      "Epoch 13:  90%|▉| 36/40 [00:02<00:00, 17.42it/s, loss=0.0141, val_loss=0.0163, a\u001b[A\n",
      "Epoch 13: 100%|█| 40/40 [00:02<00:00, 18.61it/s, loss=0.0141, val_loss=0.0154, a\u001b[A\n",
      "Epoch 14:  50%|▌| 20/40 [00:01<00:01, 10.50it/s, loss=0.0134, val_loss=0.0154, a\u001b[A\n",
      "Epoch 14:  60%|▌| 24/40 [00:01<00:01, 12.36it/s, loss=0.0134, val_loss=0.0154, a\n",
      "Epoch 14:  90%|▉| 36/40 [00:02<00:00, 17.48it/s, loss=0.0134, val_loss=0.0154, a\u001b[A\n",
      "Epoch 14: 100%|█| 40/40 [00:02<00:00, 18.56it/s, loss=0.0134, val_loss=0.0145, a\u001b[A\n",
      "Epoch 15:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.0127, val_loss=0.0145, a\u001b[A\n",
      "Epoch 15:  60%|▌| 24/40 [00:01<00:01, 12.14it/s, loss=0.0127, val_loss=0.0145, a\n",
      "Epoch 15:  90%|▉| 36/40 [00:02<00:00, 17.06it/s, loss=0.0127, val_loss=0.0145, a\u001b[A\n",
      "Epoch 15: 100%|█| 40/40 [00:02<00:00, 18.26it/s, loss=0.0127, val_loss=0.0137, a\u001b[A\n",
      "Epoch 16:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.0121, val_loss=0.0137, a\u001b[A\n",
      "Epoch 16:  60%|▌| 24/40 [00:01<00:01, 12.22it/s, loss=0.0121, val_loss=0.0137, a\n",
      "Epoch 16:  90%|▉| 36/40 [00:02<00:00, 17.14it/s, loss=0.0121, val_loss=0.0137, a\u001b[A\n",
      "Epoch 16: 100%|█| 40/40 [00:02<00:00, 18.24it/s, loss=0.0121, val_loss=0.013, av\u001b[A\n",
      "Epoch 17:  50%|▌| 20/40 [00:01<00:01, 10.08it/s, loss=0.0116, val_loss=0.013, av\u001b[A\n",
      "Epoch 17:  60%|▌| 24/40 [00:02<00:01, 11.83it/s, loss=0.0116, val_loss=0.013, av\n",
      "Epoch 17:  90%|▉| 36/40 [00:02<00:00, 16.64it/s, loss=0.0116, val_loss=0.013, av\u001b[A\n",
      "Epoch 17: 100%|█| 40/40 [00:02<00:00, 17.82it/s, loss=0.0116, val_loss=0.0123, a\u001b[A\n",
      "Epoch 18:  50%|▌| 20/40 [00:02<00:02,  9.98it/s, loss=0.0111, val_loss=0.0123, a\u001b[A\n",
      "Epoch 18:  60%|▌| 24/40 [00:02<00:01, 11.83it/s, loss=0.0111, val_loss=0.0123, a\n",
      "Epoch 18: 100%|█| 40/40 [00:02<00:00, 17.73it/s, loss=0.0111, val_loss=0.0117, a\u001b[A\n",
      "Epoch 19:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.0106, val_loss=0.0117, a\u001b[A\n",
      "Epoch 19:  60%|▌| 24/40 [00:01<00:01, 12.26it/s, loss=0.0106, val_loss=0.0117, a\n",
      "Epoch 19:  90%|▉| 36/40 [00:02<00:00, 17.23it/s, loss=0.0106, val_loss=0.0117, a\u001b[A\n",
      "Epoch 19: 100%|█| 40/40 [00:02<00:00, 18.35it/s, loss=0.0106, val_loss=0.0112, a\u001b[A\n",
      "Epoch 20:  50%|▌| 20/40 [00:01<00:01, 10.43it/s, loss=0.0102, val_loss=0.0112, a\u001b[A\n",
      "Epoch 20:  60%|▌| 24/40 [00:01<00:01, 12.26it/s, loss=0.0102, val_loss=0.0112, a\n",
      "Epoch 20:  90%|▉| 36/40 [00:02<00:00, 17.23it/s, loss=0.0102, val_loss=0.0112, a\u001b[A\n",
      "Epoch 20: 100%|█| 40/40 [00:02<00:00, 18.35it/s, loss=0.0102, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21:  50%|▌| 20/40 [00:01<00:01, 10.37it/s, loss=0.0098, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21:  60%|▌| 24/40 [00:01<00:01, 12.20it/s, loss=0.0098, val_loss=0.0107, a\n",
      "Epoch 21:  90%|▉| 36/40 [00:02<00:00, 17.19it/s, loss=0.0098, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21: 100%|█| 40/40 [00:02<00:00, 18.33it/s, loss=0.0098, val_loss=0.0103, a\u001b[A\n",
      "Epoch 22:  50%|▌| 20/40 [00:01<00:01, 10.68it/s, loss=0.00945, val_loss=0.0103, \u001b[A\n",
      "Epoch 22:  60%|▌| 24/40 [00:01<00:01, 12.71it/s, loss=0.00945, val_loss=0.0103, \n",
      "Epoch 22:  90%|▉| 36/40 [00:02<00:00, 17.74it/s, loss=0.00945, val_loss=0.0103, \u001b[A\n",
      "Epoch 22: 100%|█| 40/40 [00:02<00:00, 18.84it/s, loss=0.00945, val_loss=0.00989,\u001b[A\n",
      "Epoch 23:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.00912, val_loss=0.00989,\u001b[A\n",
      "Epoch 23:  60%|▌| 24/40 [00:01<00:01, 12.35it/s, loss=0.00912, val_loss=0.00989,\n",
      "Epoch 23:  90%|▉| 36/40 [00:02<00:00, 17.41it/s, loss=0.00912, val_loss=0.00989,\u001b[A\n",
      "Epoch 23: 100%|█| 40/40 [00:02<00:00, 18.56it/s, loss=0.00912, val_loss=0.00953,\u001b[A\n",
      "Epoch 24:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00882, val_loss=0.00953,\u001b[A\n",
      "Epoch 24:  60%|▌| 24/40 [00:01<00:01, 12.28it/s, loss=0.00882, val_loss=0.00953,\n",
      "Epoch 24:  90%|▉| 36/40 [00:02<00:00, 17.26it/s, loss=0.00882, val_loss=0.00953,\u001b[A\n",
      "Epoch 24: 100%|█| 40/40 [00:02<00:00, 18.41it/s, loss=0.00882, val_loss=0.00921,\u001b[A\n",
      "Epoch 25:  50%|▌| 20/40 [00:01<00:01, 10.73it/s, loss=0.00853, val_loss=0.00921,\u001b[A\n",
      "Epoch 25:  60%|▌| 24/40 [00:01<00:01, 12.57it/s, loss=0.00853, val_loss=0.00921,\n",
      "Epoch 25:  90%|▉| 36/40 [00:02<00:00, 17.51it/s, loss=0.00853, val_loss=0.00921,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|█| 40/40 [00:02<00:00, 18.75it/s, loss=0.00853, val_loss=0.00892,\u001b[A\n",
      "Epoch 26:  50%|▌| 20/40 [00:01<00:01, 10.42it/s, loss=0.00827, val_loss=0.00892,\u001b[A\n",
      "Epoch 26:  60%|▌| 24/40 [00:01<00:01, 12.33it/s, loss=0.00827, val_loss=0.00892,\n",
      "Epoch 26: 100%|█| 40/40 [00:02<00:00, 18.45it/s, loss=0.00827, val_loss=0.00864,\u001b[A\n",
      "Epoch 27:  50%|▌| 20/40 [00:01<00:01, 10.27it/s, loss=0.00802, val_loss=0.00864,\u001b[A\n",
      "Epoch 27:  60%|▌| 24/40 [00:01<00:01, 12.06it/s, loss=0.00802, val_loss=0.00864,\n",
      "Epoch 27:  90%|▉| 36/40 [00:02<00:00, 17.02it/s, loss=0.00802, val_loss=0.00864,\u001b[A\n",
      "Epoch 27: 100%|█| 40/40 [00:02<00:00, 18.19it/s, loss=0.00802, val_loss=0.0084, \u001b[A\n",
      "Epoch 28:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.00779, val_loss=0.0084, \u001b[A\n",
      "Epoch 28:  60%|▌| 24/40 [00:01<00:01, 12.34it/s, loss=0.00779, val_loss=0.0084, \n",
      "Epoch 28:  90%|▉| 36/40 [00:02<00:00, 17.26it/s, loss=0.00779, val_loss=0.0084, \u001b[A\n",
      "Epoch 28: 100%|█| 40/40 [00:02<00:00, 18.49it/s, loss=0.00779, val_loss=0.00818,\u001b[A\n",
      "Epoch 29:  50%|▌| 20/40 [00:02<00:02,  9.92it/s, loss=0.00757, val_loss=0.00818,\u001b[A\n",
      "Epoch 29:  60%|▌| 24/40 [00:02<00:01, 11.77it/s, loss=0.00757, val_loss=0.00818,\n",
      "Epoch 29:  90%|▉| 36/40 [00:02<00:00, 16.57it/s, loss=0.00757, val_loss=0.00818,\u001b[A\n",
      "Epoch 29: 100%|█| 40/40 [00:02<00:00, 17.64it/s, loss=0.00757, val_loss=0.00797,\u001b[A\n",
      "Epoch 30:  50%|▌| 20/40 [00:01<00:01, 10.80it/s, loss=0.00737, val_loss=0.00797,\u001b[A\n",
      "Epoch 30:  60%|▌| 24/40 [00:01<00:01, 12.78it/s, loss=0.00737, val_loss=0.00797,\n",
      "Epoch 30:  90%|▉| 36/40 [00:02<00:00, 17.95it/s, loss=0.00737, val_loss=0.00797,\u001b[A\n",
      "Epoch 30: 100%|█| 40/40 [00:02<00:00, 19.04it/s, loss=0.00737, val_loss=0.00777,\u001b[A\n",
      "Epoch 31:  50%|▌| 20/40 [00:01<00:01, 10.61it/s, loss=0.00718, val_loss=0.00777,\u001b[A\n",
      "Epoch 31:  60%|▌| 24/40 [00:01<00:01, 12.58it/s, loss=0.00718, val_loss=0.00777,\n",
      "Epoch 31:  90%|▉| 36/40 [00:02<00:00, 17.67it/s, loss=0.00718, val_loss=0.00777,\u001b[A\n",
      "Epoch 31: 100%|█| 40/40 [00:02<00:00, 18.73it/s, loss=0.00718, val_loss=0.00759,\u001b[A\n",
      "Epoch 32:  50%|▌| 20/40 [00:01<00:01, 10.69it/s, loss=0.007, val_loss=0.00759, a\u001b[A\n",
      "Epoch 32:  60%|▌| 24/40 [00:01<00:01, 12.59it/s, loss=0.007, val_loss=0.00759, a\n",
      "Epoch 32:  90%|▉| 36/40 [00:02<00:00, 17.65it/s, loss=0.007, val_loss=0.00759, a\u001b[A\n",
      "Epoch 32: 100%|█| 40/40 [00:02<00:00, 18.79it/s, loss=0.007, val_loss=0.00742, a\u001b[A\n",
      "Epoch 33:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00683, val_loss=0.00742,\u001b[A\n",
      "Epoch 33:  60%|▌| 24/40 [00:01<00:01, 12.24it/s, loss=0.00683, val_loss=0.00742,\n",
      "Epoch 33:  90%|▉| 36/40 [00:02<00:00, 17.15it/s, loss=0.00683, val_loss=0.00742,\u001b[A\n",
      "Epoch 33: 100%|█| 40/40 [00:02<00:00, 18.40it/s, loss=0.00683, val_loss=0.00725,\u001b[A\n",
      "Epoch 34:  50%|▌| 20/40 [00:01<00:01, 10.56it/s, loss=0.00666, val_loss=0.00725,\u001b[A\n",
      "Epoch 34:  60%|▌| 24/40 [00:01<00:01, 12.52it/s, loss=0.00666, val_loss=0.00725,\n",
      "Epoch 34:  90%|▉| 36/40 [00:02<00:00, 17.57it/s, loss=0.00666, val_loss=0.00725,\u001b[A\n",
      "Epoch 34: 100%|█| 40/40 [00:02<00:00, 18.63it/s, loss=0.00666, val_loss=0.00707,\u001b[A\n",
      "Epoch 35:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00651, val_loss=0.00707,\u001b[A\n",
      "Epoch 35:  60%|▌| 24/40 [00:01<00:01, 12.42it/s, loss=0.00651, val_loss=0.00707,\n",
      "Epoch 35:  90%|▉| 36/40 [00:02<00:00, 17.43it/s, loss=0.00651, val_loss=0.00707,\u001b[A\n",
      "Epoch 35: 100%|█| 40/40 [00:02<00:00, 18.51it/s, loss=0.00651, val_loss=0.0069, \u001b[A\n",
      "Epoch 36:  50%|▌| 20/40 [00:01<00:01, 10.70it/s, loss=0.00637, val_loss=0.0069, \u001b[A\n",
      "Epoch 36:  60%|▌| 24/40 [00:01<00:01, 12.61it/s, loss=0.00637, val_loss=0.0069, \n",
      "Epoch 36:  90%|▉| 36/40 [00:02<00:00, 17.68it/s, loss=0.00637, val_loss=0.0069, \u001b[A\n",
      "Epoch 36: 100%|█| 40/40 [00:02<00:00, 18.86it/s, loss=0.00637, val_loss=0.00673,\u001b[A\n",
      "Epoch 37:  50%|▌| 20/40 [00:01<00:01, 10.36it/s, loss=0.00623, val_loss=0.00673,\u001b[A\n",
      "Epoch 37:  60%|▌| 24/40 [00:01<00:01, 12.13it/s, loss=0.00623, val_loss=0.00673,\n",
      "Epoch 37:  90%|▉| 36/40 [00:02<00:00, 17.05it/s, loss=0.00623, val_loss=0.00673,\u001b[A\n",
      "Epoch 37: 100%|█| 40/40 [00:02<00:00, 18.22it/s, loss=0.00623, val_loss=0.00656,\u001b[A\n",
      "Epoch 38:  50%|▌| 20/40 [00:01<00:01, 10.36it/s, loss=0.0061, val_loss=0.00656, \u001b[A\n",
      "Epoch 38:  60%|▌| 24/40 [00:01<00:01, 12.01it/s, loss=0.0061, val_loss=0.00656, \n",
      "Epoch 38:  90%|▉| 36/40 [00:02<00:00, 16.95it/s, loss=0.0061, val_loss=0.00656, \u001b[A\n",
      "Epoch 38: 100%|█| 40/40 [00:02<00:00, 18.12it/s, loss=0.0061, val_loss=0.0064, a\u001b[A\n",
      "Epoch 39:  50%|▌| 20/40 [00:01<00:01, 10.49it/s, loss=0.00598, val_loss=0.0064, \u001b[A\n",
      "Epoch 39:  60%|▌| 24/40 [00:01<00:01, 12.40it/s, loss=0.00598, val_loss=0.0064, \n",
      "Validating:  40%|████████████▊                   | 8/20 [00:00<00:00, 75.38it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.21it/s, loss=0.00598, val_loss=0.00624,\u001b[A\n",
      "Epoch 39: 100%|█| 40/40 [00:02<00:00, 18.05it/s, loss=0.00598, val_loss=0.00624,\u001b[A\n",
      "Sizes of clusters: 385, 779, 140, 506, 190\n",
      "\n",
      "preds: [3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 3 1 1 1 1\n",
      " 3 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 1 1 1 1 3 3 1 1 1 1 1 1\n",
      " 1 3 3 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1\n",
      " 3 1 1 1 1 1 1 3 1 3 1 1 1 3 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 3 1 1 1 3 3\n",
      " 1 3 1 1 1 1 3 3 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1\n",
      " 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 1 3 1 3 1 1 1 1 1 3 3 1 1\n",
      " 1 1 1 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 1 1 1 3 1 1 1 1 3 3 1 1\n",
      " 1 1 1 3 1 1 1 1 1 1 3 1 1 3 1 1 1 1 1 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1 1 3 1\n",
      " 1 1 1 1 3 1 3 1 1 3 1 1 3 1 3 1 1 1 3 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 3 1 1 1 3 1 1 3 1 1 1 1 1 1 1 3 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1\n",
      " 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 3 1 1 1 1 3 1 3 0 0 4 0 0 0 0\n",
      " 0 0 0 0 4 4 0 0 0 0 0 0 3 0 0 0 0 0 0 4 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 2 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0\n",
      " 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 3 0 4 4 0\n",
      " 3 0 0 4 0 0 0 0 3 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 4 0 0 0 0\n",
      " 0 0 0 2 0 2 0 4 2 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 4 0 0 0 0 4 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 3 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 4 0 0 0 0 0 4\n",
      " 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 4\n",
      " 0 0 4 0 0 0 0 4 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 3 0 4 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 4 0 0 3 3 3 0 3 3 1 3 3 3 3 2 1\n",
      " 1 3 3 1 1 3 1 1 1 2 3 1 3 1 3 3 3 3 1 3 3 1 1 3 0 3 1 2 3 1 1 1 1 1 1 3 3\n",
      " 1 1 1 3 3 1 3 2 1 1 1 3 3 2 3 3 3 1 3 1 3 3 1 1 1 1 1 3 3 3 3 2 1 1 3 1 1\n",
      " 3 1 3 3 1 1 3 2 3 1 3 0 3 3 1 1 1 3 2 1 1 1 3 1 3 3 3 3 3 2 1 1 4 3 3 3 1\n",
      " 1 1 3 3 3 3 1 2 1 2 3 1 3 4 2 1 1 1 3 1 1 3 3 1 1 1 1 1 1 1 3 1 3 2 1 1 3\n",
      " 3 1 1 1 1 1 1 1 1 1 1 1 3 2 1 1 1 3 1 1 3 2 1 1 1 1 3 1 1 0 1 1 3 1 2 3 3\n",
      " 1 1 1 0 1 3 3 3 1 1 3 3 1 0 3 3 2 1 1 1 3 1 1 3 1 1 1 3 3 1 3 1 1 1 1 3 0\n",
      " 1 0 1 1 3 1 3 2 3 1 3 3 1 2 3 2 3 1 0 3 3 1 4 2 3 3 1 1 3 1 3 2 2 2 3 1 3\n",
      " 2 1 1 3 1 2 1 1 1 1 3 1 1 3 1 3 1 1 2 1 1 2 0 3 3 2 2 1 0 1 3 1 1 1 1 1 3\n",
      " 2 3 1 4 3 3 1 3 2 3 3 1 3 3 0 1 1 1 3 3 3 1 1 3 1 3 1 3 1 3 1 1 1 3 1 1 1\n",
      " 3 2 3 1 3 1 1 3 1 0 1 3 3 0 1 1 3 1 1 1 1 1 3 3 3 1 2 0 1 2 1 3 3 1 3 3 3\n",
      " 1 1 1 3 1 3 2 1 1 3 1 1 1 2 4 1 3 3 3 3 1 1 1 1 1 1 3 1 3 3 1 3 1 3 3 3 1\n",
      " 3 1 1 1 1 1 3 3 1 1 1 3 3 1 1 3 1 3 1 3 1 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 3\n",
      " 1 1 1 3 1 1 3 3 1 1 3 1 3 1 1 3 1 3 1 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 3\n",
      " 1 1 1 1 3 3 1 2 1 3 1 1 1 1 3 1 1 1 3 3 3 3 1 1 1 3 3 1 1 1 1 1 3 1 1 1 3\n",
      " 3 3 1 1 3 3 3 1 1 3 1 3 1 3 1 1 3 1 3 1 1 3 2 1 1 3 1 1 3 3 3 1 1 1 1 3 1\n",
      " 1 1 3 3 2 1 1 1 3 3 1 1 3 3 1 3 1 1 1 1 1 1 3 3 1 1 1 1 3 1 1 1 1 1 1 1 3\n",
      " 1 1 1 1 3 1 3 3 3 3 3 1 1 1 3 1 1 1 1 1 1 1 1 3 1 1 3 1 3 1 1 1 1 1 1 2 3\n",
      " 3 1 1 1 3 3 3 1 1 1 1 3 3 1 3 3 1 1 3 1 1 1 1 3 1 1 1 1 1 1 3 1 1 1 2 1 3\n",
      " 3 1 3 1 1 3 3 1 1 3 1 1 3 1 1 3 3 2 3 3 1 1 1 1 1 1 1 1 2 1 1 1 3 3 1 1 1\n",
      " 1 1 1 3 3 3 1 1 1 1 1 3 3 1 1 1 1 1 1 1 3 3 1 1 1 1 1 3 1 3 2 3 1 1 3 2 3\n",
      " 1 1 3 3 3 1 3 1 1 1 1 1 3 1 3 1 1 1 1 1 1 3 3 1 1 1 3 3 3 1 3 1 3 3 1 1 1\n",
      " 1 1 3 1 1 3 1 3 3 4 4 4 4 2 4 3 3 2 3 4 4 4 4 3 1 3 3 4 4 2 2 4 2 2 3 4 3\n",
      " 4 4 2 4 2 1 4 4 2 4 3 4 4 3 4 3 4 2 0 4 4 3 3 4 3 3 4 2 4 3 3 3 3 4 2 2 0\n",
      " 0 2 4 2 3 4 2 2 3 4 0 2 3 2 4 2 3 4 4 0 4 3 4 2 2 3 2 4 3 2 3 4 4 2 4 3 4\n",
      " 0 2 0 4 4 4 3 3 4 4 3 2 2 3 4 3 2 3 2 4 1 0 0 2 3 4 4 4 4 3 3 4 4 3 4 4 0\n",
      " 3 2 3 2 2 2 0 4 0 0 0 3 3 3 4 2 3 2 3 3 2 3 4 3 3 0 1 3 3 1 4 2 3 2 2 3 2\n",
      " 0 4 0 4 4 2 2 2 4 3 4 4 3 3 3 3 3 3 3 0 3 4 4 2 4 4 3 4 4 3 2 4 4 3 4 3 3\n",
      " 2 3 2 4 2 4 0 0 4 4 0 4 2 3 2 2 4 2 3 3 4 2 4 3 4 4 0 4 3 2 1 3 4 0 2 2 4\n",
      " 4 3 3 0 4 3 2 2 4 3 4 2 4 3 3 4 2 2 3 4 0 2 1 4 3 4 4 2 4 4 4 4 1 3 4 4 4\n",
      " 4 2 2 2 4 3 3 4 3 3 2 3 2 3 4 0 3 3 4 3 2 2 2 3 4 3 3 3 3 4 4 3 4 2 2 4 4\n",
      " 1 3 2 4 3 4 3 2 4 4 4 3 4 3 2 4 3 4 4 2 4 3 2 1 4 2 3 3 4 3 0 3 3 3 2 3 1\n",
      " 3 3 4 4 3 4 2 3 4 3 4 0 3 2 4 2 2 3 3 3 3 4 3 3 4 3 2 4 4 3 4 2 4 4 4 4 4\n",
      " 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consistency: 0.4601\n",
      "Purity: 0.5548+-0.02778056874867757\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K5_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 11.44it/s, loss=328, val_loss=0.0453, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 20.12it/s, loss=328, val_loss=1.01, avg_val\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=170, val_loss=1.01, avg_val_\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=170, val_loss=5.49, avg_val\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=15.6, val_loss=5.49, avg_val\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=15.6, val_loss=3.62, avg_va\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 11.73it/s, loss=3.87, val_loss=3.62, avg_val\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 20.57it/s, loss=3.87, val_loss=1.71, avg_va\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=1.44, val_loss=1.71, avg_val\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=1.44, val_loss=0.77, avg_va\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.703, val_loss=0.77, avg_va\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.703, val_loss=0.256, avg_\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 11.57it/s, loss=0.326, val_loss=0.256, avg_v\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 20.32it/s, loss=0.326, val_loss=0.103, avg_\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.146, val_loss=0.103, avg_v\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.146, val_loss=0.0687, avg\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0821, val_loss=0.0687, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0821, val_loss=0.0421, av\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0501, val_loss=0.0421, avg\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0501, val_loss=0.0286, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0333, val_loss=0.0286, av\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0333, val_loss=0.0239, a\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0257, val_loss=0.0239, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.0257, val_loss=0.0211, a\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 11.60it/s, loss=0.0216, val_loss=0.0211, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=0.0216, val_loss=0.0191, a\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0192, val_loss=0.0191, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0192, val_loss=0.0177, a\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0175, val_loss=0.0177, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.0175, val_loss=0.0165, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0164, val_loss=0.0165, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.0164, val_loss=0.0156, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0155, val_loss=0.0156, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0155, val_loss=0.0149, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0147, val_loss=0.0149, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0147, val_loss=0.0143, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.0141, val_loss=0.0143, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 20.34it/s, loss=0.0141, val_loss=0.0138, a\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0136, val_loss=0.0138, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0136, val_loss=0.0133, a\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0131, val_loss=0.0133, av\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0131, val_loss=0.0129, a\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0127, val_loss=0.0129, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0127, val_loss=0.0125, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0123, val_loss=0.0125, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0123, val_loss=0.0122, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.012, val_loss=0.0122, avg\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.012, val_loss=0.0119, av\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 11.61it/s, loss=0.0116, val_loss=0.0119, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 20.38it/s, loss=0.0116, val_loss=0.0116, a\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0113, val_loss=0.0116, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.0113, val_loss=0.0113, a\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0111, val_loss=0.0113, av\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 20.56it/s, loss=0.0111, val_loss=0.0111, a\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0108, val_loss=0.0111, av\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0108, val_loss=0.0108, a\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0106, val_loss=0.0108, av\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0106, val_loss=0.0106, a\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0104, val_loss=0.0106, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0104, val_loss=0.0104, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0101, val_loss=0.0104, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0101, val_loss=0.0102, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.00994, val_loss=0.0102, a\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 20.35it/s, loss=0.00994, val_loss=0.00999,\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00975, val_loss=0.00999, \n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00975, val_loss=0.00981,\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.00957, val_loss=0.00981, \n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.00957, val_loss=0.00963,\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0094, val_loss=0.00963, a\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0094, val_loss=0.00946, \n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00924, val_loss=0.00946, \n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00924, val_loss=0.00929,\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 11.73it/s, loss=0.00908, val_loss=0.00929, \n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.00908, val_loss=0.00914,\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 11.61it/s, loss=0.00893, val_loss=0.00914, \n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 20.37it/s, loss=0.00893, val_loss=0.00899,\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00878, val_loss=0.00899, \n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00878, val_loss=0.00884,\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00864, val_loss=0.00884, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00864, val_loss=0.0087, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.41it/s, loss=0.00864, val_loss=0.0087, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of clusters: 325, 475\n",
      "\n",
      "preds: [0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0\n",
      " 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5837\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=234, val_loss=0.0519, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=234, val_loss=0.308, avg_va\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 11.74it/s, loss=122, val_loss=0.308, avg_val\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 20.57it/s, loss=122, val_loss=2.26, avg_val\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=13.4, val_loss=2.26, avg_val\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=13.4, val_loss=0.884, avg_v\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=3.56, val_loss=0.884, avg_va\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=3.56, val_loss=0.691, avg_v\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=1.31, val_loss=0.691, avg_va\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=1.31, val_loss=0.395, avg_v\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 11.73it/s, loss=0.573, val_loss=0.395, avg_v\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 20.56it/s, loss=0.573, val_loss=0.281, avg_\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 11.60it/s, loss=0.308, val_loss=0.281, avg_v\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=0.308, val_loss=0.124, avg_\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.163, val_loss=0.124, avg_v\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 20.55it/s, loss=0.163, val_loss=0.0669, avg\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0864, val_loss=0.0669, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0864, val_loss=0.0552, av\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0583, val_loss=0.0552, avg\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0583, val_loss=0.0447, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0434, val_loss=0.0447, av\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0434, val_loss=0.0368, a\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0344, val_loss=0.0368, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0344, val_loss=0.0312, a\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 11.61it/s, loss=0.0291, val_loss=0.0312, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 20.35it/s, loss=0.0291, val_loss=0.0279, a\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0257, val_loss=0.0279, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0257, val_loss=0.0254, a\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0233, val_loss=0.0254, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0233, val_loss=0.0234, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.0215, val_loss=0.0234, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0215, val_loss=0.0218, a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.02, val_loss=0.0218, avg_\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.02, val_loss=0.0204, avg\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0187, val_loss=0.0204, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0187, val_loss=0.0192, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 11.60it/s, loss=0.0177, val_loss=0.0192, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=0.0177, val_loss=0.0181, a\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 11.53it/s, loss=0.0167, val_loss=0.0181, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 20.24it/s, loss=0.0167, val_loss=0.0171, a\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0159, val_loss=0.0171, av\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0159, val_loss=0.0162, a\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0152, val_loss=0.0162, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0152, val_loss=0.0154, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0145, val_loss=0.0154, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0145, val_loss=0.0147, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.0139, val_loss=0.0147, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.0139, val_loss=0.0141, a\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.0134, val_loss=0.0141, av\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 20.34it/s, loss=0.0134, val_loss=0.0135, a\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0129, val_loss=0.0135, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0129, val_loss=0.013, av\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0125, val_loss=0.013, avg\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0125, val_loss=0.0126, a\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0121, val_loss=0.0126, av\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0121, val_loss=0.0122, a\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0118, val_loss=0.0122, av\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0118, val_loss=0.0118, a\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0114, val_loss=0.0118, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0114, val_loss=0.0114, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0112, val_loss=0.0114, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0112, val_loss=0.0111, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 11.60it/s, loss=0.0109, val_loss=0.0111, av\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=0.0109, val_loss=0.0108, a\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0107, val_loss=0.0108, av\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0107, val_loss=0.0106, a\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0104, val_loss=0.0106, av\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0104, val_loss=0.0104, a\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0102, val_loss=0.0104, av\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0102, val_loss=0.0102, a\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.01, val_loss=0.0102, avg_\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.01, val_loss=0.00998, av\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00988, val_loss=0.00998, \n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.00988, val_loss=0.00982,\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 11.58it/s, loss=0.00973, val_loss=0.00982, \n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 20.32it/s, loss=0.00973, val_loss=0.00967,\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.00959, val_loss=0.00967, \n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 20.47it/s, loss=0.00959, val_loss=0.00954,\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00946, val_loss=0.00954, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00946, val_loss=0.00942,\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.44it/s, loss=0.00946, val_loss=0.00942,\n",
      "Sizes of clusters: 364, 436\n",
      "\n",
      "preds: [1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0\n",
      " 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1\n",
      " 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0\n",
      " 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 1 1\n",
      " 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1\n",
      " 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0\n",
      " 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1\n",
      " 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5375\n",
      "============= RUN 3 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=287, val_loss=0.0684, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=287, val_loss=0.197, avg_va\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=149, val_loss=0.197, avg_val\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=149, val_loss=24.5, avg_val\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=13.8, val_loss=24.5, avg_val\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 20.47it/s, loss=13.8, val_loss=30.6, avg_va\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=3.15, val_loss=30.6, avg_val\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=3.15, val_loss=31.3, avg_va\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=1.23, val_loss=31.3, avg_val\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=1.23, val_loss=23.9, avg_va\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.519, val_loss=23.9, avg_va\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.519, val_loss=5.39, avg_v\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 11.56it/s, loss=0.25, val_loss=5.39, avg_val\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 20.29it/s, loss=0.25, val_loss=2.13, avg_va\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.127, val_loss=2.13, avg_va\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.127, val_loss=0.612, avg_\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 11.66it/s, loss=0.0702, val_loss=0.612, avg_\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 20.44it/s, loss=0.0702, val_loss=0.186, avg\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0471, val_loss=0.186, avg_\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0471, val_loss=0.0741, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.0346, val_loss=0.0741, av\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 20.47it/s, loss=0.0346, val_loss=0.0448, a\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0279, val_loss=0.0448, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0279, val_loss=0.0336, a\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.024, val_loss=0.0336, avg\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 20.35it/s, loss=0.024, val_loss=0.0288, av\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0214, val_loss=0.0288, av\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0214, val_loss=0.0258, a\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0196, val_loss=0.0258, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0196, val_loss=0.0231, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0182, val_loss=0.0231, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0182, val_loss=0.0211, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0171, val_loss=0.0211, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.0171, val_loss=0.0197, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0162, val_loss=0.0197, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.0162, val_loss=0.0186, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 11.56it/s, loss=0.0153, val_loss=0.0186, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 20.29it/s, loss=0.0153, val_loss=0.0177, a\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0146, val_loss=0.0177, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0146, val_loss=0.0168, a\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 11.66it/s, loss=0.014, val_loss=0.0168, avg\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 20.46it/s, loss=0.014, val_loss=0.0159, av\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0134, val_loss=0.0159, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0134, val_loss=0.0152, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.0129, val_loss=0.0152, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0129, val_loss=0.0145, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0125, val_loss=0.0145, av\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0125, val_loss=0.014, av\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.0121, val_loss=0.014, avg\n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 20.33it/s, loss=0.0121, val_loss=0.0135, a\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0117, val_loss=0.0135, av\n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0117, val_loss=0.0131, a\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0114, val_loss=0.0131, av\n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0114, val_loss=0.0127, a\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0111, val_loss=0.0127, av\n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.0111, val_loss=0.0123, a\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0108, val_loss=0.0123, av\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0108, val_loss=0.0118, a\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0105, val_loss=0.0118, av\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.0105, val_loss=0.0115, a\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0103, val_loss=0.0115, av\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.0103, val_loss=0.0112, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.01, val_loss=0.0112, avg_\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 20.34it/s, loss=0.01, val_loss=0.0109, avg\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00981, val_loss=0.0109, a\n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00981, val_loss=0.0107, \n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0096, val_loss=0.0107, av\n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0096, val_loss=0.0105, a\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00941, val_loss=0.0105, a\n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00941, val_loss=0.0103, \n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00923, val_loss=0.0103, a\n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00923, val_loss=0.0101, \n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00906, val_loss=0.0101, a\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00906, val_loss=0.00988,\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.0089, val_loss=0.00988, a\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 20.35it/s, loss=0.0089, val_loss=0.00965, \n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 11.63it/s, loss=0.00874, val_loss=0.00965, \n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=0.00874, val_loss=0.00944,\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 11.66it/s, loss=0.0086, val_loss=0.00944, a\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.42it/s, loss=0.0086, val_loss=0.00926, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.31it/s, loss=0.0086, val_loss=0.00926, \n",
      "Sizes of clusters: 303, 497\n",
      "\n",
      "preds: [0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1\n",
      " 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1\n",
      " 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0\n",
      " 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1\n",
      " 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n",
      " 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1\n",
      " 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.6512\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 11.67it/s, loss=215, val_loss=0.0517, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 20.46it/s, loss=215, val_loss=1.86, avg_val\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=110, val_loss=1.86, avg_val_\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=110, val_loss=0.893, avg_va\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=10.2, val_loss=0.893, avg_va\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=10.2, val_loss=4.92, avg_va\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=1.73, val_loss=4.92, avg_val\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=1.73, val_loss=0.679, avg_v\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 11.67it/s, loss=0.699, val_loss=0.679, avg_v\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 20.45it/s, loss=0.699, val_loss=0.962, avg_\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.32, val_loss=0.962, avg_va\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.32, val_loss=0.359, avg_v\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 11.58it/s, loss=0.157, val_loss=0.359, avg_v\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 20.31it/s, loss=0.157, val_loss=0.153, avg_\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0802, val_loss=0.153, avg_\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0802, val_loss=0.0695, av\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0463, val_loss=0.0695, avg\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0463, val_loss=0.034, avg\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0308, val_loss=0.034, avg_\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.0308, val_loss=0.0248, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0228, val_loss=0.0248, av\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.0228, val_loss=0.0198, a\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 11.67it/s, loss=0.0189, val_loss=0.0198, av\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 20.47it/s, loss=0.0189, val_loss=0.0168, a\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 11.56it/s, loss=0.0164, val_loss=0.0168, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 20.29it/s, loss=0.0164, val_loss=0.0154, a\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.015, val_loss=0.0154, avg\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.015, val_loss=0.0144, av\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.014, val_loss=0.0144, avg\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.014, val_loss=0.0135, av\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0132, val_loss=0.0135, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0132, val_loss=0.0129, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0126, val_loss=0.0129, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.0126, val_loss=0.0123, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0121, val_loss=0.0123, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0121, val_loss=0.0118, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.0116, val_loss=0.0118, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 20.33it/s, loss=0.0116, val_loss=0.0114, a\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0112, val_loss=0.0114, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0112, val_loss=0.011, av\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0109, val_loss=0.011, avg\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0109, val_loss=0.0107, a\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0105, val_loss=0.0107, av\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.0105, val_loss=0.0104, a\n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0103, val_loss=0.0104, av\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0103, val_loss=0.0101, a\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00999, val_loss=0.0101, a\n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00999, val_loss=0.00987,\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.00975, val_loss=0.00987, \n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 20.32it/s, loss=0.00975, val_loss=0.00966,\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00952, val_loss=0.00966, \n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=0.00952, val_loss=0.00948,\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00932, val_loss=0.00948, \n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00932, val_loss=0.00931,\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00914, val_loss=0.00931, \n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00914, val_loss=0.00916,\n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00897, val_loss=0.00916, \n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00897, val_loss=0.00904,\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00882, val_loss=0.00904, \n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00882, val_loss=0.00894,\n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00868, val_loss=0.00894, \n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 20.48it/s, loss=0.00868, val_loss=0.00885,\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.00855, val_loss=0.00885, \n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 20.34it/s, loss=0.00855, val_loss=0.00878,\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00843, val_loss=0.00878, \n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00843, val_loss=0.00872,\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00832, val_loss=0.00872, \n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00832, val_loss=0.00867,\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00823, val_loss=0.00867, \n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00823, val_loss=0.00863,\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00813, val_loss=0.00863, \n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00813, val_loss=0.0086, \n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00805, val_loss=0.0086, a\n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00805, val_loss=0.00858,\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 11.59it/s, loss=0.00797, val_loss=0.00858, \n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 20.35it/s, loss=0.00797, val_loss=0.00854,\n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=0.0079, val_loss=0.00854, a\n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0079, val_loss=0.00847, \n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00783, val_loss=0.00847, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00783, val_loss=0.00838,\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.42it/s, loss=0.00783, val_loss=0.00838,\n",
      "Sizes of clusters: 519, 281\n",
      "\n",
      "preds: [1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0\n",
      " 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1\n",
      " 0 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.6987\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 8/16 [00:00<00:00, 11.68it/s, loss=234, val_loss=0.0606, avg_va\n",
      "Epoch 0: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=234, val_loss=1.66, avg_val\n",
      "Epoch 1:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=119, val_loss=1.66, avg_val_\n",
      "Epoch 1: 100%|█| 16/16 [00:00<00:00, 20.54it/s, loss=119, val_loss=31, avg_val_l\n",
      "Epoch 2:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=8.12, val_loss=31, avg_val_l\n",
      "Epoch 2: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=8.12, val_loss=48.3, avg_va\n",
      "Epoch 3:  50%|▌| 8/16 [00:00<00:00, 11.60it/s, loss=1.39, val_loss=48.3, avg_val\n",
      "Epoch 3: 100%|█| 16/16 [00:00<00:00, 20.36it/s, loss=1.39, val_loss=29.3, avg_va\n",
      "Epoch 4:  50%|▌| 8/16 [00:00<00:00, 11.66it/s, loss=0.601, val_loss=29.3, avg_va\n",
      "Epoch 4: 100%|█| 16/16 [00:00<00:00, 20.40it/s, loss=0.601, val_loss=16.3, avg_v\n",
      "Epoch 5:  50%|▌| 8/16 [00:00<00:00, 11.62it/s, loss=0.271, val_loss=16.3, avg_va\n",
      "Epoch 5: 100%|█| 16/16 [00:00<00:00, 20.37it/s, loss=0.271, val_loss=5.41, avg_v\n",
      "Epoch 6:  50%|▌| 8/16 [00:00<00:00, 11.57it/s, loss=0.13, val_loss=5.41, avg_val\n",
      "Epoch 6: 100%|█| 16/16 [00:00<00:00, 20.30it/s, loss=0.13, val_loss=1.64, avg_va\n",
      "Epoch 7:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0701, val_loss=1.64, avg_v\n",
      "Epoch 7: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0701, val_loss=0.416, avg\n",
      "Epoch 8:  50%|▌| 8/16 [00:00<00:00, 11.66it/s, loss=0.0425, val_loss=0.416, avg_\n",
      "Epoch 8: 100%|█| 16/16 [00:00<00:00, 20.43it/s, loss=0.0425, val_loss=0.115, avg\n",
      "Epoch 9:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0293, val_loss=0.115, avg_\n",
      "Epoch 9: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0293, val_loss=0.0447, av\n",
      "Epoch 10:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0226, val_loss=0.0447, av\n",
      "Epoch 10: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0226, val_loss=0.025, av\n",
      "Epoch 11:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.019, val_loss=0.025, avg_\n",
      "Epoch 11: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.019, val_loss=0.0198, av\n",
      "Epoch 12:  50%|▌| 8/16 [00:00<00:00, 11.57it/s, loss=0.0167, val_loss=0.0198, av\n",
      "Epoch 12: 100%|█| 16/16 [00:00<00:00, 20.31it/s, loss=0.0167, val_loss=0.018, av\n",
      "Epoch 13:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0153, val_loss=0.018, avg\n",
      "Epoch 13: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0153, val_loss=0.0166, a\n",
      "Epoch 14:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.0141, val_loss=0.0166, av\n",
      "Epoch 14: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.0141, val_loss=0.0154, a\n",
      "Epoch 15:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0132, val_loss=0.0154, av\n",
      "Epoch 15: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0132, val_loss=0.0145, a\n",
      "Epoch 16:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0124, val_loss=0.0145, av\n",
      "Epoch 16: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0124, val_loss=0.0137, a\n",
      "Epoch 17:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0118, val_loss=0.0137, av\n",
      "Epoch 17: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0118, val_loss=0.0129, a\n",
      "Epoch 18:  50%|▌| 8/16 [00:00<00:00, 11.57it/s, loss=0.0112, val_loss=0.0129, av\n",
      "Epoch 18: 100%|█| 16/16 [00:00<00:00, 20.31it/s, loss=0.0112, val_loss=0.0121, a\n",
      "Epoch 19:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0107, val_loss=0.0121, av\n",
      "Epoch 19: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0107, val_loss=0.0114, a\n",
      "Epoch 20:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.0102, val_loss=0.0114, av\n",
      "Epoch 20: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.0102, val_loss=0.0108, a\n",
      "Epoch 21:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00979, val_loss=0.0108, a\n",
      "Epoch 21: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00979, val_loss=0.0103, \n",
      "Epoch 22:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00941, val_loss=0.0103, a\n",
      "Epoch 22: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00941, val_loss=0.00987,\n",
      "Epoch 23:  50%|▌| 8/16 [00:00<00:00, 11.71it/s, loss=0.00907, val_loss=0.00987, \n",
      "Epoch 23: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00907, val_loss=0.00946,\n",
      "Epoch 24:  50%|▌| 8/16 [00:00<00:00, 11.58it/s, loss=0.00875, val_loss=0.00946, \n",
      "Epoch 24: 100%|█| 16/16 [00:00<00:00, 20.33it/s, loss=0.00875, val_loss=0.00906,\n",
      "Epoch 25:  50%|▌| 8/16 [00:00<00:00, 11.64it/s, loss=0.00846, val_loss=0.00906, \n",
      "Epoch 25: 100%|█| 16/16 [00:00<00:00, 20.42it/s, loss=0.00846, val_loss=0.00871,\n",
      "Epoch 26:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00819, val_loss=0.00871, \n",
      "Epoch 26: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00819, val_loss=0.00839,\n",
      "Epoch 27:  50%|▌| 8/16 [00:00<00:00, 11.72it/s, loss=0.00794, val_loss=0.00839, \n",
      "Epoch 27: 100%|█| 16/16 [00:00<00:00, 20.53it/s, loss=0.00794, val_loss=0.0081, \n",
      "Epoch 28:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00771, val_loss=0.0081, a\n",
      "Epoch 28: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.00771, val_loss=0.00785,\n",
      "Epoch 29:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.0075, val_loss=0.00785, a\n",
      "Epoch 29: 100%|█| 16/16 [00:00<00:00, 20.49it/s, loss=0.0075, val_loss=0.00761, \n",
      "Epoch 30:  50%|▌| 8/16 [00:00<00:00, 11.43it/s, loss=0.0073, val_loss=0.00761, a\n",
      "Epoch 30: 100%|█| 16/16 [00:00<00:00, 20.09it/s, loss=0.0073, val_loss=0.0074, a\n",
      "Epoch 31:  50%|▌| 8/16 [00:00<00:00, 11.58it/s, loss=0.00711, val_loss=0.0074, a\n",
      "Epoch 31: 100%|█| 16/16 [00:00<00:00, 20.33it/s, loss=0.00711, val_loss=0.00718,\n",
      "Epoch 32:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00694, val_loss=0.00718, \n",
      "Epoch 32: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00694, val_loss=0.00698,\n",
      "Epoch 33:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00677, val_loss=0.00698, \n",
      "Epoch 33: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00677, val_loss=0.00679,\n",
      "Epoch 34:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00662, val_loss=0.00679, \n",
      "Epoch 34: 100%|█| 16/16 [00:00<00:00, 20.52it/s, loss=0.00662, val_loss=0.00663,\n",
      "Epoch 35:  50%|▌| 8/16 [00:00<00:00, 11.69it/s, loss=0.00647, val_loss=0.00663, \n",
      "Epoch 35: 100%|█| 16/16 [00:00<00:00, 20.50it/s, loss=0.00647, val_loss=0.00648,\n",
      "Epoch 36:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00633, val_loss=0.00648, \n",
      "Epoch 36: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00633, val_loss=0.00632,\n",
      "Epoch 37:  50%|▌| 8/16 [00:00<00:00, 11.56it/s, loss=0.0062, val_loss=0.00632, a\n",
      "Epoch 37: 100%|█| 16/16 [00:00<00:00, 20.30it/s, loss=0.0062, val_loss=0.00618, \n",
      "Epoch 38:  50%|▌| 8/16 [00:00<00:00, 11.64it/s, loss=0.00608, val_loss=0.00618, \n",
      "Epoch 38: 100%|█| 16/16 [00:00<00:00, 20.40it/s, loss=0.00608, val_loss=0.00606,\n",
      "Epoch 39:  50%|▌| 8/16 [00:00<00:00, 11.70it/s, loss=0.00596, val_loss=0.00606, \n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.51it/s, loss=0.00596, val_loss=0.00595,\n",
      "Epoch 39: 100%|█| 16/16 [00:00<00:00, 20.41it/s, loss=0.00596, val_loss=0.00595,\n",
      "Sizes of clusters: 494, 306\n",
      "\n",
      "preds: [0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0\n",
      " 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\r\n",
      "\r\n",
      "Purity: 0.5625\r\n",
      "\r\n",
      "Consistency: 0.5485\r\n",
      "Purity: 0.60675+-0.05954305165172507\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K2_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 11.46it/s, loss=180, val_loss=0.0294, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 20.14it/s, loss=180, val_loss=4.17, avg_val\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=9.77, val_loss=4.17, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=9.77, val_loss=3.33, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 11.69it/s, loss=1.46, val_loss=3.33, avg_va\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 21.30it/s, loss=1.46, val_loss=3.33, avg_va\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 20.49it/s, loss=1.46, val_loss=0.526, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.452, val_loss=0.526, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.452, val_loss=0.333, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 11.60it/s, loss=0.159, val_loss=0.333, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 20.36it/s, loss=0.159, val_loss=0.12, avg_v\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0625, val_loss=0.12, avg_\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 21.37it/s, loss=0.0625, val_loss=0.12, avg_\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0625, val_loss=0.0478, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0354, val_loss=0.0478, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0354, val_loss=0.0332, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0269, val_loss=0.0332, av\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 21.35it/s, loss=0.0269, val_loss=0.0332, av\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 20.52it/s, loss=0.0269, val_loss=0.0282, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0232, val_loss=0.0282, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0232, val_loss=0.0259, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0211, val_loss=0.0259, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0211, val_loss=0.0247, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0197, val_loss=0.0247, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0197, val_loss=0.0234, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0185, val_loss=0.0234, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0185, val_loss=0.0218, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0175, val_loss=0.0218, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 20.42it/s, loss=0.0175, val_loss=0.0197, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 11.68it/s, loss=0.0165, val_loss=0.0197, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 20.48it/s, loss=0.0165, val_loss=0.0176, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0155, val_loss=0.0176, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 20.52it/s, loss=0.0155, val_loss=0.0162, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0147, val_loss=0.0162, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0147, val_loss=0.0154, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.014, val_loss=0.0154, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.014, val_loss=0.015, avg\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0134, val_loss=0.015, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0134, val_loss=0.0146, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=0.013, val_loss=0.0146, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.013, val_loss=0.0143, av\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=0.0126, val_loss=0.0143, a\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 21.40it/s, loss=0.0126, val_loss=0.0143, a\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.0126, val_loss=0.0138, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0122, val_loss=0.0138, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0122, val_loss=0.0133, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0118, val_loss=0.0133, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0118, val_loss=0.0128, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0115, val_loss=0.0128, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0115, val_loss=0.0123, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0111, val_loss=0.0123, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0111, val_loss=0.0118, a\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0108, val_loss=0.0118, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0108, val_loss=0.0114, a\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=0.0106, val_loss=0.0114, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0106, val_loss=0.0111, a\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0103, val_loss=0.0111, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0103, val_loss=0.0107, a\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0101, val_loss=0.0107, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0101, val_loss=0.0105, a\u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00984, val_loss=0.0105, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00984, val_loss=0.0103, \u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.00964, val_loss=0.0103, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.00964, val_loss=0.0101, \u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00946, val_loss=0.0101, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00946, val_loss=0.00992,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=0.00929, val_loss=0.00992,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00929, val_loss=0.00976,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=0.00913, val_loss=0.00976,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 20.60it/s, loss=0.00913, val_loss=0.00961,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.00898, val_loss=0.00961,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.00898, val_loss=0.00946,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00883, val_loss=0.00946,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00883, val_loss=0.00932,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00869, val_loss=0.00932,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00869, val_loss=0.00918,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00856, val_loss=0.00918,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00856, val_loss=0.00905,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.00843, val_loss=0.00905,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.00843, val_loss=0.00893,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00832, val_loss=0.00893,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00832, val_loss=0.00882,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00821, val_loss=0.00882,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00821, val_loss=0.00872,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.51it/s, loss=0.00821, val_loss=0.00872,\u001b[A\n",
      "Sizes of clusters: 543, 174, 483\n",
      "\n",
      "preds: [1 0 0 0 0 1 1 1 2 0 0 1 0 1 0 2 2 2 1 2 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      " 1 0 2 0 0 2 1 2 2 0 2 0 2 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 2 1 0 2 0 1 1 0 0 0 2 1 2 0 2 0 0 0 2 1 2 1 1 0 0 0 0 1 1 0 1\n",
      " 0 0 1 1 1 0 0 0 2 0 0 1 1 1 2 0 1 0 1 2 0 0 1 2 0 2 2 1 1 0 0 0 0 2 0 2 0\n",
      " 0 0 2 2 1 1 0 0 2 1 2 2 2 0 0 1 0 1 2 0 2 1 2 2 0 1 0 2 1 1 1 0 1 2 0 2 2\n",
      " 1 0 0 1 2 1 1 1 0 0 0 1 1 0 0 2 2 2 2 1 0 1 0 1 1 0 1 2 1 1 0 0 1 0 2 1 0\n",
      " 2 0 0 1 1 1 2 0 2 0 1 1 0 0 1 1 0 0 2 0 1 0 0 1 1 2 1 1 1 2 2 2 1 1 1 1 1\n",
      " 2 1 0 0 2 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 2 0 1 2 0 1 2 0 1 0 0 1 2 0\n",
      " 1 1 2 1 0 0 1 0 1 0 0 1 1 0 1 1 2 2 1 1 1 1 0 1 0 0 1 1 1 2 0 0 1 1 2 0 1\n",
      " 2 1 0 0 1 1 1 2 0 1 1 1 1 0 1 0 1 1 1 0 1 2 0 0 0 1 1 0 2 2 1 0 0 1 0 2 1\n",
      " 1 1 1 0 0 0 1 1 0 0 2 0 0 1 1 2 2 0 1 1 0 0 0 1 0 1 0 2 1 2 1 2 2 2 2 0 2\n",
      " 0 2 2 2 2 2 2 2 2 2 0 2 0 2 0 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 0 0 2 0 0 0\n",
      " 2 2 0 2 2 2 0 0 2 0 2 0 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 0 0 2 2 0 2 2 2 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 2 2 0\n",
      " 2 2 2 2 0 2 2 2 0 0 2 0 2 0 2 2 0 0 0 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0\n",
      " 2 2 0 2 2 0 2 0 0 2 2 2 2 0 2 0 2 2 2 2 1 0 2 0 2 2 2 0 0 0 2 2 2 2 0 2 0\n",
      " 2 2 0 2 2 0 0 0 0 0 2 2 0 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 0 0 0 2 2 2 2 0 2\n",
      " 2 2 2 2 0 2 0 0 2 2 2 2 2 0 2 2 0 0 2 0 2 0 0 2 2 2 0 0 0 2 2 2 2 2 2 0 0\n",
      " 0 0 2 2 0 0 0 2 2 0 2 2 2 2 2 0 2 0 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 0 0 2 0 2 2 0 0 0 1 2 2 2 0\n",
      " 2 2 2 2 2 2 2 0 0 0 1 2 2 0 2 2 0 0 0 0 2 2 2 2 0 2 0 2 2 2 2 0 2 2 0 2 2\n",
      " 2 0 2 0 2 2 2 2 2 2 0 0 2 0 0 2 2 2 2 2 2 2 0 0 0 0 2 0 0 0 2 0 0 2 0 0 0\n",
      " 0 2 0 0 0 2 0 2 0 0 0 2 0 2 2 0 2 0 0 0 0 0 2 2 0 2 0 0 2 2 2 0 0 2 0 1 0\n",
      " 0 0 0 0 2 2 0 0 0 2 0 2 0 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 2 0 2 0 0 2 0\n",
      " 0 0 1 0 0 0 2 0 0 0 0 0 0 1 2 0 0 2 0 0 2 2 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 2 2 2 0 2 2 0 2 0 0 0 0 2 0 0 0 0 0 0 2 0 2 0 0 0 0 0 2 0 0 2 2\n",
      " 0 2 0 0 2 0 0 0 2 2 0 2 2 0 2 2 0 0 2 0 2 0 2 2 0 2 2 2 0 0 0 2 0 0 2 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 2 2 2 2 0 2 0 0 2 0 0 0 2 2 0 0 0 0 2 2\n",
      " 0 0 2 0 2 0 0 0 0 0 2 0 0 0 2 2 0 0 2 0 0 0 2 0 0 2 0 0 2 0 0 0 2 2 0 0 2\n",
      " 0 0 0 0 2 0 0 0 0 2 2 2 2 0 0 0 2 0 0 2 0 0 0 0 0 0 0 2 2 0 0 2 2 0 2 0 2\n",
      " 0 0 0 0 2 2 2 0 0 0 0 0 1 2 2 2 0 0 0 0 0 2 0 2 2 2 0 0 2 1 2 0 0 0 0 2 0\n",
      " 2 2 1 0 2 0 0 2 0 2 0 2 0 2 0 2 2 0 2 0 2 2 0 0 0 0 2 0 0 0 0 0 2 0 2 0 2\n",
      " 0 2 2 0 2 0 2 0 0 0 0 0 0 2 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5750\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=142, val_loss=0.0459, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=142, val_loss=1.23, avg_val\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=9.16, val_loss=1.23, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=9.16, val_loss=4.37, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=1.03, val_loss=4.37, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=1.03, val_loss=1.05, avg_va\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.301, val_loss=1.05, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.301, val_loss=0.23, avg_v\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.117, val_loss=0.23, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 20.42it/s, loss=0.117, val_loss=0.0677, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.0597, val_loss=0.0677, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.53it/s, loss=0.0597, val_loss=0.0439, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.0386, val_loss=0.0439, av\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 21.32it/s, loss=0.0386, val_loss=0.0439, av\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 20.49it/s, loss=0.0386, val_loss=0.0342, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0293, val_loss=0.0342, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0293, val_loss=0.0263, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 11.60it/s, loss=0.0244, val_loss=0.0263, av\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 21.16it/s, loss=0.0244, val_loss=0.0263, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 20.36it/s, loss=0.0244, val_loss=0.022, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.0214, val_loss=0.022, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 20.53it/s, loss=0.0214, val_loss=0.0202, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0196, val_loss=0.0202, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0196, val_loss=0.0192, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 11.69it/s, loss=0.0181, val_loss=0.0192, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 20.51it/s, loss=0.0181, val_loss=0.0183, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.0169, val_loss=0.0183, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.0169, val_loss=0.0172, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0159, val_loss=0.0172, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0159, val_loss=0.0161, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0149, val_loss=0.0161, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0149, val_loss=0.0151, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.014, val_loss=0.0151, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.014, val_loss=0.0143, av\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 11.50it/s, loss=0.0132, val_loss=0.0143, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 20.21it/s, loss=0.0132, val_loss=0.0139, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0125, val_loss=0.0139, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0125, val_loss=0.0135, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0119, val_loss=0.0135, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0119, val_loss=0.013, av\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0113, val_loss=0.013, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0113, val_loss=0.0125, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0108, val_loss=0.0125, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0108, val_loss=0.0119, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0104, val_loss=0.0119, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0104, val_loss=0.0114, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0101, val_loss=0.0114, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0101, val_loss=0.011, av\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00975, val_loss=0.011, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.00975, val_loss=0.0106, \u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 11.61it/s, loss=0.00947, val_loss=0.0106, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 20.38it/s, loss=0.00947, val_loss=0.0102, \u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00922, val_loss=0.0102, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00922, val_loss=0.00991,\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.009, val_loss=0.00991, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.009, val_loss=0.00963, a\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00879, val_loss=0.00963,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00879, val_loss=0.0094, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00862, val_loss=0.0094, \u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 21.36it/s, loss=0.00862, val_loss=0.0094, \n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00862, val_loss=0.0092, \u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00846, val_loss=0.0092, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.00846, val_loss=0.00902,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00833, val_loss=0.00902,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00833, val_loss=0.00887,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00821, val_loss=0.00887,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00821, val_loss=0.00873,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00812, val_loss=0.00873,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00812, val_loss=0.00861,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.00803, val_loss=0.00861,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.00803, val_loss=0.0085, \u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00797, val_loss=0.0085, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00797, val_loss=0.0084, \u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.00791, val_loss=0.0084, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.00791, val_loss=0.0083, \u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00786, val_loss=0.0083, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00786, val_loss=0.00821,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00781, val_loss=0.00821,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.00781, val_loss=0.00813,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00776, val_loss=0.00813,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00776, val_loss=0.00805,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00771, val_loss=0.00805,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00771, val_loss=0.008, a\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.48it/s, loss=0.00771, val_loss=0.008, a\u001b[A\n",
      "Sizes of clusters: 507, 384, 309\n",
      "\n",
      "preds: [2 1 1 2 2 0 2 2 1 1 2 2 1 2 2 1 1 1 2 1 2 2 1 1 1 2 2 2 2 2 2 1 1 2 2 2 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 2 1 2 2 2 1 1 2 1\n",
      " 2 2 2 2 2 2 1 2 1 1 1 2 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 2\n",
      " 1 1 2 2 2 1 0 1 1 1 1 2 2 2 1 1 2 1 2 1 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1\n",
      " 2 2 1 1 2 2 1 2 1 2 1 1 1 1 1 2 2 2 1 1 1 2 1 1 1 2 1 1 2 2 2 2 2 1 1 1 1\n",
      " 2 1 2 2 1 2 2 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 2 2 1 2 2 1 2 2 1 1 2 1 1 2 1\n",
      " 1 1 1 2 2 2 1 2 1 1 2 1 2 1 2 2 1 2 1 1 2 1 2 2 1 1 2 2 2 1 1 1 2 2 2 2 2\n",
      " 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 2 2 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1\n",
      " 2 2 1 2 2 1 2 1 2 1 2 2 2 2 2 0 1 1 2 1 2 2 1 2 2 1 2 2 2 1 1 2 2 1 1 2 2\n",
      " 1 2 2 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2\n",
      " 1 2 2 1 1 1 2 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2 1 2 1 2 1 1 2 1 2 0 1 0 0 0 0\n",
      " 2 0 1 0 0 0 1 1 0 0 2 2 1 0 2 0 0 1 0 0 0 0 0 0 0 0 2 0 0 2 0 2 1 0 1 2 1\n",
      " 1 1 1 1 2 2 0 2 1 2 0 1 1 0 0 0 0 2 0 2 0 2 0 1 0 0 0 0 0 2 2 0 0 0 0 0 1\n",
      " 0 0 2 2 2 2 2 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 2 1 2 1 1 0 0\n",
      " 0 0 0 0 1 2 0 0 0 1 0 2 0 2 2 1 0 2 2 0 0 1 1 0 0 0 0 2 1 0 2 0 0 0 0 2 2\n",
      " 0 1 2 0 0 1 0 1 1 1 0 0 1 2 0 1 0 0 0 0 1 0 0 2 0 1 0 1 1 2 0 0 0 2 2 2 1\n",
      " 0 2 1 0 0 2 2 2 1 1 2 2 2 0 0 0 2 1 2 2 0 0 0 1 0 2 0 0 1 2 2 0 1 0 0 1 0\n",
      " 1 0 0 0 2 0 2 2 1 1 0 1 1 2 0 0 2 1 2 1 1 1 2 0 0 0 1 1 1 0 1 2 0 0 0 1 1\n",
      " 1 2 1 0 2 2 1 1 0 1 0 0 0 0 0 0 2 1 0 0 0 0 0 2 2 2 0 2 0 0 2 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 2 0 0 2 1 0 0 1 0 0 1 0 1 0 0 2 0 0 2 2 0 0 2\n",
      " 0 0 0 0 0 0 0 0 2 0 2 1 0 2 0 1 1 1 1 2 0 1 0 0 1 2 1 0 0 0 0 1 0 2 2 0 0\n",
      " 0 2 0 1 2 0 2 1 0 0 2 1 0 2 2 0 2 1 1 1 0 0 2 0 0 2 1 0 0 1 0 1 0 0 0 2 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 2 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 2 0 0 0 2 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 1 0 2 0 0 1 2 0 1 0 0 0 0 2 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 2 0 0 0 1 0 0 0 0 0 0 1 2 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 2 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0 2 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 2 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 2 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5767\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=179, val_loss=0.0213, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=179, val_loss=0.539, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=10.3, val_loss=0.539, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 20.50it/s, loss=10.3, val_loss=0.877, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=1.24, val_loss=0.877, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 20.53it/s, loss=1.24, val_loss=0.393, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.4, val_loss=0.393, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.4, val_loss=0.143, avg_va\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.126, val_loss=0.143, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.126, val_loss=0.0683, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0537, val_loss=0.0683, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0537, val_loss=0.0349, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.031, val_loss=0.0349, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.031, val_loss=0.0259, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.023, val_loss=0.0259, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 20.53it/s, loss=0.023, val_loss=0.0219, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 11.62it/s, loss=0.0194, val_loss=0.0219, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 20.40it/s, loss=0.0194, val_loss=0.0194, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.0172, val_loss=0.0194, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 20.52it/s, loss=0.0172, val_loss=0.0175, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0157, val_loss=0.0175, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 20.31it/s, loss=0.0157, val_loss=0.0161, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 11.68it/s, loss=0.0146, val_loss=0.0161, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 20.47it/s, loss=0.0146, val_loss=0.0149, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0136, val_loss=0.0149, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0136, val_loss=0.0139, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0128, val_loss=0.0139, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0128, val_loss=0.0131, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0121, val_loss=0.0131, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0121, val_loss=0.0123, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0115, val_loss=0.0123, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0115, val_loss=0.0117, a\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.011, val_loss=0.0117, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.011, val_loss=0.0112, av\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0106, val_loss=0.0112, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0106, val_loss=0.0107, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.0102, val_loss=0.0107, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.0102, val_loss=0.0102, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.00981, val_loss=0.0102, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 20.51it/s, loss=0.00981, val_loss=0.00986,\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0095, val_loss=0.00986, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0095, val_loss=0.00953, \u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00922, val_loss=0.00953,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00922, val_loss=0.00923,\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00897, val_loss=0.00923,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00897, val_loss=0.00897,\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00875, val_loss=0.00897,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00875, val_loss=0.00874,\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00854, val_loss=0.00874,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.00854, val_loss=0.00854,\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00835, val_loss=0.00854,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00835, val_loss=0.00835,\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00817, val_loss=0.00835,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00817, val_loss=0.00818,\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.00801, val_loss=0.00818,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00801, val_loss=0.00801,\u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00785, val_loss=0.00801,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00785, val_loss=0.00784,\u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00771, val_loss=0.00784,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.00771, val_loss=0.00766,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.00756, val_loss=0.00766,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 20.53it/s, loss=0.00756, val_loss=0.00749,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.00742, val_loss=0.00749,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 20.52it/s, loss=0.00742, val_loss=0.00732,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00728, val_loss=0.00732,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00728, val_loss=0.00718,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00714, val_loss=0.00718,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.00714, val_loss=0.00705,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00701, val_loss=0.00705,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00701, val_loss=0.00693,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00689, val_loss=0.00693,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00689, val_loss=0.00682,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00678, val_loss=0.00682,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00678, val_loss=0.00672,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.00667, val_loss=0.00672,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.00667, val_loss=0.00662,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00657, val_loss=0.00662,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00657, val_loss=0.00652,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00648, val_loss=0.00652,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00648, val_loss=0.00644,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.48it/s, loss=0.00648, val_loss=0.00644,\u001b[A\n",
      "Sizes of clusters: 607, 361, 232\n",
      "\n",
      "preds: [2 1 1 0 0 2 2 2 1 1 1 2 1 2 0 1 1 1 1 1 2 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 2 2 2 1 0 0 1 1 1 1 1 0 1 0 0 2 1 1 2 1\n",
      " 2 2 0 0 2 0 1 2 1 1 1 2 2 0 0 1 1 2 1 1 1 1 1 1 1 0 1 2 2 1 0 1 0 2 0 1 0\n",
      " 1 1 2 2 0 1 0 0 1 1 1 2 2 2 1 1 2 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 2 2 1 0 1 0 1 1 1 1 1 2 2 2 1 1 1 0 1 1 1 2 1 1 0 2 2 0 2 1 1 1 1\n",
      " 2 1 0 2 1 0 0 2 1 1 1 2 2 1 1 1 1 1 1 0 1 1 1 0 1 0 2 1 2 2 1 1 2 0 1 2 1\n",
      " 1 1 1 0 0 0 1 0 1 1 2 1 0 1 2 2 1 0 1 1 2 1 0 2 1 1 0 0 0 1 1 1 2 2 0 0 2\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 2 0 2 0 1 1 1 0 2 1 1 0 1 1 2 1 1 0 1 1\n",
      " 2 0 1 2 0 1 0 1 2 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 2 1 1 0 0 0 1 0 0\n",
      " 1 2 0 1 2 0 1 1 1 1 0 2 2 0 2 0 0 2 0 1 2 1 1 1 0 0 2 1 1 1 2 1 1 0 1 1 0\n",
      " 1 2 0 1 1 1 0 0 0 0 1 0 1 2 0 1 1 1 0 0 2 1 1 0 1 2 1 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 2 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 2 1\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 2 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 2 0 0 0 0 1 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 2 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 2 0 0 1 2 2 0 1 0 2 0 0 0 2\n",
      " 0 2 1 2 2 0 0 1 2 2 1 0 1 0 2 2 1 2 2 2 0 2 0 1 0 1 0 2 0 1 1 2 0 0 2 0 2\n",
      " 0 0 2 0 2 1 0 0 2 0 0 1 2 0 0 2 0 2 0 2 2 1 1 2 0 0 1 2 2 2 0 2 0 2 2 1 2\n",
      " 0 0 2 2 2 2 1 0 2 0 0 0 0 2 1 2 2 0 2 0 0 1 2 0 2 2 1 1 1 2 0 0 2 2 2 2 2\n",
      " 0 0 0 0 2 0 0 1 0 1 1 0 0 0 2 0 2 0 2 2 2 0 0 0 0 0 1 1 0 2 0 0 0 2 2 0 0\n",
      " 0 0 2 0 0 2 0 2 1 0 0 1 0 0 1 0 0 2 0 0 0 0 0 1 0 1 0 1 2 0 0 0 2 2 1 2 1\n",
      " 1 0 1 2 0 2 0 1 2 2 0 2 0 2 1 0 1 0 0 1 0 2 1 2 2 1 2 2 0 2 0 0 0 0 2 0 0\n",
      " 2 2 0 2 1 0 2 2 1 0 0 0 2 1 0 2 0 0 0 2 0 2 1 0 2 2 2 0 1 1 1 1 0 0 2 0 1\n",
      " 0 2 2 0 1 0 2 2 2 1 1 0 0 2 0 2 0 2 2 1 0 0 0 2 0 0 2 0 0 1 2 1 0 0 0 2 0\n",
      " 2 2 2 2 1 2 1 0 2 1 2 0 2 1 1 0 2 2 1 0 0 2 2 0 1 1 2 2 1 2 0 2 0 2 2 0 0\n",
      " 0 0 0 2 1 2 2 0 2 1 0 0 2 1 2 2 2 2 0 2 0 1 2 0 2 0 0 0 0 0 2 0 0 0 2 2 0\n",
      " 2 0 0 2 0 0 1 0 2 2 0 0 0 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5542\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=168, val_loss=0.0378, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=168, val_loss=0.566, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=6.57, val_loss=0.566, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=6.57, val_loss=0.892, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.672, val_loss=0.892, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.672, val_loss=0.27, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.197, val_loss=0.27, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.197, val_loss=0.101, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.0792, val_loss=0.101, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0792, val_loss=0.0479, av\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0377, val_loss=0.0479, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0377, val_loss=0.0332, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0256, val_loss=0.0332, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0256, val_loss=0.0236, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0201, val_loss=0.0236, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0201, val_loss=0.0203, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0175, val_loss=0.0203, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0175, val_loss=0.0186, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0161, val_loss=0.0186, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0161, val_loss=0.0174, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0151, val_loss=0.0174, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0151, val_loss=0.0162, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0143, val_loss=0.0162, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0143, val_loss=0.0153, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0136, val_loss=0.0153, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0136, val_loss=0.0146, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.013, val_loss=0.0146, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.013, val_loss=0.014, avg\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0126, val_loss=0.014, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0126, val_loss=0.0135, a\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0121, val_loss=0.0135, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0121, val_loss=0.013, av\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0118, val_loss=0.013, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.0118, val_loss=0.0126, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0115, val_loss=0.0126, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0115, val_loss=0.0122, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0112, val_loss=0.0122, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0112, val_loss=0.0118, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0109, val_loss=0.0118, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0109, val_loss=0.0113, a\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.0106, val_loss=0.0113, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0106, val_loss=0.011, av\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0104, val_loss=0.011, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0104, val_loss=0.0106, a\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0101, val_loss=0.0106, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0101, val_loss=0.0103, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00992, val_loss=0.0103, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00992, val_loss=0.0101, \u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0097, val_loss=0.0101, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.0097, val_loss=0.00983, \u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 11.69it/s, loss=0.0095, val_loss=0.00983, \u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 21.28it/s, loss=0.0095, val_loss=0.00983, \n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 20.48it/s, loss=0.0095, val_loss=0.00963, \u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 11.69it/s, loss=0.00931, val_loss=0.00963,\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 21.30it/s, loss=0.00931, val_loss=0.00963,\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 20.50it/s, loss=0.00931, val_loss=0.00943,\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.67it/s, loss=0.00914, val_loss=0.00943,\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 21.27it/s, loss=0.00914, val_loss=0.00943,\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 20.46it/s, loss=0.00914, val_loss=0.00924,\u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00898, val_loss=0.00924,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00898, val_loss=0.00905,\u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.00882, val_loss=0.00905,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 20.47it/s, loss=0.00882, val_loss=0.00887,\u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00867, val_loss=0.00887,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00867, val_loss=0.00868,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00852, val_loss=0.00868,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00852, val_loss=0.00851,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00838, val_loss=0.00851,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00838, val_loss=0.00835,\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 11.63it/s, loss=0.00825, val_loss=0.00835,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 20.40it/s, loss=0.00825, val_loss=0.00823,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00812, val_loss=0.00823,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00812, val_loss=0.00813,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00801, val_loss=0.00813,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00801, val_loss=0.00805,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00791, val_loss=0.00805,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00791, val_loss=0.00798,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.00781, val_loss=0.00798,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.00781, val_loss=0.00791,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00772, val_loss=0.00791,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00772, val_loss=0.00784,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00764, val_loss=0.00784,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00764, val_loss=0.00778,\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.48it/s, loss=0.00764, val_loss=0.00778,\u001b[A\n",
      "Sizes of clusters: 375, 164, 661\n",
      "\n",
      "preds: [1 0 0 1 2 1 1 1 0 0 0 1 2 1 2 0 0 0 2 0 1 2 0 2 2 1 2 2 2 2 2 2 2 1 2 2 2\n",
      " 1 2 0 0 0 0 2 0 0 2 0 0 0 2 0 2 1 1 1 1 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 1 0\n",
      " 1 1 2 1 1 2 0 1 0 0 0 1 1 2 2 2 0 1 0 2 0 0 2 0 0 2 0 1 1 0 2 2 2 1 1 2 2\n",
      " 0 0 1 1 1 2 2 0 0 2 0 1 1 1 0 0 1 0 1 0 2 2 2 0 0 0 0 1 2 0 1 0 2 0 2 0 2\n",
      " 2 2 0 0 1 1 0 2 0 2 0 0 0 0 0 1 2 1 0 0 0 2 0 0 2 1 2 0 1 1 1 2 1 0 0 0 0\n",
      " 1 2 2 2 0 2 1 1 0 0 0 1 1 2 2 0 0 0 0 2 2 2 2 1 2 2 1 0 1 1 0 2 1 2 0 1 2\n",
      " 0 0 0 1 2 2 0 2 0 0 1 2 2 0 1 1 2 2 0 2 1 0 2 1 2 0 1 2 1 0 0 0 1 1 1 2 1\n",
      " 0 1 0 0 0 2 2 0 0 2 0 2 0 0 1 0 2 1 2 1 1 2 2 0 1 1 0 0 2 0 2 1 0 2 2 0 2\n",
      " 1 1 0 1 2 0 1 0 1 2 2 2 1 1 1 1 0 0 1 2 2 1 2 2 2 2 1 2 1 0 2 2 2 2 0 2 2\n",
      " 0 1 2 0 1 2 2 0 2 2 2 1 1 2 1 2 1 1 2 2 1 0 0 2 2 2 1 2 0 0 1 0 2 1 0 0 1\n",
      " 2 1 1 0 2 0 1 1 2 2 0 2 2 1 1 0 0 0 1 2 2 2 0 2 0 1 0 0 1 0 1 2 0 2 2 2 0\n",
      " 2 2 0 0 2 2 0 0 2 2 2 0 0 2 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 0 2 2 0 2 0 2 0\n",
      " 0 0 2 0 2 2 2 2 0 2 0 2 0 0 0 0 2 0 0 2 0 0 0 0 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 2 0 0 2 2 2 2 2 2 2 0 0 2 0 0 2 2 2 0 0 0 0 2 0 0 0 0 2 0 0 2 0 2 0 0 0 0\n",
      " 2 2 2 2 2 2 0 2 2 2 0 2 0 2 0 0 2 2 2 2 0 2 0 0 2 2 2 2 0 2 2 0 2 2 2 2 2\n",
      " 0 0 2 2 2 0 2 0 2 0 2 0 2 2 2 0 2 0 0 0 2 2 0 2 2 0 0 0 2 2 0 0 0 0 2 2 2\n",
      " 0 0 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 0 0 0 0 0 2 2 0 2 2 2 2 0 2 2 0 2 0 2 2 0 2 0 2 2 0 0 2 0\n",
      " 2 2 0 0 0 2 0 2 0 2 2 2 2 0 2 0 2 0 2 0 2 0 2 2 2 2 2 2 0 0 2 2 0 2 0 0 2\n",
      " 2 2 0 0 2 0 0 2 0 0 2 2 0 0 2 2 0 2 0 0 0 2 2 2 2 0 2 0 0 0 2 2 2 2 0 0 2\n",
      " 0 0 2 0 2 0 0 2 2 0 2 0 1 2 2 2 2 2 0 2 0 0 2 0 2 2 0 2 0 2 2 0 2 2 0 0 2\n",
      " 2 2 0 2 2 2 2 0 2 0 0 2 0 2 2 2 2 0 0 0 2 2 2 2 2 2 0 2 2 2 0 2 1 2 2 1 2\n",
      " 2 2 0 2 2 2 2 0 2 1 2 2 2 2 2 2 0 2 1 2 2 2 0 0 0 0 2 1 0 0 0 2 2 2 2 2 2\n",
      " 0 2 2 2 2 0 2 2 1 2 2 0 2 2 0 2 2 2 2 1 2 0 0 1 2 2 2 2 1 2 2 2 2 2 1 2 2\n",
      " 2 2 2 2 1 2 0 2 2 2 2 2 2 1 0 2 2 0 1 2 2 0 1 2 1 1 0 2 0 2 2 2 1 1 2 1 2\n",
      " 2 2 2 2 2 0 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 1 2 2 2 2 1 2 2\n",
      " 2 0 2 2 2 2 2 1 2 0 2 2 2 2 0 2 2 1 2 2 2 2 0 0 2 0 2 0 2 2 2 2 1 2 2 2 2\n",
      " 0 2 2 2 2 1 2 0 1 2 2 2 1 2 0 1 2 2 2 0 2 2 0 1 2 0 2 1 2 2 2 2 2 2 1 2 2\n",
      " 2 1 2 2 0 2 2 1 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 2 1 2 2 2 0 0 0 2 2 2 1 2 0\n",
      " 2 1 2 2 0 2 2 2 2 0 2 2 0 2 0 2 2 2 2 0 2 1 2 2 2 2 2 2 0 0 2 0 2 2 2 2 2\n",
      " 2 2 1 2 2 2 0 2 2 0 2 2 1 0 0 0 1 2 0 2 2 2 2 2 0 0 2 1 0 1 2 2 2 1 2 0 2\n",
      " 2 2 2 1 0 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 0 1 2 2 0 2 2 2 2 1 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4617\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 12/24 [00:01<00:01, 11.75it/s, loss=165, val_loss=0.034, avg_va\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 24/24 [00:01<00:00, 20.60it/s, loss=165, val_loss=1.14, avg_val\u001b[A\n",
      "Epoch 1:  50%|▌| 12/24 [00:01<00:01, 11.68it/s, loss=8.06, val_loss=1.14, avg_va\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 24/24 [00:01<00:00, 20.50it/s, loss=8.06, val_loss=1.24, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.987, val_loss=1.24, avg_v\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.987, val_loss=0.826, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.318, val_loss=0.826, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.318, val_loss=0.465, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.119, val_loss=0.465, avg_\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.119, val_loss=0.187, avg_\u001b[A\n",
      "Epoch 5:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0594, val_loss=0.187, avg\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0594, val_loss=0.0665, av\u001b[A\n",
      "Epoch 6:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0389, val_loss=0.0665, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0389, val_loss=0.0423, av\u001b[A\n",
      "Epoch 7:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0306, val_loss=0.0423, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0306, val_loss=0.0342, av\u001b[A\n",
      "Epoch 8:  50%|▌| 12/24 [00:01<00:01, 11.61it/s, loss=0.0264, val_loss=0.0342, av\u001b[A\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 21.18it/s, loss=0.0264, val_loss=0.0342, av\n",
      "Epoch 8: 100%|█| 24/24 [00:01<00:00, 20.37it/s, loss=0.0264, val_loss=0.0296, av\u001b[A\n",
      "Epoch 9:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0236, val_loss=0.0296, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0236, val_loss=0.0265, av\u001b[A\n",
      "Epoch 10:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.0215, val_loss=0.0265, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0215, val_loss=0.0241, a\u001b[A\n",
      "Epoch 11:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0199, val_loss=0.0241, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.0199, val_loss=0.0222, a\u001b[A\n",
      "Epoch 12:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0186, val_loss=0.0222, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 24/24 [00:01<00:00, 20.47it/s, loss=0.0186, val_loss=0.0206, a\u001b[A\n",
      "Epoch 13:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0175, val_loss=0.0206, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0175, val_loss=0.0192, a\u001b[A\n",
      "Epoch 14:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.0165, val_loss=0.0192, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0165, val_loss=0.018, av\u001b[A\n",
      "Epoch 15:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.0156, val_loss=0.018, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0156, val_loss=0.017, av\u001b[A\n",
      "Epoch 16:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0148, val_loss=0.017, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 24/24 [00:01<00:00, 20.46it/s, loss=0.0148, val_loss=0.0161, a\u001b[A\n",
      "Epoch 17:  50%|▌| 12/24 [00:01<00:01, 11.70it/s, loss=0.0141, val_loss=0.0161, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 24/24 [00:01<00:00, 20.51it/s, loss=0.0141, val_loss=0.0153, a\u001b[A\n",
      "Epoch 18:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0135, val_loss=0.0153, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.0135, val_loss=0.0146, a\u001b[A\n",
      "Epoch 19:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0129, val_loss=0.0146, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0129, val_loss=0.014, av\u001b[A\n",
      "Epoch 20:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.0124, val_loss=0.014, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 24/24 [00:01<00:00, 20.44it/s, loss=0.0124, val_loss=0.0134, a\u001b[A\n",
      "Epoch 21:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.012, val_loss=0.0134, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.012, val_loss=0.0129, av\u001b[A\n",
      "Epoch 22:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0116, val_loss=0.0129, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.0116, val_loss=0.0124, a\u001b[A\n",
      "Epoch 23:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.0112, val_loss=0.0124, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.0112, val_loss=0.012, av\u001b[A\n",
      "Epoch 24:  50%|▌| 12/24 [00:01<00:01, 11.64it/s, loss=0.0109, val_loss=0.012, av\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 24/24 [00:01<00:00, 20.43it/s, loss=0.0109, val_loss=0.0116, a\u001b[A\n",
      "Epoch 25:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0105, val_loss=0.0116, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0105, val_loss=0.0112, a\u001b[A\n",
      "Epoch 26:  50%|▌| 12/24 [00:01<00:01, 11.71it/s, loss=0.0102, val_loss=0.0112, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 24/24 [00:01<00:00, 20.54it/s, loss=0.0102, val_loss=0.0109, a\u001b[A\n",
      "Epoch 27:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00998, val_loss=0.0109, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00998, val_loss=0.0105, \u001b[A\n",
      "Epoch 28:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00973, val_loss=0.0105, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00973, val_loss=0.0102, \u001b[A\n",
      "Epoch 29:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.0095, val_loss=0.0102, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.0095, val_loss=0.00998, \u001b[A\n",
      "Epoch 30:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00928, val_loss=0.00998,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00928, val_loss=0.00974,\u001b[A\n",
      "Epoch 31:  50%|▌| 12/24 [00:01<00:01, 11.72it/s, loss=0.00909, val_loss=0.00974,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 24/24 [00:01<00:00, 20.55it/s, loss=0.00909, val_loss=0.00951,\u001b[A\n",
      "Epoch 32:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0089, val_loss=0.00951, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.0089, val_loss=0.0093, a\u001b[A\n",
      "Epoch 33:  50%|▌| 12/24 [00:01<00:01, 11.65it/s, loss=0.00873, val_loss=0.0093, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 24/24 [00:01<00:00, 20.45it/s, loss=0.00873, val_loss=0.00911,\u001b[A\n",
      "Epoch 34:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00857, val_loss=0.00911,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 24/24 [00:01<00:00, 20.58it/s, loss=0.00857, val_loss=0.00894,\u001b[A\n",
      "Epoch 35:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00842, val_loss=0.00894,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 24/24 [00:01<00:00, 20.56it/s, loss=0.00842, val_loss=0.00877,\u001b[A\n",
      "Epoch 36:  50%|▌| 12/24 [00:01<00:01, 11.73it/s, loss=0.00828, val_loss=0.00877,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 24/24 [00:01<00:00, 20.57it/s, loss=0.00828, val_loss=0.00861,\u001b[A\n",
      "Epoch 37:  50%|▌| 12/24 [00:01<00:01, 11.66it/s, loss=0.00815, val_loss=0.00861,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 24/24 [00:01<00:00, 20.46it/s, loss=0.00815, val_loss=0.00847,\u001b[A\n",
      "Epoch 38:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.00802, val_loss=0.00847,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.00802, val_loss=0.00833,\u001b[A\n",
      "Epoch 39:  50%|▌| 12/24 [00:01<00:01, 11.74it/s, loss=0.0079, val_loss=0.00833, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.59it/s, loss=0.0079, val_loss=0.0082, a\u001b[A\n",
      "Epoch 39: 100%|█| 24/24 [00:01<00:00, 20.50it/s, loss=0.0079, val_loss=0.0082, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of clusters: 609, 363, 228\n",
      "\n",
      "preds: [2 1 1 0 0 2 2 2 1 1 1 2 1 2 0 1 1 1 1 1 2 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 2 2 2 1 0 0 1 1 1 1 1 0 1 0 0 2 1 1 2 1\n",
      " 2 2 0 0 2 0 1 2 1 1 1 2 2 0 0 1 1 2 1 1 1 1 1 1 1 0 1 2 2 1 0 1 0 2 0 1 0\n",
      " 1 1 2 2 0 1 0 0 1 1 1 2 2 2 1 1 2 1 0 1 0 1 0 1 1 1 1 2 0 1 0 1 1 1 0 1 1\n",
      " 0 1 1 1 2 2 1 0 1 0 1 1 1 1 1 2 2 2 1 1 1 0 1 1 1 2 1 1 0 2 2 0 2 1 1 1 1\n",
      " 2 1 0 2 1 0 0 2 1 1 1 2 2 1 1 1 1 1 1 0 1 1 1 0 1 0 2 1 2 2 1 1 2 0 1 2 1\n",
      " 1 1 1 0 0 0 1 0 1 1 0 1 0 1 2 2 1 0 1 1 2 1 0 2 1 1 0 0 0 1 1 1 2 2 0 0 2\n",
      " 1 0 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 2 0 2 0 1 1 1 0 2 1 1 0 1 1 2 1 1 0 1 1\n",
      " 2 0 1 2 0 1 0 1 2 1 0 1 0 0 0 2 1 1 0 0 1 0 1 0 0 1 0 0 2 1 1 0 0 0 1 0 0\n",
      " 1 2 0 1 2 0 1 1 1 0 0 2 2 0 2 0 0 2 0 1 2 1 1 1 0 0 2 1 1 1 2 1 1 0 1 1 0\n",
      " 1 2 0 1 1 1 0 2 0 0 1 0 1 2 0 1 1 1 0 0 2 1 1 0 1 2 1 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 2 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 2 0 0 0 0 1 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 2 0 0 1 0 2 0 1 0 2 0 0 0 2\n",
      " 0 2 1 2 2 0 0 1 2 2 1 0 1 0 2 2 1 2 2 2 0 2 0 1 0 1 0 2 0 1 1 2 0 0 2 0 2\n",
      " 0 0 2 0 2 1 0 0 2 0 0 1 2 0 0 2 0 2 0 2 2 1 1 2 0 0 1 0 2 2 0 2 0 2 2 1 2\n",
      " 0 0 2 2 2 2 1 0 2 0 0 0 0 2 1 2 2 0 2 0 0 1 2 0 2 2 1 1 1 2 0 0 2 2 2 2 0\n",
      " 0 0 0 0 2 0 0 1 0 1 1 0 0 2 2 0 2 0 2 2 2 0 0 0 0 0 1 1 0 2 0 0 0 2 2 0 0\n",
      " 0 0 2 0 0 2 0 2 1 0 2 1 0 0 1 0 0 2 0 0 0 0 0 1 0 1 0 1 2 0 0 0 2 2 1 2 1\n",
      " 1 0 1 2 0 2 0 1 2 2 0 2 0 2 1 0 1 0 0 1 0 2 1 2 2 1 2 2 0 2 0 0 2 0 2 0 0\n",
      " 2 2 0 2 1 0 2 2 1 0 0 0 2 1 0 2 0 0 0 2 0 2 1 0 2 2 2 0 1 1 1 1 0 0 2 0 1\n",
      " 0 2 2 0 1 0 0 2 2 1 1 0 0 2 0 2 0 2 2 1 0 0 0 2 0 0 2 0 0 1 2 1 0 0 0 2 0\n",
      " 2 2 2 2 1 2 1 0 2 1 2 0 2 1 1 0 2 2 1 0 0 2 2 0 1 1 0 2 1 2 0 2 0 2 2 0 0\n",
      " 0 0 0 2 1 2 2 0 2 1 0 0 2 1 2 2 2 2 0 2 0 1 2 0 2 0 0 0 0 0 2 0 0 0 2 2 0\n",
      " 2 0 0 2 0 0 1 0 2 0 0 0 0 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5492\n",
      "\n",
      "Consistency: 0.4464\n",
      "Purity: 0.5433333333333333+-0.04227226566490663\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K3_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K4_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/K5_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 100 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=114, val_loss=0.103, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 37.83it/s, loss=114, val_loss=2.3, avg_val_\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=2.16, val_loss=2.3, avg_val\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.62it/s, loss=2.16, val_loss=1.21, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.44it/s, loss=0.388, val_loss=1.21, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.61it/s, loss=0.388, val_loss=0.239, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 20.61it/s, loss=0.117, val_loss=0.239, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 36.17it/s, loss=0.117, val_loss=0.0762, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.34it/s, loss=0.0616, val_loss=0.0762, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.41it/s, loss=0.0616, val_loss=0.0486, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.0444, val_loss=0.0486, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.0444, val_loss=0.0413, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.0362, val_loss=0.0413, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.0362, val_loss=0.0364, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.0307, val_loss=0.0364, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=0.0307, val_loss=0.0324, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.0264, val_loss=0.0324, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 36.95it/s, loss=0.0264, val_loss=0.0286, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.10it/s, loss=0.0229, val_loss=0.0286, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.10it/s, loss=0.0229, val_loss=0.0253, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.0199, val_loss=0.0253, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.85it/s, loss=0.0199, val_loss=0.0223, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 22.26it/s, loss=0.0175, val_loss=0.0223, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.89it/s, loss=0.0175, val_loss=0.0196, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.0154, val_loss=0.0196, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 38.60it/s, loss=0.0154, val_loss=0.0173, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.0136, val_loss=0.0173, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.64it/s, loss=0.0136, val_loss=0.0152, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0121, val_loss=0.0152, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.0121, val_loss=0.0134, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0107, val_loss=0.0134, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.0107, val_loss=0.0119, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 22.15it/s, loss=0.00952, val_loss=0.0119, \n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.69it/s, loss=0.00952, val_loss=0.0106, \n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 22.16it/s, loss=0.00848, val_loss=0.0106, \n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.71it/s, loss=0.00848, val_loss=0.00946,\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=0.00758, val_loss=0.00946,\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.00758, val_loss=0.00846,\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 22.29it/s, loss=0.00679, val_loss=0.00846,\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.90it/s, loss=0.00679, val_loss=0.00756,\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00611, val_loss=0.00756,\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00611, val_loss=0.00677,\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00552, val_loss=0.00677,\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.00552, val_loss=0.00608,\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00502, val_loss=0.00608,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00502, val_loss=0.00549,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00459, val_loss=0.00549,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.00459, val_loss=0.00497,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.00422, val_loss=0.00497,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 36.90it/s, loss=0.00422, val_loss=0.00453,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00391, val_loss=0.00453,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=0.00391, val_loss=0.00415,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00364, val_loss=0.00415,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00364, val_loss=0.00382,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00341, val_loss=0.00382,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.88it/s, loss=0.00341, val_loss=0.00354,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00322, val_loss=0.00354,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00322, val_loss=0.00331,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00306, val_loss=0.00331,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.18it/s, loss=0.00306, val_loss=0.0031, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.50it/s, loss=0.00293, val_loss=0.0031, \n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.56it/s, loss=0.00293, val_loss=0.00293,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.00281, val_loss=0.00293,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.57it/s, loss=0.00281, val_loss=0.00279,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00271, val_loss=0.00279,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.40it/s, loss=0.00271, val_loss=0.00266,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00263, val_loss=0.00266,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00263, val_loss=0.00255,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00255, val_loss=0.00255,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.83it/s, loss=0.00255, val_loss=0.00246,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 20.93it/s, loss=0.00249, val_loss=0.00246,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 36.67it/s, loss=0.00249, val_loss=0.00238,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.12it/s, loss=0.00243, val_loss=0.00238,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 36.99it/s, loss=0.00243, val_loss=0.00232,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.00238, val_loss=0.00232,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.00238, val_loss=0.00227,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00234, val_loss=0.00227,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00234, val_loss=0.00222,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.0023, val_loss=0.00222, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.0023, val_loss=0.00217, \n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 20.81it/s, loss=0.00227, val_loss=0.00217,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 36.47it/s, loss=0.00227, val_loss=0.00213,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 21.00it/s, loss=0.00224, val_loss=0.00213,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 36.85it/s, loss=0.00224, val_loss=0.0021, \n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00221, val_loss=0.0021, \n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00221, val_loss=0.00207,\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00218, val_loss=0.00207,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00218, val_loss=0.00204,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 22.27it/s, loss=0.00216, val_loss=0.00204,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 38.90it/s, loss=0.00216, val_loss=0.00201,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.00214, val_loss=0.00201,\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00214, val_loss=0.00198,\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.00212, val_loss=0.00198,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00212, val_loss=0.00197,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.0021, val_loss=0.00197, \n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.0021, val_loss=0.00195, \n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00208, val_loss=0.00195,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.00208, val_loss=0.00192,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00206, val_loss=0.00192,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00206, val_loss=0.0019, \n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.00205, val_loss=0.0019, \n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.00205, val_loss=0.00188,\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00203, val_loss=0.00188,\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.01it/s, loss=0.00203, val_loss=0.00186,\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=0.00202, val_loss=0.00186,\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.00202, val_loss=0.00184,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.002, val_loss=0.00184, a\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=0.002, val_loss=0.00183, a\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00199, val_loss=0.00183,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=0.00199, val_loss=0.00181,\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00198, val_loss=0.00181,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.00198, val_loss=0.0018, \n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00196, val_loss=0.0018, \n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 38.26it/s, loss=0.00196, val_loss=0.00178,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.00195, val_loss=0.00178,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.69it/s, loss=0.00195, val_loss=0.00177,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=0.00194, val_loss=0.00177,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00194, val_loss=0.00175,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00193, val_loss=0.00175,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00193, val_loss=0.00174,\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.00192, val_loss=0.00174,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 38.62it/s, loss=0.00192, val_loss=0.00173,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00191, val_loss=0.00173,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.00191, val_loss=0.00172,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0019, val_loss=0.00172, \n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 37.96it/s, loss=0.0019, val_loss=0.00171, \n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00189, val_loss=0.00171,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 37.33it/s, loss=0.00189, val_loss=0.0017, \n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 21.09it/s, loss=0.00188, val_loss=0.0017, \n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 37.01it/s, loss=0.00188, val_loss=0.00168,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00187, val_loss=0.00168,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00187, val_loss=0.00167,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 21.92it/s, loss=0.00187, val_loss=0.00167,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.00187, val_loss=0.00167,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00186, val_loss=0.00167,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.00186, val_loss=0.00166,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 20.84it/s, loss=0.00185, val_loss=0.00166,\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 36.57it/s, loss=0.00185, val_loss=0.00165,\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.00184, val_loss=0.00165,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 37.50it/s, loss=0.00184, val_loss=0.00164,\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00184, val_loss=0.00164,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00184, val_loss=0.00163,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.00183, val_loss=0.00163,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 37.62it/s, loss=0.00183, val_loss=0.00162,\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.00182, val_loss=0.00162,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00182, val_loss=0.00161,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 20.70it/s, loss=0.00182, val_loss=0.00161,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 36.33it/s, loss=0.00182, val_loss=0.00161,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 20.67it/s, loss=0.00181, val_loss=0.00161,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 36.31it/s, loss=0.00181, val_loss=0.0016, \n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00181, val_loss=0.0016, \n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00181, val_loss=0.00159,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0018, val_loss=0.00159, \n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.0018, val_loss=0.00158, \n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.0018, val_loss=0.00158, \n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.41it/s, loss=0.0018, val_loss=0.00158, \n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 20.85it/s, loss=0.00179, val_loss=0.00158,\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 36.58it/s, loss=0.00179, val_loss=0.00157,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 21.23it/s, loss=0.00179, val_loss=0.00157,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 37.14it/s, loss=0.00179, val_loss=0.00157,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00178, val_loss=0.00157,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00178, val_loss=0.00156,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00178, val_loss=0.00156,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 38.17it/s, loss=0.00178, val_loss=0.00156,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00177, val_loss=0.00156,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00177, val_loss=0.00155,\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=0.00177, val_loss=0.00155,\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.00177, val_loss=0.00154,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.00176, val_loss=0.00154,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00176, val_loss=0.00153,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00176, val_loss=0.00153,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00176, val_loss=0.00153,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00175, val_loss=0.00153,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00175, val_loss=0.00152,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.00175, val_loss=0.00152,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.00175, val_loss=0.00152,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00175, val_loss=0.00152,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00175, val_loss=0.00152,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.00174, val_loss=0.00152,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.65it/s, loss=0.00174, val_loss=0.00151,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00174, val_loss=0.00151,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 38.22it/s, loss=0.00174, val_loss=0.00151,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00174, val_loss=0.00151,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00174, val_loss=0.0015, \n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.60it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.00173, val_loss=0.00149,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 21.54it/s, loss=0.00173, val_loss=0.00149,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 37.66it/s, loss=0.00173, val_loss=0.00149,\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00172, val_loss=0.00149,\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 37.34it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 21.45it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 37.61it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.00171, val_loss=0.00148,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.64it/s, loss=0.00171, val_loss=0.00147,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.00171, val_loss=0.00147,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.70it/s, loss=0.00171, val_loss=0.00147,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.30it/s, loss=0.00171, val_loss=0.00147,\n",
      "Sizes of clusters: 442, 358\n",
      "\n",
      "preds: [1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 1 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.7750\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=144, val_loss=0.143, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=144, val_loss=10, avg_val_l\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=2.59, val_loss=10, avg_val_\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=2.59, val_loss=5.26, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.474, val_loss=5.26, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.474, val_loss=0.991, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.04it/s, loss=0.143, val_loss=0.991, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 36.82it/s, loss=0.143, val_loss=0.159, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 20.53it/s, loss=0.0668, val_loss=0.159, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 36.08it/s, loss=0.0668, val_loss=0.0603, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.0458, val_loss=0.0603, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.0458, val_loss=0.0425, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.0366, val_loss=0.0425, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.0366, val_loss=0.0349, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.0309, val_loss=0.0349, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.0309, val_loss=0.0304, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0266, val_loss=0.0304, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.0266, val_loss=0.0268, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 20.74it/s, loss=0.0232, val_loss=0.0268, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 36.44it/s, loss=0.0232, val_loss=0.0238, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.0203, val_loss=0.0238, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.28it/s, loss=0.0203, val_loss=0.0212, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.0179, val_loss=0.0212, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.41it/s, loss=0.0179, val_loss=0.0189, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.0159, val_loss=0.0189, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 38.18it/s, loss=0.0159, val_loss=0.0169, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.0142, val_loss=0.0169, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.0142, val_loss=0.0151, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0127, val_loss=0.0151, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.0127, val_loss=0.0136, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.0114, val_loss=0.0136, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.0114, val_loss=0.0122, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.0103, val_loss=0.0122, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.0103, val_loss=0.011, av\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00932, val_loss=0.011, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00932, val_loss=0.00991,\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.50it/s, loss=0.00847, val_loss=0.00991,\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.68it/s, loss=0.00847, val_loss=0.00897,\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00773, val_loss=0.00897,\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00773, val_loss=0.00812,\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00707, val_loss=0.00812,\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00707, val_loss=0.00737,\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.0065, val_loss=0.00737, \n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.0065, val_loss=0.00679, \n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00599, val_loss=0.00679,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.00599, val_loss=0.00625,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00554, val_loss=0.00625,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00554, val_loss=0.00576,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00514, val_loss=0.00576,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.91it/s, loss=0.00514, val_loss=0.00533,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.17it/s, loss=0.00479, val_loss=0.00533,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.15it/s, loss=0.00479, val_loss=0.00493,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.00448, val_loss=0.00493,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.32it/s, loss=0.00448, val_loss=0.00458,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0042, val_loss=0.00458, \n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.0042, val_loss=0.00427, \n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00396, val_loss=0.00427,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.00396, val_loss=0.004, a\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00375, val_loss=0.004, a\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00375, val_loss=0.00377,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.00356, val_loss=0.00377,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.32it/s, loss=0.00356, val_loss=0.00357,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.00it/s, loss=0.00339, val_loss=0.00357,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 36.80it/s, loss=0.00339, val_loss=0.0034, \n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00324, val_loss=0.0034, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.42it/s, loss=0.00324, val_loss=0.00324,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.00311, val_loss=0.00324,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.00311, val_loss=0.00311,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.003, val_loss=0.00311, a\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.003, val_loss=0.00299, a\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.00289, val_loss=0.00299,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.00289, val_loss=0.00288,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 20.89it/s, loss=0.0028, val_loss=0.00288, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 36.61it/s, loss=0.0028, val_loss=0.00278, \n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 20.82it/s, loss=0.00272, val_loss=0.00278,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 36.57it/s, loss=0.00272, val_loss=0.0027, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00265, val_loss=0.0027, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.00265, val_loss=0.00262,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00258, val_loss=0.00262,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.42it/s, loss=0.00258, val_loss=0.00255,\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00252, val_loss=0.00255,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 37.48it/s, loss=0.00252, val_loss=0.00248,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.00247, val_loss=0.00248,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=0.00247, val_loss=0.00242,\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 20.22it/s, loss=0.00242, val_loss=0.00242,\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 35.53it/s, loss=0.00242, val_loss=0.00237,\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.00238, val_loss=0.00237,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 36.14it/s, loss=0.00238, val_loss=0.00232,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=0.00234, val_loss=0.00232,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.00234, val_loss=0.00228,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.0023, val_loss=0.00228, \n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.0023, val_loss=0.00223, \n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00227, val_loss=0.00223,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00227, val_loss=0.0022, \n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00224, val_loss=0.0022, \n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.38it/s, loss=0.00224, val_loss=0.00216,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=0.00221, val_loss=0.00216,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.28it/s, loss=0.00221, val_loss=0.00213,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00219, val_loss=0.00213,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 38.00it/s, loss=0.00219, val_loss=0.0021, \n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00216, val_loss=0.0021, \n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00216, val_loss=0.00207,\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.00214, val_loss=0.00207,\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.00214, val_loss=0.00204,\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00212, val_loss=0.00204,\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.00212, val_loss=0.00202,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.0021, val_loss=0.00202, \n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.0021, val_loss=0.00199, \n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00208, val_loss=0.00199,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00208, val_loss=0.00197,\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00206, val_loss=0.00197,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00206, val_loss=0.00195,\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00204, val_loss=0.00195,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 38.16it/s, loss=0.00204, val_loss=0.00193,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00203, val_loss=0.00193,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.17it/s, loss=0.00203, val_loss=0.00191,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00201, val_loss=0.00191,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 37.41it/s, loss=0.00201, val_loss=0.00189,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 21.17it/s, loss=0.002, val_loss=0.00189, a\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 37.06it/s, loss=0.002, val_loss=0.00187, a\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00199, val_loss=0.00187,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.00199, val_loss=0.00185,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00197, val_loss=0.00185,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00197, val_loss=0.00183,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.00196, val_loss=0.00183,\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 38.18it/s, loss=0.00196, val_loss=0.00182,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00195, val_loss=0.00182,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 37.59it/s, loss=0.00195, val_loss=0.0018, \n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 21.13it/s, loss=0.00194, val_loss=0.0018, \n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 37.04it/s, loss=0.00194, val_loss=0.00178,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.00193, val_loss=0.00178,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 37.14it/s, loss=0.00193, val_loss=0.00177,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00192, val_loss=0.00177,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00192, val_loss=0.00176,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00191, val_loss=0.00176,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00191, val_loss=0.00175,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.0019, val_loss=0.00175, \n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 37.97it/s, loss=0.0019, val_loss=0.00174, \n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 21.44it/s, loss=0.00189, val_loss=0.00174,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 37.34it/s, loss=0.00189, val_loss=0.00173,\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 21.21it/s, loss=0.00188, val_loss=0.00173,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 37.22it/s, loss=0.00188, val_loss=0.00172,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00187, val_loss=0.00172,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 38.03it/s, loss=0.00187, val_loss=0.00171,\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00186, val_loss=0.00171,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00186, val_loss=0.0017, \n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00185, val_loss=0.0017, \n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.00185, val_loss=0.00169,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 20.81it/s, loss=0.00184, val_loss=0.00169,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 36.51it/s, loss=0.00184, val_loss=0.00168,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.00184, val_loss=0.00168,\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 37.42it/s, loss=0.00184, val_loss=0.00167,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.00183, val_loss=0.00167,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.00183, val_loss=0.00166,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00182, val_loss=0.00166,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00182, val_loss=0.00165,\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00181, val_loss=0.00165,\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 38.16it/s, loss=0.00181, val_loss=0.00164,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00181, val_loss=0.00164,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00181, val_loss=0.00163,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.0018, val_loss=0.00163, \n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.0018, val_loss=0.00162, \n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00179, val_loss=0.00162,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.00179, val_loss=0.00161,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00179, val_loss=0.00161,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00179, val_loss=0.0016, \n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00178, val_loss=0.0016, \n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00178, val_loss=0.00159,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00178, val_loss=0.00159,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 38.16it/s, loss=0.00178, val_loss=0.00158,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00177, val_loss=0.00158,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00177, val_loss=0.00157,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00177, val_loss=0.00157,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00177, val_loss=0.00157,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00176, val_loss=0.00157,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 38.16it/s, loss=0.00176, val_loss=0.00156,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00176, val_loss=0.00156,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00176, val_loss=0.00155,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.00175, val_loss=0.00155,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.60it/s, loss=0.00175, val_loss=0.00154,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 20.87it/s, loss=0.00175, val_loss=0.00154,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 36.69it/s, loss=0.00175, val_loss=0.00153,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.00174, val_loss=0.00153,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 36.63it/s, loss=0.00174, val_loss=0.00153,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.00174, val_loss=0.00153,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.00174, val_loss=0.00152,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00173, val_loss=0.00152,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 38.00it/s, loss=0.00173, val_loss=0.00151,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00173, val_loss=0.00151,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 20.65it/s, loss=0.00173, val_loss=0.0015, \n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 36.27it/s, loss=0.00173, val_loss=0.00149,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 21.10it/s, loss=0.00172, val_loss=0.00149,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 37.05it/s, loss=0.00172, val_loss=0.00148,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00171, val_loss=0.00148,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00171, val_loss=0.00148,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00171, val_loss=0.00148,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00171, val_loss=0.00149,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.00171, val_loss=0.00149,\n",
      "Sizes of clusters: 449, 351\n",
      "\n",
      "preds: [1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.8088\n",
      "============= RUN 3 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=126, val_loss=0.0744, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=126, val_loss=7.46, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=1.58, val_loss=7.46, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=1.58, val_loss=1.74, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.319, val_loss=1.74, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.319, val_loss=0.274, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.103, val_loss=0.274, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.103, val_loss=0.0789, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.053, val_loss=0.0789, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.053, val_loss=0.048, avg_\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.0398, val_loss=0.048, avg\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.45it/s, loss=0.0398, val_loss=0.0403, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.0337, val_loss=0.0403, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 36.05it/s, loss=0.0337, val_loss=0.0354, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.0296, val_loss=0.0354, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.0296, val_loss=0.0326, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 22.26it/s, loss=0.0265, val_loss=0.0326, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.88it/s, loss=0.0265, val_loss=0.0299, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.024, val_loss=0.0299, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.024, val_loss=0.0268, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.0219, val_loss=0.0268, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.60it/s, loss=0.0219, val_loss=0.0251, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.0202, val_loss=0.0251, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.0202, val_loss=0.0234, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.0187, val_loss=0.0234, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.0187, val_loss=0.0216, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.0175, val_loss=0.0216, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.75it/s, loss=0.0175, val_loss=0.0196, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.0163, val_loss=0.0196, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.75it/s, loss=0.0163, val_loss=0.0181, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.0153, val_loss=0.0181, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.0153, val_loss=0.0167, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 22.17it/s, loss=0.0144, val_loss=0.0167, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.67it/s, loss=0.0144, val_loss=0.0154, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 22.15it/s, loss=0.0135, val_loss=0.0154, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.69it/s, loss=0.0135, val_loss=0.0143, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0127, val_loss=0.0143, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.0127, val_loss=0.0133, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.012, val_loss=0.0133, av\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.78it/s, loss=0.012, val_loss=0.0125, av\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.0113, val_loss=0.0125, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.76it/s, loss=0.0113, val_loss=0.0119, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.0106, val_loss=0.0119, a\n",
      "Epoch 21:  81%|▊| 26/32 [00:00<00:00, 33.70it/s, loss=0.0106, val_loss=0.0119, a\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 33.16it/s, loss=0.0106, val_loss=0.0107, a\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.01, val_loss=0.0107, avg\u001b[A\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.01, val_loss=0.0102, avg\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.00942, val_loss=0.0102, \n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=0.00942, val_loss=0.00932,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00886, val_loss=0.00932,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00886, val_loss=0.00866,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00833, val_loss=0.00866,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.86it/s, loss=0.00833, val_loss=0.00818,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00783, val_loss=0.00818,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.62it/s, loss=0.00783, val_loss=0.00787,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.00735, val_loss=0.00787,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00735, val_loss=0.00744,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.0069, val_loss=0.00744, \n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.0069, val_loss=0.00665, \n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.00648, val_loss=0.00665,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=0.00648, val_loss=0.00624,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 22.14it/s, loss=0.00608, val_loss=0.00624,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 38.68it/s, loss=0.00608, val_loss=0.00593,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00571, val_loss=0.00593,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00571, val_loss=0.00564,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 22.13it/s, loss=0.00537, val_loss=0.00564,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.66it/s, loss=0.00537, val_loss=0.00523,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.00505, val_loss=0.00523,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.00505, val_loss=0.00486,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00475, val_loss=0.00486,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00475, val_loss=0.00458,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00448, val_loss=0.00458,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.00448, val_loss=0.00434,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00423, val_loss=0.00434,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.00423, val_loss=0.00412,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00401, val_loss=0.00412,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.00401, val_loss=0.00392,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.0038, val_loss=0.00392, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.76it/s, loss=0.0038, val_loss=0.00373, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.00361, val_loss=0.00373,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00361, val_loss=0.00357,\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00344, val_loss=0.00357,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00344, val_loss=0.00342,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.00329, val_loss=0.00342,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=0.00329, val_loss=0.00331,\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00315, val_loss=0.00331,\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.00315, val_loss=0.00316,\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=0.00303, val_loss=0.00316,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.00303, val_loss=0.00305,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.00292, val_loss=0.00305,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 38.65it/s, loss=0.00292, val_loss=0.00294,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00282, val_loss=0.00294,\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.00282, val_loss=0.00285,\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00273, val_loss=0.00285,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00273, val_loss=0.00277,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00265, val_loss=0.00277,\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.00265, val_loss=0.00267,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.00257, val_loss=0.00267,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.74it/s, loss=0.00257, val_loss=0.00263,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00251, val_loss=0.00263,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=0.00251, val_loss=0.00262,\n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00245, val_loss=0.00262,\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.00245, val_loss=0.00245,\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.0024, val_loss=0.00245, \n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.0024, val_loss=0.0024, a\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00235, val_loss=0.0024, \n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.00235, val_loss=0.00235,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.0023, val_loss=0.00235, \n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.0023, val_loss=0.0023, a\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00226, val_loss=0.0023, \n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.00226, val_loss=0.00227,\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00223, val_loss=0.00227,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.00223, val_loss=0.00223,\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00219, val_loss=0.00223,\n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00219, val_loss=0.00219,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00217, val_loss=0.00219,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00217, val_loss=0.00214,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00214, val_loss=0.00214,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=0.00214, val_loss=0.00211,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.00211, val_loss=0.00211,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00211, val_loss=0.00208,\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0021, val_loss=0.00208, \n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.0021, val_loss=0.00205, \n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00207, val_loss=0.00205,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00207, val_loss=0.00203,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00205, val_loss=0.00203,\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.00205, val_loss=0.00202,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00204, val_loss=0.00202,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00204, val_loss=0.00199,\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00202, val_loss=0.00199,\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00202, val_loss=0.00197,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00201, val_loss=0.00197,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 37.78it/s, loss=0.00201, val_loss=0.00197,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.002, val_loss=0.00197, a\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.002, val_loss=0.00194, a\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00197, val_loss=0.00194,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00197, val_loss=0.00194,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00197, val_loss=0.00194,\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.00197, val_loss=0.00193,\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.00196, val_loss=0.00193,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.00196, val_loss=0.0019, \n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=0.00194, val_loss=0.0019, \n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.00194, val_loss=0.00189,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00194, val_loss=0.00189,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.00194, val_loss=0.00187,\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00192, val_loss=0.00187,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.00192, val_loss=0.00186,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00191, val_loss=0.00186,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00191, val_loss=0.00186,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.00191, val_loss=0.00186,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00191, val_loss=0.00184,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.0019, val_loss=0.00184, \n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.0019, val_loss=0.00182, \n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00189, val_loss=0.00182,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.00189, val_loss=0.00183,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.00189, val_loss=0.00183,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=0.00189, val_loss=0.0018, \n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00187, val_loss=0.0018, \n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00187, val_loss=0.0018, \n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00187, val_loss=0.0018, \n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00187, val_loss=0.00181,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00187, val_loss=0.00181,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00187, val_loss=0.00178,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00185, val_loss=0.00178,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 38.08it/s, loss=0.00185, val_loss=0.00177,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.00185, val_loss=0.00177,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.00185, val_loss=0.00177,\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00185, val_loss=0.00177,\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00185, val_loss=0.00175,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00184, val_loss=0.00175,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00184, val_loss=0.00175,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00184, val_loss=0.00175,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00184, val_loss=0.00174,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00183, val_loss=0.00174,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00183, val_loss=0.00173,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00182, val_loss=0.00173,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.00182, val_loss=0.00173,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00182, val_loss=0.00173,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00182, val_loss=0.00172,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00182, val_loss=0.00172,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00182, val_loss=0.00171,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00181, val_loss=0.00171,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00181, val_loss=0.00172,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00181, val_loss=0.00172,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.00181, val_loss=0.00171,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.0018, val_loss=0.00171, \n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.0018, val_loss=0.0017, a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.0018, val_loss=0.0017, a\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.0018, val_loss=0.0017, a\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00179, val_loss=0.0017, \n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00179, val_loss=0.00168,\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00178, val_loss=0.00168,\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00178, val_loss=0.00168,\n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00179, val_loss=0.00168,\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.00179, val_loss=0.00168,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00178, val_loss=0.00168,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00178, val_loss=0.00166,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00177, val_loss=0.00166,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00177, val_loss=0.00166,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00178, val_loss=0.00166,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00178, val_loss=0.00167,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.55it/s, loss=0.00178, val_loss=0.00167,\n",
      "Sizes of clusters: 409, 391\n",
      "\n",
      "preds: [1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
      " 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1\n",
      " 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1\n",
      " 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.6887\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 22.16it/s, loss=178, val_loss=0.123, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.71it/s, loss=178, val_loss=3.76, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 22.26it/s, loss=2.9, val_loss=3.76, avg_val\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.87it/s, loss=2.9, val_loss=3.19, avg_val\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.504, val_loss=3.19, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.504, val_loss=0.305, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.144, val_loss=0.305, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.144, val_loss=0.0876, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 22.15it/s, loss=0.0661, val_loss=0.0876, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.70it/s, loss=0.0661, val_loss=0.0508, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.0455, val_loss=0.0508, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.0455, val_loss=0.0427, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.0377, val_loss=0.0427, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.0377, val_loss=0.0372, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.0331, val_loss=0.0372, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.82it/s, loss=0.0331, val_loss=0.0335, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.0296, val_loss=0.0335, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.70it/s, loss=0.0296, val_loss=0.0305, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=0.0267, val_loss=0.0305, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.0267, val_loss=0.0279, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 22.17it/s, loss=0.0243, val_loss=0.0279, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.73it/s, loss=0.0243, val_loss=0.0256, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.0222, val_loss=0.0256, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.0222, val_loss=0.0237, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.0204, val_loss=0.0237, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.0204, val_loss=0.022, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.17it/s, loss=0.0188, val_loss=0.022, av\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.73it/s, loss=0.0188, val_loss=0.0204, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.0173, val_loss=0.0204, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.0173, val_loss=0.0189, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.016, val_loss=0.0189, av\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.016, val_loss=0.0175, av\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.0148, val_loss=0.0175, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.0148, val_loss=0.0162, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.0137, val_loss=0.0162, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.82it/s, loss=0.0137, val_loss=0.015, av\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.0126, val_loss=0.015, av\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.0126, val_loss=0.0139, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.0117, val_loss=0.0139, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.0117, val_loss=0.0129, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.0108, val_loss=0.0129, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.0108, val_loss=0.0119, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00994, val_loss=0.0119, \n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00994, val_loss=0.011, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00917, val_loss=0.011, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.00917, val_loss=0.0101, \n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00847, val_loss=0.0101, \n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.82it/s, loss=0.00847, val_loss=0.00928,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00782, val_loss=0.00928,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00782, val_loss=0.00853,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.00722, val_loss=0.00853,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.85it/s, loss=0.00722, val_loss=0.00783,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=0.00668, val_loss=0.00783,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.00668, val_loss=0.00719,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.00619, val_loss=0.00719,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.00619, val_loss=0.00663,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00574, val_loss=0.00663,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00574, val_loss=0.00612,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 22.15it/s, loss=0.00534, val_loss=0.00612,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.71it/s, loss=0.00534, val_loss=0.00566,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00498, val_loss=0.00566,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=0.00498, val_loss=0.00525,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00466, val_loss=0.00525,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=0.00466, val_loss=0.00488,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.00437, val_loss=0.00488,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.78it/s, loss=0.00437, val_loss=0.00456,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.00412, val_loss=0.00456,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.78it/s, loss=0.00412, val_loss=0.00427,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00389, val_loss=0.00427,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00389, val_loss=0.00399,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.00369, val_loss=0.00399,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 38.76it/s, loss=0.00369, val_loss=0.00375,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00351, val_loss=0.00375,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 38.69it/s, loss=0.00351, val_loss=0.00355,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.00336, val_loss=0.00355,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.00336, val_loss=0.00337,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00322, val_loss=0.00337,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.76it/s, loss=0.00322, val_loss=0.00321,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.00309, val_loss=0.00321,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00309, val_loss=0.00308,\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00298, val_loss=0.00308,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00298, val_loss=0.00295,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.00288, val_loss=0.00295,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 38.65it/s, loss=0.00288, val_loss=0.00284,\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 22.13it/s, loss=0.0028, val_loss=0.00284, \n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 38.66it/s, loss=0.0028, val_loss=0.00274, \n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00272, val_loss=0.00274,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.00272, val_loss=0.00265,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.00265, val_loss=0.00265,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00265, val_loss=0.00257,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.00258, val_loss=0.00257,\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.72it/s, loss=0.00258, val_loss=0.00249,\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.00252, val_loss=0.00249,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 38.42it/s, loss=0.00252, val_loss=0.00243,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 22.21it/s, loss=0.00247, val_loss=0.00243,\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.00247, val_loss=0.00236,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.00242, val_loss=0.00236,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.64it/s, loss=0.00242, val_loss=0.00231,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00238, val_loss=0.00231,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00238, val_loss=0.00226,\n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00234, val_loss=0.00226,\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.00234, val_loss=0.00221,\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.0023, val_loss=0.00221, \n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.0023, val_loss=0.00217, \n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.00226, val_loss=0.00217,\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.76it/s, loss=0.00226, val_loss=0.00213,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00223, val_loss=0.00213,\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00223, val_loss=0.0021, \n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=0.0022, val_loss=0.0021, a\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.78it/s, loss=0.0022, val_loss=0.00207, \n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.00218, val_loss=0.00207,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00218, val_loss=0.00204,\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00215, val_loss=0.00204,\n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.00215, val_loss=0.00201,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.00213, val_loss=0.00201,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00213, val_loss=0.00198,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00211, val_loss=0.00198,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00211, val_loss=0.00196,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00208, val_loss=0.00196,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00208, val_loss=0.00194,\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.00206, val_loss=0.00194,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=0.00206, val_loss=0.00192,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 22.10it/s, loss=0.00204, val_loss=0.00192,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00204, val_loss=0.0019, \n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00203, val_loss=0.0019, \n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.00203, val_loss=0.00188,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00201, val_loss=0.00188,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00201, val_loss=0.00185,\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00199, val_loss=0.00185,\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00199, val_loss=0.00183,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00198, val_loss=0.00183,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.00198, val_loss=0.00181,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00196, val_loss=0.00181,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.00196, val_loss=0.0018, \n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.00195, val_loss=0.0018, \n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 38.42it/s, loss=0.00195, val_loss=0.00178,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00193, val_loss=0.00178,\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 38.03it/s, loss=0.00193, val_loss=0.00176,\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00192, val_loss=0.00176,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00192, val_loss=0.00174,\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00191, val_loss=0.00174,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.00191, val_loss=0.00173,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0019, val_loss=0.00173, \n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.0019, val_loss=0.00172, \n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.00188, val_loss=0.00172,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00188, val_loss=0.0017, \n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00187, val_loss=0.0017, \n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00187, val_loss=0.00168,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00186, val_loss=0.00168,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.00186, val_loss=0.00167,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00185, val_loss=0.00167,\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00185, val_loss=0.00166,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00184, val_loss=0.00166,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00184, val_loss=0.00164,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00183, val_loss=0.00164,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00183, val_loss=0.00163,\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00182, val_loss=0.00163,\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.00182, val_loss=0.00162,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00182, val_loss=0.00162,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00182, val_loss=0.0016, \n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00181, val_loss=0.0016, \n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00181, val_loss=0.00159,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0018, val_loss=0.00159, \n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.0018, val_loss=0.00158, \n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 21.92it/s, loss=0.00179, val_loss=0.00158,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 38.30it/s, loss=0.00179, val_loss=0.00157,\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00178, val_loss=0.00157,\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00178, val_loss=0.00156,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00178, val_loss=0.00156,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.00178, val_loss=0.00155,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00177, val_loss=0.00155,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00177, val_loss=0.00154,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00176, val_loss=0.00154,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00176, val_loss=0.00152,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00176, val_loss=0.00152,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.00176, val_loss=0.00151,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00175, val_loss=0.00151,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00175, val_loss=0.00149,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00174, val_loss=0.00149,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00174, val_loss=0.00148,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00174, val_loss=0.00148,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.00174, val_loss=0.00147,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00173, val_loss=0.00147,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00173, val_loss=0.00147,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00173, val_loss=0.00147,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00173, val_loss=0.00146,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00172, val_loss=0.00146,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.00172, val_loss=0.00145,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00172, val_loss=0.00145,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00172, val_loss=0.00145,\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 21.89it/s, loss=0.00172, val_loss=0.00145,\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 38.23it/s, loss=0.00172, val_loss=0.00144,\n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00171, val_loss=0.00144,\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.00171, val_loss=0.00143,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=0.00171, val_loss=0.00143,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.00171, val_loss=0.00143,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00171, val_loss=0.00143,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.00171, val_loss=0.00141,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.0017, val_loss=0.00141, \n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 36.98it/s, loss=0.0017, val_loss=0.00141, \n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 36.60it/s, loss=0.0017, val_loss=0.00141, \n",
      "Sizes of clusters: 456, 344\n",
      "\n",
      "preds: [1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.8000\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 22.20it/s, loss=150, val_loss=0.131, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.79it/s, loss=150, val_loss=3.83, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 22.24it/s, loss=1.94, val_loss=3.83, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.83it/s, loss=1.94, val_loss=2.2, avg_val\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.392, val_loss=2.2, avg_va\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.86it/s, loss=0.392, val_loss=0.434, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.117, val_loss=0.434, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.117, val_loss=0.103, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 22.13it/s, loss=0.0637, val_loss=0.103, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.66it/s, loss=0.0637, val_loss=0.0595, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.0479, val_loss=0.0595, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.82it/s, loss=0.0479, val_loss=0.0465, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.0406, val_loss=0.0465, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.0406, val_loss=0.04, avg_\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.0359, val_loss=0.04, avg_\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.0359, val_loss=0.0353, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.0321, val_loss=0.0353, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.81it/s, loss=0.0321, val_loss=0.0316, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.029, val_loss=0.0316, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.029, val_loss=0.0285, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 22.26it/s, loss=0.0263, val_loss=0.0285, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.86it/s, loss=0.0263, val_loss=0.026, av\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.024, val_loss=0.026, avg\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.72it/s, loss=0.024, val_loss=0.0238, av\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.022, val_loss=0.0238, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.022, val_loss=0.022, avg\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.23it/s, loss=0.0202, val_loss=0.022, av\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.82it/s, loss=0.0202, val_loss=0.0203, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 22.16it/s, loss=0.0186, val_loss=0.0203, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.70it/s, loss=0.0186, val_loss=0.0188, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=0.0172, val_loss=0.0188, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.0172, val_loss=0.0175, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.0159, val_loss=0.0175, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.0159, val_loss=0.0162, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.0148, val_loss=0.0162, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.0148, val_loss=0.0151, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.0137, val_loss=0.0151, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.0137, val_loss=0.0141, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.0127, val_loss=0.0141, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.0127, val_loss=0.0131, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0119, val_loss=0.0131, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.0119, val_loss=0.0122, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.011, val_loss=0.0122, av\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.011, val_loss=0.0114, av\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.0103, val_loss=0.0114, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.0103, val_loss=0.0106, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00964, val_loss=0.0106, \n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00964, val_loss=0.00991,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00903, val_loss=0.00991,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.00903, val_loss=0.00927,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00847, val_loss=0.00927,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00847, val_loss=0.00866,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00795, val_loss=0.00866,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00795, val_loss=0.00809,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00748, val_loss=0.00809,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.00748, val_loss=0.00759,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.00705, val_loss=0.00759,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.00705, val_loss=0.00712,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00666, val_loss=0.00712,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00666, val_loss=0.00669,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.0063, val_loss=0.00669, \n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.0063, val_loss=0.0063, a\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.00597, val_loss=0.0063, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.00597, val_loss=0.00594,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00566, val_loss=0.00594,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00566, val_loss=0.00563,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00538, val_loss=0.00563,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00538, val_loss=0.00535,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00513, val_loss=0.00535,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00513, val_loss=0.00508,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00489, val_loss=0.00508,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.00489, val_loss=0.00485,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00467, val_loss=0.00485,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 38.58it/s, loss=0.00467, val_loss=0.00462,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.00447, val_loss=0.00462,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 38.16it/s, loss=0.00447, val_loss=0.00442,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00429, val_loss=0.00442,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00429, val_loss=0.00423,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00412, val_loss=0.00423,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.55it/s, loss=0.00412, val_loss=0.00407,\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00396, val_loss=0.00407,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00396, val_loss=0.00392,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00382, val_loss=0.00392,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00382, val_loss=0.00377,\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00368, val_loss=0.00377,\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00368, val_loss=0.00365,\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00356, val_loss=0.00365,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.00356, val_loss=0.00353,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00344, val_loss=0.00353,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00344, val_loss=0.00342,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00334, val_loss=0.00342,\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00334, val_loss=0.00332,\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00324, val_loss=0.00332,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.00324, val_loss=0.00322,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00315, val_loss=0.00322,\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00315, val_loss=0.00314,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00307, val_loss=0.00314,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00307, val_loss=0.00305,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00299, val_loss=0.00305,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.00299, val_loss=0.00298,\n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00292, val_loss=0.00298,\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00292, val_loss=0.00291,\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00285, val_loss=0.00291,\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00285, val_loss=0.00284,\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00279, val_loss=0.00284,\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00279, val_loss=0.00278,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.00274, val_loss=0.00278,\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.00274, val_loss=0.00271,\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00268, val_loss=0.00271,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00268, val_loss=0.00266,\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00263, val_loss=0.00266,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00263, val_loss=0.0026, \n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00259, val_loss=0.0026, \n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 38.15it/s, loss=0.00259, val_loss=0.00255,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00254, val_loss=0.00255,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00254, val_loss=0.00251,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.0025, val_loss=0.00251, \n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.0025, val_loss=0.00246, \n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00247, val_loss=0.00246,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.00247, val_loss=0.00242,\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00243, val_loss=0.00242,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00243, val_loss=0.00239,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.0024, val_loss=0.00239, \n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.0024, val_loss=0.00235, \n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00237, val_loss=0.00235,\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.00237, val_loss=0.00233,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00234, val_loss=0.00233,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00234, val_loss=0.0023, \n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00231, val_loss=0.0023, \n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00231, val_loss=0.00227,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00229, val_loss=0.00227,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.00229, val_loss=0.00224,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00226, val_loss=0.00224,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00226, val_loss=0.00222,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00224, val_loss=0.00222,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.00224, val_loss=0.0022, \n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.42it/s, loss=0.00222, val_loss=0.0022, \n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.00222, val_loss=0.0022, \n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.0022, val_loss=0.0022, a\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.0022, val_loss=0.00215, \n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00218, val_loss=0.00215,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00218, val_loss=0.00213,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00217, val_loss=0.00213,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 38.08it/s, loss=0.00217, val_loss=0.00214,\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.00215, val_loss=0.00214,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 38.36it/s, loss=0.00215, val_loss=0.00208,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00212, val_loss=0.00208,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00212, val_loss=0.00207,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.00211, val_loss=0.00207,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00211, val_loss=0.00205,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.0021, val_loss=0.00205, \n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.0021, val_loss=0.00207, \n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00209, val_loss=0.00207,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00209, val_loss=0.00201,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00206, val_loss=0.00201,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.52it/s, loss=0.00206, val_loss=0.002, a\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00205, val_loss=0.002, a\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.00205, val_loss=0.00198,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00204, val_loss=0.00198,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00204, val_loss=0.00199,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00204, val_loss=0.00199,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00204, val_loss=0.00195,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00201, val_loss=0.00195,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.00201, val_loss=0.00194,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.002, val_loss=0.00194, a\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.002, val_loss=0.00193, a\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00199, val_loss=0.00193,\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00199, val_loss=0.00192,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00199, val_loss=0.00192,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.00199, val_loss=0.00195,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00198, val_loss=0.00195,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 38.51it/s, loss=0.00198, val_loss=0.00189,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00196, val_loss=0.00189,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00196, val_loss=0.00188,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00195, val_loss=0.00188,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 38.08it/s, loss=0.00195, val_loss=0.00187,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00194, val_loss=0.00187,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00194, val_loss=0.00189,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 22.05it/s, loss=0.00195, val_loss=0.00189,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00195, val_loss=0.00184,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00192, val_loss=0.00184,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.00192, val_loss=0.00185,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00192, val_loss=0.00185,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00192, val_loss=0.00183,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00191, val_loss=0.00183,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00191, val_loss=0.00183,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00191, val_loss=0.00183,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00191, val_loss=0.00188,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00191, val_loss=0.00188,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 38.54it/s, loss=0.00191, val_loss=0.0018, \n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00188, val_loss=0.0018, \n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 38.47it/s, loss=0.00188, val_loss=0.0018, \n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00188, val_loss=0.0018, \n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 37.83it/s, loss=0.00188, val_loss=0.00179,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00187, val_loss=0.00179,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.00187, val_loss=0.0018, \n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=0.00188, val_loss=0.0018, \n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.38it/s, loss=0.00188, val_loss=0.0018, \n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00187, val_loss=0.0018, \n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.00187, val_loss=0.00176,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.52it/s, loss=0.00187, val_loss=0.00176,\n",
      "Sizes of clusters: 445, 355\n",
      "\n",
      "preds: [1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.7563\n",
      "\n",
      "Consistency: 0.7986\n",
      "Purity: 0.7657499999999999+-0.04272440754416616\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K2_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=14.3, val_loss=0.182, avg_v\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 31.05it/s, loss=14.3, val_loss=0.182, avg_v\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.13it/s, loss=14.3, val_loss=3.96, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.35it/s, loss=0.424, val_loss=3.96, avg_v\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 24.09it/s, loss=0.424, val_loss=3.96, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 39.07it/s, loss=0.424, val_loss=0.332, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.0935, val_loss=0.332, avg\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.0935, val_loss=0.332, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.0935, val_loss=0.0718, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.0495, val_loss=0.0718, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.0495, val_loss=0.0718, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.0495, val_loss=0.0516, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.0383, val_loss=0.0516, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.0383, val_loss=0.0516, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.0383, val_loss=0.0423, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.0319, val_loss=0.0423, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.0319, val_loss=0.0423, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.0319, val_loss=0.0359, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.0271, val_loss=0.0359, av\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.0271, val_loss=0.0359, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.0271, val_loss=0.0308, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.0232, val_loss=0.0308, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.0232, val_loss=0.0308, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.0232, val_loss=0.0265, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.0199, val_loss=0.0265, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 31.30it/s, loss=0.0199, val_loss=0.0265, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=0.0199, val_loss=0.0229, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.0172, val_loss=0.0229, av\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 31.81it/s, loss=0.0172, val_loss=0.0229, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.0172, val_loss=0.0199, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.0149, val_loss=0.0199, a\u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.0149, val_loss=0.0199, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.63it/s, loss=0.0149, val_loss=0.0172, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.013, val_loss=0.0172, av\u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 31.73it/s, loss=0.013, val_loss=0.0172, av\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.013, val_loss=0.0149, av\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.0114, val_loss=0.0149, a\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 31.59it/s, loss=0.0114, val_loss=0.0149, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.75it/s, loss=0.0114, val_loss=0.0129, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.0101, val_loss=0.0129, a\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.0101, val_loss=0.0129, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.0101, val_loss=0.0112, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.00909, val_loss=0.0112, \u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 31.60it/s, loss=0.00909, val_loss=0.0112, \n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 38.76it/s, loss=0.00909, val_loss=0.00988,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00826, val_loss=0.00988,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00826, val_loss=0.00988,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00826, val_loss=0.00881,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00761, val_loss=0.00881,\u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 31.58it/s, loss=0.00761, val_loss=0.00881,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 38.74it/s, loss=0.00761, val_loss=0.00796,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00709, val_loss=0.00796,\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 31.65it/s, loss=0.00709, val_loss=0.00796,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.81it/s, loss=0.00709, val_loss=0.00729,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00667, val_loss=0.00729,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 31.55it/s, loss=0.00667, val_loss=0.00729,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00667, val_loss=0.00678,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00634, val_loss=0.00678,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00634, val_loss=0.00678,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00634, val_loss=0.00637,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00607, val_loss=0.00637,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 31.55it/s, loss=0.00607, val_loss=0.00637,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00607, val_loss=0.00606,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00585, val_loss=0.00606,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 31.81it/s, loss=0.00585, val_loss=0.00606,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00585, val_loss=0.00581,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00567, val_loss=0.00581,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 31.49it/s, loss=0.00567, val_loss=0.00581,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.65it/s, loss=0.00567, val_loss=0.00558,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00551, val_loss=0.00558,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00551, val_loss=0.00558,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00551, val_loss=0.00536,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00538, val_loss=0.00536,\u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.00538, val_loss=0.00536,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.65it/s, loss=0.00538, val_loss=0.00517,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00527, val_loss=0.00517,\u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00527, val_loss=0.00517,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00527, val_loss=0.005, a\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00517, val_loss=0.005, a\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00517, val_loss=0.005, a\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00517, val_loss=0.00485,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00508, val_loss=0.00485,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00508, val_loss=0.00485,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00508, val_loss=0.00471,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00501, val_loss=0.00471,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 31.78it/s, loss=0.00501, val_loss=0.00471,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00501, val_loss=0.00459,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00494, val_loss=0.00459,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.00494, val_loss=0.00459,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00494, val_loss=0.00447,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00488, val_loss=0.00447,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00488, val_loss=0.00447,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00488, val_loss=0.00437,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00483, val_loss=0.00437,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 31.49it/s, loss=0.00483, val_loss=0.00437,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 38.63it/s, loss=0.00483, val_loss=0.00427,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00478, val_loss=0.00427,\u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00478, val_loss=0.00427,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00478, val_loss=0.00419,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.00473, val_loss=0.00419,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 31.42it/s, loss=0.00473, val_loss=0.00419,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.00473, val_loss=0.00412,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00469, val_loss=0.00412,\u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00469, val_loss=0.00412,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00469, val_loss=0.00404,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00466, val_loss=0.00404,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 31.47it/s, loss=0.00466, val_loss=0.00404,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.00466, val_loss=0.00398,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00462, val_loss=0.00398,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00462, val_loss=0.00398,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00462, val_loss=0.00392,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00459, val_loss=0.00392,\u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 31.54it/s, loss=0.00459, val_loss=0.00392,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.00459, val_loss=0.00386,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00456, val_loss=0.00386,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.00456, val_loss=0.00386,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00456, val_loss=0.00381,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00453, val_loss=0.00381,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 31.55it/s, loss=0.00453, val_loss=0.00381,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00453, val_loss=0.00376,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00451, val_loss=0.00376,\u001b[A\n",
      "Epoch 40:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00451, val_loss=0.00376,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00451, val_loss=0.00371,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00448, val_loss=0.00371,\u001b[A\n",
      "Epoch 41:  75%|▊| 36/48 [00:01<00:00, 31.52it/s, loss=0.00448, val_loss=0.00371,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00448, val_loss=0.00366,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00446, val_loss=0.00366,\u001b[A\n",
      "Epoch 42:  75%|▊| 36/48 [00:01<00:00, 31.71it/s, loss=0.00446, val_loss=0.00366,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.00446, val_loss=0.00362,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00444, val_loss=0.00362,\u001b[A\n",
      "Epoch 43:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00444, val_loss=0.00362,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00444, val_loss=0.00357,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00442, val_loss=0.00357,\u001b[A\n",
      "Epoch 44:  75%|▊| 36/48 [00:01<00:00, 31.80it/s, loss=0.00442, val_loss=0.00357,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00442, val_loss=0.00353,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.0044, val_loss=0.00353, \u001b[A\n",
      "Epoch 45:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.0044, val_loss=0.00353, \n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.0044, val_loss=0.00349, \u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00439, val_loss=0.00349,\u001b[A\n",
      "Epoch 46:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00439, val_loss=0.00349,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00439, val_loss=0.00345,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00437, val_loss=0.00345,\u001b[A\n",
      "Epoch 47:  75%|▊| 36/48 [00:01<00:00, 31.54it/s, loss=0.00437, val_loss=0.00345,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.00437, val_loss=0.00342,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00436, val_loss=0.00342,\u001b[A\n",
      "Epoch 48:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00436, val_loss=0.00342,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00436, val_loss=0.0034, \u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00434, val_loss=0.0034, \u001b[A\n",
      "Epoch 49:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00434, val_loss=0.0034, \n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00434, val_loss=0.00337,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00433, val_loss=0.00337,\u001b[A\n",
      "Epoch 50:  75%|▊| 36/48 [00:01<00:00, 31.78it/s, loss=0.00433, val_loss=0.00337,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00433, val_loss=0.00334,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00432, val_loss=0.00334,\u001b[A\n",
      "Epoch 51:  75%|▊| 36/48 [00:01<00:00, 31.75it/s, loss=0.00432, val_loss=0.00334,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00432, val_loss=0.00332,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00431, val_loss=0.00332,\u001b[A\n",
      "Epoch 52:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00431, val_loss=0.00332,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.00431, val_loss=0.0033, \u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.0043, val_loss=0.0033, a\u001b[A\n",
      "Epoch 53:  75%|▊| 36/48 [00:01<00:00, 31.81it/s, loss=0.0043, val_loss=0.0033, a\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.0043, val_loss=0.00327, \u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00429, val_loss=0.00327,\u001b[A\n",
      "Epoch 54:  75%|▊| 36/48 [00:01<00:00, 31.52it/s, loss=0.00429, val_loss=0.00327,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00429, val_loss=0.00324,\u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00428, val_loss=0.00324,\u001b[A\n",
      "Epoch 55:  75%|▊| 36/48 [00:01<00:00, 31.75it/s, loss=0.00428, val_loss=0.00324,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00428, val_loss=0.00321,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00427, val_loss=0.00321,\u001b[A\n",
      "Epoch 56:  75%|▊| 36/48 [00:01<00:00, 31.51it/s, loss=0.00427, val_loss=0.00321,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00427, val_loss=0.00318,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00426, val_loss=0.00318,\u001b[A\n",
      "Epoch 57:  75%|▊| 36/48 [00:01<00:00, 31.78it/s, loss=0.00426, val_loss=0.00318,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00426, val_loss=0.00316,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00426, val_loss=0.00316,\u001b[A\n",
      "Epoch 58:  75%|▊| 36/48 [00:01<00:00, 31.55it/s, loss=0.00426, val_loss=0.00316,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00426, val_loss=0.00314,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00425, val_loss=0.00314,\u001b[A\n",
      "Epoch 59:  75%|▊| 36/48 [00:01<00:00, 31.80it/s, loss=0.00425, val_loss=0.00314,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00425, val_loss=0.00312,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00425, val_loss=0.00312,\u001b[A\n",
      "Epoch 60:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.00425, val_loss=0.00312,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.64it/s, loss=0.00425, val_loss=0.0031, \u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00424, val_loss=0.0031, \u001b[A\n",
      "Epoch 61:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.00424, val_loss=0.0031, \n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00424, val_loss=0.00308,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.00424, val_loss=0.00308,\u001b[A\n",
      "Epoch 62:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.00424, val_loss=0.00308,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 38.64it/s, loss=0.00424, val_loss=0.00307,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00423, val_loss=0.00307,\u001b[A\n",
      "Epoch 63:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.00423, val_loss=0.00307,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00423, val_loss=0.00305,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.00423, val_loss=0.00305,\u001b[A\n",
      "Epoch 64:  75%|▊| 36/48 [00:01<00:00, 31.22it/s, loss=0.00423, val_loss=0.00305,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=0.00423, val_loss=0.00304,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00422, val_loss=0.00304,\u001b[A\n",
      "Epoch 65:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.00422, val_loss=0.00304,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00422, val_loss=0.00303,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00422, val_loss=0.00303,\u001b[A\n",
      "Epoch 66:  75%|▊| 36/48 [00:01<00:00, 31.37it/s, loss=0.00422, val_loss=0.00303,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 38.50it/s, loss=0.00422, val_loss=0.00302,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00422, val_loss=0.00302,\u001b[A\n",
      "Epoch 67:  75%|▊| 36/48 [00:01<00:00, 31.80it/s, loss=0.00422, val_loss=0.00302,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00422, val_loss=0.00301,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00421, val_loss=0.00301,\u001b[A\n",
      "Epoch 68:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00421, val_loss=0.00301,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00421, val_loss=0.003, a\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00421, val_loss=0.003, a\u001b[A\n",
      "Epoch 69:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.00421, val_loss=0.003, a\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00421, val_loss=0.00299,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00421, val_loss=0.00299,\u001b[A\n",
      "Epoch 70:  75%|▊| 36/48 [00:01<00:00, 31.57it/s, loss=0.00421, val_loss=0.00299,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00421, val_loss=0.00299,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00421, val_loss=0.00299,\u001b[A\n",
      "Epoch 71:  75%|▊| 36/48 [00:01<00:00, 31.78it/s, loss=0.00421, val_loss=0.00299,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00421, val_loss=0.00298,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00421, val_loss=0.00298,\u001b[A\n",
      "Epoch 72:  75%|▊| 36/48 [00:01<00:00, 31.52it/s, loss=0.00421, val_loss=0.00298,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00421, val_loss=0.00297,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.0042, val_loss=0.00297, \u001b[A\n",
      "Epoch 73:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.0042, val_loss=0.00297, \n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.0042, val_loss=0.00297, \u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.0042, val_loss=0.00297, \u001b[A\n",
      "Epoch 74:  75%|▊| 36/48 [00:01<00:00, 31.51it/s, loss=0.0042, val_loss=0.00297, \n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 38.65it/s, loss=0.0042, val_loss=0.00296, \u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.0042, val_loss=0.00296, \u001b[A\n",
      "Epoch 75:  75%|▊| 36/48 [00:01<00:00, 31.80it/s, loss=0.0042, val_loss=0.00296, \n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.0042, val_loss=0.00295, \u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.0042, val_loss=0.00295, \u001b[A\n",
      "Epoch 76:  75%|▊| 36/48 [00:01<00:00, 31.78it/s, loss=0.0042, val_loss=0.00295, \n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.0042, val_loss=0.00295, \u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.0042, val_loss=0.00295, \u001b[A\n",
      "Epoch 77:  75%|▊| 36/48 [00:01<00:00, 31.52it/s, loss=0.0042, val_loss=0.00295, \n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.0042, val_loss=0.00294, \u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.0042, val_loss=0.00294, \u001b[A\n",
      "Epoch 78:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.0042, val_loss=0.00294, \n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.0042, val_loss=0.00293, \u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.0042, val_loss=0.00293, \u001b[A\n",
      "Epoch 79:  75%|▊| 36/48 [00:01<00:00, 31.33it/s, loss=0.0042, val_loss=0.00293, \n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 38.46it/s, loss=0.0042, val_loss=0.00293, \u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.0042, val_loss=0.00293, \u001b[A\n",
      "Epoch 80:  75%|▊| 36/48 [00:01<00:00, 31.77it/s, loss=0.0042, val_loss=0.00293, \n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.0042, val_loss=0.00292, \u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.0042, val_loss=0.00292, \u001b[A\n",
      "Epoch 81:  75%|▊| 36/48 [00:01<00:00, 31.43it/s, loss=0.0042, val_loss=0.00292, \n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 38.57it/s, loss=0.0042, val_loss=0.00291, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 22.24it/s, loss=0.0042, val_loss=0.00291, \u001b[A\n",
      "Epoch 82:  75%|▊| 36/48 [00:01<00:00, 31.72it/s, loss=0.0042, val_loss=0.00291, \n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 38.90it/s, loss=0.0042, val_loss=0.00291, \u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.0042, val_loss=0.00291, \u001b[A\n",
      "Epoch 83:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.0042, val_loss=0.00291, \n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 84:  75%|▊| 36/48 [00:01<00:00, 31.75it/s, loss=0.0042, val_loss=0.0029, a\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 85:  75%|▊| 36/48 [00:01<00:00, 31.54it/s, loss=0.0042, val_loss=0.0029, a\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 22.22it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 86:  75%|▊| 36/48 [00:01<00:00, 31.69it/s, loss=0.0042, val_loss=0.0029, a\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.0042, val_loss=0.0029, a\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00421, val_loss=0.0029, \u001b[A\n",
      "Epoch 87:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00421, val_loss=0.0029, \n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00421, val_loss=0.0029, \u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00421, val_loss=0.0029, \u001b[A\n",
      "Epoch 88:  75%|▊| 36/48 [00:01<00:00, 31.81it/s, loss=0.00421, val_loss=0.0029, \n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00421, val_loss=0.00289,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00421, val_loss=0.00289,\u001b[A\n",
      "Epoch 89:  75%|▊| 36/48 [00:01<00:00, 31.45it/s, loss=0.00421, val_loss=0.00289,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00421, val_loss=0.00289,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00421, val_loss=0.00289,\u001b[A\n",
      "Epoch 90:  75%|▊| 36/48 [00:01<00:00, 31.81it/s, loss=0.00421, val_loss=0.00289,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00421, val_loss=0.00287,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00421, val_loss=0.00287,\u001b[A\n",
      "Epoch 91:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.00421, val_loss=0.00287,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 38.64it/s, loss=0.00421, val_loss=0.00286,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00422, val_loss=0.00286,\u001b[A\n",
      "Epoch 92:  75%|▊| 36/48 [00:01<00:00, 31.71it/s, loss=0.00422, val_loss=0.00286,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.00422, val_loss=0.00285,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00422, val_loss=0.00285,\u001b[A\n",
      "Epoch 93:  75%|▊| 36/48 [00:01<00:00, 31.55it/s, loss=0.00422, val_loss=0.00285,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00422, val_loss=0.00284,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00422, val_loss=0.00284,\u001b[A\n",
      "Epoch 94:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00422, val_loss=0.00284,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00422, val_loss=0.00283,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00422, val_loss=0.00283,\u001b[A\n",
      "Epoch 95:  75%|▊| 36/48 [00:01<00:00, 31.54it/s, loss=0.00422, val_loss=0.00283,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00422, val_loss=0.00283,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00422, val_loss=0.00283,\u001b[A\n",
      "Epoch 96:  75%|▊| 36/48 [00:01<00:00, 31.79it/s, loss=0.00422, val_loss=0.00283,\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00422, val_loss=0.00282,\u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00423, val_loss=0.00282,\u001b[A\n",
      "Epoch 97:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.00423, val_loss=0.00282,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00423, val_loss=0.00281,\u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00423, val_loss=0.00281,\u001b[A\n",
      "Epoch 98:  75%|▊| 36/48 [00:01<00:00, 31.80it/s, loss=0.00423, val_loss=0.00281,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00423, val_loss=0.0028, \u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00428, val_loss=0.0028, \u001b[A\n",
      "Epoch 99:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00428, val_loss=0.0028, \n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00428, val_loss=0.00377,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=0.00428, val_loss=0.00377,\u001b[A\n",
      "Sizes of clusters: 490, 384, 326\n",
      "\n",
      "preds: [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 2 0 1\n",
      " 0 2 0 1 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 2 2 0 2 2 0 0 0 0 1 0 0 1 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 2 0 0 0 1 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 0 2 0 2 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0\n",
      " 2 0 0 2 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 2 1 0 2 0 0 0 0 0 0 0 0 2\n",
      " 2 0 0 0 0 0 0 2 0 0 0 0 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 2 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0\n",
      " 0 2 0 0 0 0 2 0 0 2 2 0 2 0 2 1 0 2 0 0 2 0 0 2 0 0 0 0 2 2 2 0 0 2 0 0 2\n",
      " 2 2 2 0 2 2 0 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 0 2 0 2 2 2 0 0 2 0\n",
      " 0 2 0 2 2 0 0 2 2 2 0 2 2 2 0 0 2 0 2 2 0 2 2 0 0 2 0 0 0 2 2 0 0 2 2 0 2\n",
      " 0 2 2 0 2 2 2 0 0 0 2 2 2 0 2 0 0 2 2 0 2 0 2 2 0 0 2 2 0 2 2 0 2 0 0 2 0\n",
      " 0 2 2 0 0 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 0 0 0 2 0 2 0 2\n",
      " 2 2 0 2 0 2 2 2 0 2 2 0 0 0 2 0 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 0 0\n",
      " 2 0 2 2 2 2 0 2 0 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 0 0 2\n",
      " 0 2 2 2 2 2 0 0 0 2 2 0 2 0 2 0 0 2 2 2 2 2 0 0 2 0 2 2 2 0 2 0 0 2 0 2 2\n",
      " 0 2 2 2 0 2 2 2 0 2 2 2 0 0 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 0 2 2 2 0 2\n",
      " 2 2 0 0 0 0 2 2 2 2 2 0 2 0 2 0 2 0 2 0 2 2 0 2 2 0 2 2 2 2 0 0 2 2 2 2 2\n",
      " 2 2 0 0 0 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 0 2 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 0 0 0 0 2 0 0 2 2 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.7867\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 22.50it/s, loss=20.9, val_loss=0.19, avg_va\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 39.32it/s, loss=20.9, val_loss=5.48, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.51it/s, loss=0.661, val_loss=5.48, avg_v\u001b[A\n",
      "Epoch 1:  83%|▊| 40/48 [00:01<00:00, 34.90it/s, loss=0.661, val_loss=5.48, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 39.34it/s, loss=0.661, val_loss=0.488, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 22.33it/s, loss=0.101, val_loss=0.488, avg_\u001b[A\n",
      "Epoch 2:  83%|▊| 40/48 [00:01<00:00, 34.64it/s, loss=0.101, val_loss=0.488, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 39.05it/s, loss=0.101, val_loss=0.0746, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.049, val_loss=0.0746, avg\u001b[A\n",
      "Epoch 3:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.049, val_loss=0.0746, avg\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.049, val_loss=0.0488, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 22.21it/s, loss=0.0387, val_loss=0.0488, av\u001b[A\n",
      "Epoch 4:  83%|▊| 40/48 [00:01<00:00, 34.47it/s, loss=0.0387, val_loss=0.0488, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.0387, val_loss=0.0404, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.0336, val_loss=0.0404, av\u001b[A\n",
      "Epoch 5:  83%|▊| 40/48 [00:01<00:00, 34.82it/s, loss=0.0336, val_loss=0.0404, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 39.23it/s, loss=0.0336, val_loss=0.0355, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.0298, val_loss=0.0355, av\u001b[A\n",
      "Epoch 6:  83%|▊| 40/48 [00:01<00:00, 33.94it/s, loss=0.0298, val_loss=0.0355, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.0298, val_loss=0.0317, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.0267, val_loss=0.0317, av\u001b[A\n",
      "Epoch 7:  83%|▊| 40/48 [00:01<00:00, 34.77it/s, loss=0.0267, val_loss=0.0317, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 39.19it/s, loss=0.0267, val_loss=0.0284, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.0241, val_loss=0.0284, av\u001b[A\n",
      "Epoch 8:  83%|▊| 40/48 [00:01<00:00, 34.61it/s, loss=0.0241, val_loss=0.0284, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 39.02it/s, loss=0.0241, val_loss=0.0255, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 22.47it/s, loss=0.0219, val_loss=0.0255, av\u001b[A\n",
      "Epoch 9:  83%|▊| 40/48 [00:01<00:00, 34.84it/s, loss=0.0219, val_loss=0.0255, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 39.17it/s, loss=0.0219, val_loss=0.0229, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 22.24it/s, loss=0.0198, val_loss=0.0229, a\u001b[A\n",
      "Epoch 10:  83%|▊| 40/48 [00:01<00:00, 34.51it/s, loss=0.0198, val_loss=0.0229, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.90it/s, loss=0.0198, val_loss=0.0206, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.018, val_loss=0.0206, av\u001b[A\n",
      "Epoch 11:  83%|▊| 40/48 [00:01<00:00, 34.83it/s, loss=0.018, val_loss=0.0206, av\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 39.25it/s, loss=0.018, val_loss=0.0185, av\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 22.33it/s, loss=0.0163, val_loss=0.0185, a\u001b[A\n",
      "Epoch 12:  83%|▊| 40/48 [00:01<00:00, 34.63it/s, loss=0.0163, val_loss=0.0185, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 39.03it/s, loss=0.0163, val_loss=0.0165, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 22.41it/s, loss=0.0147, val_loss=0.0165, a\u001b[A\n",
      "Epoch 13:  83%|▊| 40/48 [00:01<00:00, 34.75it/s, loss=0.0147, val_loss=0.0165, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 39.18it/s, loss=0.0147, val_loss=0.0147, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 22.33it/s, loss=0.0133, val_loss=0.0147, a\u001b[A\n",
      "Epoch 14:  83%|▊| 40/48 [00:01<00:00, 34.64it/s, loss=0.0133, val_loss=0.0147, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 39.05it/s, loss=0.0133, val_loss=0.013, av\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 22.47it/s, loss=0.0119, val_loss=0.013, av\u001b[A\n",
      "Epoch 15:  83%|▊| 40/48 [00:01<00:00, 34.85it/s, loss=0.0119, val_loss=0.013, av\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 39.27it/s, loss=0.0119, val_loss=0.0114, a\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 22.33it/s, loss=0.0106, val_loss=0.0114, a\u001b[A\n",
      "Epoch 16:  83%|▊| 40/48 [00:01<00:00, 34.63it/s, loss=0.0106, val_loss=0.0114, a\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 39.05it/s, loss=0.0106, val_loss=0.00986, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00943, val_loss=0.00986,\u001b[A\n",
      "Epoch 17:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.00943, val_loss=0.00986,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.77it/s, loss=0.00943, val_loss=0.00842,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.00838, val_loss=0.00842,\u001b[A\n",
      "Epoch 18:  83%|▊| 40/48 [00:01<00:00, 34.13it/s, loss=0.00838, val_loss=0.00842,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.51it/s, loss=0.00838, val_loss=0.00713,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.00749, val_loss=0.00713,\u001b[A\n",
      "Epoch 19:  83%|▊| 40/48 [00:01<00:00, 34.74it/s, loss=0.00749, val_loss=0.00713,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 39.20it/s, loss=0.00749, val_loss=0.00607,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00675, val_loss=0.00607,\u001b[A\n",
      "Epoch 20:  83%|▊| 40/48 [00:01<00:00, 34.15it/s, loss=0.00675, val_loss=0.00607,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.53it/s, loss=0.00675, val_loss=0.00525,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.00616, val_loss=0.00525,\u001b[A\n",
      "Epoch 21:  83%|▊| 40/48 [00:01<00:00, 34.81it/s, loss=0.00616, val_loss=0.00525,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 39.25it/s, loss=0.00616, val_loss=0.00462,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 22.32it/s, loss=0.0057, val_loss=0.00462, \u001b[A\n",
      "Epoch 22:  83%|▊| 40/48 [00:01<00:00, 34.63it/s, loss=0.0057, val_loss=0.00462, \n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 39.04it/s, loss=0.0057, val_loss=0.00415, \u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.00535, val_loss=0.00415,\u001b[A\n",
      "Epoch 23:  83%|▊| 40/48 [00:01<00:00, 34.51it/s, loss=0.00535, val_loss=0.00415,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00535, val_loss=0.00379,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00508, val_loss=0.00379,\u001b[A\n",
      "Epoch 24:  83%|▊| 40/48 [00:01<00:00, 34.35it/s, loss=0.00508, val_loss=0.00379,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.00508, val_loss=0.00352,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 22.45it/s, loss=0.00487, val_loss=0.00352,\u001b[A\n",
      "Epoch 25:  83%|▊| 40/48 [00:01<00:00, 34.82it/s, loss=0.00487, val_loss=0.00352,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 39.24it/s, loss=0.00487, val_loss=0.00331,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 22.47it/s, loss=0.00471, val_loss=0.00331,\u001b[A\n",
      "Epoch 26:  83%|▊| 40/48 [00:01<00:00, 34.84it/s, loss=0.00471, val_loss=0.00331,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 39.25it/s, loss=0.00471, val_loss=0.00314,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00458, val_loss=0.00314,\u001b[A\n",
      "Epoch 27:  83%|▊| 40/48 [00:01<00:00, 34.27it/s, loss=0.00458, val_loss=0.00314,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00458, val_loss=0.00301,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00448, val_loss=0.00301,\u001b[A\n",
      "Epoch 28:  83%|▊| 40/48 [00:01<00:00, 34.52it/s, loss=0.00448, val_loss=0.00301,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00448, val_loss=0.00291,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.0044, val_loss=0.00291, \u001b[A\n",
      "Epoch 29:  83%|▊| 40/48 [00:01<00:00, 33.95it/s, loss=0.0044, val_loss=0.00291, \n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.0044, val_loss=0.00283, \u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00433, val_loss=0.00283,\u001b[A\n",
      "Epoch 30:  83%|▊| 40/48 [00:01<00:00, 34.29it/s, loss=0.00433, val_loss=0.00283,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.00433, val_loss=0.00277,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.00428, val_loss=0.00277,\u001b[A\n",
      "Epoch 31:  83%|▊| 40/48 [00:01<00:00, 34.25it/s, loss=0.00428, val_loss=0.00277,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00428, val_loss=0.00272,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00424, val_loss=0.00272,\u001b[A\n",
      "Epoch 32:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00424, val_loss=0.00272,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00424, val_loss=0.00267,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00421, val_loss=0.00267,\u001b[A\n",
      "Epoch 33:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00421, val_loss=0.00267,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00421, val_loss=0.00264,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00418, val_loss=0.00264,\u001b[A\n",
      "Epoch 34:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.00418, val_loss=0.00264,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00418, val_loss=0.0026, \u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00416, val_loss=0.0026, \u001b[A\n",
      "Epoch 35:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00416, val_loss=0.0026, \n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00416, val_loss=0.00258,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00414, val_loss=0.00258,\u001b[A\n",
      "Epoch 36:  83%|▊| 40/48 [00:01<00:00, 33.58it/s, loss=0.00414, val_loss=0.00258,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00414, val_loss=0.00255,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00413, val_loss=0.00255,\u001b[A\n",
      "Epoch 37:  83%|▊| 40/48 [00:01<00:00, 34.27it/s, loss=0.00413, val_loss=0.00255,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00413, val_loss=0.00253,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00412, val_loss=0.00253,\u001b[A\n",
      "Epoch 38:  83%|▊| 40/48 [00:01<00:00, 34.50it/s, loss=0.00412, val_loss=0.00253,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.92it/s, loss=0.00412, val_loss=0.00251,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00411, val_loss=0.00251,\u001b[A\n",
      "Epoch 39:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00411, val_loss=0.00251,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 38.59it/s, loss=0.00411, val_loss=0.00249,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.0041, val_loss=0.00249, \u001b[A\n",
      "Epoch 40:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.0041, val_loss=0.00249, \n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.0041, val_loss=0.00248, \u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00409, val_loss=0.00248,\u001b[A\n",
      "Epoch 41:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00409, val_loss=0.00248,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00409, val_loss=0.00247,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 22.20it/s, loss=0.00408, val_loss=0.00247,\u001b[A\n",
      "Epoch 42:  83%|▊| 40/48 [00:01<00:00, 34.41it/s, loss=0.00408, val_loss=0.00247,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 38.81it/s, loss=0.00408, val_loss=0.00246,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.00408, val_loss=0.00246,\u001b[A\n",
      "Epoch 43:  83%|▊| 40/48 [00:01<00:00, 33.79it/s, loss=0.00408, val_loss=0.00246,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 38.15it/s, loss=0.00408, val_loss=0.00245,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00407, val_loss=0.00245,\u001b[A\n",
      "Epoch 44:  83%|▊| 40/48 [00:01<00:00, 33.98it/s, loss=0.00407, val_loss=0.00245,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00407, val_loss=0.00244,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00407, val_loss=0.00244,\u001b[A\n",
      "Epoch 45:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00407, val_loss=0.00244,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00407, val_loss=0.00243,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00406, val_loss=0.00243,\u001b[A\n",
      "Epoch 46:  83%|▊| 40/48 [00:01<00:00, 34.40it/s, loss=0.00406, val_loss=0.00243,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.00406, val_loss=0.00243,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00406, val_loss=0.00243,\u001b[A\n",
      "Epoch 47:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00406, val_loss=0.00243,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00406, val_loss=0.00242,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00406, val_loss=0.00242,\u001b[A\n",
      "Epoch 48:  83%|▊| 40/48 [00:01<00:00, 34.52it/s, loss=0.00406, val_loss=0.00242,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 38.92it/s, loss=0.00406, val_loss=0.00241,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 49:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.00405, val_loss=0.00241,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 38.37it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 50:  83%|▊| 40/48 [00:01<00:00, 33.85it/s, loss=0.00405, val_loss=0.00241,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 51:  83%|▊| 40/48 [00:01<00:00, 34.52it/s, loss=0.00405, val_loss=0.00241,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 52:  83%|▊| 40/48 [00:01<00:00, 34.18it/s, loss=0.00405, val_loss=0.00241,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.00405, val_loss=0.00241,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.00404, val_loss=0.00241,\u001b[A\n",
      "Epoch 53:  83%|▊| 40/48 [00:01<00:00, 34.14it/s, loss=0.00404, val_loss=0.00241,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 38.46it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 54:  83%|▊| 40/48 [00:01<00:00, 34.16it/s, loss=0.00404, val_loss=0.0024, \n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 38.57it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 22.24it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 55:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.00404, val_loss=0.0024, \n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 56:  83%|▊| 40/48 [00:01<00:00, 33.76it/s, loss=0.00404, val_loss=0.0024, \n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 57:  83%|▊| 40/48 [00:01<00:00, 34.46it/s, loss=0.00404, val_loss=0.0024, \n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00404, val_loss=0.0024, \u001b[A\n",
      "Epoch 58:  83%|▊| 40/48 [00:01<00:00, 34.22it/s, loss=0.00404, val_loss=0.0024, \n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.00404, val_loss=0.00239,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00404, val_loss=0.00239,\u001b[A\n",
      "Epoch 59:  83%|▊| 40/48 [00:01<00:00, 34.44it/s, loss=0.00404, val_loss=0.00239,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.00404, val_loss=0.00239,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00404, val_loss=0.00239,\u001b[A\n",
      "Epoch 60:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00404, val_loss=0.00239,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00404, val_loss=0.00238,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 22.20it/s, loss=0.00405, val_loss=0.00238,\u001b[A\n",
      "Epoch 61:  83%|▊| 40/48 [00:01<00:00, 34.41it/s, loss=0.00405, val_loss=0.00238,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 38.82it/s, loss=0.00405, val_loss=0.00238,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.00405, val_loss=0.00238,\u001b[A\n",
      "Epoch 62:  83%|▊| 40/48 [00:01<00:00, 33.80it/s, loss=0.00405, val_loss=0.00238,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.00405, val_loss=0.00236,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.00405, val_loss=0.00236,\u001b[A\n",
      "Epoch 63:  83%|▊| 40/48 [00:01<00:00, 34.49it/s, loss=0.00405, val_loss=0.00236,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 38.91it/s, loss=0.00405, val_loss=0.00239,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00403, val_loss=0.00239,\u001b[A\n",
      "Epoch 64:  83%|▊| 40/48 [00:01<00:00, 34.22it/s, loss=0.00403, val_loss=0.00239,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.00403, val_loss=0.0024, \u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 22.22it/s, loss=0.00397, val_loss=0.0024, \u001b[A\n",
      "Epoch 65:  83%|▊| 40/48 [00:01<00:00, 34.44it/s, loss=0.00397, val_loss=0.0024, \n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.00397, val_loss=0.0031, \u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00423, val_loss=0.0031, \u001b[A\n",
      "Epoch 66:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00423, val_loss=0.0031, \n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 38.59it/s, loss=0.00423, val_loss=0.00281,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.0042, val_loss=0.00281, \u001b[A\n",
      "Epoch 67:  83%|▊| 40/48 [00:01<00:00, 34.50it/s, loss=0.0042, val_loss=0.00281, \n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 38.91it/s, loss=0.0042, val_loss=0.00291, \u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00415, val_loss=0.00291,\u001b[A\n",
      "Epoch 68:  83%|▊| 40/48 [00:01<00:00, 34.16it/s, loss=0.00415, val_loss=0.00291,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 38.54it/s, loss=0.00415, val_loss=0.00255,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00406, val_loss=0.00255,\u001b[A\n",
      "Epoch 69:  83%|▊| 40/48 [00:01<00:00, 33.97it/s, loss=0.00406, val_loss=0.00255,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00406, val_loss=0.00281,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00417, val_loss=0.00281,\u001b[A\n",
      "Epoch 70:  83%|▊| 40/48 [00:01<00:00, 34.21it/s, loss=0.00417, val_loss=0.00281,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 38.62it/s, loss=0.00417, val_loss=0.00253,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 22.20it/s, loss=0.00409, val_loss=0.00253,\u001b[A\n",
      "Epoch 71:  83%|▊| 40/48 [00:01<00:00, 34.42it/s, loss=0.00409, val_loss=0.00253,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 38.81it/s, loss=0.00409, val_loss=0.00269,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00413, val_loss=0.00269,\u001b[A\n",
      "Epoch 72:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00413, val_loss=0.00269,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 38.59it/s, loss=0.00413, val_loss=0.00245,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00406, val_loss=0.00245,\u001b[A\n",
      "Epoch 73:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.00406, val_loss=0.00245,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.00406, val_loss=0.00261,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 22.01it/s, loss=0.00412, val_loss=0.00261,\u001b[A\n",
      "Epoch 74:  83%|▊| 40/48 [00:01<00:00, 34.13it/s, loss=0.00412, val_loss=0.00261,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.00412, val_loss=0.0024, \u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00406, val_loss=0.0024, \u001b[A\n",
      "Epoch 75:  83%|▊| 40/48 [00:01<00:00, 34.33it/s, loss=0.00406, val_loss=0.0024, \n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 38.75it/s, loss=0.00406, val_loss=0.00255,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.0041, val_loss=0.00255, \u001b[A\n",
      "Epoch 76:  83%|▊| 40/48 [00:01<00:00, 34.51it/s, loss=0.0041, val_loss=0.00255, \n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 38.92it/s, loss=0.0041, val_loss=0.00236, \u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00406, val_loss=0.00236,\u001b[A\n",
      "Epoch 77:  83%|▊| 40/48 [00:01<00:00, 33.80it/s, loss=0.00406, val_loss=0.00236,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.00406, val_loss=0.00249,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 22.21it/s, loss=0.00409, val_loss=0.00249,\u001b[A\n",
      "Epoch 78:  83%|▊| 40/48 [00:01<00:00, 34.43it/s, loss=0.00409, val_loss=0.00249,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 38.83it/s, loss=0.00409, val_loss=0.00232,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00406, val_loss=0.00232,\u001b[A\n",
      "Epoch 79:  83%|▊| 40/48 [00:01<00:00, 34.18it/s, loss=0.00406, val_loss=0.00232,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00406, val_loss=0.00246,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00409, val_loss=0.00246,\u001b[A\n",
      "Epoch 80:  83%|▊| 40/48 [00:01<00:00, 34.50it/s, loss=0.00409, val_loss=0.00246,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00409, val_loss=0.00229,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00406, val_loss=0.00229,\u001b[A\n",
      "Epoch 81:  83%|▊| 40/48 [00:01<00:00, 34.23it/s, loss=0.00406, val_loss=0.00229,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 38.62it/s, loss=0.00406, val_loss=0.00242,\u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00409, val_loss=0.00242,\u001b[A\n",
      "Epoch 82:  83%|▊| 40/48 [00:01<00:00, 34.43it/s, loss=0.00409, val_loss=0.00242,\n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.00409, val_loss=0.00226,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00406, val_loss=0.00226,\u001b[A\n",
      "Epoch 83:  83%|▊| 40/48 [00:01<00:00, 34.21it/s, loss=0.00406, val_loss=0.00226,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 38.60it/s, loss=0.00406, val_loss=0.0024, \u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.00409, val_loss=0.0024, \u001b[A\n",
      "Epoch 84:  83%|▊| 40/48 [00:01<00:00, 34.50it/s, loss=0.00409, val_loss=0.0024, \n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 38.88it/s, loss=0.00409, val_loss=0.00225,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00406, val_loss=0.00225,\u001b[A\n",
      "Epoch 85:  83%|▊| 40/48 [00:01<00:00, 34.21it/s, loss=0.00406, val_loss=0.00225,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 38.60it/s, loss=0.00406, val_loss=0.00238,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 22.24it/s, loss=0.00409, val_loss=0.00238,\u001b[A\n",
      "Epoch 86:  83%|▊| 40/48 [00:01<00:00, 34.47it/s, loss=0.00409, val_loss=0.00238,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 38.87it/s, loss=0.00409, val_loss=0.00223,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00406, val_loss=0.00223,\u001b[A\n",
      "Epoch 87:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00406, val_loss=0.00223,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00406, val_loss=0.00237,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00409, val_loss=0.00237,\u001b[A\n",
      "Epoch 88:  83%|▊| 40/48 [00:01<00:00, 34.35it/s, loss=0.00409, val_loss=0.00237,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 38.76it/s, loss=0.00409, val_loss=0.00223,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.00407, val_loss=0.00223,\u001b[A\n",
      "Epoch 89:  83%|▊| 40/48 [00:01<00:00, 34.17it/s, loss=0.00407, val_loss=0.00223,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.00407, val_loss=0.00236,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.0041, val_loss=0.00236, \u001b[A\n",
      "Epoch 90:  83%|▊| 40/48 [00:01<00:00, 34.05it/s, loss=0.0041, val_loss=0.00236, \n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 38.45it/s, loss=0.0041, val_loss=0.00222, \u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 22.01it/s, loss=0.00407, val_loss=0.00222,\u001b[A\n",
      "Epoch 91:  83%|▊| 40/48 [00:01<00:00, 34.13it/s, loss=0.00407, val_loss=0.00222,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.00407, val_loss=0.00235,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.0041, val_loss=0.00235, \u001b[A\n",
      "Epoch 92:  83%|▊| 40/48 [00:01<00:00, 34.50it/s, loss=0.0041, val_loss=0.00235, \n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 38.91it/s, loss=0.0041, val_loss=0.00221, \u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00408, val_loss=0.00221,\u001b[A\n",
      "Epoch 93:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00408, val_loss=0.00221,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00408, val_loss=0.00234,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.00411, val_loss=0.00234,\u001b[A\n",
      "Epoch 94:  83%|▊| 40/48 [00:01<00:00, 34.33it/s, loss=0.00411, val_loss=0.00234,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00411, val_loss=0.0022, \u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.00409, val_loss=0.0022, \u001b[A\n",
      "Epoch 95:  83%|▊| 40/48 [00:01<00:00, 34.16it/s, loss=0.00409, val_loss=0.0022, \n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.00409, val_loss=0.00232,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00412, val_loss=0.00232,\u001b[A\n",
      "Epoch 96:  83%|▊| 40/48 [00:01<00:00, 34.51it/s, loss=0.00412, val_loss=0.00232,\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00412, val_loss=0.00218,\u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00409, val_loss=0.00218,\u001b[A\n",
      "Epoch 97:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00409, val_loss=0.00218,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 38.59it/s, loss=0.00409, val_loss=0.0023, \u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00412, val_loss=0.0023, \u001b[A\n",
      "Epoch 98:  83%|▊| 40/48 [00:01<00:00, 34.44it/s, loss=0.00412, val_loss=0.0023, \n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 38.85it/s, loss=0.00412, val_loss=0.00216,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.0041, val_loss=0.00216, \u001b[A\n",
      "Epoch 99:  83%|▊| 40/48 [00:01<00:00, 34.14it/s, loss=0.0041, val_loss=0.00216, \n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.54it/s, loss=0.0041, val_loss=0.00229, \u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.28it/s, loss=0.0041, val_loss=0.00229, \u001b[A\n",
      "Sizes of clusters: 445, 386, 369\n",
      "\n",
      "preds: [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 2 0 1\n",
      " 0 2 0 1 0 2 0 0 0 0 0 2 2 2 0 2 0 0 0 2 2 0 2 2 0 0 0 0 1 0 0 1 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0\n",
      " 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 1 0 0 0 2 0 2 0 0 0 2 0 0 1 2 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 2 0 0 0 1 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0\n",
      " 2 0 0 2 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 2 0 0 0 0 0 2 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 1 0 2 0 0 0 0 0 0 0 0 2\n",
      " 2 0 0 0 0 2 0 2 0 0 0 0 0 2 0 2 0 0 2 0 0 2 0 0 0 0 0 2 2 2 0 2 0 0 2 0 0\n",
      " 1 1 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 0 2 0 0 2 2 0 2 0 2 1 0 2 0 0 2 0 0 2 0 2 0 2 2 2 2 0 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2 2 2 0 0 2 2\n",
      " 0 2 0 2 2 0 0 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 2 0 0 0 2 2 2 0 2 2 0 2\n",
      " 0 2 2 0 2 2 2 0 0 2 2 2 2 0 2 2 0 2 2 0 2 0 2 2 0 0 2 2 0 2 2 0 2 0 2 2 0\n",
      " 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 0 2 0 2 0 2\n",
      " 2 2 0 2 0 2 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 0\n",
      " 2 2 2 2 2 2 0 2 0 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 0 2\n",
      " 0 2 2 2 2 2 2 0 2 2 2 0 2 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 2 0 2 0 0 2 0 2 2\n",
      " 0 2 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 2 2 0 0 0 0 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8158\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 22.42it/s, loss=10.6, val_loss=0.167, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 39.17it/s, loss=10.6, val_loss=18.5, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.384, val_loss=18.5, avg_v\u001b[A\n",
      "Epoch 1:  83%|▊| 40/48 [00:01<00:00, 34.78it/s, loss=0.384, val_loss=18.5, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 39.21it/s, loss=0.384, val_loss=4.02, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.0709, val_loss=4.02, avg_\u001b[A\n",
      "Epoch 2:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.0709, val_loss=4.02, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.0709, val_loss=0.128, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.0351, val_loss=0.128, avg\u001b[A\n",
      "Epoch 3:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.0351, val_loss=0.128, avg\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 39.23it/s, loss=0.0351, val_loss=0.0345, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.0255, val_loss=0.0345, av\u001b[A\n",
      "Epoch 4:  83%|▊| 40/48 [00:01<00:00, 34.61it/s, loss=0.0255, val_loss=0.0345, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 39.03it/s, loss=0.0255, val_loss=0.025, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.0201, val_loss=0.025, avg\u001b[A\n",
      "Epoch 5:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.0201, val_loss=0.025, avg\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 39.21it/s, loss=0.0201, val_loss=0.0197, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.0163, val_loss=0.0197, av\u001b[A\n",
      "Epoch 6:  83%|▊| 40/48 [00:01<00:00, 34.61it/s, loss=0.0163, val_loss=0.0197, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 39.02it/s, loss=0.0163, val_loss=0.0159, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.0135, val_loss=0.0159, av\u001b[A\n",
      "Epoch 7:  83%|▊| 40/48 [00:01<00:00, 34.80it/s, loss=0.0135, val_loss=0.0159, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 39.25it/s, loss=0.0135, val_loss=0.0129, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.0114, val_loss=0.0129, av\u001b[A\n",
      "Epoch 8:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.0114, val_loss=0.0129, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.0114, val_loss=0.0106, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 22.45it/s, loss=0.00972, val_loss=0.0106, a\u001b[A\n",
      "Epoch 9:  83%|▊| 40/48 [00:01<00:00, 34.80it/s, loss=0.00972, val_loss=0.0106, a\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 39.23it/s, loss=0.00972, val_loss=0.00879, \u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00845, val_loss=0.00879,\u001b[A\n",
      "Epoch 10:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00845, val_loss=0.00879,\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00845, val_loss=0.00737,\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.00746, val_loss=0.00737,\u001b[A\n",
      "Epoch 11:  83%|▊| 40/48 [00:01<00:00, 34.80it/s, loss=0.00746, val_loss=0.00737,\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 39.22it/s, loss=0.00746, val_loss=0.00625,\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00669, val_loss=0.00625,\u001b[A\n",
      "Epoch 12:  83%|▊| 40/48 [00:01<00:00, 34.58it/s, loss=0.00669, val_loss=0.00625,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00669, val_loss=0.00541,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 22.42it/s, loss=0.00609, val_loss=0.00541,\u001b[A\n",
      "Epoch 13:  83%|▊| 40/48 [00:01<00:00, 34.76it/s, loss=0.00609, val_loss=0.00541,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 39.18it/s, loss=0.00609, val_loss=0.00475,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00562, val_loss=0.00475,\u001b[A\n",
      "Epoch 14:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00562, val_loss=0.00475,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00562, val_loss=0.00428,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.00525, val_loss=0.00428,\u001b[A\n",
      "Epoch 15:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.00525, val_loss=0.00428,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 39.21it/s, loss=0.00525, val_loss=0.00396,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00496, val_loss=0.00396,\u001b[A\n",
      "Epoch 16:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00496, val_loss=0.00396,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00496, val_loss=0.00369,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.45it/s, loss=0.00473, val_loss=0.00369,\u001b[A\n",
      "Epoch 17:  83%|▊| 40/48 [00:01<00:00, 34.80it/s, loss=0.00473, val_loss=0.00369,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 39.22it/s, loss=0.00473, val_loss=0.00348,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00456, val_loss=0.00348,\u001b[A\n",
      "Epoch 18:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00456, val_loss=0.00348,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 39.03it/s, loss=0.00456, val_loss=0.00334,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 22.47it/s, loss=0.00442, val_loss=0.00334,\u001b[A\n",
      "Epoch 19:  83%|▊| 40/48 [00:01<00:00, 34.85it/s, loss=0.00442, val_loss=0.00334,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 39.28it/s, loss=0.00442, val_loss=0.00318,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00432, val_loss=0.00318,\u001b[A\n",
      "Epoch 20:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00432, val_loss=0.00318,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00432, val_loss=0.00303,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.00424, val_loss=0.00303,\u001b[A\n",
      "Epoch 21:  83%|▊| 40/48 [00:01<00:00, 34.78it/s, loss=0.00424, val_loss=0.00303,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 39.21it/s, loss=0.00424, val_loss=0.00293,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00417, val_loss=0.00293,\u001b[A\n",
      "Epoch 22:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00417, val_loss=0.00293,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00417, val_loss=0.00283,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.00412, val_loss=0.00283,\u001b[A\n",
      "Epoch 23:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.00412, val_loss=0.00283,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 39.22it/s, loss=0.00412, val_loss=0.00275,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00408, val_loss=0.00275,\u001b[A\n",
      "Epoch 24:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.00408, val_loss=0.00275,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00408, val_loss=0.00268,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 22.38it/s, loss=0.00405, val_loss=0.00268,\u001b[A\n",
      "Epoch 25:  83%|▊| 40/48 [00:01<00:00, 34.70it/s, loss=0.00405, val_loss=0.00268,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 39.09it/s, loss=0.00405, val_loss=0.00264,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.00403, val_loss=0.00264,\u001b[A\n",
      "Epoch 26:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.00403, val_loss=0.00264,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 39.21it/s, loss=0.00403, val_loss=0.00276,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.00401, val_loss=0.00276,\u001b[A\n",
      "Epoch 27:  83%|▊| 40/48 [00:01<00:00, 34.39it/s, loss=0.00401, val_loss=0.00276,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00401, val_loss=0.00272,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.00399, val_loss=0.00272,\u001b[A\n",
      "Epoch 28:  83%|▊| 40/48 [00:01<00:00, 34.78it/s, loss=0.00399, val_loss=0.00272,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 39.19it/s, loss=0.00399, val_loss=0.00262,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00398, val_loss=0.00262,\u001b[A\n",
      "Epoch 29:  83%|▊| 40/48 [00:01<00:00, 34.57it/s, loss=0.00398, val_loss=0.00262,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00398, val_loss=0.00257,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 22.42it/s, loss=0.00397, val_loss=0.00257,\u001b[A\n",
      "Epoch 30:  83%|▊| 40/48 [00:01<00:00, 34.58it/s, loss=0.00397, val_loss=0.00257,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00397, val_loss=0.00256,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00396, val_loss=0.00256,\u001b[A\n",
      "Epoch 31:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00396, val_loss=0.00256,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00396, val_loss=0.00252,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 22.45it/s, loss=0.00395, val_loss=0.00252,\u001b[A\n",
      "Epoch 32:  83%|▊| 40/48 [00:01<00:00, 34.82it/s, loss=0.00395, val_loss=0.00252,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 39.24it/s, loss=0.00395, val_loss=0.00253,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00394, val_loss=0.00253,\u001b[A\n",
      "Epoch 33:  83%|▊| 40/48 [00:01<00:00, 34.57it/s, loss=0.00394, val_loss=0.00253,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00394, val_loss=0.00247,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.00394, val_loss=0.00247,\u001b[A\n",
      "Epoch 34:  83%|▊| 40/48 [00:01<00:00, 34.77it/s, loss=0.00394, val_loss=0.00247,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 39.20it/s, loss=0.00394, val_loss=0.00245,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 22.32it/s, loss=0.00393, val_loss=0.00245,\u001b[A\n",
      "Epoch 35:  83%|▊| 40/48 [00:01<00:00, 34.61it/s, loss=0.00393, val_loss=0.00245,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 39.02it/s, loss=0.00393, val_loss=0.00242,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.00393, val_loss=0.00242,\u001b[A\n",
      "Epoch 36:  83%|▊| 40/48 [00:01<00:00, 34.78it/s, loss=0.00393, val_loss=0.00242,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 39.20it/s, loss=0.00393, val_loss=0.00241,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00392, val_loss=0.00241,\u001b[A\n",
      "Epoch 37:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00392, val_loss=0.00241,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00392, val_loss=0.00236,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.00392, val_loss=0.00236,\u001b[A\n",
      "Epoch 38:  83%|▊| 40/48 [00:01<00:00, 34.81it/s, loss=0.00392, val_loss=0.00236,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 39.24it/s, loss=0.00392, val_loss=0.00235,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00392, val_loss=0.00235,\u001b[A\n",
      "Epoch 39:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00392, val_loss=0.00235,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00392, val_loss=0.00231,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 22.44it/s, loss=0.00392, val_loss=0.00231,\u001b[A\n",
      "Epoch 40:  83%|▊| 40/48 [00:01<00:00, 34.80it/s, loss=0.00392, val_loss=0.00231,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 39.22it/s, loss=0.00392, val_loss=0.00225,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00391, val_loss=0.00225,\u001b[A\n",
      "Epoch 41:  83%|▊| 40/48 [00:01<00:00, 34.57it/s, loss=0.00391, val_loss=0.00225,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00391, val_loss=0.00227,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 22.41it/s, loss=0.00392, val_loss=0.00227,\u001b[A\n",
      "Epoch 42:  83%|▊| 40/48 [00:01<00:00, 34.75it/s, loss=0.00392, val_loss=0.00227,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 39.17it/s, loss=0.00392, val_loss=0.00228,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00392, val_loss=0.00228,\u001b[A\n",
      "Epoch 43:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00392, val_loss=0.00228,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00392, val_loss=0.00224,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=0.00392, val_loss=0.00224,\u001b[A\n",
      "Epoch 44:  83%|▊| 40/48 [00:01<00:00, 34.82it/s, loss=0.00392, val_loss=0.00224,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 39.24it/s, loss=0.00392, val_loss=0.00224,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00392, val_loss=0.00224,\u001b[A\n",
      "Epoch 45:  83%|▊| 40/48 [00:01<00:00, 34.37it/s, loss=0.00392, val_loss=0.00224,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 38.77it/s, loss=0.00392, val_loss=0.00223,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00392, val_loss=0.00223,\u001b[A\n",
      "Epoch 46:  83%|▊| 40/48 [00:01<00:00, 34.45it/s, loss=0.00392, val_loss=0.00223,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.00392, val_loss=0.00223,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00392, val_loss=0.00223,\u001b[A\n",
      "Epoch 47:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00392, val_loss=0.00223,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.00392, val_loss=0.00218,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 22.25it/s, loss=0.00393, val_loss=0.00218,\u001b[A\n",
      "Epoch 48:  83%|▊| 40/48 [00:01<00:00, 34.49it/s, loss=0.00393, val_loss=0.00218,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 38.92it/s, loss=0.00393, val_loss=0.00218,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00393, val_loss=0.00218,\u001b[A\n",
      "Epoch 49:  83%|▊| 40/48 [00:01<00:00, 34.21it/s, loss=0.00393, val_loss=0.00218,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 38.62it/s, loss=0.00393, val_loss=0.00218,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00393, val_loss=0.00218,\u001b[A\n",
      "Epoch 50:  83%|▊| 40/48 [00:01<00:00, 34.44it/s, loss=0.00393, val_loss=0.00218,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 38.86it/s, loss=0.00393, val_loss=0.00219,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 22.18it/s, loss=0.00393, val_loss=0.00219,\u001b[A\n",
      "Epoch 51:  83%|▊| 40/48 [00:01<00:00, 34.39it/s, loss=0.00393, val_loss=0.00219,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.00393, val_loss=0.00217,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00393, val_loss=0.00217,\u001b[A\n",
      "Epoch 52:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00393, val_loss=0.00217,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00393, val_loss=0.00216,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00394, val_loss=0.00216,\u001b[A\n",
      "Epoch 53:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00394, val_loss=0.00216,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00394, val_loss=0.00213,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.00394, val_loss=0.00213,\u001b[A\n",
      "Epoch 54:  83%|▊| 40/48 [00:01<00:00, 34.24it/s, loss=0.00394, val_loss=0.00213,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00394, val_loss=0.00216,\u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 22.27it/s, loss=0.00394, val_loss=0.00216,\u001b[A\n",
      "Epoch 55:  83%|▊| 40/48 [00:01<00:00, 34.51it/s, loss=0.00394, val_loss=0.00216,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 38.92it/s, loss=0.00394, val_loss=0.00212,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00395, val_loss=0.00212,\u001b[A\n",
      "Epoch 56:  83%|▊| 40/48 [00:01<00:00, 34.22it/s, loss=0.00395, val_loss=0.00212,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 38.63it/s, loss=0.00395, val_loss=0.00212,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00395, val_loss=0.00212,\u001b[A\n",
      "Epoch 57:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00395, val_loss=0.00212,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00395, val_loss=0.00212,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00395, val_loss=0.00212,\u001b[A\n",
      "Epoch 58:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00395, val_loss=0.00212,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00395, val_loss=0.00214,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00396, val_loss=0.00214,\u001b[A\n",
      "Epoch 59:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00396, val_loss=0.00214,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00396, val_loss=0.00215,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00396, val_loss=0.00215,\u001b[A\n",
      "Epoch 60:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00396, val_loss=0.00215,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00396, val_loss=0.00212,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00396, val_loss=0.00212,\u001b[A\n",
      "Epoch 61:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00396, val_loss=0.00212,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00396, val_loss=0.00212,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00397, val_loss=0.00212,\u001b[A\n",
      "Epoch 62:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00397, val_loss=0.00212,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00397, val_loss=0.00215,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00397, val_loss=0.00215,\u001b[A\n",
      "Epoch 63:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00397, val_loss=0.00215,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00397, val_loss=0.00212,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00398, val_loss=0.00212,\u001b[A\n",
      "Epoch 64:  83%|▊| 40/48 [00:01<00:00, 34.29it/s, loss=0.00398, val_loss=0.00212,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 38.69it/s, loss=0.00398, val_loss=0.00213,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 22.32it/s, loss=0.00398, val_loss=0.00213,\u001b[A\n",
      "Epoch 65:  83%|▊| 40/48 [00:01<00:00, 34.57it/s, loss=0.00398, val_loss=0.00213,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.00398, val_loss=0.0021, \u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00399, val_loss=0.0021, \u001b[A\n",
      "Epoch 66:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00399, val_loss=0.0021, \n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00399, val_loss=0.00212,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00399, val_loss=0.00212,\u001b[A\n",
      "Epoch 67:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00399, val_loss=0.00212,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00399, val_loss=0.00212,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.004, val_loss=0.00212, a\u001b[A\n",
      "Epoch 68:  83%|▊| 40/48 [00:01<00:00, 34.33it/s, loss=0.004, val_loss=0.00212, a\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.004, val_loss=0.00211, a\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.004, val_loss=0.00211, a\u001b[A\n",
      "Epoch 69:  83%|▊| 40/48 [00:01<00:00, 34.57it/s, loss=0.004, val_loss=0.00211, a\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 38.99it/s, loss=0.004, val_loss=0.00214, a\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00401, val_loss=0.00214,\u001b[A\n",
      "Epoch 70:  83%|▊| 40/48 [00:01<00:00, 34.33it/s, loss=0.00401, val_loss=0.00214,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00401, val_loss=0.00214,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00401, val_loss=0.00214,\u001b[A\n",
      "Epoch 71:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00401, val_loss=0.00214,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00401, val_loss=0.00212,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00402, val_loss=0.00212,\u001b[A\n",
      "Epoch 72:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00402, val_loss=0.00212,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00402, val_loss=0.00212,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00403, val_loss=0.00212,\u001b[A\n",
      "Epoch 73:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.00403, val_loss=0.00212,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00403, val_loss=0.00214,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00403, val_loss=0.00214,\u001b[A\n",
      "Epoch 74:  83%|▊| 40/48 [00:01<00:00, 34.30it/s, loss=0.00403, val_loss=0.00214,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00403, val_loss=0.00213,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00404, val_loss=0.00213,\u001b[A\n",
      "Epoch 75:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.00404, val_loss=0.00213,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 38.93it/s, loss=0.00404, val_loss=0.00215,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00405, val_loss=0.00215,\u001b[A\n",
      "Epoch 76:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00405, val_loss=0.00215,\n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00405, val_loss=0.00214,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00405, val_loss=0.00214,\u001b[A\n",
      "Epoch 77:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00405, val_loss=0.00214,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00405, val_loss=0.00214,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.00406, val_loss=0.00214,\u001b[A\n",
      "Epoch 78:  83%|▊| 40/48 [00:01<00:00, 34.59it/s, loss=0.00406, val_loss=0.00214,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 39.01it/s, loss=0.00406, val_loss=0.00214,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00407, val_loss=0.00214,\u001b[A\n",
      "Epoch 79:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00407, val_loss=0.00214,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00407, val_loss=0.00214,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00408, val_loss=0.00214,\u001b[A\n",
      "Epoch 80:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00408, val_loss=0.00214,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00408, val_loss=0.00213,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 22.11it/s, loss=0.00409, val_loss=0.00213,\u001b[A\n",
      "Epoch 81:  83%|▊| 40/48 [00:01<00:00, 34.29it/s, loss=0.00409, val_loss=0.00213,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00409, val_loss=0.00215,\u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00409, val_loss=0.00215,\u001b[A\n",
      "Epoch 82:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00409, val_loss=0.00215,\n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 38.95it/s, loss=0.00409, val_loss=0.00213,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.0041, val_loss=0.00213, \u001b[A\n",
      "Epoch 83:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.0041, val_loss=0.00213, \n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.0041, val_loss=0.00216, \u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00411, val_loss=0.00216,\u001b[A\n",
      "Epoch 84:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00411, val_loss=0.00216,\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00411, val_loss=0.00213,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00412, val_loss=0.00213,\u001b[A\n",
      "Epoch 85:  83%|▊| 40/48 [00:01<00:00, 34.30it/s, loss=0.00412, val_loss=0.00213,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00412, val_loss=0.00217,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00413, val_loss=0.00217,\u001b[A\n",
      "Epoch 86:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00413, val_loss=0.00217,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 38.98it/s, loss=0.00413, val_loss=0.00213,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.00413, val_loss=0.00213,\u001b[A\n",
      "Epoch 87:  83%|▊| 40/48 [00:01<00:00, 34.05it/s, loss=0.00413, val_loss=0.00213,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 38.43it/s, loss=0.00413, val_loss=0.00218,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 22.01it/s, loss=0.00414, val_loss=0.00218,\u001b[A\n",
      "Epoch 88:  83%|▊| 40/48 [00:01<00:00, 34.13it/s, loss=0.00414, val_loss=0.00218,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 38.51it/s, loss=0.00414, val_loss=0.00214,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00415, val_loss=0.00214,\u001b[A\n",
      "Epoch 89:  83%|▊| 40/48 [00:01<00:00, 34.32it/s, loss=0.00415, val_loss=0.00214,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00415, val_loss=0.00216,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.00416, val_loss=0.00216,\u001b[A\n",
      "Epoch 90:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.00416, val_loss=0.00216,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00416, val_loss=0.00218,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00416, val_loss=0.00218,\u001b[A\n",
      "Epoch 91:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00416, val_loss=0.00218,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00416, val_loss=0.00218,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 22.31it/s, loss=0.00417, val_loss=0.00218,\u001b[A\n",
      "Epoch 92:  83%|▊| 40/48 [00:01<00:00, 34.58it/s, loss=0.00417, val_loss=0.00218,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 39.00it/s, loss=0.00417, val_loss=0.00211,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00418, val_loss=0.00211,\u001b[A\n",
      "Epoch 93:  83%|▊| 40/48 [00:01<00:00, 34.27it/s, loss=0.00418, val_loss=0.00211,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00418, val_loss=0.00211,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00419, val_loss=0.00211,\u001b[A\n",
      "Epoch 94:  83%|▊| 40/48 [00:01<00:00, 34.53it/s, loss=0.00419, val_loss=0.00211,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 38.94it/s, loss=0.00419, val_loss=0.00211,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.0105, val_loss=0.00211, \u001b[A\n",
      "Epoch 95:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.0105, val_loss=0.00211, \n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.0105, val_loss=0.0723, a\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 22.29it/s, loss=0.0111, val_loss=0.0723, a\u001b[A\n",
      "Epoch 96:  83%|▊| 40/48 [00:01<00:00, 34.56it/s, loss=0.0111, val_loss=0.0723, a\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.0111, val_loss=0.00534, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00484, val_loss=0.00534,\u001b[A\n",
      "Epoch 97:  83%|▊| 40/48 [00:01<00:00, 33.81it/s, loss=0.00484, val_loss=0.00534,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 38.18it/s, loss=0.00484, val_loss=0.00259,\u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00426, val_loss=0.00259,\u001b[A\n",
      "Epoch 98:  83%|▊| 40/48 [00:01<00:00, 34.55it/s, loss=0.00426, val_loss=0.00259,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 38.96it/s, loss=0.00426, val_loss=0.00217,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00422, val_loss=0.00217,\u001b[A\n",
      "Epoch 99:  83%|▊| 40/48 [00:01<00:00, 34.28it/s, loss=0.00422, val_loss=0.00217,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00422, val_loss=0.00212,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.41it/s, loss=0.00422, val_loss=0.00212,\u001b[A\n",
      "Sizes of clusters: 450, 386, 364\n",
      "\n",
      "preds: [1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 2 0 1\n",
      " 0 2 0 1 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 2 2 0 2 2 0 0 0 0 1 0 0 1 2 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0\n",
      " 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 2 0 0 0 2 0 0 1 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 2 0 0 0 1 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 0 0 2 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0\n",
      " 0 0 0 2 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 2 1 0 2 0 0 0 0 0 0 0 0 2\n",
      " 2 0 0 0 0 0 0 2 0 0 0 0 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 2 2 0 2 0 0 2 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 0 2 0 0 2 2 0 2 0 2 1 0 2 0 0 2 0 0 2 0 2 0 2 2 2 2 0 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2 2 2 0 0 2 2\n",
      " 0 2 0 2 2 0 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 2 0 0 0 2 2 2 0 2 2 0 2\n",
      " 0 2 2 0 2 2 2 0 0 2 2 2 2 0 2 2 0 2 2 0 2 0 2 2 0 0 2 2 0 2 2 0 2 0 2 2 0\n",
      " 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 0 2 0 2 0 2\n",
      " 2 2 0 2 0 2 2 2 2 2 2 0 0 0 2 0 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 0 2 2 2 2 0\n",
      " 2 2 2 2 2 2 0 2 0 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 0 2\n",
      " 0 2 2 2 2 2 2 0 2 2 2 0 2 2 2 0 0 2 2 2 2 2 0 2 2 2 2 2 2 0 2 0 0 2 0 2 2\n",
      " 0 2 2 2 0 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 2 2 0 0 0 0 2 2 2 2 2 0 2 0 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 2 2 0 2 2 0 2 2 0 2 2 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8217\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 22.46it/s, loss=11.6, val_loss=0.154, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 39.24it/s, loss=11.6, val_loss=3.29, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.49it/s, loss=0.483, val_loss=3.29, avg_v\u001b[A\n",
      "Epoch 1:  83%|▊| 40/48 [00:01<00:00, 34.86it/s, loss=0.483, val_loss=3.29, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 39.30it/s, loss=0.483, val_loss=0.29, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 22.33it/s, loss=0.0834, val_loss=0.29, avg_\u001b[A\n",
      "Epoch 2:  83%|▊| 40/48 [00:01<00:00, 34.65it/s, loss=0.0834, val_loss=0.29, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 39.06it/s, loss=0.0834, val_loss=0.0764, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.43it/s, loss=0.0393, val_loss=0.0764, av\u001b[A\n",
      "Epoch 3:  83%|▊| 40/48 [00:01<00:00, 34.79it/s, loss=0.0393, val_loss=0.0764, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 39.16it/s, loss=0.0393, val_loss=0.05, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.0293, val_loss=0.05, avg_\u001b[A\n",
      "Epoch 4:  83%|▊| 40/48 [00:01<00:00, 33.90it/s, loss=0.0293, val_loss=0.05, avg_\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.0293, val_loss=0.0398, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.21it/s, loss=0.0246, val_loss=0.0398, av\u001b[A\n",
      "Epoch 5:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.0246, val_loss=0.0398, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.0246, val_loss=0.0324, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.0213, val_loss=0.0324, av\u001b[A\n",
      "Epoch 6:  83%|▊| 40/48 [00:01<00:00, 33.93it/s, loss=0.0213, val_loss=0.0324, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.0213, val_loss=0.0272, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.0187, val_loss=0.0272, av\u001b[A\n",
      "Epoch 7:  83%|▊| 40/48 [00:01<00:00, 33.95it/s, loss=0.0187, val_loss=0.0272, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.0187, val_loss=0.0232, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.0165, val_loss=0.0232, av\u001b[A\n",
      "Epoch 8:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.0165, val_loss=0.0232, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.0165, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.0146, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 9:  83%|▊| 40/48 [00:01<00:00, 34.12it/s, loss=0.0146, val_loss=0.02, avg_\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.51it/s, loss=0.0146, val_loss=0.0174, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.0128, val_loss=0.0174, a\u001b[A\n",
      "Epoch 10:  83%|▊| 40/48 [00:01<00:00, 33.97it/s, loss=0.0128, val_loss=0.0174, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.0128, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.0112, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  83%|▊| 40/48 [00:01<00:00, 34.34it/s, loss=0.0112, val_loss=0.0152, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.75it/s, loss=0.0112, val_loss=0.0133, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.0099, val_loss=0.0133, a\u001b[A\n",
      "Epoch 12:  83%|▊| 40/48 [00:01<00:00, 33.67it/s, loss=0.0099, val_loss=0.0133, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.0099, val_loss=0.0117, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00874, val_loss=0.0117, \u001b[A\n",
      "Epoch 13:  83%|▊| 40/48 [00:01<00:00, 33.64it/s, loss=0.00874, val_loss=0.0117, \n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.00874, val_loss=0.0103, \u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00777, val_loss=0.0103, \u001b[A\n",
      "Epoch 14:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.00777, val_loss=0.0103, \n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 38.37it/s, loss=0.00777, val_loss=0.00912,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00697, val_loss=0.00912,\u001b[A\n",
      "Epoch 15:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00697, val_loss=0.00912,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.67it/s, loss=0.00697, val_loss=0.0081, \u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00633, val_loss=0.0081, \u001b[A\n",
      "Epoch 16:  83%|▊| 40/48 [00:01<00:00, 33.94it/s, loss=0.00633, val_loss=0.0081, \n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00633, val_loss=0.00724,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00583, val_loss=0.00724,\u001b[A\n",
      "Epoch 17:  83%|▊| 40/48 [00:01<00:00, 34.36it/s, loss=0.00583, val_loss=0.00724,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.77it/s, loss=0.00583, val_loss=0.00653,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00545, val_loss=0.00653,\u001b[A\n",
      "Epoch 18:  83%|▊| 40/48 [00:01<00:00, 33.51it/s, loss=0.00545, val_loss=0.00653,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.25it/s, loss=0.00545, val_loss=0.00597,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00516, val_loss=0.00597,\u001b[A\n",
      "Epoch 19:  83%|▊| 40/48 [00:01<00:00, 34.30it/s, loss=0.00516, val_loss=0.00597,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00516, val_loss=0.00552,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00495, val_loss=0.00552,\u001b[A\n",
      "Epoch 20:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.00495, val_loss=0.00552,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.39it/s, loss=0.00495, val_loss=0.00516,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 22.16it/s, loss=0.00479, val_loss=0.00516,\u001b[A\n",
      "Epoch 21:  83%|▊| 40/48 [00:01<00:00, 34.32it/s, loss=0.00479, val_loss=0.00516,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.74it/s, loss=0.00479, val_loss=0.00489,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.00467, val_loss=0.00489,\u001b[A\n",
      "Epoch 22:  83%|▊| 40/48 [00:01<00:00, 34.02it/s, loss=0.00467, val_loss=0.00489,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.41it/s, loss=0.00467, val_loss=0.00468,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00458, val_loss=0.00468,\u001b[A\n",
      "Epoch 23:  83%|▊| 40/48 [00:01<00:00, 34.33it/s, loss=0.00458, val_loss=0.00468,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.75it/s, loss=0.00458, val_loss=0.00452,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00451, val_loss=0.00452,\u001b[A\n",
      "Epoch 24:  83%|▊| 40/48 [00:01<00:00, 33.93it/s, loss=0.00451, val_loss=0.00452,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.00451, val_loss=0.0044, \u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00446, val_loss=0.0044, \u001b[A\n",
      "Epoch 25:  83%|▊| 40/48 [00:01<00:00, 33.97it/s, loss=0.00446, val_loss=0.0044, \n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.00446, val_loss=0.00429,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 22.20it/s, loss=0.00441, val_loss=0.00429,\u001b[A\n",
      "Epoch 26:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.00441, val_loss=0.00429,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.00441, val_loss=0.0042, \u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00438, val_loss=0.0042, \u001b[A\n",
      "Epoch 27:  83%|▊| 40/48 [00:01<00:00, 33.91it/s, loss=0.00438, val_loss=0.0042, \n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.00438, val_loss=0.00413,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00435, val_loss=0.00413,\u001b[A\n",
      "Epoch 28:  83%|▊| 40/48 [00:01<00:00, 34.32it/s, loss=0.00435, val_loss=0.00413,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.00435, val_loss=0.00407,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00433, val_loss=0.00407,\u001b[A\n",
      "Epoch 29:  83%|▊| 40/48 [00:01<00:00, 34.00it/s, loss=0.00433, val_loss=0.00407,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 38.39it/s, loss=0.00433, val_loss=0.00402,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.0043, val_loss=0.00402, \u001b[A\n",
      "Epoch 30:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.0043, val_loss=0.00402, \n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.0043, val_loss=0.00397, \u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.86it/s, loss=0.00428, val_loss=0.00397,\u001b[A\n",
      "Epoch 31:  83%|▊| 40/48 [00:01<00:00, 33.89it/s, loss=0.00428, val_loss=0.00397,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 38.27it/s, loss=0.00428, val_loss=0.00392,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00427, val_loss=0.00392,\u001b[A\n",
      "Epoch 32:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00427, val_loss=0.00392,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00427, val_loss=0.00387,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00425, val_loss=0.00387,\u001b[A\n",
      "Epoch 33:  83%|▊| 40/48 [00:01<00:00, 33.98it/s, loss=0.00425, val_loss=0.00387,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 38.37it/s, loss=0.00425, val_loss=0.00382,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 22.20it/s, loss=0.00424, val_loss=0.00382,\u001b[A\n",
      "Epoch 34:  83%|▊| 40/48 [00:01<00:00, 34.37it/s, loss=0.00424, val_loss=0.00382,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.78it/s, loss=0.00424, val_loss=0.00379,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00423, val_loss=0.00379,\u001b[A\n",
      "Epoch 35:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.00423, val_loss=0.00379,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.00423, val_loss=0.00375,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00421, val_loss=0.00375,\u001b[A\n",
      "Epoch 36:  83%|▊| 40/48 [00:01<00:00, 34.36it/s, loss=0.00421, val_loss=0.00375,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.77it/s, loss=0.00421, val_loss=0.00371,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.0042, val_loss=0.00371, \u001b[A\n",
      "Epoch 37:  83%|▊| 40/48 [00:01<00:00, 33.91it/s, loss=0.0042, val_loss=0.00371, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.0042, val_loss=0.00368, \u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00419, val_loss=0.00368,\u001b[A\n",
      "Epoch 38:  83%|▊| 40/48 [00:01<00:00, 33.73it/s, loss=0.00419, val_loss=0.00368,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.00419, val_loss=0.00365,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00418, val_loss=0.00365,\u001b[A\n",
      "Epoch 39:  83%|▊| 40/48 [00:01<00:00, 33.99it/s, loss=0.00418, val_loss=0.00365,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 38.37it/s, loss=0.00418, val_loss=0.00362,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00418, val_loss=0.00362,\u001b[A\n",
      "Epoch 40:  83%|▊| 40/48 [00:01<00:00, 34.30it/s, loss=0.00418, val_loss=0.00362,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00418, val_loss=0.0036, \u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00417, val_loss=0.0036, \u001b[A\n",
      "Epoch 41:  83%|▊| 40/48 [00:01<00:00, 33.94it/s, loss=0.00417, val_loss=0.0036, \n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.00417, val_loss=0.00358,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00416, val_loss=0.00358,\u001b[A\n",
      "Epoch 42:  83%|▊| 40/48 [00:01<00:00, 34.32it/s, loss=0.00416, val_loss=0.00358,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.00416, val_loss=0.00357,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00415, val_loss=0.00357,\u001b[A\n",
      "Epoch 43:  83%|▊| 40/48 [00:01<00:00, 33.98it/s, loss=0.00415, val_loss=0.00357,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00415, val_loss=0.00355,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 22.19it/s, loss=0.00415, val_loss=0.00355,\u001b[A\n",
      "Epoch 44:  83%|▊| 40/48 [00:01<00:00, 34.35it/s, loss=0.00415, val_loss=0.00355,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 38.75it/s, loss=0.00415, val_loss=0.00353,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00414, val_loss=0.00353,\u001b[A\n",
      "Epoch 45:  83%|▊| 40/48 [00:01<00:00, 33.67it/s, loss=0.00414, val_loss=0.00353,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 38.04it/s, loss=0.00414, val_loss=0.00351,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00414, val_loss=0.00351,\u001b[A\n",
      "Epoch 46:  83%|▊| 40/48 [00:01<00:00, 34.18it/s, loss=0.00414, val_loss=0.00351,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00414, val_loss=0.00349,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00413, val_loss=0.00349,\u001b[A\n",
      "Epoch 47:  83%|▊| 40/48 [00:01<00:00, 33.94it/s, loss=0.00413, val_loss=0.00349,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.00413, val_loss=0.00346,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 22.16it/s, loss=0.00413, val_loss=0.00346,\u001b[A\n",
      "Epoch 48:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00413, val_loss=0.00346,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00413, val_loss=0.00344,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.00412, val_loss=0.00344,\u001b[A\n",
      "Epoch 49:  83%|▊| 40/48 [00:01<00:00, 33.84it/s, loss=0.00412, val_loss=0.00344,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00412, val_loss=0.00343,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00412, val_loss=0.00343,\u001b[A\n",
      "Epoch 50:  83%|▊| 40/48 [00:01<00:00, 34.31it/s, loss=0.00412, val_loss=0.00343,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 38.72it/s, loss=0.00412, val_loss=0.00343,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.00412, val_loss=0.00343,\u001b[A\n",
      "Epoch 51:  83%|▊| 40/48 [00:01<00:00, 34.30it/s, loss=0.00412, val_loss=0.00343,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00412, val_loss=0.00342,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00411, val_loss=0.00342,\u001b[A\n",
      "Epoch 52:  83%|▊| 40/48 [00:01<00:00, 33.97it/s, loss=0.00411, val_loss=0.00342,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00411, val_loss=0.00342,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.00411, val_loss=0.00342,\u001b[A\n",
      "Epoch 53:  83%|▊| 40/48 [00:01<00:00, 34.29it/s, loss=0.00411, val_loss=0.00342,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00411, val_loss=0.00341,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 21.86it/s, loss=0.00411, val_loss=0.00341,\u001b[A\n",
      "Epoch 54:  83%|▊| 40/48 [00:01<00:00, 33.90it/s, loss=0.00411, val_loss=0.00341,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00411, val_loss=0.0034, \u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 22.14it/s, loss=0.00411, val_loss=0.0034, \u001b[A\n",
      "Epoch 55:  83%|▊| 40/48 [00:01<00:00, 34.29it/s, loss=0.00411, val_loss=0.0034, \n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.00411, val_loss=0.0034, \u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00411, val_loss=0.0034, \u001b[A\n",
      "Epoch 56:  83%|▊| 40/48 [00:01<00:00, 33.84it/s, loss=0.00411, val_loss=0.0034, \n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00411, val_loss=0.00339,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00411, val_loss=0.00339,\u001b[A\n",
      "Epoch 57:  83%|▊| 40/48 [00:01<00:00, 34.35it/s, loss=0.00411, val_loss=0.00339,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 38.77it/s, loss=0.00411, val_loss=0.00338,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00411, val_loss=0.00338,\u001b[A\n",
      "Epoch 58:  83%|▊| 40/48 [00:01<00:00, 33.98it/s, loss=0.00411, val_loss=0.00338,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.00411, val_loss=0.00337,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 22.18it/s, loss=0.00411, val_loss=0.00337,\u001b[A\n",
      "Epoch 59:  83%|▊| 40/48 [00:01<00:00, 34.38it/s, loss=0.00411, val_loss=0.00337,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 38.80it/s, loss=0.00411, val_loss=0.00336,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.00412, val_loss=0.00336,\u001b[A\n",
      "Epoch 60:  83%|▊| 40/48 [00:01<00:00, 34.16it/s, loss=0.00412, val_loss=0.00336,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.55it/s, loss=0.00412, val_loss=0.00335,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 22.24it/s, loss=0.00412, val_loss=0.00335,\u001b[A\n",
      "Epoch 61:  83%|▊| 40/48 [00:01<00:00, 34.46it/s, loss=0.00412, val_loss=0.00335,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 38.88it/s, loss=0.00412, val_loss=0.00335,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00412, val_loss=0.00335,\u001b[A\n",
      "Epoch 62:  83%|▊| 40/48 [00:01<00:00, 34.19it/s, loss=0.00412, val_loss=0.00335,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 38.59it/s, loss=0.00412, val_loss=0.00333,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 22.22it/s, loss=0.00412, val_loss=0.00333,\u001b[A\n",
      "Epoch 63:  83%|▊| 40/48 [00:01<00:00, 34.43it/s, loss=0.00412, val_loss=0.00333,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 38.85it/s, loss=0.00412, val_loss=0.00332,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 22.03it/s, loss=0.00412, val_loss=0.00332,\u001b[A\n",
      "Epoch 64:  83%|▊| 40/48 [00:01<00:00, 34.15it/s, loss=0.00412, val_loss=0.00332,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.00412, val_loss=0.00331,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 22.23it/s, loss=0.00412, val_loss=0.00331,\u001b[A\n",
      "Epoch 65:  83%|▊| 40/48 [00:01<00:00, 34.44it/s, loss=0.00412, val_loss=0.00331,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 38.87it/s, loss=0.00412, val_loss=0.00331,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00412, val_loss=0.00331,\u001b[A\n",
      "Epoch 66:  83%|▊| 40/48 [00:01<00:00, 33.95it/s, loss=0.00412, val_loss=0.00331,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00412, val_loss=0.0033, \u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00413, val_loss=0.0033, \u001b[A\n",
      "Epoch 67:  83%|▊| 40/48 [00:01<00:00, 33.58it/s, loss=0.00413, val_loss=0.0033, \n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00413, val_loss=0.0033, \u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 22.01it/s, loss=0.00413, val_loss=0.0033, \u001b[A\n",
      "Epoch 68:  83%|▊| 40/48 [00:01<00:00, 34.14it/s, loss=0.00413, val_loss=0.0033, \n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 38.51it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 69:  83%|▊| 40/48 [00:01<00:00, 34.09it/s, loss=0.00413, val_loss=0.00329,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 38.48it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 70:  83%|▊| 40/48 [00:01<00:00, 34.20it/s, loss=0.00413, val_loss=0.00329,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 38.60it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 22.30it/s, loss=0.00413, val_loss=0.00329,\u001b[A\n",
      "Epoch 71:  83%|▊| 40/48 [00:01<00:00, 34.54it/s, loss=0.00413, val_loss=0.00329,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 38.97it/s, loss=0.00413, val_loss=0.00328,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00414, val_loss=0.00328,\u001b[A\n",
      "Epoch 72:  83%|▊| 40/48 [00:01<00:00, 34.26it/s, loss=0.00414, val_loss=0.00328,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00414, val_loss=0.00329,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 21.45it/s, loss=0.00414, val_loss=0.00329,\u001b[A\n",
      "Epoch 73:  83%|▊| 40/48 [00:01<00:00, 33.13it/s, loss=0.00414, val_loss=0.00329,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 37.45it/s, loss=0.00414, val_loss=0.00327,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 20.92it/s, loss=0.00414, val_loss=0.00327,\u001b[A\n",
      "Epoch 74:  83%|▊| 40/48 [00:01<00:00, 32.37it/s, loss=0.00414, val_loss=0.00327,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 36.51it/s, loss=0.00414, val_loss=0.00326,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 21.41it/s, loss=0.00414, val_loss=0.00326,\u001b[A\n",
      "Epoch 75:  83%|▊| 40/48 [00:01<00:00, 33.21it/s, loss=0.00414, val_loss=0.00326,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 37.53it/s, loss=0.00414, val_loss=0.00326,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00414, val_loss=0.00326,\u001b[A\n",
      "Epoch 76:  83%|▊| 40/48 [00:01<00:00, 33.48it/s, loss=0.00414, val_loss=0.00326,\n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00414, val_loss=0.00326,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 20.98it/s, loss=0.00415, val_loss=0.00326,\u001b[A\n",
      "Epoch 77:  83%|▊| 40/48 [00:01<00:00, 32.68it/s, loss=0.00415, val_loss=0.00326,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 36.89it/s, loss=0.00415, val_loss=0.00324,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 20.99it/s, loss=0.00415, val_loss=0.00324,\u001b[A\n",
      "Epoch 78:  83%|▊| 40/48 [00:01<00:00, 32.53it/s, loss=0.00415, val_loss=0.00324,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 36.89it/s, loss=0.00415, val_loss=0.00324,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 19.99it/s, loss=0.00416, val_loss=0.00324,\u001b[A\n",
      "Epoch 79:  83%|▊| 40/48 [00:01<00:00, 31.07it/s, loss=0.00416, val_loss=0.00324,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 35.40it/s, loss=0.00416, val_loss=0.00327,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 21.02it/s, loss=0.0321, val_loss=0.00327, \u001b[A\n",
      "Epoch 80:  83%|▊| 40/48 [00:01<00:00, 32.66it/s, loss=0.0321, val_loss=0.00327, \n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 36.84it/s, loss=0.0321, val_loss=0.141, av\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.85it/s, loss=0.0157, val_loss=0.141, av\u001b[A\n",
      "Epoch 81:  83%|▊| 40/48 [00:01<00:00, 32.19it/s, loss=0.0157, val_loss=0.141, av\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 36.59it/s, loss=0.0157, val_loss=0.00424, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 21.23it/s, loss=0.00492, val_loss=0.00424,\u001b[A\n",
      "Epoch 82:  83%|▊| 40/48 [00:01<00:00, 32.88it/s, loss=0.00492, val_loss=0.00424,\n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 37.25it/s, loss=0.00492, val_loss=0.00334,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 20.52it/s, loss=0.00421, val_loss=0.00334,\u001b[A\n",
      "Epoch 83:  83%|▊| 40/48 [00:01<00:00, 31.81it/s, loss=0.00421, val_loss=0.00334,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 35.98it/s, loss=0.00421, val_loss=0.00328,\u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 20.78it/s, loss=0.00416, val_loss=0.00328,\u001b[A\n",
      "Epoch 84:  83%|▊| 40/48 [00:01<00:00, 32.02it/s, loss=0.00416, val_loss=0.00328,\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 36.53it/s, loss=0.00416, val_loss=0.00321,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 21.27it/s, loss=0.00416, val_loss=0.00321,\u001b[A\n",
      "Epoch 85:  83%|▊| 40/48 [00:01<00:00, 32.68it/s, loss=0.00416, val_loss=0.00321,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 37.08it/s, loss=0.00416, val_loss=0.0032, \u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 20.50it/s, loss=0.00416, val_loss=0.0032, \u001b[A\n",
      "Epoch 86:  83%|▊| 40/48 [00:01<00:00, 31.83it/s, loss=0.00416, val_loss=0.0032, \n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 36.04it/s, loss=0.00416, val_loss=0.00319,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 20.72it/s, loss=0.00423, val_loss=0.00319,\u001b[A\n",
      "Epoch 87:  83%|▊| 40/48 [00:01<00:00, 32.23it/s, loss=0.00423, val_loss=0.00319,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 36.44it/s, loss=0.00423, val_loss=0.00431,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 20.70it/s, loss=0.071, val_loss=0.00431, a\u001b[A\n",
      "Epoch 88:  83%|▊| 40/48 [00:01<00:00, 32.05it/s, loss=0.071, val_loss=0.00431, a\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 36.38it/s, loss=0.071, val_loss=0.0124, av\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 20.77it/s, loss=0.00952, val_loss=0.0124, \u001b[A\n",
      "Epoch 89:  83%|▊| 40/48 [00:01<00:00, 32.34it/s, loss=0.00952, val_loss=0.0124, \n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 36.62it/s, loss=0.00952, val_loss=0.00726,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 21.10it/s, loss=0.00467, val_loss=0.00726,\u001b[A\n",
      "Epoch 90:  83%|▊| 40/48 [00:01<00:00, 32.53it/s, loss=0.00467, val_loss=0.00726,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 36.93it/s, loss=0.00467, val_loss=0.0032, \u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 21.06it/s, loss=0.00419, val_loss=0.0032, \u001b[A\n",
      "Epoch 91:  83%|▊| 40/48 [00:01<00:00, 32.68it/s, loss=0.00419, val_loss=0.0032, \n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 36.96it/s, loss=0.00419, val_loss=0.00324,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00416, val_loss=0.00324,\u001b[A\n",
      "Epoch 92:  83%|▊| 40/48 [00:01<00:00, 31.92it/s, loss=0.00416, val_loss=0.00324,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 36.26it/s, loss=0.00416, val_loss=0.00316,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 20.74it/s, loss=0.00416, val_loss=0.00316,\u001b[A\n",
      "Epoch 93:  83%|▊| 40/48 [00:01<00:00, 32.21it/s, loss=0.00416, val_loss=0.00316,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 36.45it/s, loss=0.00416, val_loss=0.00315,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 20.53it/s, loss=0.00417, val_loss=0.00315,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 35.88it/s, loss=0.00417, val_loss=0.00314,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.00418, val_loss=0.00314,\u001b[A\n",
      "Epoch 95:  83%|▊| 40/48 [00:01<00:00, 32.10it/s, loss=0.00418, val_loss=0.00314,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 36.23it/s, loss=0.00418, val_loss=0.00323,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 20.73it/s, loss=0.0531, val_loss=0.00323, \u001b[A\n",
      "Epoch 96:  83%|▊| 40/48 [00:01<00:00, 32.10it/s, loss=0.0531, val_loss=0.00323, \n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 36.36it/s, loss=0.0531, val_loss=0.00456, \u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 20.01it/s, loss=0.0145, val_loss=0.00456, \u001b[A\n",
      "Epoch 97:  83%|▊| 40/48 [00:01<00:00, 31.17it/s, loss=0.0145, val_loss=0.00456, \n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 35.44it/s, loss=0.0145, val_loss=0.00555, \u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.00494, val_loss=0.00555,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 35.73it/s, loss=0.00494, val_loss=0.00323,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 20.43it/s, loss=0.00423, val_loss=0.00323,\u001b[A\n",
      "Epoch 99:  83%|▊| 40/48 [00:01<00:00, 31.51it/s, loss=0.00423, val_loss=0.00323,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.86it/s, loss=0.00423, val_loss=0.00317,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.46it/s, loss=0.00423, val_loss=0.00317,\u001b[A\n",
      "Sizes of clusters: 412, 344, 444\n",
      "\n",
      "preds: [1 1 1 2 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2\n",
      " 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2\n",
      " 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 2 1 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 2 2 2 2 0 2 1\n",
      " 2 0 2 1 2 0 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 0 0 2 2 2 2 1 2 2 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 1 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 0 2 0 2 2 2 0 2 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 0 2 2 0 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 1 2\n",
      " 0 2 2 0 0 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 1 2 2 2 2 2 2 2 2 2 2 0\n",
      " 0 2 2 2 2 2 2 0 2 2 2 2 0 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 1 1 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 2 0 2 2 2 2 0 2 2 0 0 2 0 2 0 1 2 0 2 2 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0\n",
      " 0 0 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0 2\n",
      " 2 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 2 0 0 0\n",
      " 0 0 2 0 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 2 0 0\n",
      " 2 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 2 2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8317\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=7.87, val_loss=0.152, avg_v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  71%|▋| 34/48 [00:01<00:00, 27.71it/s, loss=7.87, val_loss=0.152, avg_v\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 36.08it/s, loss=7.87, val_loss=2.38, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 19.85it/s, loss=0.364, val_loss=2.38, avg_v\u001b[A\n",
      "Epoch 1:  69%|▋| 33/48 [00:01<00:00, 26.34it/s, loss=0.364, val_loss=2.38, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.364, val_loss=0.6, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 20.93it/s, loss=0.0714, val_loss=0.6, avg_v\u001b[A\n",
      "Epoch 2:  69%|▋| 33/48 [00:01<00:00, 27.77it/s, loss=0.0714, val_loss=0.6, avg_v\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 36.76it/s, loss=0.0714, val_loss=0.127, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.0347, val_loss=0.127, avg\u001b[A\n",
      "Epoch 3:  69%|▋| 33/48 [00:01<00:00, 27.61it/s, loss=0.0347, val_loss=0.127, avg\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 36.67it/s, loss=0.0347, val_loss=0.0577, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 20.56it/s, loss=0.0252, val_loss=0.0577, av\u001b[A\n",
      "Epoch 4:  69%|▋| 33/48 [00:01<00:00, 27.21it/s, loss=0.0252, val_loss=0.0577, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 35.92it/s, loss=0.0252, val_loss=0.0394, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 20.90it/s, loss=0.0203, val_loss=0.0394, av\u001b[A\n",
      "Epoch 5:  69%|▋| 33/48 [00:01<00:00, 27.66it/s, loss=0.0203, val_loss=0.0394, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 36.67it/s, loss=0.0203, val_loss=0.0293, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.0172, val_loss=0.0293, av\u001b[A\n",
      "Epoch 6:  69%|▋| 33/48 [00:01<00:00, 27.24it/s, loss=0.0172, val_loss=0.0293, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 36.04it/s, loss=0.0172, val_loss=0.0231, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 20.81it/s, loss=0.015, val_loss=0.0231, avg\u001b[A\n",
      "Epoch 7:  62%|▋| 30/48 [00:01<00:00, 25.58it/s, loss=0.015, val_loss=0.0231, avg\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 36.67it/s, loss=0.015, val_loss=0.0191, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 20.87it/s, loss=0.0134, val_loss=0.0191, av\u001b[A\n",
      "Epoch 8:  71%|▋| 34/48 [00:01<00:00, 28.33it/s, loss=0.0134, val_loss=0.0191, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 36.58it/s, loss=0.0134, val_loss=0.0165, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 20.57it/s, loss=0.0121, val_loss=0.0165, av\u001b[A\n",
      "Epoch 9:  71%|▋| 34/48 [00:01<00:00, 27.85it/s, loss=0.0121, val_loss=0.0165, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 36.17it/s, loss=0.0121, val_loss=0.0148, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 20.14it/s, loss=0.0109, val_loss=0.0148, a\u001b[A\n",
      "Epoch 10:  71%|▋| 34/48 [00:01<00:00, 27.33it/s, loss=0.0109, val_loss=0.0148, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 35.57it/s, loss=0.0109, val_loss=0.0136, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.45it/s, loss=0.00993, val_loss=0.0136, \u001b[A\n",
      "Epoch 11:  71%|▋| 34/48 [00:01<00:00, 28.94it/s, loss=0.00993, val_loss=0.0136, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.32it/s, loss=0.00993, val_loss=0.0127, \u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 20.84it/s, loss=0.00907, val_loss=0.0127, \u001b[A\n",
      "Epoch 12:  71%|▋| 34/48 [00:01<00:00, 28.07it/s, loss=0.00907, val_loss=0.0127, \n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 36.58it/s, loss=0.00907, val_loss=0.0118, \u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.64it/s, loss=0.00831, val_loss=0.0118, \u001b[A\n",
      "Epoch 13:  71%|▋| 34/48 [00:01<00:00, 29.28it/s, loss=0.00831, val_loss=0.0118, \n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00831, val_loss=0.011, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.00766, val_loss=0.011, a\u001b[A\n",
      "Epoch 14:  71%|▋| 34/48 [00:01<00:00, 27.92it/s, loss=0.00766, val_loss=0.011, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 36.23it/s, loss=0.00766, val_loss=0.0103, \u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 20.47it/s, loss=0.0071, val_loss=0.0103, a\u001b[A\n",
      "Epoch 15:  71%|▋| 34/48 [00:01<00:00, 27.83it/s, loss=0.0071, val_loss=0.0103, a\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 35.98it/s, loss=0.0071, val_loss=0.00983, \u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=0.00663, val_loss=0.00983,\u001b[A\n",
      "Epoch 16:  71%|▋| 34/48 [00:01<00:00, 28.37it/s, loss=0.00663, val_loss=0.00983,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 36.61it/s, loss=0.00663, val_loss=0.00917,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 20.86it/s, loss=0.00623, val_loss=0.00917,\u001b[A\n",
      "Epoch 17:  71%|▋| 34/48 [00:01<00:00, 28.31it/s, loss=0.00623, val_loss=0.00917,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 36.57it/s, loss=0.00623, val_loss=0.00873,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 20.73it/s, loss=0.0059, val_loss=0.00873, \u001b[A\n",
      "Epoch 18:  71%|▋| 34/48 [00:01<00:00, 28.28it/s, loss=0.0059, val_loss=0.00873, \n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 36.47it/s, loss=0.0059, val_loss=0.00841, \u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 20.85it/s, loss=0.00563, val_loss=0.00841,\u001b[A\n",
      "Epoch 19:  71%|▋| 34/48 [00:01<00:00, 28.47it/s, loss=0.00563, val_loss=0.00841,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 36.74it/s, loss=0.00563, val_loss=0.00803,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.0054, val_loss=0.00803, \u001b[A\n",
      "Epoch 20:  71%|▋| 34/48 [00:01<00:00, 27.99it/s, loss=0.0054, val_loss=0.00803, \n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 36.19it/s, loss=0.0054, val_loss=0.00775, \u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.00it/s, loss=0.00522, val_loss=0.00775,\u001b[A\n",
      "Epoch 21:  71%|▋| 34/48 [00:01<00:00, 28.55it/s, loss=0.00522, val_loss=0.00775,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 36.98it/s, loss=0.00522, val_loss=0.00769,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 20.76it/s, loss=0.00507, val_loss=0.00769,\u001b[A\n",
      "Epoch 22:  71%|▋| 34/48 [00:01<00:00, 28.20it/s, loss=0.00507, val_loss=0.00769,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 36.26it/s, loss=0.00507, val_loss=0.0073, \u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 20.98it/s, loss=0.00494, val_loss=0.0073, \u001b[A\n",
      "Epoch 23:  71%|▋| 34/48 [00:01<00:00, 28.56it/s, loss=0.00494, val_loss=0.0073, \n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 36.93it/s, loss=0.00494, val_loss=0.00736,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 20.74it/s, loss=0.00484, val_loss=0.00736,\u001b[A\n",
      "Epoch 24:  71%|▋| 34/48 [00:01<00:00, 28.07it/s, loss=0.00484, val_loss=0.00736,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 36.33it/s, loss=0.00484, val_loss=0.00722,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.32it/s, loss=0.00476, val_loss=0.00722,\u001b[A\n",
      "Epoch 25:  71%|▋| 34/48 [00:01<00:00, 29.08it/s, loss=0.00476, val_loss=0.00722,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 37.46it/s, loss=0.00476, val_loss=0.00687,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 20.75it/s, loss=0.00468, val_loss=0.00687,\u001b[A\n",
      "Epoch 26:  71%|▋| 34/48 [00:01<00:00, 28.24it/s, loss=0.00468, val_loss=0.00687,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 36.47it/s, loss=0.00468, val_loss=0.00682,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 20.34it/s, loss=0.00462, val_loss=0.00682,\u001b[A\n",
      "Epoch 27:  71%|▋| 34/48 [00:01<00:00, 27.75it/s, loss=0.00462, val_loss=0.00682,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 35.93it/s, loss=0.00462, val_loss=0.00704,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.02it/s, loss=0.00457, val_loss=0.00704,\u001b[A\n",
      "Epoch 28:  71%|▋| 34/48 [00:01<00:00, 28.70it/s, loss=0.00457, val_loss=0.00704,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 36.89it/s, loss=0.00457, val_loss=0.00667,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00452, val_loss=0.00667,\u001b[A\n",
      "Epoch 29:  71%|▋| 34/48 [00:01<00:00, 27.66it/s, loss=0.00452, val_loss=0.00667,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 35.82it/s, loss=0.00452, val_loss=0.00674,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.10it/s, loss=0.00448, val_loss=0.00674,\u001b[A\n",
      "Epoch 30:  71%|▋| 34/48 [00:01<00:00, 28.48it/s, loss=0.00448, val_loss=0.00674,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 36.96it/s, loss=0.00448, val_loss=0.00662,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 20.05it/s, loss=0.00445, val_loss=0.00662,\u001b[A\n",
      "Epoch 31:  71%|▋| 34/48 [00:01<00:00, 27.37it/s, loss=0.00445, val_loss=0.00662,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 35.47it/s, loss=0.00445, val_loss=0.00652,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 20.24it/s, loss=0.00442, val_loss=0.00652,\u001b[A\n",
      "Epoch 32:  71%|▋| 34/48 [00:01<00:00, 27.54it/s, loss=0.00442, val_loss=0.00652,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 35.77it/s, loss=0.00442, val_loss=0.00622,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 19.69it/s, loss=0.00439, val_loss=0.00622,\u001b[A\n",
      "Epoch 33:  71%|▋| 34/48 [00:01<00:00, 26.77it/s, loss=0.00439, val_loss=0.00622,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 34.80it/s, loss=0.00439, val_loss=0.00605,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 20.56it/s, loss=0.00436, val_loss=0.00605,\u001b[A\n",
      "Epoch 34:  71%|▋| 34/48 [00:01<00:00, 28.01it/s, loss=0.00436, val_loss=0.00605,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00436, val_loss=0.00596,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 20.75it/s, loss=0.00434, val_loss=0.00596,\u001b[A\n",
      "Epoch 35:  71%|▋| 34/48 [00:01<00:00, 27.83it/s, loss=0.00434, val_loss=0.00596,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 36.19it/s, loss=0.00434, val_loss=0.00624,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 20.80it/s, loss=0.00432, val_loss=0.00624,\u001b[A\n",
      "Epoch 36:  71%|▋| 34/48 [00:01<00:00, 28.42it/s, loss=0.00432, val_loss=0.00624,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 36.65it/s, loss=0.00432, val_loss=0.00644,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.68it/s, loss=0.0043, val_loss=0.00644, \u001b[A\n",
      "Epoch 37:  71%|▋| 34/48 [00:01<00:00, 27.99it/s, loss=0.0043, val_loss=0.00644, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 36.17it/s, loss=0.0043, val_loss=0.00624, \u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 20.81it/s, loss=0.00429, val_loss=0.00624,\u001b[A\n",
      "Epoch 38:  71%|▋| 34/48 [00:01<00:00, 28.40it/s, loss=0.00429, val_loss=0.00624,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 36.69it/s, loss=0.00429, val_loss=0.0063, \u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 19.91it/s, loss=0.00427, val_loss=0.0063, \u001b[A\n",
      "Epoch 39:  71%|▋| 34/48 [00:01<00:00, 27.11it/s, loss=0.00427, val_loss=0.0063, \n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 35.20it/s, loss=0.00427, val_loss=0.00659,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 20.87it/s, loss=0.00426, val_loss=0.00659,\u001b[A\n",
      "Epoch 40:  71%|▋| 34/48 [00:01<00:00, 28.26it/s, loss=0.00426, val_loss=0.00659,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 36.61it/s, loss=0.00426, val_loss=0.00651,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 20.48it/s, loss=0.00424, val_loss=0.00651,\u001b[A\n",
      "Epoch 41:  71%|▋| 34/48 [00:01<00:00, 27.93it/s, loss=0.00424, val_loss=0.00651,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 35.91it/s, loss=0.00424, val_loss=0.00633,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00423, val_loss=0.00633,\u001b[A\n",
      "Epoch 42:  71%|▋| 34/48 [00:01<00:00, 27.68it/s, loss=0.00423, val_loss=0.00633,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 35.95it/s, loss=0.00423, val_loss=0.00658,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 20.94it/s, loss=0.00422, val_loss=0.00658,\u001b[A\n",
      "Epoch 43:  71%|▋| 34/48 [00:01<00:00, 28.51it/s, loss=0.00422, val_loss=0.00658,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 36.77it/s, loss=0.00422, val_loss=0.00653,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.00421, val_loss=0.00653,\u001b[A\n",
      "Epoch 44:  71%|▋| 34/48 [00:01<00:00, 27.57it/s, loss=0.00421, val_loss=0.00653,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 35.97it/s, loss=0.00421, val_loss=0.00672,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 21.40it/s, loss=0.0042, val_loss=0.00672, \u001b[A\n",
      "Epoch 45:  71%|▋| 34/48 [00:01<00:00, 29.04it/s, loss=0.0042, val_loss=0.00672, \n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 37.57it/s, loss=0.0042, val_loss=0.00691, \u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 20.62it/s, loss=0.00419, val_loss=0.00691,\u001b[A\n",
      "Epoch 46:  71%|▋| 34/48 [00:01<00:00, 27.96it/s, loss=0.00419, val_loss=0.00691,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00419, val_loss=0.00689,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 20.97it/s, loss=0.00418, val_loss=0.00689,\u001b[A\n",
      "Epoch 47:  71%|▋| 34/48 [00:01<00:00, 28.55it/s, loss=0.00418, val_loss=0.00689,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 36.91it/s, loss=0.00418, val_loss=0.00668,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 21.15it/s, loss=0.00418, val_loss=0.00668,\u001b[A\n",
      "Epoch 48:  71%|▋| 34/48 [00:01<00:00, 28.73it/s, loss=0.00418, val_loss=0.00668,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 37.10it/s, loss=0.00418, val_loss=0.00673,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 20.71it/s, loss=0.00417, val_loss=0.00673,\u001b[A\n",
      "Epoch 49:  71%|▋| 34/48 [00:01<00:00, 28.19it/s, loss=0.00417, val_loss=0.00673,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 36.40it/s, loss=0.00417, val_loss=0.00662,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 20.97it/s, loss=0.00416, val_loss=0.00662,\u001b[A\n",
      "Epoch 50:  71%|▋| 34/48 [00:01<00:00, 28.64it/s, loss=0.00416, val_loss=0.00662,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 36.85it/s, loss=0.00416, val_loss=0.00706,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 20.98it/s, loss=0.00416, val_loss=0.00706,\u001b[A\n",
      "Epoch 51:  71%|▋| 34/48 [00:01<00:00, 28.63it/s, loss=0.00416, val_loss=0.00706,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 36.93it/s, loss=0.00416, val_loss=0.00687,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00415, val_loss=0.00687,\u001b[A\n",
      "Epoch 52:  71%|▋| 34/48 [00:01<00:00, 27.46it/s, loss=0.00415, val_loss=0.00687,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 35.83it/s, loss=0.00415, val_loss=0.0073, \u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00415, val_loss=0.0073, \u001b[A\n",
      "Epoch 53:  71%|▋| 34/48 [00:01<00:00, 28.15it/s, loss=0.00415, val_loss=0.0073, \n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 36.36it/s, loss=0.00415, val_loss=0.00709,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 20.41it/s, loss=0.00414, val_loss=0.00709,\u001b[A\n",
      "Epoch 54:  71%|▋| 34/48 [00:01<00:00, 27.72it/s, loss=0.00414, val_loss=0.00709,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 35.89it/s, loss=0.00414, val_loss=0.00745,\u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 20.74it/s, loss=0.00414, val_loss=0.00745,\u001b[A\n",
      "Epoch 55:  71%|▋| 34/48 [00:01<00:00, 27.95it/s, loss=0.00414, val_loss=0.00745,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 36.35it/s, loss=0.00414, val_loss=0.00736,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 20.81it/s, loss=0.00413, val_loss=0.00736,\u001b[A\n",
      "Epoch 56:  71%|▋| 34/48 [00:01<00:00, 28.17it/s, loss=0.00413, val_loss=0.00736,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 36.68it/s, loss=0.00413, val_loss=0.00765,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 21.25it/s, loss=0.00413, val_loss=0.00765,\u001b[A\n",
      "Epoch 57:  71%|▋| 34/48 [00:01<00:00, 28.81it/s, loss=0.00413, val_loss=0.00765,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 37.25it/s, loss=0.00413, val_loss=0.00794,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 20.90it/s, loss=0.00413, val_loss=0.00794,\u001b[A\n",
      "Epoch 58:  71%|▋| 34/48 [00:01<00:00, 28.27it/s, loss=0.00413, val_loss=0.00794,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 36.76it/s, loss=0.00413, val_loss=0.00828,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.00412, val_loss=0.00828,\u001b[A\n",
      "Epoch 59:  71%|▋| 34/48 [00:01<00:00, 28.09it/s, loss=0.00412, val_loss=0.00828,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 36.26it/s, loss=0.00412, val_loss=0.00806,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00412, val_loss=0.00806,\u001b[A\n",
      "Epoch 60:  71%|▋| 34/48 [00:01<00:00, 27.86it/s, loss=0.00412, val_loss=0.00806,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 36.31it/s, loss=0.00412, val_loss=0.00845,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.00412, val_loss=0.00845,\u001b[A\n",
      "Epoch 61:  71%|▋| 34/48 [00:01<00:00, 27.89it/s, loss=0.00412, val_loss=0.00845,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 36.25it/s, loss=0.00412, val_loss=0.00836,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 20.19it/s, loss=0.00412, val_loss=0.00836,\u001b[A\n",
      "Epoch 62:  71%|▋| 34/48 [00:01<00:00, 27.15it/s, loss=0.00412, val_loss=0.00836,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 35.42it/s, loss=0.00412, val_loss=0.00833,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 21.20it/s, loss=0.00412, val_loss=0.00833,\u001b[A\n",
      "Epoch 63:  71%|▋| 34/48 [00:01<00:00, 28.82it/s, loss=0.00412, val_loss=0.00833,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 37.21it/s, loss=0.00412, val_loss=0.00866,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 20.55it/s, loss=0.00412, val_loss=0.00866,\u001b[A\n",
      "Epoch 64:  71%|▋| 34/48 [00:01<00:00, 27.91it/s, loss=0.00412, val_loss=0.00866,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 36.14it/s, loss=0.00412, val_loss=0.00843,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 20.55it/s, loss=0.00411, val_loss=0.00843,\u001b[A\n",
      "Epoch 65:  71%|▋| 34/48 [00:01<00:00, 27.70it/s, loss=0.00411, val_loss=0.00843,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 36.08it/s, loss=0.00411, val_loss=0.00871,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 20.52it/s, loss=0.00411, val_loss=0.00871,\u001b[A\n",
      "Epoch 66:  71%|▋| 34/48 [00:01<00:00, 27.89it/s, loss=0.00411, val_loss=0.00871,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 35.91it/s, loss=0.00411, val_loss=0.00909,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 20.99it/s, loss=0.00411, val_loss=0.00909,\u001b[A\n",
      "Epoch 67:  71%|▋| 34/48 [00:01<00:00, 28.65it/s, loss=0.00411, val_loss=0.00909,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 36.95it/s, loss=0.00411, val_loss=0.00891,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 20.11it/s, loss=0.00411, val_loss=0.00891,\u001b[A\n",
      "Epoch 68:  71%|▋| 34/48 [00:01<00:00, 27.11it/s, loss=0.00411, val_loss=0.00891,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 35.34it/s, loss=0.00411, val_loss=0.00884,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 20.86it/s, loss=0.00411, val_loss=0.00884,\u001b[A\n",
      "Epoch 69:  71%|▋| 34/48 [00:01<00:00, 28.50it/s, loss=0.00411, val_loss=0.00884,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 36.76it/s, loss=0.00411, val_loss=0.00952,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 20.87it/s, loss=0.00411, val_loss=0.00952,\u001b[A\n",
      "Epoch 70:  71%|▋| 34/48 [00:01<00:00, 28.34it/s, loss=0.00411, val_loss=0.00952,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 36.73it/s, loss=0.00411, val_loss=0.00913,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 21.37it/s, loss=0.00411, val_loss=0.00913,\u001b[A\n",
      "Epoch 71:  71%|▋| 34/48 [00:01<00:00, 28.97it/s, loss=0.00411, val_loss=0.00913,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 37.51it/s, loss=0.00411, val_loss=0.00949,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 21.28it/s, loss=0.00411, val_loss=0.00949,\u001b[A\n",
      "Epoch 72:  71%|▋| 34/48 [00:01<00:00, 29.04it/s, loss=0.00411, val_loss=0.00949,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 37.41it/s, loss=0.00411, val_loss=0.00974,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00411, val_loss=0.00974,\u001b[A\n",
      "Epoch 73:  71%|▋| 34/48 [00:01<00:00, 29.30it/s, loss=0.00411, val_loss=0.00974,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00411, val_loss=0.0102, \u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 20.88it/s, loss=0.00411, val_loss=0.0102, \u001b[A\n",
      "Epoch 74:  71%|▋| 34/48 [00:01<00:00, 28.51it/s, loss=0.00411, val_loss=0.0102, \n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 36.79it/s, loss=0.00411, val_loss=0.0105, \u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 20.99it/s, loss=0.00412, val_loss=0.0105, \u001b[A\n",
      "Epoch 75:  71%|▋| 34/48 [00:01<00:00, 28.37it/s, loss=0.00412, val_loss=0.0105, \n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 36.78it/s, loss=0.00412, val_loss=0.0105, \u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 20.96it/s, loss=0.00412, val_loss=0.0105, \u001b[A\n",
      "Epoch 76:  71%|▋| 34/48 [00:01<00:00, 28.54it/s, loss=0.00412, val_loss=0.0105, \n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 36.82it/s, loss=0.00412, val_loss=0.011, a\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 20.13it/s, loss=0.00412, val_loss=0.011, a\u001b[A\n",
      "Epoch 77:  71%|▋| 34/48 [00:01<00:00, 27.39it/s, loss=0.00412, val_loss=0.011, a\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 35.46it/s, loss=0.00412, val_loss=0.011, a\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.00412, val_loss=0.011, a\u001b[A\n",
      "Epoch 78:  71%|▋| 34/48 [00:01<00:00, 29.36it/s, loss=0.00412, val_loss=0.011, a\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00412, val_loss=0.0109, \u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 20.38it/s, loss=0.00412, val_loss=0.0109, \u001b[A\n",
      "Epoch 79:  71%|▋| 34/48 [00:01<00:00, 27.64it/s, loss=0.00412, val_loss=0.0109, \n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 35.98it/s, loss=0.00412, val_loss=0.0109, \u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00412, val_loss=0.0109, \u001b[A\n",
      "Epoch 80:  71%|▋| 34/48 [00:01<00:00, 27.59it/s, loss=0.00412, val_loss=0.0109, \n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 35.81it/s, loss=0.00412, val_loss=0.0113, \u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.90it/s, loss=0.00412, val_loss=0.0113, \u001b[A\n",
      "Epoch 81:  71%|▋| 34/48 [00:01<00:00, 28.32it/s, loss=0.00412, val_loss=0.0113, \n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 36.42it/s, loss=0.00412, val_loss=0.0117, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 20.87it/s, loss=0.00413, val_loss=0.0117, \u001b[A\n",
      "Epoch 82:  71%|▋| 34/48 [00:01<00:00, 28.50it/s, loss=0.00413, val_loss=0.0117, \n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 36.68it/s, loss=0.00413, val_loss=0.012, a\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 19.89it/s, loss=0.00413, val_loss=0.012, a\u001b[A\n",
      "Epoch 83:  71%|▋| 34/48 [00:01<00:00, 26.77it/s, loss=0.00413, val_loss=0.012, a\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 34.85it/s, loss=0.00413, val_loss=0.0122, \u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00413, val_loss=0.0122, \u001b[A\n",
      "Epoch 84:  71%|▋| 34/48 [00:01<00:00, 29.20it/s, loss=0.00413, val_loss=0.0122, \n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 37.70it/s, loss=0.00413, val_loss=0.0119, \u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 20.80it/s, loss=0.00413, val_loss=0.0119, \u001b[A\n",
      "Epoch 85:  71%|▋| 34/48 [00:01<00:00, 28.24it/s, loss=0.00413, val_loss=0.0119, \n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 36.58it/s, loss=0.00413, val_loss=0.0121, \u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 21.20it/s, loss=0.00413, val_loss=0.0121, \u001b[A\n",
      "Epoch 86:  71%|▋| 34/48 [00:01<00:00, 28.75it/s, loss=0.00413, val_loss=0.0121, \n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 37.19it/s, loss=0.00413, val_loss=0.0126, \u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 20.90it/s, loss=0.00414, val_loss=0.0126, \u001b[A\n",
      "Epoch 87:  71%|▋| 34/48 [00:01<00:00, 28.45it/s, loss=0.00414, val_loss=0.0126, \n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 36.80it/s, loss=0.00414, val_loss=0.0126, \u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 20.49it/s, loss=0.00414, val_loss=0.0126, \u001b[A\n",
      "Epoch 88:  71%|▋| 34/48 [00:01<00:00, 27.84it/s, loss=0.00414, val_loss=0.0126, \n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 36.17it/s, loss=0.00414, val_loss=0.0134, \u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 21.01it/s, loss=0.00414, val_loss=0.0134, \u001b[A\n",
      "Epoch 89:  71%|▋| 34/48 [00:01<00:00, 28.66it/s, loss=0.00414, val_loss=0.0134, \n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 36.83it/s, loss=0.00414, val_loss=0.0132, \u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00414, val_loss=0.0132, \u001b[A\n",
      "Epoch 90:  71%|▋| 34/48 [00:01<00:00, 28.24it/s, loss=0.00414, val_loss=0.0132, \n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 36.46it/s, loss=0.00414, val_loss=0.0134, \u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 20.98it/s, loss=0.00415, val_loss=0.0134, \u001b[A\n",
      "Epoch 91:  71%|▋| 34/48 [00:01<00:00, 28.56it/s, loss=0.00415, val_loss=0.0134, \n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 36.84it/s, loss=0.00415, val_loss=0.0138, \u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00415, val_loss=0.0138, \u001b[A\n",
      "Epoch 92:  71%|▋| 34/48 [00:01<00:00, 28.19it/s, loss=0.00415, val_loss=0.0138, \n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 36.40it/s, loss=0.00415, val_loss=0.0144, \u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 21.23it/s, loss=0.00415, val_loss=0.0144, \u001b[A\n",
      "Epoch 93:  71%|▋| 34/48 [00:01<00:00, 28.90it/s, loss=0.00415, val_loss=0.0144, \n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 37.30it/s, loss=0.00415, val_loss=0.0142, \u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00416, val_loss=0.0142, \u001b[A\n",
      "Epoch 94:  71%|▋| 34/48 [00:01<00:00, 29.54it/s, loss=0.00416, val_loss=0.0142, \n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 37.99it/s, loss=0.00416, val_loss=0.0145, \u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 21.25it/s, loss=0.00416, val_loss=0.0145, \u001b[A\n",
      "Epoch 95:  71%|▋| 34/48 [00:01<00:00, 28.98it/s, loss=0.00416, val_loss=0.0145, \n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 37.19it/s, loss=0.00416, val_loss=0.0146, \u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 21.21it/s, loss=0.00416, val_loss=0.0146, \u001b[A\n",
      "Epoch 96:  71%|▋| 34/48 [00:01<00:00, 28.96it/s, loss=0.00416, val_loss=0.0146, \n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 37.30it/s, loss=0.00416, val_loss=0.0147, \u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00417, val_loss=0.0147, \u001b[A\n",
      "Epoch 97:  71%|▋| 34/48 [00:01<00:00, 29.40it/s, loss=0.00417, val_loss=0.0147, \n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 37.87it/s, loss=0.00417, val_loss=0.0149, \u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00417, val_loss=0.0149, \u001b[A\n",
      "Epoch 98:  71%|▋| 34/48 [00:01<00:00, 29.38it/s, loss=0.00417, val_loss=0.0149, \n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 37.97it/s, loss=0.00417, val_loss=0.0152, \u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 20.37it/s, loss=0.00417, val_loss=0.0152, \u001b[A\n",
      "Epoch 99:  71%|▋| 34/48 [00:01<00:00, 27.72it/s, loss=0.00417, val_loss=0.0152, \n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.92it/s, loss=0.00417, val_loss=0.0151, \u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.00417, val_loss=0.0151, \u001b[A\n",
      "Sizes of clusters: 399, 344, 457\n",
      "\n",
      "preds: [1 1 1 2 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2\n",
      " 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2\n",
      " 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 2 1 1 2 1 1 1 1 1 1 2 2 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 2 2 2 2 0 2 1\n",
      " 2 0 2 1 2 0 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 0 2 2 2 2 2 1 2 2 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 1 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 0 2 0 2 2 2 0 2 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 0 2 2 0 2 0 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 1 2\n",
      " 0 2 2 0 0 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 0 2 2 2 1 2 2 2 2 0 2 2 2 2 2 2 0\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 1 2 2 2 2 2 2 2 2 2 2 0\n",
      " 0 2 2 2 2 2 2 0 2 2 2 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 1 1 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 2 0 2 2 2 2 0 2 2 0 0 2 0 2 0 1 2 0 2 2 0 2 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0\n",
      " 0 0 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 2 0 0 0 0\n",
      " 2 0 0 2 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 2 0 0 2\n",
      " 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 2 0 2 0\n",
      " 0 0 2 0 2 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 2 0 0\n",
      " 2 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 2 2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8242\n",
      "\n",
      "Consistency: 0.8389\n",
      "Purity: 0.8160000000000001+-0.015522385269166765\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K3_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=3.08, val_loss=0.129, avg_v\n",
      "Epoch 0:  80%|▊| 51/64 [00:01<00:00, 32.34it/s, loss=3.08, val_loss=0.129, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=3.08, val_loss=5.92, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.169, val_loss=5.92, avg_v\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 25.17it/s, loss=0.169, val_loss=5.92, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.169, val_loss=0.139, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.0503, val_loss=0.139, avg\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.66it/s, loss=0.0503, val_loss=0.139, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.38it/s, loss=0.0503, val_loss=0.0558, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0377, val_loss=0.0558, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.46it/s, loss=0.0377, val_loss=0.0558, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.26it/s, loss=0.0377, val_loss=0.046, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.0315, val_loss=0.046, avg\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 25.37it/s, loss=0.0315, val_loss=0.046, avg\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.02it/s, loss=0.0315, val_loss=0.0396, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 22.21it/s, loss=0.0272, val_loss=0.0396, av\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:00, 26.02it/s, loss=0.0272, val_loss=0.0396, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.81it/s, loss=0.0272, val_loss=0.0347, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.0239, val_loss=0.0347, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 25.67it/s, loss=0.0239, val_loss=0.0347, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.0239, val_loss=0.0308, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.0213, val_loss=0.0308, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 25.56it/s, loss=0.0213, val_loss=0.0308, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.0213, val_loss=0.0274, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 22.17it/s, loss=0.0192, val_loss=0.0274, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.89it/s, loss=0.0192, val_loss=0.0274, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.76it/s, loss=0.0192, val_loss=0.0245, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.0173, val_loss=0.0245, av\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.0173, val_loss=0.0245, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.0173, val_loss=0.0219, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.0157, val_loss=0.0219, a\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 25.73it/s, loss=0.0157, val_loss=0.0219, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.44it/s, loss=0.0157, val_loss=0.0194, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.0142, val_loss=0.0194, a\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 25.80it/s, loss=0.0142, val_loss=0.0194, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.59it/s, loss=0.0142, val_loss=0.0173, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.0128, val_loss=0.0173, a\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.68it/s, loss=0.0128, val_loss=0.0173, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.36it/s, loss=0.0128, val_loss=0.0155, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 22.12it/s, loss=0.0116, val_loss=0.0155, a\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 25.90it/s, loss=0.0116, val_loss=0.0155, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.69it/s, loss=0.0116, val_loss=0.0138, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.0105, val_loss=0.0138, a\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.72it/s, loss=0.0105, val_loss=0.0138, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.42it/s, loss=0.0105, val_loss=0.0124, a\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.00953, val_loss=0.0124, \u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 25.86it/s, loss=0.00953, val_loss=0.0124, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.67it/s, loss=0.00953, val_loss=0.011, a\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 22.11it/s, loss=0.00866, val_loss=0.011, a\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 25.88it/s, loss=0.00866, val_loss=0.011, a\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.66it/s, loss=0.00866, val_loss=0.00996,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 22.04it/s, loss=0.00789, val_loss=0.00996,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 25.81it/s, loss=0.00789, val_loss=0.00996,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.56it/s, loss=0.00789, val_loss=0.00912,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.00723, val_loss=0.00912,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 25.75it/s, loss=0.00723, val_loss=0.00912,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 38.49it/s, loss=0.00723, val_loss=0.00817,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.00667, val_loss=0.00817,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 25.91it/s, loss=0.00667, val_loss=0.00817,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.70it/s, loss=0.00667, val_loss=0.0075, \u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 22.06it/s, loss=0.00621, val_loss=0.0075, \u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 25.82it/s, loss=0.00621, val_loss=0.0075, \n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 38.59it/s, loss=0.00621, val_loss=0.00699,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.00582, val_loss=0.00699,\u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 25.75it/s, loss=0.00582, val_loss=0.00699,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.51it/s, loss=0.00582, val_loss=0.00632,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 22.19it/s, loss=0.0055, val_loss=0.00632, \u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.98it/s, loss=0.0055, val_loss=0.00632, \n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.80it/s, loss=0.0055, val_loss=0.00589, \u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00524, val_loss=0.00589,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 25.66it/s, loss=0.00524, val_loss=0.00589,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00524, val_loss=0.0057, \u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00504, val_loss=0.0057, \u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 25.74it/s, loss=0.00504, val_loss=0.0057, \n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 38.45it/s, loss=0.00504, val_loss=0.00535,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 22.26it/s, loss=0.00487, val_loss=0.00535,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:00, 26.11it/s, loss=0.00487, val_loss=0.00535,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.92it/s, loss=0.00487, val_loss=0.0051, \u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.00474, val_loss=0.0051, \u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.86it/s, loss=0.00474, val_loss=0.0051, \n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.62it/s, loss=0.00474, val_loss=0.00504,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 22.16it/s, loss=0.00463, val_loss=0.00504,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.88it/s, loss=0.00463, val_loss=0.00504,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.60it/s, loss=0.00463, val_loss=0.00481,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.00455, val_loss=0.00481,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.90it/s, loss=0.00455, val_loss=0.00481,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.63it/s, loss=0.00455, val_loss=0.00472,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00448, val_loss=0.00472,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.75it/s, loss=0.00448, val_loss=0.00472,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.00448, val_loss=0.00464,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 22.26it/s, loss=0.00443, val_loss=0.00464,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.96it/s, loss=0.00443, val_loss=0.00464,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.85it/s, loss=0.00443, val_loss=0.00456,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.00439, val_loss=0.00456,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.75it/s, loss=0.00439, val_loss=0.00456,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 38.52it/s, loss=0.00439, val_loss=0.00449,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00435, val_loss=0.00449,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00435, val_loss=0.00449,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00435, val_loss=0.00438,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 22.23it/s, loss=0.00432, val_loss=0.00438,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:00, 26.04it/s, loss=0.00432, val_loss=0.00438,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.88it/s, loss=0.00432, val_loss=0.00438,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.00429, val_loss=0.00438,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 25.96it/s, loss=0.00429, val_loss=0.00438,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.74it/s, loss=0.00429, val_loss=0.0044, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00427, val_loss=0.0044, \u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.00427, val_loss=0.0044, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 38.40it/s, loss=0.00427, val_loss=0.00443,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 22.23it/s, loss=0.00425, val_loss=0.00443,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:00, 26.07it/s, loss=0.00425, val_loss=0.00443,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.87it/s, loss=0.00425, val_loss=0.00438,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 22.11it/s, loss=0.00423, val_loss=0.00438,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.94it/s, loss=0.00423, val_loss=0.00438,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.71it/s, loss=0.00423, val_loss=0.00423,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 22.22it/s, loss=0.00421, val_loss=0.00423,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:00, 26.05it/s, loss=0.00421, val_loss=0.00423,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.84it/s, loss=0.00421, val_loss=0.0044, \u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 22.17it/s, loss=0.00419, val_loss=0.0044, \u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 25.98it/s, loss=0.00419, val_loss=0.0044, \n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 38.76it/s, loss=0.00419, val_loss=0.0041, \u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.00418, val_loss=0.0041, \u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 25.84it/s, loss=0.00418, val_loss=0.0041, \n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 38.58it/s, loss=0.00418, val_loss=0.00425,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 22.39it/s, loss=0.00416, val_loss=0.00425,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:00, 26.27it/s, loss=0.00416, val_loss=0.00425,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 39.14it/s, loss=0.00416, val_loss=0.00424,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.00415, val_loss=0.00424,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 25.78it/s, loss=0.00415, val_loss=0.00424,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 38.52it/s, loss=0.00415, val_loss=0.0043, \u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00414, val_loss=0.0043, \u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 25.56it/s, loss=0.00414, val_loss=0.0043, \n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 38.26it/s, loss=0.00414, val_loss=0.00404,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.00413, val_loss=0.00404,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 25.80it/s, loss=0.00413, val_loss=0.00404,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 38.52it/s, loss=0.00413, val_loss=0.00403,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 22.12it/s, loss=0.00411, val_loss=0.00403,\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 25.95it/s, loss=0.00411, val_loss=0.00403,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 38.74it/s, loss=0.00411, val_loss=0.00427,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 22.10it/s, loss=0.0041, val_loss=0.00427, \u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 25.89it/s, loss=0.0041, val_loss=0.00427, \n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 38.68it/s, loss=0.0041, val_loss=0.00436, \u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 22.24it/s, loss=0.00409, val_loss=0.00436,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:00, 26.04it/s, loss=0.00409, val_loss=0.00436,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 38.88it/s, loss=0.00409, val_loss=0.00412,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.00408, val_loss=0.00412,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 25.76it/s, loss=0.00408, val_loss=0.00412,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 38.55it/s, loss=0.00408, val_loss=0.00399,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.95it/s, loss=0.00407, val_loss=0.00399,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 25.69it/s, loss=0.00407, val_loss=0.00399,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 38.43it/s, loss=0.00407, val_loss=0.00435,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 22.17it/s, loss=0.00406, val_loss=0.00435,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 25.96it/s, loss=0.00406, val_loss=0.00435,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 38.76it/s, loss=0.00406, val_loss=0.00477,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.00406, val_loss=0.00477,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 25.78it/s, loss=0.00406, val_loss=0.00477,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 38.57it/s, loss=0.00406, val_loss=0.0043, \u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 22.33it/s, loss=0.00405, val_loss=0.0043, \u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:00, 26.20it/s, loss=0.00405, val_loss=0.0043, \n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 39.07it/s, loss=0.00405, val_loss=0.00464,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.00404, val_loss=0.00464,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 25.73it/s, loss=0.00404, val_loss=0.00464,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 38.47it/s, loss=0.00404, val_loss=0.00408,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00403, val_loss=0.00408,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 25.61it/s, loss=0.00403, val_loss=0.00408,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.00403, val_loss=0.00428,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 22.18it/s, loss=0.00403, val_loss=0.00428,\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:00, 26.02it/s, loss=0.00403, val_loss=0.00428,\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 38.82it/s, loss=0.00403, val_loss=0.0045, \u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.00402, val_loss=0.0045, \u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 25.91it/s, loss=0.00402, val_loss=0.0045, \n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 38.68it/s, loss=0.00402, val_loss=0.00446,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 22.10it/s, loss=0.00402, val_loss=0.00446,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 25.93it/s, loss=0.00402, val_loss=0.00446,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 38.68it/s, loss=0.00402, val_loss=0.00424,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 22.30it/s, loss=0.00401, val_loss=0.00424,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:00, 26.15it/s, loss=0.00401, val_loss=0.00424,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 38.98it/s, loss=0.00401, val_loss=0.00481,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.00401, val_loss=0.00481,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 25.96it/s, loss=0.00401, val_loss=0.00481,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 38.75it/s, loss=0.00401, val_loss=0.0046, \u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.004, val_loss=0.0046, av\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 25.32it/s, loss=0.004, val_loss=0.0046, av\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 38.03it/s, loss=0.004, val_loss=0.005, avg\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 22.00it/s, loss=0.004, val_loss=0.005, avg\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 25.68it/s, loss=0.004, val_loss=0.005, avg\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 38.48it/s, loss=0.004, val_loss=0.0048, av\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.00399, val_loss=0.0048, \u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 25.49it/s, loss=0.00399, val_loss=0.0048, \n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00399, val_loss=0.00459,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00399, val_loss=0.00459,\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 25.47it/s, loss=0.00399, val_loss=0.00459,\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.00399, val_loss=0.00537,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.00399, val_loss=0.00537,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 25.82it/s, loss=0.00399, val_loss=0.00537,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 38.55it/s, loss=0.00399, val_loss=0.00567,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 22.00it/s, loss=0.00398, val_loss=0.00567,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 25.81it/s, loss=0.00398, val_loss=0.00567,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 38.53it/s, loss=0.00398, val_loss=0.00488,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.00398, val_loss=0.00488,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 25.80it/s, loss=0.00398, val_loss=0.00488,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 38.64it/s, loss=0.00398, val_loss=0.0049, \u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00398, val_loss=0.0049, \u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.00398, val_loss=0.0049, \n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 38.35it/s, loss=0.00398, val_loss=0.00459,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00398, val_loss=0.00459,\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 25.70it/s, loss=0.00398, val_loss=0.00459,\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 38.41it/s, loss=0.00398, val_loss=0.00493,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 22.25it/s, loss=0.00397, val_loss=0.00493,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:00, 26.11it/s, loss=0.00397, val_loss=0.00493,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 38.93it/s, loss=0.00397, val_loss=0.00533,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.00397, val_loss=0.00533,\u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 25.62it/s, loss=0.00397, val_loss=0.00533,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 38.40it/s, loss=0.00397, val_loss=0.00564,\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 22.17it/s, loss=0.00397, val_loss=0.00564,\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:00, 26.02it/s, loss=0.00397, val_loss=0.00564,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 38.80it/s, loss=0.00397, val_loss=0.00556,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 22.30it/s, loss=0.00397, val_loss=0.00556,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:00, 26.16it/s, loss=0.00397, val_loss=0.00556,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 39.00it/s, loss=0.00397, val_loss=0.00566,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 22.15it/s, loss=0.00397, val_loss=0.00566,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 25.97it/s, loss=0.00397, val_loss=0.00566,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 38.76it/s, loss=0.00397, val_loss=0.00607,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 22.21it/s, loss=0.00397, val_loss=0.00607,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:00, 26.06it/s, loss=0.00397, val_loss=0.00607,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 38.87it/s, loss=0.00397, val_loss=0.00597,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 22.30it/s, loss=0.00396, val_loss=0.00597,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:00, 26.16it/s, loss=0.00396, val_loss=0.00597,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 39.01it/s, loss=0.00396, val_loss=0.00605,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 22.29it/s, loss=0.00396, val_loss=0.00605,\u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:00, 26.15it/s, loss=0.00396, val_loss=0.00605,\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 39.00it/s, loss=0.00396, val_loss=0.00598,\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 22.26it/s, loss=0.00396, val_loss=0.00598,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:00, 26.11it/s, loss=0.00396, val_loss=0.00598,\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 38.93it/s, loss=0.00396, val_loss=0.00619,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.00396, val_loss=0.00619,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 25.79it/s, loss=0.00396, val_loss=0.00619,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 38.52it/s, loss=0.00396, val_loss=0.00655,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 22.06it/s, loss=0.00396, val_loss=0.00655,\u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 25.89it/s, loss=0.00396, val_loss=0.00655,\n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 38.62it/s, loss=0.00396, val_loss=0.00655,\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 22.23it/s, loss=0.00396, val_loss=0.00655,\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 26.00it/s, loss=0.00396, val_loss=0.00655,\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 38.91it/s, loss=0.00396, val_loss=0.00663,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 22.14it/s, loss=0.00396, val_loss=0.00663,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 25.97it/s, loss=0.00396, val_loss=0.00663,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 38.75it/s, loss=0.00396, val_loss=0.0075, \u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.00396, val_loss=0.0075, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 25.83it/s, loss=0.00396, val_loss=0.0075, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 38.57it/s, loss=0.00396, val_loss=0.00728,\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.0214, val_loss=0.00728, \u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.78it/s, loss=0.0214, val_loss=0.00728, \n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.0214, val_loss=0.0274, a\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.00519, val_loss=0.0274, \u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 24.15it/s, loss=0.00519, val_loss=0.0274, \n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 36.47it/s, loss=0.00519, val_loss=0.00771,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00399, val_loss=0.00771,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.00399, val_loss=0.00771,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.72it/s, loss=0.00399, val_loss=0.00687,\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00394, val_loss=0.00687,\u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 24.55it/s, loss=0.00394, val_loss=0.00687,\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00394, val_loss=0.00795,\u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00394, val_loss=0.00795,\u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.21it/s, loss=0.00394, val_loss=0.00795,\n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.50it/s, loss=0.00394, val_loss=0.00784,\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 20.55it/s, loss=0.004, val_loss=0.00784, a\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 23.80it/s, loss=0.004, val_loss=0.00784, a\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 36.08it/s, loss=0.004, val_loss=0.00922, a\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 20.51it/s, loss=0.0396, val_loss=0.00922, \u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.08it/s, loss=0.0396, val_loss=0.00922, \n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 36.25it/s, loss=0.0396, val_loss=0.0195, a\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00486, val_loss=0.0195, \u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.00486, val_loss=0.0195, \n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 36.84it/s, loss=0.00486, val_loss=0.00896,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.00397, val_loss=0.00896,\u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.00397, val_loss=0.00896,\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00397, val_loss=0.00816,\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.52it/s, loss=0.0065, val_loss=0.00816, \u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 23.96it/s, loss=0.0065, val_loss=0.00816, \n",
      "Epoch 92:  89%|▉| 57/64 [00:01<00:00, 33.34it/s, loss=0.0065, val_loss=0.00816, \u001b[A\n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.13it/s, loss=0.0065, val_loss=0.0402, a\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.0108, val_loss=0.0402, a\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.05it/s, loss=0.0108, val_loss=0.0402, a\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.0108, val_loss=0.0108, a\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.00418, val_loss=0.0108, \u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 24.23it/s, loss=0.00418, val_loss=0.0108, \n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 36.61it/s, loss=0.00418, val_loss=0.00907,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 20.62it/s, loss=0.00394, val_loss=0.00907,\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.04it/s, loss=0.00394, val_loss=0.00907,\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=0.00394, val_loss=0.009, a\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.00394, val_loss=0.009, a\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00394, val_loss=0.009, a\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 37.07it/s, loss=0.00394, val_loss=0.0104, \u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00421, val_loss=0.0104, \u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.82it/s, loss=0.00421, val_loss=0.0104, \n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00421, val_loss=0.0137, \u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 20.66it/s, loss=0.0584, val_loss=0.0137, a\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.12it/s, loss=0.0584, val_loss=0.0137, a\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 36.35it/s, loss=0.0584, val_loss=0.0333, a\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 20.17it/s, loss=0.00506, val_loss=0.0333, \u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 23.52it/s, loss=0.00506, val_loss=0.0333, \n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 35.64it/s, loss=0.00506, val_loss=0.00866,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 35.43it/s, loss=0.00506, val_loss=0.00866,\u001b[A\n",
      "Sizes of clusters: 485, 430, 315, 370\n",
      "\n",
      "preds: [0 2 2 0 2 0 0 2 3 0 0 3 3 0 2 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 3 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2 0 2 0 0 0 3 0 0\n",
      " 0 0 0 0 3 2 0 0 0 2 0 3 0 2 0 0 0 3 0 0 3 0 0 0 0 1 2 2 0 0 0 0 2 0 0 0 0\n",
      " 1 0 0 3 0 0 0 0 0 2 0 2 0 1 2 3 0 0 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 3 0 0 2 2 0 0 0 0 3 0 0 3 0 2 0 0 2 0 3 0 0 0 0 3 0 0 0 0 0 0 2 0 0 0 3 0\n",
      " 0 2 0 0 2 3 0 2 0 0 2 0 3 2 0 3 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 2 0 0 0\n",
      " 0 0 0 3 2 0 0 0 3 0 0 0 0 2 0 2 0 0 2 0 0 0 0 0 2 2 2 0 0 0 0 2 0 0 0 0 2\n",
      " 0 0 2 3 0 0 0 0 0 0 2 3 2 2 0 0 0 0 1 2 2 0 3 1 2 0 0 0 0 0 0 0 2 0 0 0 3\n",
      " 0 2 0 0 0 0 0 2 0 3 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 3 0 0 0 2 0 2 2 0 2 1 2 2 0 0 2 0 2 2 0 0 0 2 0 0 0 0 0 0 0 2 0 3 0\n",
      " 0 0 0 0 3 2 0 0 2 0 0 0 0 2 0 0 2 0 0 0 0 3 2 0 0 3 2 0 0 0 2 2 0 2 2 2 2\n",
      " 2 2 0 2 2 2 0 0 2 2 2 0 0 2 2 2 2 0 0 0 2 2 3 0 0 2 2 2 0 0 2 0 0 0 2 2 2\n",
      " 2 0 2 2 2 2 0 2 2 0 2 2 3 2 2 0 2 0 2 0 2 2 2 2 2 2 2 0 0 2 2 0 2 0 2 2 0\n",
      " 2 2 2 2 0 3 2 3 0 0 0 0 0 2 2 2 2 0 2 0 2 0 2 0 2 0 0 3 2 0 2 0 0 2 2 0 2\n",
      " 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 0 2 0 0 2 0 0 0 2 2 0 2 2 2 2 2 0 0 0 0 0 0\n",
      " 2 0 2 2 2 0 2 0 2 2 2 0 0 3 2 2 2 0 2 2 0 2 2 2 2 2 0 0 2 2 0 2 2 0 0 0 2\n",
      " 3 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 0 0 0 2 2 0 2 2 0 2 2 2 2 0\n",
      " 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 3 0 2 0 0 2 2 2 2 2 2 2 0 2 0 2 2 0 0 0 0 2\n",
      " 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 0 0 2 2 0 2 2 0 2 2 0 2 0 0 2 2 2 2 0 0 0 2\n",
      " 2 0 0 2 0 0 0 2 2 0 2 0 0 0 2 0 0 2 2 2 0 2 2 0 2 2 2 3 2 2 2 2 2 0 2 2 0\n",
      " 2 2 0 2 2 2 0 0 0 0 0 0 2 2 1 2 2 0 2 0 0 0 2 2 2 0 2 2 2 0 2 2 0 0 0 2 0\n",
      " 2 2 2 2 2 0 0 2 2 2 3 2 0 0 0 0 2 2 0 2 0 2 2 1 3 1 3 1 0 3 1 3 1 3 1 1 3\n",
      " 3 1 1 1 1 1 1 3 0 1 3 3 3 3 3 3 0 3 1 0 3 1 1 1 3 3 1 3 0 1 1 1 1 1 1 1 1\n",
      " 1 1 3 1 3 1 3 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 3 3 1 1\n",
      " 1 1 3 1 1 3 1 1 1 1 3 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 0\n",
      " 1 1 3 1 1 1 1 3 1 1 1 3 1 3 1 1 1 1 1 1 1 3 1 1 1 3 1 3 0 1 1 1 3 1 3 1 3\n",
      " 1 1 1 1 3 1 1 3 1 1 3 0 0 1 3 1 3 3 1 1 1 3 1 1 1 1 0 3 1 1 1 1 3 1 3 1 1\n",
      " 1 3 1 3 3 1 1 3 1 0 1 3 1 3 3 1 3 0 1 1 1 3 1 1 3 1 1 3 1 1 1 1 1 1 3 1 0\n",
      " 3 1 3 3 3 3 3 3 0 1 1 3 1 0 1 1 1 1 1 0 3 3 1 1 1 1 3 1 3 1 3 3 1 3 1 1 3\n",
      " 1 3 1 0 1 1 1 1 1 3 0 1 1 1 1 1 1 0 3 1 1 1 3 1 3 1 3 3 1 3 1 1 1 1 1 1 3\n",
      " 1 1 1 3 1 0 1 3 3 1 1 3 3 1 3 1 0 1 1 3 1 3 1 1 1 1 3 3 1 1 1 3 3 1 0 3 3\n",
      " 1 1 1 1 1 3 0 1 3 1 1 3 1 1 3 1 1 0 1 1 1 1 1 1 1 3 1 1 3 0 1 1 1 3 3 1 1\n",
      " 1 1 1 1 1 0 3 1 3 3 3 1 1 3 0 1 3 1 3 3 3 3 1 3 3 1 3 1 1 3 3 1 1 3 1 3 3\n",
      " 3 3 3 1 3 1 0 3 1 3 3 0 3 3 3 3 3 1 3 1 1 3 3 3 1 3 1 1 1 3 1 1 1 1 0 1 3\n",
      " 3 3 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 0 1 3 3 3 1 1 3 1 3 1 3 1 3 1 3 0 3 3\n",
      " 1 3 3 1 3 3 3 3 1 0 3 3 1 1 3 3 3 3 1 1 3 1 1 1 3 1 3 3 3 1 1 0 3 1 1 1 1\n",
      " 3 3 1 3 0 3 3 3 1 3 1 3 3 1 1 3 3 3 1 1 1 1 3 0 3 3 1 3 3 3 3 1 3 3 3 1 3\n",
      " 3 1 3 3 0 1 3 1 3 1 3 3 1 3 1 3 3 1 3 0 3 3 0 3 3 0 1 1 3 3 1 3 1 3 3 1 3\n",
      " 1 1 1 3 1 3 1 3 3 1 3 3 1 3 3 1 0 3 1 3 1 3 3 3 3 3 3 0 1 1 3 1 1 1 1 3 1\n",
      " 3 1 3 3 3 1 3 1 3 1 1 1 1 1 1 3 3 3 3 3 1 1 3 3 3 1 1 1 3 3 3 1 1 1 1 3 3\n",
      " 1 3 3 1 3 1 3 0 1 3 3 1 1 3 3 3 3 3 1 3 3 3 3 0 3 3 3 3 3 1 3 1 1 1 0 3 1\n",
      " 3 1 1 3 3 3 3 3 3 3 1 3 3 1 3 1 3 1 1 1 0 1 1 3 3 3 3 1 3 1 1 3 3 3 3 1 1\n",
      " 1 3 1 3 1 1 1 1 0 0 1 1 3 3 3 3 3 1 1 3 3 1 1 3 0 3 3 1 1 1 1 3 1 0 1 1 3\n",
      " 3 3 1 3 1 3 3 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.6194\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=2.92, val_loss=0.116, avg_v\n",
      "Epoch 0:  78%|▊| 50/64 [00:01<00:00, 31.01it/s, loss=2.92, val_loss=0.116, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=2.92, val_loss=5.73, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.17, val_loss=5.73, avg_va\u001b[A\n",
      "Epoch 1:  56%|▌| 36/64 [00:01<00:01, 23.37it/s, loss=0.17, val_loss=5.73, avg_va\n",
      "Epoch 1:  84%|▊| 54/64 [00:01<00:00, 32.61it/s, loss=0.17, val_loss=5.73, avg_va\u001b[A\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 36.45it/s, loss=0.17, val_loss=0.298, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 20.14it/s, loss=0.0676, val_loss=0.298, avg\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 22.37it/s, loss=0.0676, val_loss=0.298, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 35.53it/s, loss=0.0676, val_loss=0.089, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.0508, val_loss=0.089, avg\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 23.31it/s, loss=0.0508, val_loss=0.089, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.0508, val_loss=0.0705, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.0426, val_loss=0.0705, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 23.17it/s, loss=0.0426, val_loss=0.0705, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 36.57it/s, loss=0.0426, val_loss=0.0632, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.0369, val_loss=0.0632, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 22.86it/s, loss=0.0369, val_loss=0.0632, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.0369, val_loss=0.0578, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 19.95it/s, loss=0.0337, val_loss=0.0578, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 22.11it/s, loss=0.0337, val_loss=0.0578, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 35.24it/s, loss=0.0337, val_loss=0.0532, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 20.61it/s, loss=0.0299, val_loss=0.0532, av\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 23.00it/s, loss=0.0299, val_loss=0.0532, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 36.19it/s, loss=0.0299, val_loss=0.0549, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 20.80it/s, loss=0.0281, val_loss=0.0549, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 23.04it/s, loss=0.0281, val_loss=0.0549, av\n",
      "Epoch 8:  84%|▊| 54/64 [00:01<00:00, 32.00it/s, loss=0.0281, val_loss=0.0549, av\u001b[A\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 36.14it/s, loss=0.0281, val_loss=0.0567, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 20.69it/s, loss=0.0248, val_loss=0.0567, av\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 22.93it/s, loss=0.0248, val_loss=0.0567, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=0.0248, val_loss=0.0353, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.43it/s, loss=0.022, val_loss=0.0353, av\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 22.81it/s, loss=0.022, val_loss=0.0353, av\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 36.11it/s, loss=0.022, val_loss=0.0473, av\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 20.53it/s, loss=0.0193, val_loss=0.0473, a\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 22.81it/s, loss=0.0193, val_loss=0.0473, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 36.02it/s, loss=0.0193, val_loss=0.0237, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.0172, val_loss=0.0237, a\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 23.07it/s, loss=0.0172, val_loss=0.0237, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.0172, val_loss=0.0266, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.0157, val_loss=0.0266, a\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 23.04it/s, loss=0.0157, val_loss=0.0266, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.0157, val_loss=0.0194, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.25it/s, loss=0.0142, val_loss=0.0194, a\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 22.57it/s, loss=0.0142, val_loss=0.0194, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 35.83it/s, loss=0.0142, val_loss=0.0177, a\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 20.20it/s, loss=0.0129, val_loss=0.0177, a\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 22.44it/s, loss=0.0129, val_loss=0.0177, a\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 35.63it/s, loss=0.0129, val_loss=0.0162, a\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.0119, val_loss=0.0162, a\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 23.20it/s, loss=0.0119, val_loss=0.0162, a\n",
      "Epoch 16:  84%|▊| 54/64 [00:01<00:00, 32.30it/s, loss=0.0119, val_loss=0.0162, a\u001b[A\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 36.55it/s, loss=0.0119, val_loss=0.0152, a\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.011, val_loss=0.0152, av\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 23.21it/s, loss=0.011, val_loss=0.0152, av\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 36.68it/s, loss=0.011, val_loss=0.0144, av\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.57it/s, loss=0.0103, val_loss=0.0144, a\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 22.95it/s, loss=0.0103, val_loss=0.0144, a\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.31it/s, loss=0.0103, val_loss=0.0138, a\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00956, val_loss=0.0138, \u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 23.41it/s, loss=0.00956, val_loss=0.0138, \n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.96it/s, loss=0.00956, val_loss=0.013, a\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00893, val_loss=0.013, a\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 22.95it/s, loss=0.00893, val_loss=0.013, a\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 36.30it/s, loss=0.00893, val_loss=0.0125, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.00838, val_loss=0.0125, \u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 23.03it/s, loss=0.00838, val_loss=0.0125, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.30it/s, loss=0.00838, val_loss=0.0119, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00785, val_loss=0.0119, \u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 23.22it/s, loss=0.00785, val_loss=0.0119, \n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00785, val_loss=0.0109, \u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 20.61it/s, loss=0.00734, val_loss=0.0109, \u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 22.90it/s, loss=0.00734, val_loss=0.0109, \n",
      "Epoch 23:  84%|▊| 54/64 [00:01<00:00, 32.01it/s, loss=0.00734, val_loss=0.0109, \u001b[A\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 36.00it/s, loss=0.00734, val_loss=0.00973,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.22it/s, loss=0.00693, val_loss=0.00973,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 22.47it/s, loss=0.00693, val_loss=0.00973,\n",
      "Epoch 24:  84%|▊| 54/64 [00:01<00:00, 31.26it/s, loss=0.00693, val_loss=0.00973,\u001b[A\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 35.39it/s, loss=0.00693, val_loss=0.00883,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.01it/s, loss=0.00659, val_loss=0.00883,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 23.35it/s, loss=0.00659, val_loss=0.00883,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.00659, val_loss=0.00845,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 20.77it/s, loss=0.00627, val_loss=0.00845,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 22.89it/s, loss=0.00627, val_loss=0.00845,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 36.38it/s, loss=0.00627, val_loss=0.00979,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00598, val_loss=0.00979,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 23.03it/s, loss=0.00598, val_loss=0.00979,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=0.00598, val_loss=0.0079, \u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.00572, val_loss=0.0079, \u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 23.16it/s, loss=0.00572, val_loss=0.0079, \n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 36.78it/s, loss=0.00572, val_loss=0.00727,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 20.36it/s, loss=0.00549, val_loss=0.00727,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 22.65it/s, loss=0.00549, val_loss=0.00727,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 35.85it/s, loss=0.00549, val_loss=0.00694,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.33it/s, loss=0.00529, val_loss=0.00694,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 22.50it/s, loss=0.00529, val_loss=0.00694,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 35.79it/s, loss=0.00529, val_loss=0.00662,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=0.00512, val_loss=0.00662,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 23.32it/s, loss=0.00512, val_loss=0.00662,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.00512, val_loss=0.00626,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00498, val_loss=0.00626,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 23.14it/s, loss=0.00498, val_loss=0.00626,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.00498, val_loss=0.00602,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.00485, val_loss=0.00602,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 22.87it/s, loss=0.00485, val_loss=0.00602,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 36.36it/s, loss=0.00485, val_loss=0.00572,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 20.53it/s, loss=0.00475, val_loss=0.00572,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 24.07it/s, loss=0.00475, val_loss=0.00572,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 36.25it/s, loss=0.00475, val_loss=0.00552,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00466, val_loss=0.00552,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 24.31it/s, loss=0.00466, val_loss=0.00552,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00466, val_loss=0.00533,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00458, val_loss=0.00533,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 24.23it/s, loss=0.00458, val_loss=0.00533,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 36.63it/s, loss=0.00458, val_loss=0.00515,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00452, val_loss=0.00515,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00452, val_loss=0.00515,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.00452, val_loss=0.00509,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00447, val_loss=0.00509,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00447, val_loss=0.00509,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.00447, val_loss=0.005, a\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00443, val_loss=0.005, a\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 24.58it/s, loss=0.00443, val_loss=0.005, a\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 36.93it/s, loss=0.00443, val_loss=0.00491,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00439, val_loss=0.00491,\u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 24.63it/s, loss=0.00439, val_loss=0.00491,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 37.06it/s, loss=0.00439, val_loss=0.00491,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 20.81it/s, loss=0.00434, val_loss=0.00491,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.14it/s, loss=0.00434, val_loss=0.00491,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.00434, val_loss=0.00494,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00428, val_loss=0.00494,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.00428, val_loss=0.00494,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 36.58it/s, loss=0.00428, val_loss=0.00482,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 20.01it/s, loss=0.00424, val_loss=0.00482,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 23.47it/s, loss=0.00424, val_loss=0.00482,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 35.45it/s, loss=0.00424, val_loss=0.00473,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00422, val_loss=0.00473,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00422, val_loss=0.00473,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.00422, val_loss=0.00467,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.0042, val_loss=0.00467, \u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 24.02it/s, loss=0.0042, val_loss=0.00467, \n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 36.21it/s, loss=0.0042, val_loss=0.00459, \u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 20.36it/s, loss=0.00419, val_loss=0.00459,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 23.77it/s, loss=0.00419, val_loss=0.00459,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 35.85it/s, loss=0.00419, val_loss=0.00455,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 20.66it/s, loss=0.00418, val_loss=0.00455,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 24.02it/s, loss=0.00418, val_loss=0.00455,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 36.32it/s, loss=0.00418, val_loss=0.00458,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.31it/s, loss=0.00417, val_loss=0.00458,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 23.59it/s, loss=0.00417, val_loss=0.00458,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 35.73it/s, loss=0.00417, val_loss=0.00448,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.00416, val_loss=0.00448,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.00416, val_loss=0.00448,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 36.72it/s, loss=0.00416, val_loss=0.00449,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.01it/s, loss=0.00414, val_loss=0.00449,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00414, val_loss=0.00449,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00414, val_loss=0.00456,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00413, val_loss=0.00456,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 24.56it/s, loss=0.00413, val_loss=0.00456,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00413, val_loss=0.00498,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00411, val_loss=0.00498,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00411, val_loss=0.00498,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.00411, val_loss=0.00492,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00409, val_loss=0.00492,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.13it/s, loss=0.00409, val_loss=0.00492,\n",
      "Epoch 53:  89%|▉| 57/64 [00:01<00:00, 33.81it/s, loss=0.00409, val_loss=0.00492,\u001b[A\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 36.49it/s, loss=0.00409, val_loss=0.00465,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 20.13it/s, loss=0.00407, val_loss=0.00465,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 23.45it/s, loss=0.00407, val_loss=0.00465,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 35.41it/s, loss=0.00407, val_loss=0.00458,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 20.72it/s, loss=0.00405, val_loss=0.00458,\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 23.87it/s, loss=0.00405, val_loss=0.00458,\n",
      "Epoch 55:  89%|▉| 57/64 [00:01<00:00, 33.24it/s, loss=0.00405, val_loss=0.00458,\u001b[A\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 36.08it/s, loss=0.00405, val_loss=0.00458,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.00403, val_loss=0.00458,\u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.00403, val_loss=0.00458,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.61it/s, loss=0.00403, val_loss=0.0046, \u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00402, val_loss=0.0046, \u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00402, val_loss=0.0046, \n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.00402, val_loss=0.00459,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00401, val_loss=0.00459,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 24.71it/s, loss=0.00401, val_loss=0.00459,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00401, val_loss=0.00461,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00399, val_loss=0.00461,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.00399, val_loss=0.00461,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00399, val_loss=0.00462,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00398, val_loss=0.00462,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00398, val_loss=0.00462,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.05it/s, loss=0.00398, val_loss=0.00459,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00397, val_loss=0.00459,\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 24.45it/s, loss=0.00397, val_loss=0.00459,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.00397, val_loss=0.00454,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00396, val_loss=0.00454,\u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00396, val_loss=0.00454,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 37.08it/s, loss=0.00396, val_loss=0.0047, \u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00396, val_loss=0.0047, \u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 24.84it/s, loss=0.00396, val_loss=0.0047, \n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00396, val_loss=0.00456,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 20.44it/s, loss=0.00395, val_loss=0.00456,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 23.94it/s, loss=0.00395, val_loss=0.00456,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 36.11it/s, loss=0.00395, val_loss=0.00456,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00394, val_loss=0.00456,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 24.68it/s, loss=0.00394, val_loss=0.00456,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 37.03it/s, loss=0.00394, val_loss=0.00458,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.00394, val_loss=0.00458,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 24.79it/s, loss=0.00394, val_loss=0.00458,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.00394, val_loss=0.00456,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.00393, val_loss=0.00456,\u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.00393, val_loss=0.00456,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00393, val_loss=0.00458,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00393, val_loss=0.00458,\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 24.72it/s, loss=0.00393, val_loss=0.00458,\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 37.02it/s, loss=0.00393, val_loss=0.00455,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00392, val_loss=0.00455,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 24.87it/s, loss=0.00392, val_loss=0.00455,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00392, val_loss=0.00454,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 20.04it/s, loss=0.00392, val_loss=0.00454,\u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 23.45it/s, loss=0.00392, val_loss=0.00454,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 35.45it/s, loss=0.00392, val_loss=0.00465,\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.17it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 23.59it/s, loss=0.00391, val_loss=0.00465,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 35.69it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 25.31it/s, loss=0.00391, val_loss=0.00465,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 37.85it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 24.12it/s, loss=0.00391, val_loss=0.00465,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 36.32it/s, loss=0.00391, val_loss=0.00461,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00391, val_loss=0.00461,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 24.72it/s, loss=0.00391, val_loss=0.00461,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00391, val_loss=0.00465,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 25.31it/s, loss=0.00391, val_loss=0.00465,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 37.90it/s, loss=0.00391, val_loss=0.00468,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.0039, val_loss=0.00468, \u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 24.72it/s, loss=0.0039, val_loss=0.00468, \n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.0039, val_loss=0.00467, \u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.0039, val_loss=0.00467, \u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 25.11it/s, loss=0.0039, val_loss=0.00467, \n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.0039, val_loss=0.00474, \u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.0145, val_loss=0.00474, \u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.48it/s, loss=0.0145, val_loss=0.00474, \n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 36.80it/s, loss=0.0145, val_loss=0.0398, a\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 20.72it/s, loss=0.00594, val_loss=0.0398, \u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 24.18it/s, loss=0.00594, val_loss=0.0398, \n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.00594, val_loss=0.00559,\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00398, val_loss=0.00559,\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.00398, val_loss=0.00559,\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 37.55it/s, loss=0.00398, val_loss=0.00485,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 20.80it/s, loss=0.00389, val_loss=0.00485,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 24.33it/s, loss=0.00389, val_loss=0.00485,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.00389, val_loss=0.00485,\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.0039, val_loss=0.00485, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.0039, val_loss=0.00485, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 37.77it/s, loss=0.0039, val_loss=0.0049, a\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.0336, val_loss=0.0049, a\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.27it/s, loss=0.0336, val_loss=0.0049, a\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.0336, val_loss=0.0199, a\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00749, val_loss=0.0199, \u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00749, val_loss=0.0199, \n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00749, val_loss=0.00709,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.00406, val_loss=0.00709,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.47it/s, loss=0.00406, val_loss=0.00709,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00406, val_loss=0.00494,\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.0039, val_loss=0.00494, \u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 25.41it/s, loss=0.0039, val_loss=0.00494, \n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.0039, val_loss=0.00503, \u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.44it/s, loss=0.0039, val_loss=0.00503, \u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 23.92it/s, loss=0.0039, val_loss=0.00503, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.0039, val_loss=0.0051, a\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00391, val_loss=0.0051, \u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.00391, val_loss=0.0051, \n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 38.23it/s, loss=0.00391, val_loss=0.00517,\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 20.66it/s, loss=0.0585, val_loss=0.00517, \u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.00it/s, loss=0.0585, val_loss=0.00517, \n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.0585, val_loss=0.0166, a\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00829, val_loss=0.0166, \u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00829, val_loss=0.0166, \n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00829, val_loss=0.00751,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 20.79it/s, loss=0.00401, val_loss=0.00751,\u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 24.32it/s, loss=0.00401, val_loss=0.00751,\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 36.61it/s, loss=0.00401, val_loss=0.00519,\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.0039, val_loss=0.00519, \u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.0039, val_loss=0.00519, \n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=0.0039, val_loss=0.00526, \u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00389, val_loss=0.00526,\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.67it/s, loss=0.00389, val_loss=0.00526,\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.99it/s, loss=0.00389, val_loss=0.0054, \u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00391, val_loss=0.0054, \u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 24.66it/s, loss=0.00391, val_loss=0.0054, \n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 37.08it/s, loss=0.00391, val_loss=0.00559,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.0042, val_loss=0.00559, \u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.0042, val_loss=0.00559, \n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 36.74it/s, loss=0.0042, val_loss=0.00629, \u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.0517, val_loss=0.00629, \u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.0517, val_loss=0.00629, \n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.0517, val_loss=0.0245, a\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.00649, val_loss=0.0245, \u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.00649, val_loss=0.0245, \n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.00649, val_loss=0.00689,\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.00409, val_loss=0.00689,\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.52it/s, loss=0.00409, val_loss=0.00689,\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.00409, val_loss=0.00576,\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.00396, val_loss=0.00576,\u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 24.38it/s, loss=0.00396, val_loss=0.00576,\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 36.68it/s, loss=0.00396, val_loss=0.00592,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 36.26it/s, loss=0.00396, val_loss=0.00592,\u001b[A\n",
      "Sizes of clusters: 403, 321, 460, 416\n",
      "\n",
      "preds: [3 0 0 2 0 2 2 0 3 2 0 3 2 3 0 2 2 0 3 3 2 2 3 2 2 2 0 2 3 0 3 3 2 3 3 3 2\n",
      " 2 3 2 3 3 2 3 0 3 2 3 2 2 0 2 3 2 2 2 2 0 2 3 2 3 0 2 2 0 3 0 0 2 3 3 2 3\n",
      " 2 2 3 2 3 0 3 3 2 0 3 3 2 0 2 3 3 3 0 3 1 0 0 2 3 1 0 0 2 0 0 2 3 2 3 2 0\n",
      " 3 3 2 1 3 2 2 3 0 0 2 0 3 1 0 3 3 2 0 3 0 3 2 0 2 0 3 2 3 2 2 3 0 3 0 3 3\n",
      " 3 3 3 0 3 0 2 0 3 3 2 3 1 3 0 2 2 0 3 1 2 3 2 3 3 0 2 2 0 2 3 0 3 3 3 2 2\n",
      " 2 0 3 3 0 3 2 0 3 2 0 2 1 0 2 1 3 2 1 2 3 0 3 3 2 3 0 2 3 2 3 0 2 0 0 0 3\n",
      " 1 3 3 3 0 3 0 0 2 2 2 3 0 0 2 0 2 3 0 2 3 3 2 2 3 0 0 3 2 2 2 0 3 2 3 3 0\n",
      " 3 0 0 3 3 3 3 2 0 3 0 3 0 0 3 3 2 3 1 0 0 3 3 2 0 0 2 3 3 3 2 2 0 3 2 3 3\n",
      " 3 0 3 2 3 2 1 0 3 3 2 3 3 3 3 3 3 3 2 3 2 2 2 2 3 0 2 0 3 3 3 2 2 2 0 3 2\n",
      " 2 3 2 3 3 3 2 0 3 0 3 0 0 1 0 0 2 2 0 1 0 0 2 0 0 0 0 2 2 3 0 3 2 0 3 3 2\n",
      " 3 3 0 3 3 0 2 3 0 0 0 3 3 0 3 3 0 0 3 3 3 3 0 2 2 2 0 3 3 2 0 0 3 0 0 0 0\n",
      " 0 0 3 0 0 0 3 0 0 0 0 3 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 3 0 3 3 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 3 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0\n",
      " 0 0 0 0 0 3 0 3 3 3 0 3 0 0 0 0 0 3 0 3 0 3 0 3 0 3 0 3 0 3 0 0 3 0 0 3 0\n",
      " 0 0 0 0 3 0 0 0 3 0 0 0 0 3 0 3 0 0 3 0 3 3 3 0 0 3 0 0 0 0 0 0 0 0 3 0 3\n",
      " 0 3 0 0 0 3 0 3 0 0 0 0 3 3 0 0 0 0 0 0 3 0 0 0 0 0 3 3 0 0 0 0 0 3 3 0 3\n",
      " 1 3 0 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 0 3 0 0 3 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 3 0 3 0 0 3 3 3 3 0\n",
      " 0 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0 3 0 0 3 0 0 3 0 0 3 0 0 0 0 0 0 0 3 3 3 0\n",
      " 0 0 3 0 3 3 0 0 0 3 0 3 0 3 0 3 0 0 0 0 3 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0\n",
      " 0 0 3 0 0 0 3 3 3 0 3 3 0 0 1 0 0 3 0 3 0 3 0 0 0 3 0 0 0 3 0 0 0 3 3 0 0\n",
      " 0 0 0 0 0 3 3 0 0 0 3 0 3 3 3 3 0 0 3 0 3 0 0 1 3 1 1 1 3 3 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 3 1 1 1 1 3 3 3 3 1 1 3 1 1 1 1 3 1 1 3 3 1 1 1 1 1 1 1 1\n",
      " 1 1 3 1 3 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1\n",
      " 1 1 3 1 1 3 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3\n",
      " 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 3 1 1 1 3 1 1 1 3\n",
      " 1 1 1 1 3 1 1 3 1 1 1 3 3 1 1 1 1 3 1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 1 3 1 1\n",
      " 1 3 1 1 3 1 1 3 1 3 1 3 1 1 1 1 3 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3\n",
      " 1 1 3 3 1 3 3 3 3 1 1 1 1 3 1 1 1 1 1 3 1 1 1 3 3 1 3 1 3 1 3 1 1 3 1 1 1\n",
      " 1 1 1 3 1 1 1 1 1 3 3 1 1 1 1 1 1 3 3 1 1 1 3 1 1 1 3 3 1 3 1 1 1 1 1 1 1\n",
      " 1 1 1 3 1 3 1 1 3 1 1 3 3 1 3 1 3 1 1 3 1 1 1 1 3 1 3 3 1 1 1 3 3 1 3 3 1\n",
      " 1 1 1 1 1 1 3 1 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 3 1 1 1 3 1 1 1\n",
      " 1 1 1 1 1 3 3 1 3 3 3 1 1 3 3 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 3 2 2\n",
      " 2 2 2 3 2 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 2 2 2 2 3 2 2 2 3 1 3 2 3 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2\n",
      " 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 3 2 2 0 3 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 3 2 2 2 2\n",
      " 2 3 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 2 3 2 2 2 3 2 3 2 2 2 1 3 3 2 3 2 2 2 2 3 3 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 3 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 3 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 3 2 2 2 3 2 2 3 2 2 2 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2\n",
      " 2 2 2 2 2 3 2 2 3 0 3 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 3 2 2 2 2 2 2 3\n",
      " 2 2 3 2 3 2 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.6781\n",
      "============= RUN 3 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=1.92, val_loss=0.0992, avg_\n",
      "Epoch 0:  80%|▊| 51/64 [00:01<00:00, 31.55it/s, loss=1.92, val_loss=0.0992, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=1.92, val_loss=6.45, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.114, val_loss=6.45, avg_v\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.114, val_loss=6.45, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.114, val_loss=0.145, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.037, val_loss=0.145, avg_\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.037, val_loss=0.145, avg_\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.037, val_loss=0.042, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.0249, val_loss=0.042, avg\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.0249, val_loss=0.042, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.0249, val_loss=0.0302, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 20.55it/s, loss=0.0183, val_loss=0.0302, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 23.85it/s, loss=0.0183, val_loss=0.0302, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.0183, val_loss=0.0231, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.014, val_loss=0.0231, avg\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.014, val_loss=0.0231, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 36.78it/s, loss=0.014, val_loss=0.0175, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.011, val_loss=0.0175, avg\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.011, val_loss=0.0175, avg\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.011, val_loss=0.0141, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00914, val_loss=0.0141, a\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 24.30it/s, loss=0.00914, val_loss=0.0141, a\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 36.57it/s, loss=0.00914, val_loss=0.0109, a\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00783, val_loss=0.0109, a\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00783, val_loss=0.0109, a\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00783, val_loss=0.0092, a\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 20.99it/s, loss=0.00697, val_loss=0.0092, a\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 24.56it/s, loss=0.00697, val_loss=0.0092, a\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 36.97it/s, loss=0.00697, val_loss=0.00753, \u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.00632, val_loss=0.00753,\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 24.01it/s, loss=0.00632, val_loss=0.00753,\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 36.21it/s, loss=0.00632, val_loss=0.00706,\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.00586, val_loss=0.00706,\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 24.48it/s, loss=0.00586, val_loss=0.00706,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.00586, val_loss=0.00586,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.00546, val_loss=0.00586,\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.12it/s, loss=0.00546, val_loss=0.00586,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.78it/s, loss=0.00546, val_loss=0.00569,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00516, val_loss=0.00569,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 24.70it/s, loss=0.00516, val_loss=0.00569,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.00516, val_loss=0.00493,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.81it/s, loss=0.0049, val_loss=0.00493, \u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 24.21it/s, loss=0.0049, val_loss=0.00493, \n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.0049, val_loss=0.00498, \u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 20.16it/s, loss=0.0047, val_loss=0.00498, \u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 23.57it/s, loss=0.0047, val_loss=0.00498, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 35.65it/s, loss=0.0047, val_loss=0.00436, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00453, val_loss=0.00436,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 24.32it/s, loss=0.00453, val_loss=0.00436,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 36.57it/s, loss=0.00453, val_loss=0.00449,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00439, val_loss=0.00449,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 24.13it/s, loss=0.00439, val_loss=0.00449,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 36.34it/s, loss=0.00439, val_loss=0.00397,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.85it/s, loss=0.00428, val_loss=0.00397,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00428, val_loss=0.00397,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.71it/s, loss=0.00428, val_loss=0.00411,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.00419, val_loss=0.00411,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.00419, val_loss=0.00411,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.58it/s, loss=0.00419, val_loss=0.0037, \u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 20.42it/s, loss=0.00411, val_loss=0.0037, \u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 23.90it/s, loss=0.00411, val_loss=0.0037, \n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 36.08it/s, loss=0.00411, val_loss=0.00384,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.14it/s, loss=0.00406, val_loss=0.00384,\u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 24.46it/s, loss=0.00406, val_loss=0.00384,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.00406, val_loss=0.00351,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00401, val_loss=0.00351,\u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 24.35it/s, loss=0.00401, val_loss=0.00351,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 36.58it/s, loss=0.00401, val_loss=0.00362,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.00397, val_loss=0.00362,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00397, val_loss=0.00362,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.00397, val_loss=0.00337,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00394, val_loss=0.00337,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 24.55it/s, loss=0.00394, val_loss=0.00337,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 36.95it/s, loss=0.00394, val_loss=0.00347,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.00391, val_loss=0.00347,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 25.40it/s, loss=0.00391, val_loss=0.00347,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00391, val_loss=0.00326,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.00389, val_loss=0.00326,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.72it/s, loss=0.00389, val_loss=0.00326,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.44it/s, loss=0.00389, val_loss=0.00333,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.00387, val_loss=0.00333,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 24.97it/s, loss=0.00387, val_loss=0.00333,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.41it/s, loss=0.00387, val_loss=0.00318,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.00385, val_loss=0.00318,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00385, val_loss=0.00318,\n",
      "Epoch 28:  89%|▉| 57/64 [00:01<00:00, 33.91it/s, loss=0.00385, val_loss=0.00318,\u001b[A\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 36.74it/s, loss=0.00385, val_loss=0.00324,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 20.78it/s, loss=0.00383, val_loss=0.00324,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 24.18it/s, loss=0.00383, val_loss=0.00324,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 36.48it/s, loss=0.00383, val_loss=0.0031, \u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00382, val_loss=0.0031, \u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 24.27it/s, loss=0.00382, val_loss=0.0031, \n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 36.56it/s, loss=0.00382, val_loss=0.00313,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.80it/s, loss=0.00381, val_loss=0.00313,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 24.16it/s, loss=0.00381, val_loss=0.00313,\n",
      "Epoch 31:  89%|▉| 57/64 [00:01<00:00, 33.80it/s, loss=0.00381, val_loss=0.00313,\u001b[A\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.44it/s, loss=0.00381, val_loss=0.00305,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 20.66it/s, loss=0.0038, val_loss=0.00305, \u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 24.23it/s, loss=0.0038, val_loss=0.00305, \n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.0038, val_loss=0.00307, \u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00378, val_loss=0.00307,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 24.90it/s, loss=0.00378, val_loss=0.00307,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.00378, val_loss=0.00302,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=0.00377, val_loss=0.00302,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.00377, val_loss=0.00302,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00377, val_loss=0.00303,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 20.61it/s, loss=0.00377, val_loss=0.00303,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 24.04it/s, loss=0.00377, val_loss=0.00303,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 36.36it/s, loss=0.00377, val_loss=0.00299,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.00376, val_loss=0.00299,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 24.58it/s, loss=0.00376, val_loss=0.00299,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.08it/s, loss=0.00376, val_loss=0.00298,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00375, val_loss=0.00298,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.18it/s, loss=0.00375, val_loss=0.00298,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.76it/s, loss=0.00375, val_loss=0.00296,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 20.85it/s, loss=0.00374, val_loss=0.00296,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 24.30it/s, loss=0.00374, val_loss=0.00296,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 36.73it/s, loss=0.00374, val_loss=0.00296,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 20.53it/s, loss=0.00374, val_loss=0.00296,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 23.88it/s, loss=0.00374, val_loss=0.00296,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 36.20it/s, loss=0.00374, val_loss=0.00294,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00373, val_loss=0.00294,\u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 23.98it/s, loss=0.00373, val_loss=0.00294,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.37it/s, loss=0.00373, val_loss=0.00292,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 36.93it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 24.67it/s, loss=0.00373, val_loss=0.00292,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.03it/s, loss=0.00373, val_loss=0.00291,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.00372, val_loss=0.00291,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.00372, val_loss=0.00291,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.00372, val_loss=0.00289,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 19.97it/s, loss=0.00372, val_loss=0.00289,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 23.27it/s, loss=0.00372, val_loss=0.00289,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 35.38it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.00372, val_loss=0.00288,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 36.54it/s, loss=0.00372, val_loss=0.00287,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00372, val_loss=0.00287,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 24.87it/s, loss=0.00372, val_loss=0.00287,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 37.29it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00371, val_loss=0.00288,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.00371, val_loss=0.00288,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00371, val_loss=0.00287,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.00371, val_loss=0.00287,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.00371, val_loss=0.00287,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00371, val_loss=0.00288,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00371, val_loss=0.00288,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.53it/s, loss=0.00371, val_loss=0.00288,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 37.02it/s, loss=0.00371, val_loss=0.00288,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 25.18it/s, loss=0.00372, val_loss=0.00288,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.75it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 24.76it/s, loss=0.00372, val_loss=0.00288,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.00372, val_loss=0.00288,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.00it/s, loss=0.00372, val_loss=0.00288,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.00372, val_loss=0.00289,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.00372, val_loss=0.00289,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.64it/s, loss=0.00372, val_loss=0.00289,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.01it/s, loss=0.00372, val_loss=0.0029, \u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 20.44it/s, loss=0.00372, val_loss=0.0029, \u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 23.96it/s, loss=0.00372, val_loss=0.0029, \n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 36.11it/s, loss=0.00372, val_loss=0.0029, \u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.00372, val_loss=0.0029, \u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 24.95it/s, loss=0.00372, val_loss=0.0029, \n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.00372, val_loss=0.00291,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 20.49it/s, loss=0.00373, val_loss=0.00291,\u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 23.97it/s, loss=0.00373, val_loss=0.00291,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.08it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00373, val_loss=0.00292,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00373, val_loss=0.00292,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 36.65it/s, loss=0.00373, val_loss=0.00293,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.00373, val_loss=0.00293,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00373, val_loss=0.00293,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 38.23it/s, loss=0.00373, val_loss=0.00295,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00374, val_loss=0.00295,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00374, val_loss=0.00295,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00374, val_loss=0.00297,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 22.12it/s, loss=0.00374, val_loss=0.00297,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 25.94it/s, loss=0.00374, val_loss=0.00297,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 38.69it/s, loss=0.00374, val_loss=0.003, a\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 22.20it/s, loss=0.00375, val_loss=0.003, a\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:00, 26.04it/s, loss=0.00375, val_loss=0.003, a\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 38.83it/s, loss=0.00375, val_loss=0.00299,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 22.20it/s, loss=0.00375, val_loss=0.00299,\u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:00, 26.03it/s, loss=0.00375, val_loss=0.00299,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 38.83it/s, loss=0.00375, val_loss=0.003, a\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 22.30it/s, loss=0.00376, val_loss=0.003, a\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:00, 26.16it/s, loss=0.00376, val_loss=0.003, a\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 38.97it/s, loss=0.00376, val_loss=0.003, a\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.00376, val_loss=0.003, a\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 25.70it/s, loss=0.00376, val_loss=0.003, a\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 38.49it/s, loss=0.00376, val_loss=0.00302,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.00377, val_loss=0.00302,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 25.90it/s, loss=0.00377, val_loss=0.00302,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 38.63it/s, loss=0.00377, val_loss=0.00302,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 22.29it/s, loss=0.00377, val_loss=0.00302,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:00, 26.14it/s, loss=0.00377, val_loss=0.00302,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 38.95it/s, loss=0.00377, val_loss=0.00302,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 22.03it/s, loss=0.00378, val_loss=0.00302,\u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 25.85it/s, loss=0.00378, val_loss=0.00302,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 38.58it/s, loss=0.00378, val_loss=0.003, a\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.00378, val_loss=0.003, a\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 25.84it/s, loss=0.00378, val_loss=0.003, a\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 38.60it/s, loss=0.00378, val_loss=0.00301,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 22.12it/s, loss=0.00379, val_loss=0.00301,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 25.92it/s, loss=0.00379, val_loss=0.00301,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 38.71it/s, loss=0.00379, val_loss=0.003, a\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00379, val_loss=0.003, a\u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 25.64it/s, loss=0.00379, val_loss=0.003, a\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.00379, val_loss=0.00301,\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 22.22it/s, loss=0.0038, val_loss=0.00301, \u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:00, 26.04it/s, loss=0.0038, val_loss=0.00301, \n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 38.69it/s, loss=0.0038, val_loss=0.00301, \u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 22.16it/s, loss=0.00381, val_loss=0.00301,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 26.00it/s, loss=0.00381, val_loss=0.00301,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 38.78it/s, loss=0.00381, val_loss=0.003, a\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.00381, val_loss=0.003, a\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 25.85it/s, loss=0.00381, val_loss=0.003, a\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 38.61it/s, loss=0.00381, val_loss=0.003, a\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.00382, val_loss=0.003, a\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 25.93it/s, loss=0.00382, val_loss=0.003, a\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 38.73it/s, loss=0.00382, val_loss=0.00302,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00382, val_loss=0.00302,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.00382, val_loss=0.00302,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 38.36it/s, loss=0.00382, val_loss=0.00302,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.00383, val_loss=0.00302,\u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 25.76it/s, loss=0.00383, val_loss=0.00302,\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.00383, val_loss=0.00301,\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 22.31it/s, loss=0.00384, val_loss=0.00301,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:00, 26.18it/s, loss=0.00384, val_loss=0.00301,\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 39.01it/s, loss=0.00384, val_loss=0.00302,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.00384, val_loss=0.00302,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 25.92it/s, loss=0.00384, val_loss=0.00302,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 38.68it/s, loss=0.00384, val_loss=0.00302,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 22.21it/s, loss=0.00385, val_loss=0.00302,\u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:00, 26.06it/s, loss=0.00385, val_loss=0.00302,\n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 38.86it/s, loss=0.00385, val_loss=0.00301,\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 22.12it/s, loss=0.00386, val_loss=0.00301,\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 25.92it/s, loss=0.00386, val_loss=0.00301,\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 38.71it/s, loss=0.00386, val_loss=0.00302,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.00386, val_loss=0.00302,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 25.81it/s, loss=0.00386, val_loss=0.00302,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 38.57it/s, loss=0.00386, val_loss=0.00304,\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 22.16it/s, loss=0.00387, val_loss=0.00304,\u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 25.95it/s, loss=0.00387, val_loss=0.00304,\n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 38.78it/s, loss=0.00387, val_loss=0.00304,\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.00388, val_loss=0.00304,\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 25.82it/s, loss=0.00388, val_loss=0.00304,\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 38.57it/s, loss=0.00388, val_loss=0.00304,\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 22.00it/s, loss=0.00389, val_loss=0.00304,\u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 25.76it/s, loss=0.00389, val_loss=0.00304,\n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 38.47it/s, loss=0.00389, val_loss=0.00304,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00391, val_loss=0.00304,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00391, val_loss=0.00304,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00391, val_loss=0.00311,\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 22.19it/s, loss=0.123, val_loss=0.00311, a\u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:00, 26.02it/s, loss=0.123, val_loss=0.00311, a\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 38.81it/s, loss=0.123, val_loss=0.0279, av\u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.00794, val_loss=0.0279, \u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 25.95it/s, loss=0.00794, val_loss=0.0279, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 38.72it/s, loss=0.00794, val_loss=0.00609,\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.00404, val_loss=0.00609,\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 25.78it/s, loss=0.00404, val_loss=0.00609,\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 38.50it/s, loss=0.00404, val_loss=0.00317,\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.00389, val_loss=0.00317,\u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 25.75it/s, loss=0.00389, val_loss=0.00317,\n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 38.48it/s, loss=0.00389, val_loss=0.00302,\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 22.04it/s, loss=0.0039, val_loss=0.00302, \u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 25.79it/s, loss=0.0039, val_loss=0.00302, \n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 38.54it/s, loss=0.0039, val_loss=0.00302, \u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.0061, val_loss=0.00302, \u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 25.88it/s, loss=0.0061, val_loss=0.00302, \n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 38.71it/s, loss=0.0061, val_loss=0.0416, a\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.0354, val_loss=0.0416, a\u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 25.66it/s, loss=0.0354, val_loss=0.0416, a\n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.0354, val_loss=0.0184, a\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.00487, val_loss=0.0184, \u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 25.76it/s, loss=0.00487, val_loss=0.0184, \n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.00487, val_loss=0.00335,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00393, val_loss=0.00335,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 25.44it/s, loss=0.00393, val_loss=0.00335,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.00393, val_loss=0.00299,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.00391, val_loss=0.00299,\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 25.89it/s, loss=0.00391, val_loss=0.00299,\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 38.66it/s, loss=0.00391, val_loss=0.00298,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.95it/s, loss=0.00392, val_loss=0.00298,\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 25.76it/s, loss=0.00392, val_loss=0.00298,\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.00392, val_loss=0.00299,\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.0051, val_loss=0.00299, \u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 25.49it/s, loss=0.0051, val_loss=0.00299, \n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.0051, val_loss=0.0224, a\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.0494, val_loss=0.0224, a\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 25.87it/s, loss=0.0494, val_loss=0.0224, a\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 38.66it/s, loss=0.0494, val_loss=0.0223, a\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.95it/s, loss=0.00546, val_loss=0.0223, \u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 25.71it/s, loss=0.00546, val_loss=0.0223, \n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 38.45it/s, loss=0.00546, val_loss=0.00291,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00546, val_loss=0.00291,\u001b[A\n",
      "Sizes of clusters: 342, 267, 528, 463\n",
      "\n",
      "preds: [3 1 3 2 1 2 3 3 2 2 3 2 2 3 3 3 2 3 3 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2\n",
      " 2 2 2 3 3 3 2 3 3 2 3 3 2 3 3 3 3 2 2 2 1 3 3 2 3 3 3 2 3 3 1 3 2 3 2 2 3\n",
      " 3 3 3 3 2 3 3 3 2 3 3 2 2 3 3 3 3 2 3 3 2 3 3 3 3 2 1 1 2 3 3 3 3 2 3 3 3\n",
      " 0 3 3 2 3 2 3 3 3 3 2 3 3 0 1 2 3 2 3 3 3 3 2 3 3 1 3 2 3 2 3 3 3 3 3 3 3\n",
      " 2 3 3 1 3 3 3 3 3 2 3 3 2 3 3 3 2 3 3 2 3 3 2 3 2 3 2 2 3 3 3 3 3 3 3 0 3\n",
      " 2 3 3 3 1 2 3 1 3 2 3 3 2 1 3 2 3 2 3 2 3 1 3 3 3 3 3 2 3 2 2 3 2 3 3 3 3\n",
      " 3 3 3 2 1 3 3 3 2 2 2 3 3 1 2 1 2 3 1 3 3 3 3 3 3 1 1 3 2 2 3 1 3 2 3 3 1\n",
      " 3 3 3 2 3 3 3 3 3 3 3 2 1 3 3 3 3 3 0 3 3 3 2 0 1 3 3 3 3 3 2 3 1 3 2 3 2\n",
      " 3 1 3 2 3 3 3 3 3 2 3 3 3 3 3 2 3 3 3 3 2 2 3 2 3 3 2 1 3 3 3 3 3 3 1 3 3\n",
      " 2 3 2 2 3 3 2 1 3 1 3 3 3 0 1 1 2 2 3 3 1 3 2 3 3 1 3 3 3 3 3 3 2 1 3 2 3\n",
      " 3 3 3 3 2 1 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 2 1 2 3 2 3 3 3 3 1 1 3 1 1 1 1\n",
      " 1 1 3 1 1 3 3 3 1 1 1 3 3 3 1 3 1 3 3 3 1 1 2 3 3 1 1 1 3 3 1 3 3 3 1 3 1\n",
      " 1 3 1 1 1 1 3 1 1 3 1 3 2 1 1 3 1 3 1 3 1 1 1 1 1 1 1 3 3 1 1 3 1 3 1 1 3\n",
      " 1 1 1 1 3 2 1 2 3 3 3 3 3 1 1 1 1 3 3 3 1 3 1 3 1 3 3 2 1 3 1 3 3 1 1 3 1\n",
      " 3 1 1 1 3 1 1 1 1 1 1 1 1 3 1 3 1 3 3 1 3 3 3 1 1 3 1 1 1 1 1 3 3 3 3 3 3\n",
      " 1 3 1 1 1 3 1 3 1 1 1 3 3 2 1 1 1 3 1 1 3 1 1 1 1 1 3 3 1 1 3 1 1 3 3 3 3\n",
      " 2 3 1 3 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 3 1 1 3 3 3 3 1 1 3 1 1 3 1 1 1 3 3\n",
      " 1 1 1 3 1 3 1 3 1 1 1 3 1 1 1 2 3 1 3 1 1 1 1 1 1 1 1 3 1 3 1 1 3 3 3 3 1\n",
      " 1 1 3 3 1 1 1 3 1 1 3 1 1 1 1 3 3 1 1 3 1 1 3 1 1 3 1 3 3 1 3 1 1 3 3 3 1\n",
      " 1 3 3 1 3 3 3 1 1 3 1 3 3 3 1 3 3 1 3 1 3 1 1 1 1 1 1 2 1 1 1 1 1 3 1 1 3\n",
      " 1 1 3 1 1 1 3 3 3 3 3 3 1 1 0 1 1 3 1 3 3 3 1 1 1 3 1 1 1 3 1 1 3 3 3 1 3\n",
      " 1 1 1 1 1 3 3 1 1 1 2 1 3 3 3 3 1 1 3 1 3 1 1 0 2 2 3 2 3 2 0 2 0 2 2 2 2\n",
      " 2 0 2 2 0 0 2 2 3 0 2 2 2 2 2 2 3 2 2 3 2 0 0 0 2 2 2 2 3 2 2 0 2 2 2 2 0\n",
      " 0 0 2 2 2 2 2 3 2 3 2 2 0 2 2 0 2 0 2 2 0 2 2 0 0 3 0 3 2 0 2 0 2 2 2 0 0\n",
      " 2 0 2 2 2 2 0 2 0 2 2 2 3 2 2 0 2 0 0 0 0 0 2 2 2 2 2 2 2 0 2 2 2 0 2 0 3\n",
      " 2 2 2 0 2 0 0 2 2 0 2 2 2 2 2 0 2 0 0 0 2 2 2 2 0 2 0 2 3 2 0 2 2 0 2 0 2\n",
      " 0 0 0 2 2 0 0 2 2 2 2 3 3 0 2 0 2 2 0 0 2 2 0 0 0 2 3 2 0 2 0 0 2 2 2 2 0\n",
      " 2 2 2 2 2 0 2 2 0 3 2 2 2 2 2 2 2 3 2 2 0 2 0 0 2 2 0 2 2 0 0 0 0 2 2 0 3\n",
      " 2 2 2 2 2 2 2 2 3 0 2 2 0 3 2 2 2 0 0 3 2 2 0 0 2 0 2 0 2 0 2 2 2 2 2 0 2\n",
      " 2 2 2 3 2 0 0 2 0 2 3 2 0 2 0 2 2 3 2 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2\n",
      " 0 0 2 2 0 3 0 2 2 2 2 2 2 0 2 2 3 0 0 2 0 2 0 0 0 0 2 2 0 0 0 2 2 0 3 2 2\n",
      " 0 2 0 2 0 2 3 2 2 0 0 2 0 2 2 2 2 3 2 2 0 0 2 0 0 2 0 2 2 3 0 2 2 2 2 2 0\n",
      " 2 2 2 0 0 3 2 2 2 2 2 2 0 2 3 2 2 0 2 2 2 2 0 0 2 0 0 0 0 2 2 0 2 2 0 0 2\n",
      " 2 0 2 2 2 0 2 2 0 2 2 3 0 2 2 0 2 0 0 0 0 2 2 2 0 2 0 0 0 2 0 0 0 0 2 0 0\n",
      " 2 2 2 2 0 2 0 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 2 0 2 0 2 0 2 2 2 2\n",
      " 0 2 0 0 2 0 0 2 0 2 0 2 2 0 0 2 0 2 0 2 2 2 0 0 2 0 2 2 2 0 0 2 2 0 0 0 2\n",
      " 0 2 0 0 2 0 2 2 0 2 0 2 2 0 0 2 2 2 0 0 0 0 2 2 0 2 0 2 2 2 2 0 2 0 2 0 2\n",
      " 2 0 0 2 3 0 2 0 0 0 0 2 0 2 0 0 0 0 0 3 2 0 2 2 2 3 0 0 2 2 0 2 0 2 2 0 2\n",
      " 0 0 0 2 0 2 0 0 2 0 0 2 0 2 2 0 3 2 0 2 0 0 2 2 2 2 0 2 0 0 0 0 0 0 0 2 2\n",
      " 0 2 2 2 0 0 0 0 0 0 0 0 2 0 0 2 0 2 2 2 0 2 0 0 2 0 0 0 2 0 0 0 0 0 0 2 2\n",
      " 0 2 2 0 2 2 2 3 0 2 2 2 0 2 2 0 0 2 0 2 2 0 2 3 0 2 0 2 0 0 2 0 0 0 3 2 0\n",
      " 2 0 0 2 2 0 2 2 2 2 0 2 2 0 0 0 2 2 0 0 2 2 0 2 2 2 0 0 0 0 0 2 2 2 2 0 0\n",
      " 0 2 0 2 0 0 0 0 3 3 2 0 2 2 2 2 0 0 0 2 2 0 0 2 3 2 0 0 0 2 0 0 0 2 0 0 2\n",
      " 2 2 0 0 0 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5850\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 22.00it/s, loss=1.98, val_loss=0.132, avg_v\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.56it/s, loss=1.98, val_loss=0.132, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.54it/s, loss=1.98, val_loss=1.43, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 22.15it/s, loss=0.113, val_loss=1.43, avg_v\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 23.35it/s, loss=0.113, val_loss=1.43, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.63it/s, loss=0.113, val_loss=0.0817, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.0405, val_loss=0.0817, av\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.15it/s, loss=0.0405, val_loss=0.0817, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.0405, val_loss=0.0474, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.029, val_loss=0.0474, avg\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.029, val_loss=0.0474, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.36it/s, loss=0.029, val_loss=0.037, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.023, val_loss=0.037, avg_\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.24it/s, loss=0.023, val_loss=0.037, avg_\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.023, val_loss=0.0301, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.0191, val_loss=0.0301, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.0191, val_loss=0.0301, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.0191, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.0163, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.54it/s, loss=0.0163, val_loss=0.0246, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.50it/s, loss=0.0163, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.0141, val_loss=0.02, avg_\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.24it/s, loss=0.0141, val_loss=0.02, avg_\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.0141, val_loss=0.0164, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.0123, val_loss=0.0164, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.46it/s, loss=0.0123, val_loss=0.0164, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.45it/s, loss=0.0123, val_loss=0.0136, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.0107, val_loss=0.0136, av\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 23.80it/s, loss=0.0107, val_loss=0.0136, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.57it/s, loss=0.0107, val_loss=0.0113, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.00933, val_loss=0.0113, \u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.48it/s, loss=0.00933, val_loss=0.0113, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.42it/s, loss=0.00933, val_loss=0.0095, \u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 22.22it/s, loss=0.00818, val_loss=0.0095, \u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.81it/s, loss=0.00818, val_loss=0.0095, \n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.87it/s, loss=0.00818, val_loss=0.00808,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 22.05it/s, loss=0.00723, val_loss=0.00808,\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 24.58it/s, loss=0.00723, val_loss=0.00808,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.62it/s, loss=0.00723, val_loss=0.00697,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 22.15it/s, loss=0.00646, val_loss=0.00697,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.64it/s, loss=0.00646, val_loss=0.00697,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.72it/s, loss=0.00646, val_loss=0.0061, \u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00585, val_loss=0.0061, \u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.26it/s, loss=0.00585, val_loss=0.0061, \n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00585, val_loss=0.00542,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.00538, val_loss=0.00542,\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.51it/s, loss=0.00538, val_loss=0.00542,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.47it/s, loss=0.00538, val_loss=0.00492,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00502, val_loss=0.00492,\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.00502, val_loss=0.00492,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00502, val_loss=0.00454,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.00475, val_loss=0.00454,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.07it/s, loss=0.00475, val_loss=0.00454,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.90it/s, loss=0.00475, val_loss=0.00427,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=0.00455, val_loss=0.00427,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 23.39it/s, loss=0.00455, val_loss=0.00427,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00455, val_loss=0.00405,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00441, val_loss=0.00405,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.00441, val_loss=0.00405,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.30it/s, loss=0.00441, val_loss=0.00389,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.0043, val_loss=0.00389, \u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 23.84it/s, loss=0.0043, val_loss=0.00389, \n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.0043, val_loss=0.00376, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.00422, val_loss=0.00376,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 23.55it/s, loss=0.00422, val_loss=0.00376,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00422, val_loss=0.00365,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.00416, val_loss=0.00365,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.36it/s, loss=0.00416, val_loss=0.00365,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.39it/s, loss=0.00416, val_loss=0.00355,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00411, val_loss=0.00355,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00411, val_loss=0.00355,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.38it/s, loss=0.00411, val_loss=0.00349,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00408, val_loss=0.00349,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 22.93it/s, loss=0.00408, val_loss=0.00349,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 36.33it/s, loss=0.00408, val_loss=0.00344,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00405, val_loss=0.00344,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.17it/s, loss=0.00405, val_loss=0.00344,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00405, val_loss=0.00341,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00402, val_loss=0.00341,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 23.65it/s, loss=0.00402, val_loss=0.00341,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00402, val_loss=0.00337,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.00401, val_loss=0.00337,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 23.30it/s, loss=0.00401, val_loss=0.00337,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.00401, val_loss=0.00334,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.00399, val_loss=0.00334,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 23.73it/s, loss=0.00399, val_loss=0.00334,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00399, val_loss=0.00333,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.54it/s, loss=0.00398, val_loss=0.00333,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.94it/s, loss=0.00398, val_loss=0.00333,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.00398, val_loss=0.00334,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00396, val_loss=0.00334,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00396, val_loss=0.00334,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00396, val_loss=0.00337,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.40it/s, loss=0.00395, val_loss=0.00337,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 22.72it/s, loss=0.00395, val_loss=0.00337,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.04it/s, loss=0.00395, val_loss=0.00339,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00395, val_loss=0.00339,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 23.66it/s, loss=0.00395, val_loss=0.00339,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.00395, val_loss=0.00341,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00394, val_loss=0.00341,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 23.81it/s, loss=0.00394, val_loss=0.00341,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00394, val_loss=0.00342,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00393, val_loss=0.00342,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00393, val_loss=0.00342,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00393, val_loss=0.00343,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00393, val_loss=0.00343,\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.00393, val_loss=0.00343,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.00393, val_loss=0.00344,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00392, val_loss=0.00344,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00392, val_loss=0.00344,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00392, val_loss=0.00346,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00392, val_loss=0.00346,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.12it/s, loss=0.00392, val_loss=0.00346,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.02it/s, loss=0.00392, val_loss=0.00348,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.54it/s, loss=0.00391, val_loss=0.00348,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 23.98it/s, loss=0.00391, val_loss=0.00348,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.82it/s, loss=0.00391, val_loss=0.00349,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00391, val_loss=0.00349,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.55it/s, loss=0.00391, val_loss=0.00349,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.00391, val_loss=0.0035, \u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00391, val_loss=0.0035, \u001b[A\n",
      "Epoch 40:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00391, val_loss=0.0035, \n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.00391, val_loss=0.00352,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.00391, val_loss=0.00352,\u001b[A\n",
      "Epoch 41:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00391, val_loss=0.00352,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 38.22it/s, loss=0.00391, val_loss=0.00352,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.00391, val_loss=0.00352,\u001b[A\n",
      "Epoch 42:  56%|▌| 36/64 [00:01<00:01, 24.39it/s, loss=0.00391, val_loss=0.00352,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 38.38it/s, loss=0.00391, val_loss=0.00353,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00391, val_loss=0.00353,\u001b[A\n",
      "Epoch 43:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.00391, val_loss=0.00353,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=0.00391, val_loss=0.00354,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00391, val_loss=0.00354,\u001b[A\n",
      "Epoch 44:  56%|▌| 36/64 [00:01<00:01, 23.89it/s, loss=0.00391, val_loss=0.00354,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.00391, val_loss=0.00355,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00391, val_loss=0.00355,\u001b[A\n",
      "Epoch 45:  56%|▌| 36/64 [00:01<00:01, 24.02it/s, loss=0.00391, val_loss=0.00355,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 37.84it/s, loss=0.00391, val_loss=0.00358,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00391, val_loss=0.00358,\u001b[A\n",
      "Epoch 46:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00391, val_loss=0.00358,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 38.28it/s, loss=0.00391, val_loss=0.00362,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.00391, val_loss=0.00362,\u001b[A\n",
      "Epoch 47:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.00391, val_loss=0.00362,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.00391, val_loss=0.00367,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00392, val_loss=0.00367,\u001b[A\n",
      "Epoch 48:  56%|▌| 36/64 [00:01<00:01, 23.22it/s, loss=0.00392, val_loss=0.00367,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.00392, val_loss=0.00372,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00392, val_loss=0.00372,\u001b[A\n",
      "Epoch 49:  56%|▌| 36/64 [00:01<00:01, 23.57it/s, loss=0.00392, val_loss=0.00372,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.00392, val_loss=0.00377,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00392, val_loss=0.00377,\u001b[A\n",
      "Epoch 50:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.00392, val_loss=0.00377,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.96it/s, loss=0.00392, val_loss=0.00382,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00392, val_loss=0.00382,\u001b[A\n",
      "Epoch 51:  56%|▌| 36/64 [00:01<00:01, 24.19it/s, loss=0.00392, val_loss=0.00382,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00392, val_loss=0.00387,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00393, val_loss=0.00387,\u001b[A\n",
      "Epoch 52:  56%|▌| 36/64 [00:01<00:01, 24.28it/s, loss=0.00393, val_loss=0.00387,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00393, val_loss=0.00392,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.65it/s, loss=0.00393, val_loss=0.00392,\u001b[A\n",
      "Epoch 53:  56%|▌| 36/64 [00:01<00:01, 24.10it/s, loss=0.00393, val_loss=0.00392,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00393, val_loss=0.00397,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00393, val_loss=0.00397,\u001b[A\n",
      "Epoch 54:  56%|▌| 36/64 [00:01<00:01, 23.89it/s, loss=0.00393, val_loss=0.00397,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.00393, val_loss=0.00406,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.0453, val_loss=0.00406, \u001b[A\n",
      "Epoch 55:  56%|▌| 36/64 [00:01<00:01, 24.00it/s, loss=0.0453, val_loss=0.00406, \n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.93it/s, loss=0.0453, val_loss=0.043, av\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00552, val_loss=0.043, a\u001b[A\n",
      "Epoch 56:  56%|▌| 36/64 [00:01<00:01, 23.82it/s, loss=0.00552, val_loss=0.043, a\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.00552, val_loss=0.00467,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00397, val_loss=0.00467,\u001b[A\n",
      "Epoch 57:  56%|▌| 36/64 [00:01<00:01, 23.99it/s, loss=0.00397, val_loss=0.00467,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 37.83it/s, loss=0.00397, val_loss=0.00432,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00392, val_loss=0.00432,\u001b[A\n",
      "Epoch 58:  56%|▌| 36/64 [00:01<00:01, 23.97it/s, loss=0.00392, val_loss=0.00432,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.77it/s, loss=0.00392, val_loss=0.00421,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00393, val_loss=0.00421,\u001b[A\n",
      "Epoch 59:  56%|▌| 36/64 [00:01<00:01, 23.49it/s, loss=0.00393, val_loss=0.00421,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00393, val_loss=0.0042, \u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00394, val_loss=0.0042, \u001b[A\n",
      "Epoch 60:  56%|▌| 36/64 [00:01<00:01, 24.08it/s, loss=0.00394, val_loss=0.0042, \n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00394, val_loss=0.00423,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00395, val_loss=0.00423,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:  56%|▌| 36/64 [00:01<00:01, 23.67it/s, loss=0.00395, val_loss=0.00423,\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.00395, val_loss=0.00426,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00395, val_loss=0.00426,\u001b[A\n",
      "Epoch 62:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.00395, val_loss=0.00426,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00395, val_loss=0.00428,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00396, val_loss=0.00428,\u001b[A\n",
      "Epoch 63:  56%|▌| 36/64 [00:01<00:01, 23.23it/s, loss=0.00396, val_loss=0.00428,\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.00396, val_loss=0.00432,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 20.03it/s, loss=0.00454, val_loss=0.00432,\u001b[A\n",
      "Epoch 64:  56%|▌| 36/64 [00:01<00:01, 22.25it/s, loss=0.00454, val_loss=0.00432,\n",
      "Epoch 64:  84%|▊| 54/64 [00:01<00:00, 31.12it/s, loss=0.00454, val_loss=0.00432,\u001b[A\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 35.10it/s, loss=0.00454, val_loss=0.0148, \u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 20.53it/s, loss=0.017, val_loss=0.0148, av\u001b[A\n",
      "Epoch 65:  56%|▌| 36/64 [00:01<00:01, 22.76it/s, loss=0.017, val_loss=0.0148, av\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 36.10it/s, loss=0.017, val_loss=0.0137, av\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 20.29it/s, loss=0.00441, val_loss=0.0137, \u001b[A\n",
      "Epoch 66:  56%|▌| 36/64 [00:01<00:01, 22.64it/s, loss=0.00441, val_loss=0.0137, \n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 35.89it/s, loss=0.00441, val_loss=0.00478,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 20.32it/s, loss=0.00398, val_loss=0.00478,\u001b[A\n",
      "Epoch 67:  56%|▌| 36/64 [00:01<00:01, 22.65it/s, loss=0.00398, val_loss=0.00478,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 35.83it/s, loss=0.00398, val_loss=0.00446,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 20.21it/s, loss=0.00397, val_loss=0.00446,\u001b[A\n",
      "Epoch 68:  56%|▌| 36/64 [00:01<00:01, 22.45it/s, loss=0.00397, val_loss=0.00446,\n",
      "Epoch 68:  84%|▊| 54/64 [00:01<00:00, 31.48it/s, loss=0.00397, val_loss=0.00446,\u001b[A\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 35.56it/s, loss=0.00397, val_loss=0.0044, \u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 20.33it/s, loss=0.00398, val_loss=0.0044, \u001b[A\n",
      "Epoch 69:  56%|▌| 36/64 [00:01<00:01, 22.65it/s, loss=0.00398, val_loss=0.0044, \n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 35.82it/s, loss=0.00398, val_loss=0.00439,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 19.42it/s, loss=0.00399, val_loss=0.00439,\u001b[A\n",
      "Epoch 70:  56%|▌| 36/64 [00:01<00:01, 21.50it/s, loss=0.00399, val_loss=0.00439,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 34.40it/s, loss=0.00399, val_loss=0.0044, \u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.004, val_loss=0.0044, av\u001b[A\n",
      "Epoch 71:  56%|▌| 36/64 [00:01<00:01, 22.94it/s, loss=0.004, val_loss=0.0044, av\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.23it/s, loss=0.004, val_loss=0.00445, a\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 20.20it/s, loss=0.00464, val_loss=0.00445,\u001b[A\n",
      "Epoch 72:  56%|▌| 36/64 [00:01<00:01, 22.44it/s, loss=0.00464, val_loss=0.00445,\n",
      "Epoch 72:  84%|▊| 54/64 [00:01<00:00, 31.45it/s, loss=0.00464, val_loss=0.00445,\u001b[A\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 35.61it/s, loss=0.00464, val_loss=0.0162, \u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 20.36it/s, loss=0.0261, val_loss=0.0162, a\u001b[A\n",
      "Epoch 73:  56%|▌| 36/64 [00:01<00:01, 22.61it/s, loss=0.0261, val_loss=0.0162, a\n",
      "Epoch 73:  84%|▊| 54/64 [00:01<00:00, 31.52it/s, loss=0.0261, val_loss=0.0162, a\u001b[A\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 35.52it/s, loss=0.0261, val_loss=0.0126, a\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 20.85it/s, loss=0.00468, val_loss=0.0126, \u001b[A\n",
      "Epoch 74:  56%|▌| 36/64 [00:01<00:01, 23.06it/s, loss=0.00468, val_loss=0.0126, \n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 36.55it/s, loss=0.00468, val_loss=0.00509,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00402, val_loss=0.00509,\u001b[A\n",
      "Epoch 75:  56%|▌| 36/64 [00:01<00:01, 23.65it/s, loss=0.00402, val_loss=0.00509,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 37.30it/s, loss=0.00402, val_loss=0.00461,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 20.19it/s, loss=0.00401, val_loss=0.00461,\u001b[A\n",
      "Epoch 76:  56%|▌| 36/64 [00:01<00:01, 21.89it/s, loss=0.00401, val_loss=0.00461,\n",
      "Epoch 76:  86%|▊| 55/64 [00:01<00:00, 31.42it/s, loss=0.00401, val_loss=0.00461,\u001b[A\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 34.97it/s, loss=0.00401, val_loss=0.00455,\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00401, val_loss=0.00455,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 24.01it/s, loss=0.00401, val_loss=0.00455,\n",
      "Epoch 77:  89%|▉| 57/64 [00:01<00:00, 33.52it/s, loss=0.00401, val_loss=0.00455,\u001b[A\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.00401, val_loss=0.00452,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00403, val_loss=0.00452,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 23.99it/s, loss=0.00403, val_loss=0.00452,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 36.10it/s, loss=0.00403, val_loss=0.00461,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 20.26it/s, loss=0.112, val_loss=0.00461, a\u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 23.42it/s, loss=0.112, val_loss=0.00461, a\n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 35.64it/s, loss=0.112, val_loss=0.0383, av\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 19.80it/s, loss=0.00674, val_loss=0.0383, \u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 23.07it/s, loss=0.00674, val_loss=0.0383, \n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 35.03it/s, loss=0.00674, val_loss=0.00449,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 20.17it/s, loss=0.00408, val_loss=0.00449,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 23.48it/s, loss=0.00408, val_loss=0.00449,\n",
      "Validating:  31%|█████████▋                     | 10/32 [00:00<00:00, 90.87it/s]\u001b[A\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 34.44it/s, loss=0.00408, val_loss=0.00482,\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 20.21it/s, loss=0.004, val_loss=0.00482, a\u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 23.48it/s, loss=0.004, val_loss=0.00482, a\n",
      "Epoch 82:  89%|▉| 57/64 [00:01<00:00, 32.52it/s, loss=0.004, val_loss=0.00482, a\u001b[A\n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 35.34it/s, loss=0.004, val_loss=0.00468, a\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 20.44it/s, loss=0.0336, val_loss=0.00468, \u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 23.79it/s, loss=0.0336, val_loss=0.00468, \n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.0336, val_loss=0.0275, a\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 20.31it/s, loss=0.00689, val_loss=0.0275, \u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 23.70it/s, loss=0.00689, val_loss=0.0275, \n",
      "Epoch 84:  89%|▉| 57/64 [00:01<00:00, 33.12it/s, loss=0.00689, val_loss=0.0275, \u001b[A\n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 35.70it/s, loss=0.00689, val_loss=0.00556,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.06it/s, loss=0.00494, val_loss=0.00556,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 23.37it/s, loss=0.00494, val_loss=0.00556,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 35.33it/s, loss=0.00494, val_loss=0.0164, \u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.012, val_loss=0.0164, av\u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 23.76it/s, loss=0.012, val_loss=0.0164, av\n",
      "Epoch 86:  89%|▉| 57/64 [00:01<00:00, 33.40it/s, loss=0.012, val_loss=0.0164, av\u001b[A\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 36.05it/s, loss=0.012, val_loss=0.0068, av\u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.25it/s, loss=0.00435, val_loss=0.0068, \u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 23.48it/s, loss=0.00435, val_loss=0.0068, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 35.62it/s, loss=0.00435, val_loss=0.00471,\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00406, val_loss=0.00471,\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 23.79it/s, loss=0.00406, val_loss=0.00471,\n",
      "Epoch 88:  89%|▉| 57/64 [00:01<00:00, 33.21it/s, loss=0.00406, val_loss=0.00471,\u001b[A\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 36.00it/s, loss=0.00406, val_loss=0.00486,\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00406, val_loss=0.00486,\u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 23.85it/s, loss=0.00406, val_loss=0.00486,\n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 35.97it/s, loss=0.00406, val_loss=0.00484,\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 19.87it/s, loss=0.00407, val_loss=0.00484,\u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 23.18it/s, loss=0.00407, val_loss=0.00484,\n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 35.17it/s, loss=0.00407, val_loss=0.00485,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 20.30it/s, loss=0.0644, val_loss=0.00485, \u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 23.61it/s, loss=0.0644, val_loss=0.00485, \n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 35.75it/s, loss=0.0644, val_loss=0.181, av\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.19it/s, loss=0.0122, val_loss=0.181, av\u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 23.56it/s, loss=0.0122, val_loss=0.181, av\n",
      "Epoch 92:  89%|▉| 57/64 [00:01<00:00, 32.81it/s, loss=0.0122, val_loss=0.181, av\u001b[A\n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 34.59it/s, loss=0.0122, val_loss=0.00821, \u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 19.88it/s, loss=0.00433, val_loss=0.00821,\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 23.15it/s, loss=0.00433, val_loss=0.00821,\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 35.02it/s, loss=0.00433, val_loss=0.00495,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 20.00it/s, loss=0.00409, val_loss=0.00495,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 23.43it/s, loss=0.00409, val_loss=0.00495,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 35.41it/s, loss=0.00409, val_loss=0.00485,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 20.60it/s, loss=0.00409, val_loss=0.00485,\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.10it/s, loss=0.00409, val_loss=0.00485,\n",
      "Epoch 95:  89%|▉| 57/64 [00:01<00:00, 33.70it/s, loss=0.00409, val_loss=0.00485,\u001b[A\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 36.25it/s, loss=0.00409, val_loss=0.00493,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 20.39it/s, loss=0.0394, val_loss=0.00493, \u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 23.88it/s, loss=0.0394, val_loss=0.00493, \n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 35.98it/s, loss=0.0394, val_loss=0.0724, a\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00839, val_loss=0.0724, \u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.19it/s, loss=0.00839, val_loss=0.0724, \n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 36.47it/s, loss=0.00839, val_loss=0.0065, \u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00428, val_loss=0.0065, \u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 23.98it/s, loss=0.00428, val_loss=0.0065, \n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 36.16it/s, loss=0.00428, val_loss=0.00506,\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 19.95it/s, loss=0.032, val_loss=0.00506, a\u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 23.19it/s, loss=0.032, val_loss=0.00506, a\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 35.18it/s, loss=0.032, val_loss=0.191, avg\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 34.97it/s, loss=0.032, val_loss=0.191, avg\u001b[A\n",
      "Sizes of clusters: 493, 199, 315, 593\n",
      "\n",
      "preds: [0 2 2 0 2 0 0 2 3 0 0 3 3 0 2 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 3 0 0 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2 0 2 0 0 0 3 0 0\n",
      " 0 0 0 0 3 2 0 0 0 2 0 0 0 2 0 0 0 3 0 0 3 0 0 0 0 3 2 2 0 0 0 0 2 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 2 0 2 0 3 2 3 0 0 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
      " 3 0 0 2 2 0 0 0 0 3 0 0 3 0 2 0 0 2 0 3 0 0 0 0 3 0 0 0 0 0 0 2 0 0 0 3 0\n",
      " 0 2 0 0 2 3 0 2 0 0 2 0 3 2 0 3 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 2 0 0 0\n",
      " 0 0 0 3 2 0 0 0 3 0 0 0 0 2 0 2 0 0 2 0 0 0 0 0 2 2 2 0 0 0 0 2 0 0 0 0 2\n",
      " 0 0 2 3 0 0 0 0 0 0 2 0 2 2 0 0 0 0 3 2 2 0 3 3 2 0 0 0 0 0 0 0 2 0 0 0 3\n",
      " 0 2 0 0 0 0 0 2 0 3 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 2 0 0\n",
      " 0 0 0 0 0 0 0 2 0 2 2 0 2 3 2 2 0 0 2 0 2 2 0 0 0 2 0 0 0 0 0 0 0 2 0 3 0\n",
      " 0 0 0 0 0 2 0 0 2 0 0 0 0 2 0 0 2 0 0 0 0 3 2 0 0 3 2 0 0 0 2 2 0 2 2 2 2\n",
      " 2 2 0 2 2 2 0 0 2 2 2 0 0 2 2 2 2 0 0 0 2 2 3 0 0 2 2 2 0 0 2 0 0 0 2 2 2\n",
      " 2 0 2 2 2 2 0 2 2 0 2 2 3 2 2 0 2 0 2 0 2 2 2 2 2 2 2 0 0 2 2 0 2 0 2 2 0\n",
      " 2 2 2 2 0 3 2 3 0 0 0 0 0 2 2 2 2 0 2 0 2 0 2 0 2 0 0 3 2 0 2 0 0 2 2 0 2\n",
      " 2 2 2 2 0 2 2 2 0 2 2 2 2 0 2 0 2 0 0 2 0 0 0 2 2 0 2 2 2 2 2 0 0 0 0 0 0\n",
      " 2 0 2 2 2 0 2 0 2 2 2 0 0 3 2 2 2 0 2 2 0 2 2 2 2 2 0 0 2 2 0 2 2 0 0 0 2\n",
      " 3 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 0 0 0 0 2 2 0 2 2 0 2 2 2 2 0\n",
      " 2 2 2 0 2 0 2 2 2 2 2 0 2 2 2 3 0 2 0 0 2 2 2 2 2 2 2 0 2 0 2 2 0 0 0 0 2\n",
      " 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 0 0 2 2 0 2 2 0 2 2 0 2 0 0 2 2 2 2 0 0 0 2\n",
      " 2 0 0 2 0 0 0 2 2 0 2 0 0 0 2 0 0 2 2 2 0 2 2 0 2 2 2 3 2 2 2 2 2 0 2 2 0\n",
      " 2 2 0 2 2 2 0 0 0 0 0 0 2 2 3 2 2 0 2 0 0 0 2 2 2 0 2 2 2 0 2 2 0 0 0 2 0\n",
      " 2 2 2 2 2 0 0 2 2 2 3 2 0 0 0 0 2 2 0 2 0 2 2 1 3 3 3 3 0 3 1 3 3 3 3 3 3\n",
      " 3 1 3 1 1 1 3 3 0 1 3 3 3 3 3 3 0 3 3 0 3 3 3 1 0 3 3 3 0 3 3 1 3 3 3 3 3\n",
      " 3 1 3 1 3 3 3 3 3 3 3 1 1 3 3 1 1 3 1 3 3 3 3 3 1 0 1 0 3 1 3 3 3 3 3 1 3\n",
      " 3 1 3 3 3 3 3 3 3 3 3 3 0 3 3 1 3 3 3 3 3 1 3 1 3 3 3 3 3 3 3 3 3 3 3 1 0\n",
      " 3 3 3 3 3 1 3 3 3 3 3 3 3 3 1 1 3 1 3 1 3 3 1 1 3 3 1 3 0 3 1 3 3 1 3 1 3\n",
      " 3 3 3 3 3 3 1 3 1 3 3 0 0 3 3 3 3 3 3 3 3 3 1 1 1 3 0 3 3 3 1 3 3 1 3 3 1\n",
      " 3 3 3 3 3 3 3 3 1 0 3 3 3 3 3 3 3 0 3 3 1 3 3 1 3 3 1 3 3 1 1 3 3 3 3 3 0\n",
      " 3 3 3 3 3 3 3 3 0 3 3 3 1 0 3 3 3 1 3 0 3 3 1 3 3 3 3 1 3 1 3 3 3 3 3 3 3\n",
      " 3 3 3 0 3 1 3 3 1 3 0 3 1 3 1 3 1 0 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3\n",
      " 1 3 3 3 3 0 3 3 3 3 3 3 3 1 3 3 0 3 3 3 3 3 3 1 1 3 3 3 3 1 1 3 3 1 0 3 3\n",
      " 1 3 1 3 3 3 0 3 3 1 3 3 3 3 3 3 3 0 3 3 1 1 3 1 1 3 1 3 3 0 1 3 3 3 3 1 3\n",
      " 3 1 3 3 3 0 3 3 3 3 3 1 1 3 0 1 3 1 3 3 3 3 1 3 3 1 3 1 1 3 3 3 3 3 1 3 3\n",
      " 3 3 3 3 3 1 0 3 1 3 3 0 3 3 3 3 3 1 3 3 1 3 3 3 1 3 1 3 1 3 1 3 1 1 0 1 3\n",
      " 3 3 3 3 1 3 1 3 1 3 1 1 1 3 1 1 1 1 0 1 3 3 3 1 1 3 1 3 3 3 1 3 1 3 0 3 3\n",
      " 1 3 3 3 3 3 3 3 3 0 3 3 3 1 3 3 3 3 1 3 3 3 1 1 3 1 3 3 3 1 1 0 3 1 1 1 3\n",
      " 3 3 1 3 0 3 3 3 1 3 3 3 3 1 1 3 3 3 1 3 3 3 3 0 3 3 1 3 3 0 3 1 3 3 3 1 3\n",
      " 3 1 3 3 0 3 3 1 3 1 3 3 3 3 3 3 3 3 3 0 3 3 0 3 3 0 1 3 3 3 1 3 1 3 3 3 3\n",
      " 3 1 1 3 1 3 1 3 3 3 3 3 1 3 3 1 0 3 1 3 1 3 3 3 3 3 3 0 1 1 3 1 1 1 1 3 3\n",
      " 3 3 3 3 3 1 3 3 3 1 1 1 3 3 1 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 1 1 3 3\n",
      " 1 3 3 1 3 3 3 0 1 3 3 3 3 3 3 3 3 3 1 3 3 3 3 0 3 3 3 0 3 3 3 1 1 1 0 3 1\n",
      " 3 1 1 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 1 0 3 1 3 3 3 3 1 3 1 1 3 3 3 3 3 1\n",
      " 1 3 1 3 1 3 1 1 0 0 3 1 3 3 3 3 3 1 1 3 3 1 1 3 0 3 3 3 1 3 1 3 1 0 1 1 3\n",
      " 3 3 3 3 3 3 3 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5806\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  52%|▌| 33/64 [00:01<00:01, 21.79it/s, loss=2.04, val_loss=0.0956, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=2.04, val_loss=0.837, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.119, val_loss=0.837, avg_\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.119, val_loss=0.837, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.119, val_loss=0.1, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 20.05it/s, loss=0.0479, val_loss=0.1, avg_v\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 23.40it/s, loss=0.0479, val_loss=0.1, avg_v\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 35.51it/s, loss=0.0479, val_loss=0.0575, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.41it/s, loss=0.0376, val_loss=0.0575, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 23.59it/s, loss=0.0376, val_loss=0.0575, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 35.58it/s, loss=0.0376, val_loss=0.0467, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 20.07it/s, loss=0.032, val_loss=0.0467, avg\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 23.48it/s, loss=0.032, val_loss=0.0467, avg\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 35.45it/s, loss=0.032, val_loss=0.0388, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.0283, val_loss=0.0388, av\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 24.70it/s, loss=0.0283, val_loss=0.0388, av\n",
      "Epoch 5:  89%|▉| 57/64 [00:01<00:00, 34.12it/s, loss=0.0283, val_loss=0.0388, av\u001b[A\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 36.93it/s, loss=0.0283, val_loss=0.0346, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 19.53it/s, loss=0.0252, val_loss=0.0346, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 22.78it/s, loss=0.0252, val_loss=0.0346, av\n",
      "Validating:  34%|██████████▎                   | 11/32 [00:00<00:00, 106.02it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 33.59it/s, loss=0.0252, val_loss=0.0299, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 19.62it/s, loss=0.0231, val_loss=0.0299, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 23.00it/s, loss=0.0231, val_loss=0.0299, av\n",
      "Epoch 7:  89%|▉| 57/64 [00:01<00:00, 31.82it/s, loss=0.0231, val_loss=0.0299, av\u001b[A\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 34.32it/s, loss=0.0231, val_loss=0.0279, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 20.18it/s, loss=0.0207, val_loss=0.0279, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 23.51it/s, loss=0.0207, val_loss=0.0279, av\n",
      "Epoch 8:  89%|▉| 57/64 [00:01<00:00, 32.84it/s, loss=0.0207, val_loss=0.0279, av\u001b[A\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 35.52it/s, loss=0.0207, val_loss=0.0242, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 19.80it/s, loss=0.0187, val_loss=0.0242, av\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 22.97it/s, loss=0.0187, val_loss=0.0242, av\n",
      "Epoch 9:  89%|▉| 57/64 [00:01<00:00, 32.38it/s, loss=0.0187, val_loss=0.0242, av\u001b[A\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 34.81it/s, loss=0.0187, val_loss=0.0219, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.15it/s, loss=0.0168, val_loss=0.0219, a\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 23.47it/s, loss=0.0168, val_loss=0.0219, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 35.50it/s, loss=0.0168, val_loss=0.0194, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 20.02it/s, loss=0.0152, val_loss=0.0194, a\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 23.04it/s, loss=0.0152, val_loss=0.0194, a\n",
      "Epoch 11:  89%|▉| 57/64 [00:01<00:00, 31.99it/s, loss=0.0152, val_loss=0.0194, a\u001b[A\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 34.28it/s, loss=0.0152, val_loss=0.0175, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 19.90it/s, loss=0.0136, val_loss=0.0175, a\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 23.09it/s, loss=0.0136, val_loss=0.0175, a\n",
      "Epoch 12:  89%|▉| 57/64 [00:01<00:00, 32.00it/s, loss=0.0136, val_loss=0.0175, a\u001b[A\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 34.84it/s, loss=0.0136, val_loss=0.0155, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 20.49it/s, loss=0.0122, val_loss=0.0155, a\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 23.97it/s, loss=0.0122, val_loss=0.0155, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 35.85it/s, loss=0.0122, val_loss=0.0138, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.46it/s, loss=0.0109, val_loss=0.0138, a\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 24.00it/s, loss=0.0109, val_loss=0.0138, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 36.10it/s, loss=0.0109, val_loss=0.0121, a\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 20.18it/s, loss=0.00979, val_loss=0.0121, \u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 23.41it/s, loss=0.00979, val_loss=0.0121, \n",
      "Epoch 15:  89%|▉| 57/64 [00:01<00:00, 32.89it/s, loss=0.00979, val_loss=0.0121, \u001b[A\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 35.55it/s, loss=0.00979, val_loss=0.0107, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 20.71it/s, loss=0.0088, val_loss=0.0107, a\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 24.14it/s, loss=0.0088, val_loss=0.0107, a\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 36.45it/s, loss=0.0088, val_loss=0.00942, \u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00795, val_loss=0.00942,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00795, val_loss=0.00942,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00795, val_loss=0.00835,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.61it/s, loss=0.00722, val_loss=0.00835,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 24.20it/s, loss=0.00722, val_loss=0.00835,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.39it/s, loss=0.00722, val_loss=0.00737,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.00662, val_loss=0.00737,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.00662, val_loss=0.00737,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.68it/s, loss=0.00662, val_loss=0.00661,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 18.50it/s, loss=0.00611, val_loss=0.00661,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 21.67it/s, loss=0.00611, val_loss=0.00661,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 33.02it/s, loss=0.00611, val_loss=0.00596,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 20.44it/s, loss=0.0057, val_loss=0.00596, \u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 23.97it/s, loss=0.0057, val_loss=0.00596, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.12it/s, loss=0.0057, val_loss=0.00545, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 20.66it/s, loss=0.00536, val_loss=0.00545,\u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 23.45it/s, loss=0.00536, val_loss=0.00545,\n",
      "Validating:  28%|█████████                       | 9/32 [00:00<00:00, 82.49it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 34.89it/s, loss=0.00536, val_loss=0.00505,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 19.78it/s, loss=0.00509, val_loss=0.00505,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 22.96it/s, loss=0.00509, val_loss=0.00505,\n",
      "Epoch 23:  89%|▉| 57/64 [00:01<00:00, 32.14it/s, loss=0.00509, val_loss=0.00505,\u001b[A\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 34.91it/s, loss=0.00509, val_loss=0.00474,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.19it/s, loss=0.00488, val_loss=0.00474,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 23.46it/s, loss=0.00488, val_loss=0.00474,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 35.55it/s, loss=0.00488, val_loss=0.00448,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.0047, val_loss=0.00448, \u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 23.85it/s, loss=0.0047, val_loss=0.00448, \n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 36.10it/s, loss=0.0047, val_loss=0.00428, \u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 20.55it/s, loss=0.00457, val_loss=0.00428,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 23.80it/s, loss=0.00457, val_loss=0.00428,\n",
      "Epoch 26:  89%|▉| 57/64 [00:01<00:00, 33.36it/s, loss=0.00457, val_loss=0.00428,\u001b[A\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 36.02it/s, loss=0.00457, val_loss=0.0041, \u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00446, val_loss=0.0041, \u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 24.05it/s, loss=0.00446, val_loss=0.0041, \n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.00446, val_loss=0.00396,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 19.82it/s, loss=0.00437, val_loss=0.00396,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 23.06it/s, loss=0.00437, val_loss=0.00396,\n",
      "Epoch 28:  89%|▉| 57/64 [00:01<00:00, 32.25it/s, loss=0.00437, val_loss=0.00396,\u001b[A\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 34.98it/s, loss=0.00437, val_loss=0.00386,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00431, val_loss=0.00386,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 24.10it/s, loss=0.00431, val_loss=0.00386,\n",
      "Epoch 29:  89%|▉| 57/64 [00:01<00:00, 33.40it/s, loss=0.00431, val_loss=0.00386,\u001b[A\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 36.30it/s, loss=0.00431, val_loss=0.00377,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.43it/s, loss=0.00425, val_loss=0.00377,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 23.77it/s, loss=0.00425, val_loss=0.00377,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 35.95it/s, loss=0.00425, val_loss=0.00369,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.40it/s, loss=0.0042, val_loss=0.00369, \u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 23.85it/s, loss=0.0042, val_loss=0.00369, \n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.06it/s, loss=0.0042, val_loss=0.00363, \u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 20.21it/s, loss=0.00417, val_loss=0.00363,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 23.46it/s, loss=0.00417, val_loss=0.00363,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 35.61it/s, loss=0.00417, val_loss=0.00357,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 20.19it/s, loss=0.00413, val_loss=0.00357,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 23.44it/s, loss=0.00413, val_loss=0.00357,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 35.58it/s, loss=0.00413, val_loss=0.00353,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 19.89it/s, loss=0.0041, val_loss=0.00353, \u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 23.11it/s, loss=0.0041, val_loss=0.00353, \n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 35.06it/s, loss=0.0041, val_loss=0.00349, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 20.60it/s, loss=0.00408, val_loss=0.00349,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 24.13it/s, loss=0.00408, val_loss=0.00349,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 36.23it/s, loss=0.00408, val_loss=0.00347,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 20.26it/s, loss=0.00406, val_loss=0.00347,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 23.72it/s, loss=0.00406, val_loss=0.00347,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 35.78it/s, loss=0.00406, val_loss=0.00345,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 20.51it/s, loss=0.00404, val_loss=0.00345,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 24.02it/s, loss=0.00404, val_loss=0.00345,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 36.09it/s, loss=0.00404, val_loss=0.00341,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.00402, val_loss=0.00341,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00402, val_loss=0.00341,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.00402, val_loss=0.00337,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00401, val_loss=0.00337,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 23.95it/s, loss=0.00401, val_loss=0.00337,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 36.14it/s, loss=0.00401, val_loss=0.00334,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 20.28it/s, loss=0.00399, val_loss=0.00334,\u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 23.68it/s, loss=0.00399, val_loss=0.00334,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 35.88it/s, loss=0.00399, val_loss=0.0033, \u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 20.77it/s, loss=0.00398, val_loss=0.0033, \u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.33it/s, loss=0.00398, val_loss=0.0033, \n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.00398, val_loss=0.00326,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00397, val_loss=0.00326,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 24.10it/s, loss=0.00397, val_loss=0.00326,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 36.26it/s, loss=0.00397, val_loss=0.00324,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 19.26it/s, loss=0.00396, val_loss=0.00324,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 22.31it/s, loss=0.00396, val_loss=0.00324,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 33.88it/s, loss=0.00396, val_loss=0.00322,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 20.00it/s, loss=0.00395, val_loss=0.00322,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 23.40it/s, loss=0.00395, val_loss=0.00322,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 35.40it/s, loss=0.00395, val_loss=0.00321,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 19.63it/s, loss=0.00394, val_loss=0.00321,\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 22.92it/s, loss=0.00394, val_loss=0.00321,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 34.83it/s, loss=0.00394, val_loss=0.00321,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 20.39it/s, loss=0.00393, val_loss=0.00321,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 23.83it/s, loss=0.00393, val_loss=0.00321,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 35.90it/s, loss=0.00393, val_loss=0.00321,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.00392, val_loss=0.00321,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 24.42it/s, loss=0.00392, val_loss=0.00321,\n",
      "Epoch 47:  89%|▉| 57/64 [00:01<00:00, 33.60it/s, loss=0.00392, val_loss=0.00321,\u001b[A\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.00392, val_loss=0.0032, \u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.14it/s, loss=0.00391, val_loss=0.0032, \u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 23.42it/s, loss=0.00391, val_loss=0.0032, \n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 35.54it/s, loss=0.00391, val_loss=0.0032, \u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 20.25it/s, loss=0.00391, val_loss=0.0032, \u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 23.74it/s, loss=0.00391, val_loss=0.0032, \n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 35.81it/s, loss=0.00391, val_loss=0.0032, \u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 20.50it/s, loss=0.0039, val_loss=0.0032, a\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 24.01it/s, loss=0.0039, val_loss=0.0032, a\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 36.18it/s, loss=0.0039, val_loss=0.0032, a\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 20.30it/s, loss=0.0039, val_loss=0.0032, a\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 23.58it/s, loss=0.0039, val_loss=0.0032, a\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 35.77it/s, loss=0.0039, val_loss=0.0032, a\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.38it/s, loss=0.00389, val_loss=0.0032, \n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 36.62it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 20.55it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.04it/s, loss=0.00389, val_loss=0.0032, \n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 36.27it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 24.55it/s, loss=0.00389, val_loss=0.0032, \n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 36.89it/s, loss=0.00389, val_loss=0.0032, \u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00388, val_loss=0.0032, \u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.00388, val_loss=0.0032, \n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.00388, val_loss=0.0032, \u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00388, val_loss=0.0032, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 24.55it/s, loss=0.00388, val_loss=0.0032, \n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.99it/s, loss=0.00388, val_loss=0.00319,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 20.60it/s, loss=0.00388, val_loss=0.00319,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.15it/s, loss=0.00388, val_loss=0.00319,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 36.36it/s, loss=0.00388, val_loss=0.00317,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00388, val_loss=0.00317,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 23.96it/s, loss=0.00388, val_loss=0.00317,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 36.06it/s, loss=0.00388, val_loss=0.00314,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00388, val_loss=0.00314,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00388, val_loss=0.00314,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 37.16it/s, loss=0.00388, val_loss=0.00313,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00387, val_loss=0.00313,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.45it/s, loss=0.00387, val_loss=0.00313,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 20.78it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 24.13it/s, loss=0.00387, val_loss=0.00312,\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.00387, val_loss=0.00312,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 37.04it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00387, val_loss=0.00312,\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00387, val_loss=0.00312,\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 37.00it/s, loss=0.00387, val_loss=0.00313,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 20.71it/s, loss=0.00387, val_loss=0.00313,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 24.26it/s, loss=0.00387, val_loss=0.00313,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 36.30it/s, loss=0.00387, val_loss=0.00314,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00387, val_loss=0.00314,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 25.09it/s, loss=0.00387, val_loss=0.00314,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00387, val_loss=0.00315,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00387, val_loss=0.00315,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.00387, val_loss=0.00315,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00387, val_loss=0.00317,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 20.49it/s, loss=0.00387, val_loss=0.00317,\u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 23.79it/s, loss=0.00387, val_loss=0.00317,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 35.97it/s, loss=0.00387, val_loss=0.0032, \u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.00387, val_loss=0.0032, \u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00387, val_loss=0.0032, \n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 36.34it/s, loss=0.00387, val_loss=0.00322,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00399, val_loss=0.00322,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 24.48it/s, loss=0.00399, val_loss=0.00322,\n",
      "Epoch 69:  89%|▉| 57/64 [00:01<00:00, 34.17it/s, loss=0.00399, val_loss=0.00322,\u001b[A\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 36.49it/s, loss=0.00399, val_loss=0.00507,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.0398, val_loss=0.00507, \u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 24.39it/s, loss=0.0398, val_loss=0.00507, \n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.0398, val_loss=0.00672, \u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00471, val_loss=0.00672,\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 24.48it/s, loss=0.00471, val_loss=0.00672,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.83it/s, loss=0.00471, val_loss=0.00289,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.0039, val_loss=0.00289, \u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 24.72it/s, loss=0.0039, val_loss=0.00289, \n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.0039, val_loss=0.00293, \u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 20.47it/s, loss=0.00387, val_loss=0.00293,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 23.87it/s, loss=0.00387, val_loss=0.00293,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 36.13it/s, loss=0.00387, val_loss=0.0029, \u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 20.77it/s, loss=0.00387, val_loss=0.0029, \u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 24.08it/s, loss=0.00387, val_loss=0.0029, \n",
      "Epoch 74:  89%|▉| 57/64 [00:01<00:00, 33.75it/s, loss=0.00387, val_loss=0.0029, \u001b[A\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.00387, val_loss=0.00291,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00389, val_loss=0.00291,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00389, val_loss=0.00291,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.00389, val_loss=0.00303,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 20.35it/s, loss=0.0597, val_loss=0.00303, \u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 23.77it/s, loss=0.0597, val_loss=0.00303, \n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 35.93it/s, loss=0.0597, val_loss=0.0167, a\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.0058, val_loss=0.0167, a\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 24.66it/s, loss=0.0058, val_loss=0.0167, a\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.0058, val_loss=0.00363, \u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 20.72it/s, loss=0.00394, val_loss=0.00363,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.29it/s, loss=0.00394, val_loss=0.00363,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 36.54it/s, loss=0.00394, val_loss=0.00288,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.0224, val_loss=0.00288, \u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 24.53it/s, loss=0.0224, val_loss=0.00288, \n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.0224, val_loss=0.11, avg\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00731, val_loss=0.11, av\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 24.51it/s, loss=0.00731, val_loss=0.11, av\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.00731, val_loss=0.00325,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00401, val_loss=0.00325,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 24.96it/s, loss=0.00401, val_loss=0.00325,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00401, val_loss=0.0029, \u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 20.63it/s, loss=0.00389, val_loss=0.0029, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 24.00it/s, loss=0.00389, val_loss=0.0029, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 36.34it/s, loss=0.00389, val_loss=0.00287,\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00389, val_loss=0.00287,\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.38it/s, loss=0.00389, val_loss=0.00287,\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.00389, val_loss=0.00287,\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00391, val_loss=0.00287,\u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 24.62it/s, loss=0.00391, val_loss=0.00287,\n",
      "Epoch 84:  89%|▉| 57/64 [00:01<00:00, 34.34it/s, loss=0.00391, val_loss=0.00287,\u001b[A\n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 37.05it/s, loss=0.00391, val_loss=0.00308,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.32it/s, loss=0.108, val_loss=0.00308, a\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 23.83it/s, loss=0.108, val_loss=0.00308, a\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 35.80it/s, loss=0.108, val_loss=0.0543, av\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00737, val_loss=0.0543, \u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 24.45it/s, loss=0.00737, val_loss=0.0543, \n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.00737, val_loss=0.00294,\u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00402, val_loss=0.00294,\u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00402, val_loss=0.00294,\n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 37.01it/s, loss=0.00402, val_loss=0.0028, \u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0039, val_loss=0.0028, a\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 25.00it/s, loss=0.0039, val_loss=0.0028, a\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.0039, val_loss=0.00275, \u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.0039, val_loss=0.00275, \u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.76it/s, loss=0.0039, val_loss=0.00275, \n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.0039, val_loss=0.00276, \u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.0039, val_loss=0.00276, \u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.97it/s, loss=0.0039, val_loss=0.00276, \n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.0039, val_loss=0.00277, \u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.129, val_loss=0.00277, a\u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.129, val_loss=0.00277, a\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 37.29it/s, loss=0.129, val_loss=0.0635, av\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.0151, val_loss=0.0635, a\u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.67it/s, loss=0.0151, val_loss=0.0635, a\n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.0151, val_loss=0.00664, \u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00433, val_loss=0.00664,\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00433, val_loss=0.00664,\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.84it/s, loss=0.00433, val_loss=0.00281,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00393, val_loss=0.00281,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 24.83it/s, loss=0.00393, val_loss=0.00281,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.00393, val_loss=0.0027, \u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00392, val_loss=0.0027, \u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.85it/s, loss=0.00392, val_loss=0.0027, \n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 37.29it/s, loss=0.00392, val_loss=0.00269,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00391, val_loss=0.00269,\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.59it/s, loss=0.00391, val_loss=0.00269,\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.00391, val_loss=0.00271,\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00391, val_loss=0.00271,\u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.71it/s, loss=0.00391, val_loss=0.00271,\n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.00391, val_loss=0.00271,\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.00392, val_loss=0.00271,\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00392, val_loss=0.00271,\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.00392, val_loss=0.0027, \u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 20.20it/s, loss=0.00533, val_loss=0.0027, \u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 23.58it/s, loss=0.00533, val_loss=0.0027, \n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 35.75it/s, loss=0.00533, val_loss=0.0269, \u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 35.56it/s, loss=0.00533, val_loss=0.0269, \u001b[A\n",
      "Sizes of clusters: 401, 363, 202, 634\n",
      "\n",
      "preds: [0 2 0 3 0 3 0 0 3 3 0 3 3 0 0 3 3 0 0 3 3 3 0 3 3 3 0 0 3 0 3 0 3 0 0 3 3\n",
      " 3 3 3 3 0 3 3 0 0 3 0 3 3 0 3 0 3 3 3 3 0 3 0 3 0 0 3 3 0 0 0 0 3 0 3 3 3\n",
      " 3 3 0 3 3 0 0 0 3 0 0 3 3 0 3 3 3 3 0 0 1 0 0 0 3 3 0 0 3 0 0 3 0 3 0 3 0\n",
      " 1 3 3 3 0 3 3 0 0 0 3 0 0 1 0 3 0 3 0 0 0 3 3 0 0 0 3 3 0 3 3 0 0 0 0 0 3\n",
      " 3 3 0 0 0 0 3 0 0 3 3 0 1 0 0 3 3 0 3 3 3 3 3 0 3 0 3 3 0 3 0 0 3 0 0 1 3\n",
      " 3 0 3 0 0 3 3 0 0 3 0 3 1 0 3 1 0 3 0 3 0 2 3 3 3 0 0 3 0 3 3 0 3 0 0 0 3\n",
      " 0 3 0 3 0 0 0 0 3 3 3 0 0 0 3 0 3 0 0 3 0 0 3 3 0 0 0 0 3 3 3 0 3 3 0 0 0\n",
      " 0 0 0 3 0 0 3 3 0 0 0 3 0 0 3 0 3 0 1 0 0 0 3 1 0 0 3 0 0 0 3 3 0 0 3 0 3\n",
      " 0 0 0 3 0 0 0 0 0 3 3 3 0 3 0 3 0 0 3 0 3 3 3 3 3 0 3 0 0 3 0 3 3 3 0 3 3\n",
      " 3 0 3 3 3 0 3 0 3 0 0 0 0 1 2 0 3 3 0 0 0 0 3 0 0 0 0 3 0 3 0 0 3 0 0 3 3\n",
      " 0 0 0 0 3 0 3 0 0 0 0 0 3 0 0 3 0 0 3 3 0 3 0 3 3 3 0 3 0 3 0 2 0 2 2 2 0\n",
      " 0 2 0 2 0 0 3 0 2 2 0 0 0 0 2 0 2 0 0 0 0 2 3 0 0 2 2 2 0 0 2 0 3 0 0 0 0\n",
      " 2 0 2 2 0 2 0 2 2 0 2 0 3 2 2 0 2 0 2 0 2 2 2 2 2 2 0 0 0 2 2 0 2 0 0 2 0\n",
      " 2 2 2 2 0 3 2 3 0 0 0 0 0 2 2 2 2 0 0 0 2 0 2 0 2 0 0 3 2 0 2 0 0 0 2 0 2\n",
      " 0 2 2 2 0 2 2 2 0 2 2 2 2 0 2 0 2 0 0 2 0 0 3 2 0 0 2 2 0 2 2 0 0 0 0 0 0\n",
      " 2 0 2 2 2 0 2 0 0 2 2 0 0 3 2 0 2 0 2 2 0 0 2 2 2 2 0 3 2 2 0 2 2 0 3 0 0\n",
      " 1 0 2 0 2 2 0 2 2 2 2 2 0 2 3 2 2 2 2 0 2 2 0 0 0 0 2 2 3 2 2 0 2 2 2 0 0\n",
      " 2 2 2 0 2 0 2 0 2 2 0 0 2 2 2 3 0 2 0 0 0 2 2 2 2 2 2 0 2 3 2 2 0 3 0 0 2\n",
      " 2 2 0 0 0 2 2 0 2 2 0 2 2 2 2 0 0 0 2 3 2 2 0 2 2 0 2 0 0 2 0 2 2 0 0 3 2\n",
      " 2 0 0 2 3 3 0 2 2 0 2 0 0 3 0 3 0 2 0 2 3 2 2 0 2 2 2 3 2 2 2 0 2 0 0 2 0\n",
      " 2 2 3 2 2 2 0 0 0 0 0 0 2 2 1 2 2 0 2 0 0 3 2 0 2 0 2 2 2 0 0 0 0 3 0 2 0\n",
      " 2 2 2 2 2 0 0 2 2 2 3 2 0 0 0 0 2 2 0 2 3 2 2 1 3 3 3 3 3 3 1 3 1 3 3 3 3\n",
      " 3 1 3 1 1 1 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 1 1 1 3 1 3 3 0 3 3 1 3 3 3 3 1\n",
      " 1 1 3 1 3 3 3 3 3 3 3 1 1 3 3 1 1 1 1 3 1 3 3 1 1 3 1 0 3 1 3 1 3 3 3 1 1\n",
      " 3 1 3 3 3 3 1 3 1 3 3 3 0 3 3 1 3 1 1 1 1 1 3 1 3 3 3 3 3 1 3 3 3 1 3 1 3\n",
      " 3 3 3 1 3 1 1 3 3 1 3 3 3 3 1 1 3 1 1 1 3 3 1 1 1 3 1 3 0 3 1 3 3 1 3 1 3\n",
      " 1 1 1 3 3 1 1 3 1 3 1 0 3 1 3 1 3 3 1 1 3 1 1 1 1 3 0 3 1 3 1 1 3 1 3 3 1\n",
      " 3 3 3 3 3 1 3 3 1 0 3 3 3 3 3 3 3 3 3 3 1 3 1 1 3 3 1 3 3 1 1 1 1 3 3 1 0\n",
      " 3 3 3 3 3 3 3 3 0 1 3 3 1 0 3 3 3 1 1 0 3 3 1 1 3 1 3 1 3 1 3 3 3 3 3 1 3\n",
      " 3 1 3 0 3 1 1 3 1 3 0 3 1 3 1 3 1 0 3 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 1 1 3\n",
      " 1 1 3 3 1 3 1 1 3 3 3 3 3 1 3 3 0 1 1 3 1 3 1 1 1 1 3 3 1 1 1 3 3 1 0 3 3\n",
      " 1 3 1 3 1 3 3 3 3 1 1 3 1 3 3 3 3 0 3 3 1 1 3 1 1 3 1 3 3 0 1 3 3 3 3 1 1\n",
      " 3 1 3 1 1 3 3 3 3 3 3 1 1 3 3 1 3 1 3 3 3 3 1 3 3 1 1 1 1 3 3 1 3 3 1 1 3\n",
      " 3 1 3 3 3 1 3 3 1 3 3 3 1 3 3 1 3 1 1 1 1 3 3 3 1 3 1 1 1 3 1 1 1 1 3 1 1\n",
      " 3 3 3 3 1 3 1 3 1 1 1 1 1 3 1 1 1 1 3 1 3 1 3 1 1 1 1 3 1 3 1 3 1 3 3 3 3\n",
      " 1 3 1 1 3 1 1 3 1 3 1 3 3 1 1 3 3 3 1 3 3 3 1 1 3 1 3 3 3 1 1 3 3 1 1 1 3\n",
      " 1 3 1 1 3 1 3 3 1 3 1 3 3 1 1 3 3 3 1 1 1 1 3 3 1 3 1 3 3 3 3 1 3 1 3 1 3\n",
      " 3 1 1 3 0 1 3 1 1 1 1 3 1 3 1 3 1 1 1 0 3 1 3 3 3 0 1 1 3 3 1 3 1 3 3 1 3\n",
      " 1 1 1 3 1 3 1 1 3 1 1 3 1 3 3 1 3 3 1 3 1 1 3 3 3 3 1 3 1 1 3 1 1 1 1 3 3\n",
      " 1 3 3 3 1 1 1 1 1 1 1 1 3 1 1 3 1 3 3 3 1 3 1 1 3 1 1 1 3 1 1 1 1 1 1 3 3\n",
      " 1 3 3 1 3 3 3 3 1 3 3 3 1 3 3 1 1 3 1 3 3 1 3 3 1 3 1 3 1 1 3 1 1 1 0 3 1\n",
      " 3 1 1 3 3 1 3 3 3 3 1 3 3 1 1 1 3 3 1 1 3 3 1 3 3 3 1 1 1 1 1 3 3 3 3 1 1\n",
      " 1 3 1 3 1 1 1 1 3 0 3 1 3 3 3 3 3 1 1 3 3 1 1 3 0 3 1 1 1 3 1 1 1 3 1 1 3\n",
      " 3 3 1 1 1 1 3 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.4896\r\n",
      "Purity: 0.5974999999999999+-0.05053154955075095\r\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K4_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  51%|▌| 41/80 [00:01<00:01, 21.96it/s, loss=0.874, val_loss=0.0881, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  75%|▊| 60/80 [00:01<00:00, 30.40it/s, loss=0.874, val_loss=0.0881, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.66it/s, loss=0.874, val_loss=1.26, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.0546, val_loss=1.26, avg_\u001b[A\n",
      "Epoch 1:  71%|▋| 57/80 [00:01<00:00, 29.01it/s, loss=0.0546, val_loss=1.26, avg_\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.80it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.50it/s, loss=0.0546, val_loss=0.0457, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.0308, val_loss=0.0457, av\u001b[A\n",
      "Epoch 2:  71%|▋| 57/80 [00:01<00:00, 29.34it/s, loss=0.0308, val_loss=0.0457, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.61it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.89it/s, loss=0.0308, val_loss=0.0296, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.0239, val_loss=0.0296, av\u001b[A\n",
      "Epoch 3:  71%|▋| 57/80 [00:01<00:00, 29.29it/s, loss=0.0239, val_loss=0.0296, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.50it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 37.80it/s, loss=0.0239, val_loss=0.0238, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.0193, val_loss=0.0238, av\u001b[A\n",
      "Epoch 4:  71%|▋| 57/80 [00:01<00:00, 29.43it/s, loss=0.0193, val_loss=0.0238, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 173.87it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.0193, val_loss=0.0197, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.0158, val_loss=0.0197, av\u001b[A\n",
      "Epoch 5:  71%|▋| 57/80 [00:01<00:00, 29.50it/s, loss=0.0158, val_loss=0.0197, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.90it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.0158, val_loss=0.0163, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.28it/s, loss=0.0128, val_loss=0.0163, av\u001b[A\n",
      "Epoch 6:  71%|▋| 57/80 [00:01<00:00, 28.95it/s, loss=0.0128, val_loss=0.0163, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.09it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 37.40it/s, loss=0.0128, val_loss=0.0134, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.62it/s, loss=0.0104, val_loss=0.0134, av\u001b[A\n",
      "Epoch 7:  71%|▋| 57/80 [00:01<00:00, 29.40it/s, loss=0.0104, val_loss=0.0134, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.65it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.0104, val_loss=0.0109, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00845, val_loss=0.0109, a\u001b[A\n",
      "Epoch 8:  71%|▋| 57/80 [00:01<00:00, 29.23it/s, loss=0.00845, val_loss=0.0109, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.72it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00845, val_loss=0.00884, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00685, val_loss=0.00884, \u001b[A\n",
      "Epoch 9:  71%|▋| 57/80 [00:01<00:00, 29.64it/s, loss=0.00685, val_loss=0.00884, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.34it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00685, val_loss=0.00721, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00557, val_loss=0.00721,\u001b[A\n",
      "Epoch 10:  71%|▋| 57/80 [00:01<00:00, 29.45it/s, loss=0.00557, val_loss=0.00721,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.83it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.00557, val_loss=0.00592,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.32it/s, loss=0.00457, val_loss=0.00592,\u001b[A\n",
      "Epoch 11:  71%|▋| 57/80 [00:01<00:00, 29.02it/s, loss=0.00457, val_loss=0.00592,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.56it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 37.50it/s, loss=0.00457, val_loss=0.00492,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.48it/s, loss=0.00381, val_loss=0.00492,\u001b[A\n",
      "Epoch 12:  71%|▋| 57/80 [00:01<00:00, 29.18it/s, loss=0.00381, val_loss=0.00492,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.40it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00381, val_loss=0.00417,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00323, val_loss=0.00417,\u001b[A\n",
      "Epoch 13:  71%|▋| 57/80 [00:01<00:00, 29.29it/s, loss=0.00323, val_loss=0.00417,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.79it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.81it/s, loss=0.00323, val_loss=0.00359,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.0028, val_loss=0.00359, \u001b[A\n",
      "Epoch 14:  71%|▋| 57/80 [00:01<00:00, 29.40it/s, loss=0.0028, val_loss=0.00359, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.38it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.0028, val_loss=0.00315, \u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00247, val_loss=0.00315,\u001b[A\n",
      "Epoch 15:  71%|▋| 57/80 [00:01<00:00, 29.59it/s, loss=0.00247, val_loss=0.00315,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.66it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00247, val_loss=0.00285,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.00223, val_loss=0.00285,\u001b[A\n",
      "Epoch 16:  71%|▋| 57/80 [00:01<00:00, 29.08it/s, loss=0.00223, val_loss=0.00285,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.89it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.58it/s, loss=0.00223, val_loss=0.00262,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.47it/s, loss=0.00205, val_loss=0.00262,\u001b[A\n",
      "Epoch 17:  71%|▋| 57/80 [00:01<00:00, 29.19it/s, loss=0.00205, val_loss=0.00262,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.97it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 37.67it/s, loss=0.00205, val_loss=0.00246,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.60it/s, loss=0.00191, val_loss=0.00246,\u001b[A\n",
      "Epoch 18:  71%|▋| 57/80 [00:01<00:00, 29.37it/s, loss=0.00191, val_loss=0.00246,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.79it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 37.90it/s, loss=0.00191, val_loss=0.00232,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.47it/s, loss=0.00181, val_loss=0.00232,\u001b[A\n",
      "Epoch 19:  71%|▋| 57/80 [00:01<00:00, 29.21it/s, loss=0.00181, val_loss=0.00232,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.52it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00181, val_loss=0.00222,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00172, val_loss=0.00222,\u001b[A\n",
      "Epoch 20:  71%|▋| 57/80 [00:01<00:00, 29.23it/s, loss=0.00172, val_loss=0.00222,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.50it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 37.79it/s, loss=0.00172, val_loss=0.00215,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00166, val_loss=0.00215,\u001b[A\n",
      "Epoch 21:  71%|▋| 57/80 [00:01<00:00, 29.29it/s, loss=0.00166, val_loss=0.00215,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.30it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.83it/s, loss=0.00166, val_loss=0.0021, \u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.44it/s, loss=0.00161, val_loss=0.0021, \u001b[A\n",
      "Epoch 22:  71%|▋| 57/80 [00:01<00:00, 29.18it/s, loss=0.00161, val_loss=0.0021, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.31it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.67it/s, loss=0.00161, val_loss=0.00205,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.62it/s, loss=0.00156, val_loss=0.00205,\u001b[A\n",
      "Epoch 23:  71%|▋| 57/80 [00:01<00:00, 29.40it/s, loss=0.00156, val_loss=0.00205,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.54it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.00156, val_loss=0.00201,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00153, val_loss=0.00201,\u001b[A\n",
      "Epoch 24:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.00153, val_loss=0.00201,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.27it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00153, val_loss=0.00195,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.0015, val_loss=0.00195, \u001b[A\n",
      "Epoch 25:  71%|▋| 57/80 [00:01<00:00, 29.96it/s, loss=0.0015, val_loss=0.00195, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.10it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.60it/s, loss=0.0015, val_loss=0.00192, \u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.52it/s, loss=0.00148, val_loss=0.00192,\u001b[A\n",
      "Epoch 26:  71%|▋| 57/80 [00:01<00:00, 29.26it/s, loss=0.00148, val_loss=0.00192,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.57it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 37.79it/s, loss=0.00148, val_loss=0.00189,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.00146, val_loss=0.00189,\u001b[A\n",
      "Epoch 27:  71%|▋| 57/80 [00:01<00:00, 29.36it/s, loss=0.00146, val_loss=0.00189,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.65it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 37.88it/s, loss=0.00146, val_loss=0.00188,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00144, val_loss=0.00188,\u001b[A\n",
      "Epoch 28:  71%|▋| 57/80 [00:01<00:00, 29.75it/s, loss=0.00144, val_loss=0.00188,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.63it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00144, val_loss=0.00186,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00142, val_loss=0.00186,\u001b[A\n",
      "Epoch 29:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00142, val_loss=0.00186,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.97it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00142, val_loss=0.00186,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00141, val_loss=0.00186,\u001b[A\n",
      "Epoch 30:  71%|▋| 57/80 [00:01<00:00, 29.49it/s, loss=0.00141, val_loss=0.00186,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.89it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00141, val_loss=0.00186,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00139, val_loss=0.00186,\u001b[A\n",
      "Epoch 31:  71%|▋| 57/80 [00:01<00:00, 29.21it/s, loss=0.00139, val_loss=0.00186,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.20it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 37.71it/s, loss=0.00139, val_loss=0.00186,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00139, val_loss=0.00186,\u001b[A\n",
      "Epoch 32:  71%|▋| 57/80 [00:01<00:00, 29.48it/s, loss=0.00139, val_loss=0.00186,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.25it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.00139, val_loss=0.00185,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.00138, val_loss=0.00185,\u001b[A\n",
      "Epoch 33:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.00138, val_loss=0.00185,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.15it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00138, val_loss=0.00185,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.46it/s, loss=0.00137, val_loss=0.00185,\u001b[A\n",
      "Epoch 34:  71%|▋| 57/80 [00:01<00:00, 29.21it/s, loss=0.00137, val_loss=0.00185,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.03it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00137, val_loss=0.00188,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00136, val_loss=0.00188,\u001b[A\n",
      "Epoch 35:  71%|▋| 57/80 [00:01<00:00, 29.48it/s, loss=0.00136, val_loss=0.00188,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.41it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.00136, val_loss=0.0019, \u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.00135, val_loss=0.0019, \u001b[A\n",
      "Epoch 36:  71%|▋| 57/80 [00:01<00:00, 29.09it/s, loss=0.00135, val_loss=0.0019, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.48it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 37.57it/s, loss=0.00135, val_loss=0.00185,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00134, val_loss=0.00185,\u001b[A\n",
      "Epoch 37:  71%|▋| 57/80 [00:01<00:00, 29.42it/s, loss=0.00134, val_loss=0.00185,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.13it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.00134, val_loss=0.00185,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00134, val_loss=0.00185,\u001b[A\n",
      "Epoch 38:  71%|▋| 57/80 [00:01<00:00, 29.37it/s, loss=0.00134, val_loss=0.00185,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.56it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.90it/s, loss=0.00134, val_loss=0.00184,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.00134, val_loss=0.00184,\u001b[A\n",
      "Epoch 39:  71%|▋| 57/80 [00:01<00:00, 29.12it/s, loss=0.00134, val_loss=0.00184,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.36it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.63it/s, loss=0.00134, val_loss=0.00182,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:02<00:02, 19.80it/s, loss=0.00133, val_loss=0.00182,\u001b[A\n",
      "Epoch 40:  71%|▋| 57/80 [00:02<00:00, 27.03it/s, loss=0.00133, val_loss=0.00182,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.88it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 35.11it/s, loss=0.00133, val_loss=0.00185,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.00132, val_loss=0.00185,\u001b[A\n",
      "Epoch 41:  71%|▋| 57/80 [00:01<00:00, 29.02it/s, loss=0.00132, val_loss=0.00185,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.37it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 37.49it/s, loss=0.00132, val_loss=0.00188,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.00132, val_loss=0.00188,\u001b[A\n",
      "Epoch 42:  71%|▋| 57/80 [00:01<00:00, 29.17it/s, loss=0.00132, val_loss=0.00188,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.02it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 37.69it/s, loss=0.00132, val_loss=0.00191,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 21.34it/s, loss=0.00131, val_loss=0.00191,\u001b[A\n",
      "Epoch 43:  71%|▋| 57/80 [00:01<00:00, 29.02it/s, loss=0.00131, val_loss=0.00191,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.94it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 37.50it/s, loss=0.00131, val_loss=0.00186,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.0013, val_loss=0.00186, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  71%|▋| 57/80 [00:01<00:00, 29.43it/s, loss=0.0013, val_loss=0.00186, \n",
      "Epoch 44:  95%|▉| 76/80 [00:02<00:00, 36.95it/s, loss=0.0013, val_loss=0.00186, \u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.0013, val_loss=0.00181, \u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.0013, val_loss=0.00181, \u001b[A\n",
      "Epoch 45:  71%|▋| 57/80 [00:01<00:00, 29.32it/s, loss=0.0013, val_loss=0.00181, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.33it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 37.85it/s, loss=0.0013, val_loss=0.00181, \u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 21.32it/s, loss=0.0013, val_loss=0.00181, \u001b[A\n",
      "Epoch 46:  71%|▋| 57/80 [00:01<00:00, 29.01it/s, loss=0.0013, val_loss=0.00181, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.73it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 37.48it/s, loss=0.0013, val_loss=0.00183, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.0013, val_loss=0.00183, \u001b[A\n",
      "Epoch 47:  71%|▋| 57/80 [00:01<00:00, 29.27it/s, loss=0.0013, val_loss=0.00183, \n",
      "Epoch 47:  95%|▉| 76/80 [00:02<00:00, 36.78it/s, loss=0.0013, val_loss=0.00183, \u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 37.80it/s, loss=0.0013, val_loss=0.00186, \u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.00129, val_loss=0.00186,\u001b[A\n",
      "Epoch 48:  71%|▋| 57/80 [00:01<00:00, 29.18it/s, loss=0.00129, val_loss=0.00186,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.71it/s]\u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 37.69it/s, loss=0.00129, val_loss=0.00186,\u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00129, val_loss=0.00186,\u001b[A\n",
      "Epoch 49:  71%|▋| 57/80 [00:01<00:00, 29.29it/s, loss=0.00129, val_loss=0.00186,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.46it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 37.81it/s, loss=0.00129, val_loss=0.00179,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00128, val_loss=0.00179,\u001b[A\n",
      "Epoch 50:  71%|▋| 57/80 [00:01<00:00, 29.57it/s, loss=0.00128, val_loss=0.00179,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.71it/s]\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00128, val_loss=0.00177,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00128, val_loss=0.00177,\u001b[A\n",
      "Epoch 51:  71%|▋| 57/80 [00:01<00:00, 29.51it/s, loss=0.00128, val_loss=0.00177,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.88it/s]\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00128, val_loss=0.00179,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00128, val_loss=0.00179,\u001b[A\n",
      "Epoch 52:  71%|▋| 57/80 [00:01<00:00, 29.57it/s, loss=0.00128, val_loss=0.00179,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.51it/s]\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00128, val_loss=0.00182,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00128, val_loss=0.00182,\u001b[A\n",
      "Epoch 53:  71%|▋| 57/80 [00:01<00:00, 29.63it/s, loss=0.00128, val_loss=0.00182,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.40it/s]\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00128, val_loss=0.00182,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 21.47it/s, loss=0.00127, val_loss=0.00182,\u001b[A\n",
      "Epoch 54:  71%|▋| 57/80 [00:01<00:00, 29.19it/s, loss=0.00127, val_loss=0.00182,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.40it/s]\u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00127, val_loss=0.00176,\u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 21.62it/s, loss=0.00127, val_loss=0.00176,\u001b[A\n",
      "Epoch 55:  71%|▋| 57/80 [00:01<00:00, 29.39it/s, loss=0.00127, val_loss=0.00176,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.11it/s]\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.00127, val_loss=0.00173,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.0512, val_loss=0.00173, \u001b[A\n",
      "Epoch 56:  71%|▋| 57/80 [00:01<00:00, 29.17it/s, loss=0.0512, val_loss=0.00173, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.86it/s]\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 37.67it/s, loss=0.0512, val_loss=0.0291, a\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.0019, val_loss=0.0291, a\u001b[A\n",
      "Epoch 57:  71%|▋| 57/80 [00:01<00:00, 29.31it/s, loss=0.0019, val_loss=0.0291, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.79it/s]\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 37.82it/s, loss=0.0019, val_loss=0.00191, \u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 21.59it/s, loss=0.00126, val_loss=0.00191,\u001b[A\n",
      "Epoch 58:  71%|▋| 57/80 [00:01<00:00, 29.36it/s, loss=0.00126, val_loss=0.00191,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.06it/s]\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 37.90it/s, loss=0.00126, val_loss=0.00178,\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00125, val_loss=0.00178,\u001b[A\n",
      "Epoch 59:  71%|▋| 57/80 [00:01<00:00, 29.83it/s, loss=0.00125, val_loss=0.00178,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.68it/s]\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00125, val_loss=0.00179,\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00125, val_loss=0.00179,\u001b[A\n",
      "Epoch 60:  71%|▋| 57/80 [00:01<00:00, 29.43it/s, loss=0.00125, val_loss=0.00179,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.10it/s]\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.00125, val_loss=0.0018, \u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 21.56it/s, loss=0.00125, val_loss=0.0018, \u001b[A\n",
      "Epoch 61:  71%|▋| 57/80 [00:01<00:00, 29.31it/s, loss=0.00125, val_loss=0.0018, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.16it/s]\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 37.85it/s, loss=0.00125, val_loss=0.00178,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.0365, val_loss=0.00178, \u001b[A\n",
      "Epoch 62:  71%|▋| 57/80 [00:01<00:00, 29.79it/s, loss=0.0365, val_loss=0.00178, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.70it/s]\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.0365, val_loss=0.304, av\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.00664, val_loss=0.304, a\u001b[A\n",
      "Epoch 63:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.00664, val_loss=0.304, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.73it/s]\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.00664, val_loss=0.00286,\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00132, val_loss=0.00286,\u001b[A\n",
      "Epoch 64:  71%|▋| 57/80 [00:01<00:00, 29.47it/s, loss=0.00132, val_loss=0.00286,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.39it/s]\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 38.02it/s, loss=0.00132, val_loss=0.00178,\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00123, val_loss=0.00178,\u001b[A\n",
      "Epoch 65:  71%|▋| 57/80 [00:01<00:00, 29.51it/s, loss=0.00123, val_loss=0.00178,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.38it/s]\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00123, val_loss=0.00169,\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.00123, val_loss=0.00169,\u001b[A\n",
      "Epoch 66:  71%|▋| 57/80 [00:01<00:00, 29.12it/s, loss=0.00123, val_loss=0.00169,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.87it/s]\u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 37.62it/s, loss=0.00123, val_loss=0.00168,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 21.50it/s, loss=0.00123, val_loss=0.00168,\u001b[A\n",
      "Epoch 67:  71%|▋| 57/80 [00:01<00:00, 29.25it/s, loss=0.00123, val_loss=0.00168,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.36it/s]\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 37.76it/s, loss=0.00123, val_loss=0.00169,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 21.29it/s, loss=0.122, val_loss=0.00169, a\u001b[A\n",
      "Epoch 68:  71%|▋| 57/80 [00:01<00:00, 28.96it/s, loss=0.122, val_loss=0.00169, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.53it/s]\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 37.43it/s, loss=0.122, val_loss=0.0221, av\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00383, val_loss=0.0221, \u001b[A\n",
      "Epoch 69:  71%|▋| 57/80 [00:01<00:00, 29.29it/s, loss=0.00383, val_loss=0.0221, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.74it/s]\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 37.79it/s, loss=0.00383, val_loss=0.00333,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00126, val_loss=0.00333,\u001b[A\n",
      "Epoch 70:  71%|▋| 57/80 [00:01<00:00, 29.47it/s, loss=0.00126, val_loss=0.00333,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.89it/s]\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00126, val_loss=0.00171,\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 21.56it/s, loss=0.00122, val_loss=0.00171,\u001b[A\n",
      "Epoch 71:  71%|▋| 57/80 [00:01<00:00, 29.34it/s, loss=0.00122, val_loss=0.00171,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.73it/s]\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 37.86it/s, loss=0.00122, val_loss=0.00174,\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00121, val_loss=0.00174,\u001b[A\n",
      "Epoch 72:  71%|▋| 57/80 [00:01<00:00, 29.48it/s, loss=0.00121, val_loss=0.00174,\n",
      "Epoch 72:  95%|▉| 76/80 [00:02<00:00, 37.03it/s, loss=0.00121, val_loss=0.00174,\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00121, val_loss=0.00175,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.0702, val_loss=0.00175, \u001b[A\n",
      "Epoch 73:  71%|▋| 57/80 [00:02<00:00, 28.45it/s, loss=0.0702, val_loss=0.00175, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 172.02it/s]\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 36.76it/s, loss=0.0702, val_loss=0.0411, a\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.19it/s, loss=0.00231, val_loss=0.0411, \u001b[A\n",
      "Epoch 74:  71%|▋| 57/80 [00:02<00:00, 27.53it/s, loss=0.00231, val_loss=0.0411, \n",
      "Epoch 74:  95%|▉| 76/80 [00:02<00:00, 34.72it/s, loss=0.00231, val_loss=0.0411, \u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 35.74it/s, loss=0.00231, val_loss=0.00235,\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.00122, val_loss=0.00235,\u001b[A\n",
      "Epoch 75:  71%|▋| 57/80 [00:02<00:00, 28.48it/s, loss=0.00122, val_loss=0.00235,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 162.89it/s]\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 36.85it/s, loss=0.00122, val_loss=0.00175,\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.0012, val_loss=0.00175, \u001b[A\n",
      "Epoch 76:  71%|▋| 57/80 [00:02<00:00, 27.73it/s, loss=0.0012, val_loss=0.00175, \n",
      "Epoch 76:  95%|▉| 76/80 [00:02<00:00, 35.02it/s, loss=0.0012, val_loss=0.00175, \u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.05it/s, loss=0.0012, val_loss=0.00179, \u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:02<00:02, 19.35it/s, loss=0.00121, val_loss=0.00179,\u001b[A\n",
      "Epoch 77:  71%|▋| 57/80 [00:02<00:00, 26.39it/s, loss=0.00121, val_loss=0.00179,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.58it/s]\u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 34.34it/s, loss=0.00121, val_loss=0.00185,\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.30it/s, loss=0.0598, val_loss=0.00185, \u001b[A\n",
      "Epoch 78:  71%|▋| 57/80 [00:02<00:00, 27.69it/s, loss=0.0598, val_loss=0.00185, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.46it/s]\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 35.92it/s, loss=0.0598, val_loss=0.0231, a\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 20.81it/s, loss=0.0018, val_loss=0.0231, a\u001b[A\n",
      "Epoch 79:  71%|▋| 57/80 [00:02<00:00, 28.31it/s, loss=0.0018, val_loss=0.0231, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 163.95it/s]\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 36.61it/s, loss=0.0018, val_loss=0.00207, \u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 20.19it/s, loss=0.0012, val_loss=0.00207, \u001b[A\n",
      "Epoch 80:  71%|▋| 57/80 [00:02<00:00, 27.47it/s, loss=0.0012, val_loss=0.00207, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 173.07it/s]\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 35.62it/s, loss=0.0012, val_loss=0.00183, \u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 20.46it/s, loss=0.0012, val_loss=0.00183, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  71%|▋| 57/80 [00:02<00:00, 27.69it/s, loss=0.0012, val_loss=0.00183, \u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 35.80it/s, loss=0.0012, val_loss=0.00189, \u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.0861, val_loss=0.00189, \u001b[A\n",
      "Epoch 82:  71%|▋| 57/80 [00:02<00:00, 27.98it/s, loss=0.0861, val_loss=0.00189, \n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.42it/s]\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.30it/s, loss=0.0861, val_loss=0.0588, a\u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.00471, val_loss=0.0588, \u001b[A\n",
      "Epoch 83:  71%|▋| 57/80 [00:02<00:00, 27.42it/s, loss=0.00471, val_loss=0.0588, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.76it/s]\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 35.59it/s, loss=0.00471, val_loss=0.00303,\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.29it/s, loss=0.00124, val_loss=0.00303,\u001b[A\n",
      "Epoch 84:  71%|▋| 57/80 [00:02<00:00, 27.61it/s, loss=0.00124, val_loss=0.00303,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.62it/s]\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 35.89it/s, loss=0.00124, val_loss=0.00201,\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00118, val_loss=0.00201,\u001b[A\n",
      "Epoch 85:  71%|▋| 57/80 [00:02<00:00, 27.61it/s, loss=0.00118, val_loss=0.00201,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 165.91it/s]\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 35.61it/s, loss=0.00118, val_loss=0.00209,\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.0457, val_loss=0.00209, \u001b[A\n",
      "Epoch 86:  71%|▋| 57/80 [00:02<00:00, 27.86it/s, loss=0.0457, val_loss=0.00209, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.02it/s]\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 36.13it/s, loss=0.0457, val_loss=0.463, av\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.25it/s, loss=0.00949, val_loss=0.463, a\u001b[A\n",
      "Epoch 87:  71%|▋| 57/80 [00:02<00:00, 27.57it/s, loss=0.00949, val_loss=0.463, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.77it/s]\u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 35.85it/s, loss=0.00949, val_loss=0.00425,\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 20.26it/s, loss=0.00131, val_loss=0.00425,\u001b[A\n",
      "Epoch 88:  71%|▋| 57/80 [00:02<00:00, 27.55it/s, loss=0.00131, val_loss=0.00425,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.58it/s]\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 35.82it/s, loss=0.00131, val_loss=0.00214,\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00118, val_loss=0.00214,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  71%|▋| 57/80 [00:02<00:00, 27.57it/s, loss=0.00118, val_loss=0.00214,\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.00118, val_loss=0.00219,\u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.00118, val_loss=0.00219,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  71%|▋| 57/80 [00:02<00:00, 27.81it/s, loss=0.00118, val_loss=0.00219,\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 36.22it/s, loss=0.00118, val_loss=0.00224,\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 20.42it/s, loss=0.15, val_loss=0.00224, av\u001b[A\n",
      "Epoch 91:  71%|▋| 57/80 [00:02<00:00, 27.75it/s, loss=0.15, val_loss=0.00224, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.27it/s]\u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 36.03it/s, loss=0.15, val_loss=0.13, avg_v\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 20.05it/s, loss=0.00672, val_loss=0.13, av\u001b[A\n",
      "Epoch 92:  71%|▋| 57/80 [00:02<00:00, 27.29it/s, loss=0.00672, val_loss=0.13, av\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.28it/s]\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 35.31it/s, loss=0.00672, val_loss=0.00315,\u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00126, val_loss=0.00315,\u001b[A\n",
      "Epoch 93:  71%|▋| 57/80 [00:02<00:00, 28.33it/s, loss=0.00126, val_loss=0.00315,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 166.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 36.65it/s, loss=0.00126, val_loss=0.0022, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.00116, val_loss=0.0022, \u001b[A\n",
      "Epoch 94:  71%|▋| 57/80 [00:02<00:00, 28.07it/s, loss=0.00116, val_loss=0.0022, \n",
      "Epoch 94:  95%|▉| 76/80 [00:02<00:00, 35.37it/s, loss=0.00116, val_loss=0.0022, \u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 36.40it/s, loss=0.00116, val_loss=0.00234,\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00116, val_loss=0.00234,\u001b[A\n",
      "Epoch 95:  71%|▋| 57/80 [00:02<00:00, 28.22it/s, loss=0.00116, val_loss=0.00234,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 169.04it/s]\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00116, val_loss=0.00234,\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.12it/s, loss=0.00118, val_loss=0.00234,\u001b[A\n",
      "Epoch 96:  71%|▋| 57/80 [00:02<00:00, 27.31it/s, loss=0.00118, val_loss=0.00234,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 164.66it/s]\u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 35.55it/s, loss=0.00118, val_loss=0.00255,\u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.0507, val_loss=0.00255, \u001b[A\n",
      "Epoch 97:  71%|▋| 57/80 [00:02<00:00, 27.92it/s, loss=0.0507, val_loss=0.00255, \n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 165.52it/s]\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 36.26it/s, loss=0.0507, val_loss=0.0181, a\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.00179, val_loss=0.0181, \u001b[A\n",
      "Epoch 98:  71%|▋| 57/80 [00:02<00:00, 27.65it/s, loss=0.00179, val_loss=0.0181, \n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 164.86it/s]\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 35.88it/s, loss=0.00179, val_loss=0.00249,\u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:02<00:02, 19.94it/s, loss=0.00117, val_loss=0.00249,\u001b[A\n",
      "Epoch 99:  71%|▋| 57/80 [00:02<00:00, 27.15it/s, loss=0.00117, val_loss=0.00249,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.10it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 35.32it/s, loss=0.00117, val_loss=0.00232,\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 35.05it/s, loss=0.00117, val_loss=0.00232,\u001b[A\n",
      "Sizes of clusters: 116, 669, 315, 336, 564\n",
      "\n",
      "preds: [4 0 2 0 0 1 1 2 0 0 2 0 4 2 2 1 2 4 4 4 4 0 2 4 4 4 2 2 4 4 2 2 1 2 2 2 0\n",
      " 0 2 3 2 2 4 0 2 2 0 2 0 2 0 2 2 2 0 2 0 2 4 2 1 4 2 2 0 0 2 2 4 2 1 2 4 2\n",
      " 2 4 4 2 4 4 2 0 2 2 4 4 0 0 2 4 0 2 4 0 4 1 4 0 0 4 4 2 2 0 1 2 1 2 4 2 2\n",
      " 4 4 2 2 2 0 0 1 1 4 2 0 4 0 2 2 0 1 2 2 0 1 0 0 4 2 0 2 0 4 0 2 2 2 0 0 4\n",
      " 2 4 2 0 4 4 4 2 0 2 0 2 2 3 0 0 1 4 2 0 2 0 4 4 0 2 2 0 4 4 2 2 2 4 4 4 0\n",
      " 1 2 4 4 2 0 0 2 2 0 4 2 2 2 4 0 2 1 0 2 0 2 2 0 2 0 2 2 4 4 2 0 4 4 2 4 1\n",
      " 2 0 0 2 2 2 2 2 1 2 0 4 1 0 4 2 4 4 4 2 2 2 4 2 2 2 0 2 2 2 1 4 1 1 2 0 2\n",
      " 0 2 2 2 2 2 2 1 2 2 0 2 0 2 0 4 4 2 2 0 4 2 4 0 0 1 2 2 2 0 0 2 1 1 4 4 2\n",
      " 2 1 0 2 0 4 2 4 1 0 2 4 4 2 4 2 1 4 1 0 2 0 0 2 2 4 2 2 2 1 0 4 1 2 4 4 0\n",
      " 4 2 4 4 2 4 2 4 4 2 0 4 2 4 0 2 0 2 0 2 2 0 0 2 4 2 2 0 2 4 2 0 4 0 1 2 2\n",
      " 2 0 2 2 2 2 4 2 2 2 0 0 4 2 4 4 2 2 3 4 2 2 4 2 2 2 2 0 1 2 1 1 2 4 4 2 4\n",
      " 1 1 1 3 4 2 1 2 4 3 4 4 1 4 4 2 4 4 3 1 4 4 3 4 3 2 3 1 4 1 0 4 4 1 2 1 1\n",
      " 4 1 4 1 4 1 4 1 1 4 2 4 4 1 4 4 4 1 1 1 4 4 4 4 3 4 1 4 2 1 4 4 1 3 0 2 1\n",
      " 2 3 4 0 4 1 1 1 1 2 4 4 4 1 2 2 1 3 4 4 4 4 4 4 4 4 4 2 3 0 4 4 4 4 2 4 2\n",
      " 0 4 2 4 3 2 1 1 4 3 1 4 4 0 4 2 4 1 4 1 1 3 3 4 4 4 1 1 1 4 4 4 2 4 2 4 2\n",
      " 1 0 3 4 3 4 4 2 2 3 2 1 1 4 1 1 4 4 3 4 1 2 4 4 2 4 1 1 1 1 1 1 4 4 1 4 1\n",
      " 4 2 2 2 4 4 4 2 1 4 2 2 1 4 2 4 1 1 2 2 4 1 1 4 4 4 3 1 4 2 0 4 2 1 1 3 1\n",
      " 2 1 1 3 2 4 4 1 2 1 1 1 3 2 2 1 4 1 3 2 4 1 2 1 4 4 2 1 1 2 4 4 1 1 1 2 4\n",
      " 1 2 3 1 1 2 4 4 1 3 1 2 4 2 2 1 3 1 2 1 2 1 1 1 4 1 1 2 1 4 4 4 1 2 4 1 1\n",
      " 4 1 4 4 4 2 1 1 4 1 3 4 1 3 4 4 4 2 2 0 2 1 1 1 3 4 1 1 4 1 4 1 2 4 4 1 2\n",
      " 1 4 4 1 1 1 0 2 4 1 2 0 4 1 4 4 1 2 4 1 2 2 1 2 1 2 2 1 1 4 1 1 1 2 3 1 1\n",
      " 1 4 3 0 4 2 1 2 3 4 0 4 3 4 1 2 4 3 4 4 1 4 4 1 3 1 3 3 3 3 1 1 4 4 2 1 4\n",
      " 4 4 1 4 3 3 1 1 4 3 4 1 3 3 3 1 3 1 3 4 3 1 4 1 3 4 3 3 3 1 3 4 4 3 4 4 1\n",
      " 3 3 3 3 4 4 1 3 4 1 1 1 3 4 3 4 1 3 3 1 1 3 1 4 3 4 1 3 3 1 2 3 4 1 4 3 1\n",
      " 1 3 4 4 4 1 3 1 1 1 4 3 1 4 1 4 3 3 1 1 1 3 3 1 3 3 2 1 1 4 1 3 1 1 1 4 1\n",
      " 3 4 1 3 3 4 3 3 3 1 1 4 3 1 3 3 1 1 4 3 3 1 1 1 1 3 1 3 3 3 3 4 1 4 1 1 3\n",
      " 3 1 3 3 1 3 3 3 1 3 3 1 1 1 3 4 1 4 3 3 3 4 3 1 3 1 3 1 4 1 3 4 4 4 3 1 3\n",
      " 1 3 1 3 1 4 4 4 4 1 1 1 4 3 4 3 1 4 4 4 1 1 3 3 1 3 3 3 3 3 1 4 3 3 3 1 1\n",
      " 1 4 3 1 4 1 4 3 4 3 1 4 1 4 3 1 3 1 1 2 1 1 3 3 3 3 4 3 1 4 4 4 4 1 3 3 1\n",
      " 4 3 1 4 1 4 3 4 3 3 3 4 4 1 1 1 1 1 3 4 1 1 1 3 3 3 1 3 3 4 3 1 2 3 4 1 3\n",
      " 3 3 4 3 1 4 3 1 4 3 4 3 3 3 1 3 1 3 4 3 3 3 1 1 1 4 4 3 1 1 3 1 1 3 3 3 4\n",
      " 3 3 1 1 3 4 3 3 3 3 4 3 1 3 3 4 3 4 3 1 3 1 4 3 1 1 3 1 3 3 3 3 4 4 3 4 3\n",
      " 1 4 4 1 1 1 4 3 4 3 3 1 4 1 1 4 1 4 4 1 2 1 3 1 1 1 1 1 1 3 1 1 3 1 2 1 4\n",
      " 4 4 2 4 3 1 2 1 1 1 2 4 4 4 4 2 4 1 0 4 1 1 1 3 4 1 4 1 4 1 1 3 1 4 2 1 4\n",
      " 1 1 4 1 2 1 3 2 4 1 1 1 2 3 2 1 2 1 1 3 4 1 1 4 1 2 4 1 0 1 4 2 2 0 1 1 4\n",
      " 4 4 4 1 4 1 1 1 1 1 0 4 2 4 1 1 1 4 4 4 4 3 4 1 4 1 1 2 1 1 4 4 4 4 1 3 1\n",
      " 1 4 1 3 2 2 1 4 1 1 1 1 1 1 4 1 1 1 4 1 3 1 1 1 4 4 1 1 4 2 2 4 4 1 1 1 4\n",
      " 2 1 1 1 4 4 1 4 2 1 4 1 4 2 1 3 1 4 3 1 1 4 1 1 2 1 1 4 1 1 3 1 4 1 4 4 1\n",
      " 1 1 1 1 3 1 4 4 3 1 4 1 3 4 1 1 2 1 2 1 2 4 1 1 2 4 2 4 1 1 4 4 4 4 4 1 4\n",
      " 4 4 4 4 1 4 4 1 1 4 1 1 2 1 1 2 4 2 0 4 1 4 4 1 4 3 3 1 1 1 1 4 4 1 2 1 1\n",
      " 1 2 1 1 3 4 1 1 1 3 4 3 4 4 1 4 4 1 4 0 1 1 4 1 3 1 4 0 2 1 4 3 3 1 1 4 2\n",
      " 1 1 4 2 3 4 1 1 1 1 4 1 1 0 1 1 1 1 2 2 2 2 1 1 4 4 4 4 1 4 4 2 1 1 4 4 4\n",
      " 3 1 4 2 3 1 1 1 3 4 1 1 1 3 1 1 4 4 4 4 1 4 2 4 4 3 1 4 1 3 2 4 1 1 1 2 4\n",
      " 4 1 1 2 1 3 4 0 4 4 4 4 1 4 3 2 1 1 1 1 3 1 4 2 3 1 4 4 1 4 3 1 3 1 1 3 4\n",
      " 3 1 1 3 1 3 3 3 1 1 4 4 1 4 1 1 2 3 1 1 1 4 3 4 2 3 4 1 1 4 2 1 1 1 4 2 4\n",
      " 4 4 1 4 4 3 1 4 4 1 1 1 4 1 3 4 4 1 3 1 1 4 4 3 1 1 1 3 3 3 4 1 4 1 3 1 1\n",
      " 1 4 4 3 1 1 3 1 1 3 3 0 3 4 1 1 1 3 1 1 3 1 4 1 3 1 4 4 1 3 4 1 4 3 1 1 4\n",
      " 3 4 4 4 1 3 4 1 1 1 1 1 1 1 4 3 1 4 3 4 1 1 3 4 4 3 4 1 1 1 1 3 3 3 3 4 1\n",
      " 4 4 4 1 3 1 1 3 1 1 3 2 1 1 1 1 3 1 4 1 1 1 3 4 1 1 3 4 3 4 4 3 4 1 3 1 3\n",
      " 1 1 4 1 3 1 1 3 1 3 1 1 4 3 3 1 1 4 4 4 4 3 4 1 3 4 1 2 3 1 3 3 3 4 3 3 2\n",
      " 1 3 3 1 4 4 1 1 1 3 3 1 1 1 1 3 3 4 3 3 1 4 1 3 4 2 3 1 1 4 4 3 3 3 4 1 4\n",
      " 4 2 1 1 1 1 3 4 4 1 1 1 1 3 3 1 1 4 4 1 3 3 3 1 1 4 1 1 1 3 1 1 4 3 1 3 3\n",
      " 3 4 1 2 3 2 1 1 1 4 1 4 1 1 1 1 1 1 3 3 1 1 1 1 1 4 3 3 4 3 1 1 1 1 4 1 1\n",
      " 1 1 1 4 1 1 4 3 4 1 1 3 3 1 1 4 1 4 4 1 1 1 4 1 1 3 1 1 1 1 3 1 1 4 1 1 3\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3795\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.46it/s, loss=1.26, val_loss=0.08, avg_va\n",
      "Epoch 0:  65%|▋| 52/80 [00:02<00:01, 25.81it/s, loss=1.26, val_loss=0.08, avg_va\n",
      "Epoch 0:  85%|▊| 68/80 [00:02<00:00, 32.06it/s, loss=1.26, val_loss=0.08, avg_va\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 36.06it/s, loss=1.26, val_loss=3.64, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.60it/s, loss=0.0741, val_loss=3.64, avg_\u001b[A\n",
      "Epoch 1:  60%|▌| 48/80 [00:01<00:01, 24.32it/s, loss=0.0741, val_loss=3.64, avg_\n",
      "Epoch 1:  80%|▊| 64/80 [00:02<00:00, 30.74it/s, loss=0.0741, val_loss=3.64, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 36.40it/s, loss=0.0741, val_loss=0.119, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.35it/s, loss=0.0336, val_loss=0.119, avg\u001b[A\n",
      "Epoch 2:  60%|▌| 48/80 [00:02<00:01, 23.98it/s, loss=0.0336, val_loss=0.119, avg\n",
      "Epoch 2:  81%|▊| 65/80 [00:02<00:00, 30.89it/s, loss=0.0336, val_loss=0.119, avg\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 35.86it/s, loss=0.0336, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.0214, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:02<00:01, 24.86it/s, loss=0.0214, val_loss=0.0411, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:02<00:00, 31.66it/s, loss=0.0214, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 35.59it/s, loss=0.0214, val_loss=0.0299, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.39it/s, loss=0.0148, val_loss=0.0299, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:02<00:01, 25.26it/s, loss=0.0148, val_loss=0.0299, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:02<00:00, 31.99it/s, loss=0.0148, val_loss=0.0299, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 35.89it/s, loss=0.0148, val_loss=0.022, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.0109, val_loss=0.022, avg\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:02<00:01, 24.73it/s, loss=0.0109, val_loss=0.022, avg\n",
      "Epoch 5:  86%|▊| 69/80 [00:02<00:00, 31.86it/s, loss=0.0109, val_loss=0.022, avg\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 35.40it/s, loss=0.0109, val_loss=0.0155, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.0084, val_loss=0.0155, av\u001b[A\n",
      "Epoch 6:  68%|▋| 54/80 [00:02<00:00, 26.67it/s, loss=0.0084, val_loss=0.0155, av\n",
      "Validating:  40%|████████████                  | 16/40 [00:00<00:00, 152.12it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.0084, val_loss=0.0119, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:02<00:02, 19.47it/s, loss=0.00682, val_loss=0.0119, a\u001b[A\n",
      "Epoch 7:  68%|▋| 54/80 [00:02<00:01, 25.44it/s, loss=0.00682, val_loss=0.0119, a\n",
      "Epoch 7:  90%|▉| 72/80 [00:02<00:00, 32.16it/s, loss=0.00682, val_loss=0.0119, a\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 34.62it/s, loss=0.00682, val_loss=0.00983, \u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.00573, val_loss=0.00983, \u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:02<00:00, 26.35it/s, loss=0.00573, val_loss=0.00983, \n",
      "Validating:  38%|███████████▎                  | 15/40 [00:00<00:00, 149.51it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 35.74it/s, loss=0.00573, val_loss=0.00779, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.00492, val_loss=0.00779, \u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00492, val_loss=0.00779, \n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 33.61it/s, loss=0.00492, val_loss=0.00779, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.00492, val_loss=0.00637, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:02<00:02, 19.24it/s, loss=0.00434, val_loss=0.00637,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:02<00:01, 25.13it/s, loss=0.00434, val_loss=0.00637,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 31.75it/s, loss=0.00434, val_loss=0.00637,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 34.17it/s, loss=0.00434, val_loss=0.00587,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.11it/s, loss=0.00392, val_loss=0.00587,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:02<00:00, 26.25it/s, loss=0.00392, val_loss=0.00587,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 33.16it/s, loss=0.00392, val_loss=0.00587,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 35.62it/s, loss=0.00392, val_loss=0.00554,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00358, val_loss=0.00554,\u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:02<00:00, 26.04it/s, loss=0.00358, val_loss=0.00554,\n",
      "Validating:  35%|██████████▌                   | 14/40 [00:00<00:00, 136.26it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 35.19it/s, loss=0.00358, val_loss=0.0051, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:02<00:02, 19.86it/s, loss=0.00331, val_loss=0.0051, \u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:02<00:01, 25.77it/s, loss=0.00331, val_loss=0.0051, \n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 32.67it/s, loss=0.00331, val_loss=0.0051, \u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 35.17it/s, loss=0.00331, val_loss=0.00488,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 20.82it/s, loss=0.0031, val_loss=0.00488, \u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.0031, val_loss=0.00488, \n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 34.12it/s, loss=0.0031, val_loss=0.00488, \u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 36.65it/s, loss=0.0031, val_loss=0.00458, \u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:02<00:02, 19.81it/s, loss=0.00293, val_loss=0.00458,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:02<00:01, 25.75it/s, loss=0.00293, val_loss=0.00458,\n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 32.58it/s, loss=0.00293, val_loss=0.00458,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 35.13it/s, loss=0.00293, val_loss=0.00419,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:02<00:02, 19.63it/s, loss=0.00279, val_loss=0.00419,\u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:02<00:01, 25.63it/s, loss=0.00279, val_loss=0.00419,\n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 32.09it/s, loss=0.00279, val_loss=0.00419,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 34.67it/s, loss=0.00279, val_loss=0.00396,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:02<00:02, 19.38it/s, loss=0.00268, val_loss=0.00396,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:02<00:01, 25.12it/s, loss=0.00268, val_loss=0.00396,\n",
      "Validating:  38%|███████████▎                  | 15/40 [00:00<00:00, 142.55it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 33.66it/s, loss=0.00268, val_loss=0.00399,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 20.13it/s, loss=0.00256, val_loss=0.00399,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:02<00:00, 26.04it/s, loss=0.00256, val_loss=0.00399,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 32.86it/s, loss=0.00256, val_loss=0.00399,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 35.52it/s, loss=0.00256, val_loss=0.00365,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 20.31it/s, loss=0.00243, val_loss=0.00365,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:02<00:00, 26.50it/s, loss=0.00243, val_loss=0.00365,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 33.41it/s, loss=0.00243, val_loss=0.00365,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 35.94it/s, loss=0.00243, val_loss=0.00369,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.49it/s, loss=0.00232, val_loss=0.00369,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:02<00:00, 26.64it/s, loss=0.00232, val_loss=0.00369,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 33.57it/s, loss=0.00232, val_loss=0.00369,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 36.12it/s, loss=0.00232, val_loss=0.00334,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:02<00:02, 19.94it/s, loss=0.00223, val_loss=0.00334,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:02<00:01, 25.84it/s, loss=0.00223, val_loss=0.00334,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 32.67it/s, loss=0.00223, val_loss=0.00334,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 35.10it/s, loss=0.00223, val_loss=0.00335,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00216, val_loss=0.00335,\u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:02<00:00, 26.67it/s, loss=0.00216, val_loss=0.00335,\n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 33.59it/s, loss=0.00216, val_loss=0.00335,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 36.24it/s, loss=0.00216, val_loss=0.00318,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.0021, val_loss=0.00318, \u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:02<00:00, 26.91it/s, loss=0.0021, val_loss=0.00318, \n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.0021, val_loss=0.00318, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.45it/s, loss=0.0021, val_loss=0.00303, \u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.00203, val_loss=0.00303,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:02<00:00, 26.52it/s, loss=0.00203, val_loss=0.00303,\n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 33.50it/s, loss=0.00203, val_loss=0.00303,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 36.01it/s, loss=0.00203, val_loss=0.00305,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00197, val_loss=0.00305,\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:02<00:00, 26.62it/s, loss=0.00197, val_loss=0.00305,\n",
      "Validating:  35%|██████████▌                   | 14/40 [00:00<00:00, 133.04it/s]\u001b[A\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 33.40it/s, loss=0.00197, val_loss=0.00305,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 35.35it/s, loss=0.00197, val_loss=0.00305,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:02<00:02, 19.75it/s, loss=0.00191, val_loss=0.00305,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:02<00:01, 25.77it/s, loss=0.00191, val_loss=0.00305,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 32.61it/s, loss=0.00191, val_loss=0.00305,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 35.05it/s, loss=0.00191, val_loss=0.00289,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00186, val_loss=0.00289,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:02<00:00, 26.48it/s, loss=0.00186, val_loss=0.00289,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 33.52it/s, loss=0.00186, val_loss=0.00289,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.00186, val_loss=0.00293,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.19it/s, loss=0.00182, val_loss=0.00293,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:02<00:00, 26.23it/s, loss=0.00182, val_loss=0.00293,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 33.05it/s, loss=0.00182, val_loss=0.00293,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.00182, val_loss=0.00285,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00177, val_loss=0.00285,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:02<00:00, 26.30it/s, loss=0.00177, val_loss=0.00285,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 33.22it/s, loss=0.00177, val_loss=0.00285,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 35.77it/s, loss=0.00177, val_loss=0.00287,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:02<00:02, 19.66it/s, loss=0.00172, val_loss=0.00287,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:02<00:01, 25.55it/s, loss=0.00172, val_loss=0.00287,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 32.33it/s, loss=0.00172, val_loss=0.00287,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 34.85it/s, loss=0.00172, val_loss=0.00273,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.0017, val_loss=0.00273, \u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:02<00:00, 26.51it/s, loss=0.0017, val_loss=0.00273, \n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 33.47it/s, loss=0.0017, val_loss=0.00273, \u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 36.03it/s, loss=0.0017, val_loss=0.00274, \u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00168, val_loss=0.00274,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:02<00:00, 26.97it/s, loss=0.00168, val_loss=0.00274,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 34.09it/s, loss=0.00168, val_loss=0.00274,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 36.59it/s, loss=0.00168, val_loss=0.00268,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 20.28it/s, loss=0.00167, val_loss=0.00268,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:02<00:00, 26.38it/s, loss=0.00167, val_loss=0.00268,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 33.29it/s, loss=0.00167, val_loss=0.00268,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 35.79it/s, loss=0.00167, val_loss=0.00261,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00165, val_loss=0.00261,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00165, val_loss=0.00261,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 33.64it/s, loss=0.00165, val_loss=0.00261,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.11it/s, loss=0.00165, val_loss=0.00262,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00163, val_loss=0.00262,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 27.00it/s, loss=0.00163, val_loss=0.00262,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 33.90it/s, loss=0.00163, val_loss=0.00262,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00163, val_loss=0.00261,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:02<00:02, 19.92it/s, loss=0.0016, val_loss=0.00261, \u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:02<00:01, 25.98it/s, loss=0.0016, val_loss=0.00261, \n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 32.76it/s, loss=0.0016, val_loss=0.00261, \u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 35.29it/s, loss=0.0016, val_loss=0.00257, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00157, val_loss=0.00257,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 27.13it/s, loss=0.00157, val_loss=0.00257,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 34.29it/s, loss=0.00157, val_loss=0.00257,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 36.80it/s, loss=0.00157, val_loss=0.00243,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 20.53it/s, loss=0.00155, val_loss=0.00243,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:02<00:00, 26.69it/s, loss=0.00155, val_loss=0.00243,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 33.60it/s, loss=0.00155, val_loss=0.00243,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 35.84it/s, loss=0.00155, val_loss=0.00245,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 20.57it/s, loss=0.00153, val_loss=0.00245,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:02<00:00, 26.70it/s, loss=0.00153, val_loss=0.00245,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 33.76it/s, loss=0.00153, val_loss=0.00245,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 36.34it/s, loss=0.00153, val_loss=0.00254,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.00153, val_loss=0.00254,\u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:01<00:00, 27.09it/s, loss=0.00153, val_loss=0.00254,\n",
      "Epoch 40:  90%|▉| 72/80 [00:02<00:00, 34.17it/s, loss=0.00153, val_loss=0.00254,\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 36.67it/s, loss=0.00153, val_loss=0.00252,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:02<00:02, 19.89it/s, loss=0.00154, val_loss=0.00252,\u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:02<00:01, 25.92it/s, loss=0.00154, val_loss=0.00252,\n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 32.75it/s, loss=0.00154, val_loss=0.00252,\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 35.17it/s, loss=0.00154, val_loss=0.00255,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 20.04it/s, loss=0.00157, val_loss=0.00255,\u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:02<00:00, 26.04it/s, loss=0.00157, val_loss=0.00255,\n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 32.88it/s, loss=0.00157, val_loss=0.00255,\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 35.33it/s, loss=0.00157, val_loss=0.0024, \u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 20.29it/s, loss=0.00156, val_loss=0.0024, \u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:02<00:00, 26.29it/s, loss=0.00156, val_loss=0.0024, \n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 33.31it/s, loss=0.00156, val_loss=0.0024, \u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 35.88it/s, loss=0.00156, val_loss=0.00237,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.32it/s, loss=0.00156, val_loss=0.00237,\u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:02<00:00, 26.19it/s, loss=0.00156, val_loss=0.00237,\n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 33.27it/s, loss=0.00156, val_loss=0.00237,\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 35.72it/s, loss=0.00156, val_loss=0.00253,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00158, val_loss=0.00253,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00158, val_loss=0.00253,\n",
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.00158, val_loss=0.00253,\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 36.68it/s, loss=0.00158, val_loss=0.00252,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:02<00:02, 19.87it/s, loss=0.00157, val_loss=0.00252,\u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:02<00:01, 25.89it/s, loss=0.00157, val_loss=0.00252,\n",
      "Epoch 46:  90%|▉| 72/80 [00:02<00:00, 32.73it/s, loss=0.00157, val_loss=0.00252,\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 35.22it/s, loss=0.00157, val_loss=0.00264,\u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 20.55it/s, loss=0.00152, val_loss=0.00264,\u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:02<00:00, 26.77it/s, loss=0.00152, val_loss=0.00264,\n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 33.80it/s, loss=0.00152, val_loss=0.00264,\u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 36.29it/s, loss=0.00152, val_loss=0.00263,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:02<00:02, 19.95it/s, loss=0.0015, val_loss=0.00263, \u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:02<00:01, 25.88it/s, loss=0.0015, val_loss=0.00263, \n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 32.87it/s, loss=0.0015, val_loss=0.00263, \u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 35.36it/s, loss=0.0015, val_loss=0.00271, \u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00154, val_loss=0.00271,\u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.00154, val_loss=0.00271,\n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 33.83it/s, loss=0.00154, val_loss=0.00271,\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00154, val_loss=0.00255,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 20.31it/s, loss=0.00156, val_loss=0.00255,\u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:02<00:00, 26.33it/s, loss=0.00156, val_loss=0.00255,\n",
      "Epoch 50:  90%|▉| 72/80 [00:02<00:00, 33.33it/s, loss=0.00156, val_loss=0.00255,\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 35.79it/s, loss=0.00156, val_loss=0.0026, \u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 20.44it/s, loss=0.00164, val_loss=0.0026, \u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:02<00:00, 26.61it/s, loss=0.00164, val_loss=0.0026, \n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 33.67it/s, loss=0.00164, val_loss=0.0026, \u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.00164, val_loss=0.00258,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.0123, val_loss=0.00258, \u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:02<00:00, 26.41it/s, loss=0.0123, val_loss=0.00258, \n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 33.36it/s, loss=0.0123, val_loss=0.00258, \u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 35.83it/s, loss=0.0123, val_loss=0.0504, a\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00239, val_loss=0.0504, \u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:02<00:00, 26.85it/s, loss=0.00239, val_loss=0.0504, \n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 33.74it/s, loss=0.00239, val_loss=0.0504, \u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00239, val_loss=0.00288,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:02<00:02, 19.39it/s, loss=0.00157, val_loss=0.00288,\u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:02<00:01, 25.23it/s, loss=0.00157, val_loss=0.00288,\n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 31.86it/s, loss=0.00157, val_loss=0.00288,\u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 34.36it/s, loss=0.00157, val_loss=0.00252,\u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 20.20it/s, loss=0.00172, val_loss=0.00252,\u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:02<00:00, 26.20it/s, loss=0.00172, val_loss=0.00252,\n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 33.00it/s, loss=0.00172, val_loss=0.00252,\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 35.55it/s, loss=0.00172, val_loss=0.00296,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:02<00:02, 19.71it/s, loss=0.00236, val_loss=0.00296,\u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:02<00:01, 25.66it/s, loss=0.00236, val_loss=0.00296,\n",
      "Epoch 56:  90%|▉| 72/80 [00:02<00:00, 32.54it/s, loss=0.00236, val_loss=0.00296,\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 34.98it/s, loss=0.00236, val_loss=0.00347,\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.029, val_loss=0.00347, a\u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.029, val_loss=0.00347, a\n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 34.38it/s, loss=0.029, val_loss=0.00347, a\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 36.88it/s, loss=0.029, val_loss=0.104, avg\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00348, val_loss=0.104, a\u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:02<00:00, 26.89it/s, loss=0.00348, val_loss=0.104, a\n",
      "Epoch 58:  90%|▉| 72/80 [00:02<00:00, 33.97it/s, loss=0.00348, val_loss=0.104, a\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00348, val_loss=0.00317,\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.0074, val_loss=0.00317, \u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:01<00:00, 27.16it/s, loss=0.0074, val_loss=0.00317, \n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 34.30it/s, loss=0.0074, val_loss=0.00317, \u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.0074, val_loss=0.0351, a\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00281, val_loss=0.0351, \u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.00281, val_loss=0.0351, \n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 33.93it/s, loss=0.00281, val_loss=0.0351, \u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00281, val_loss=0.00372,\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00226, val_loss=0.00372,\u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:02<00:00, 26.61it/s, loss=0.00226, val_loss=0.00372,\n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 33.62it/s, loss=0.00226, val_loss=0.00372,\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.00226, val_loss=0.00497,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 21.14it/s, loss=0.00262, val_loss=0.00497,\u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:01<00:00, 27.55it/s, loss=0.00262, val_loss=0.00497,\n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 34.67it/s, loss=0.00262, val_loss=0.00497,\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 37.23it/s, loss=0.00262, val_loss=0.0087, \u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 20.57it/s, loss=0.0127, val_loss=0.0087, a\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:02<00:00, 26.65it/s, loss=0.0127, val_loss=0.0087, a\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 33.73it/s, loss=0.0127, val_loss=0.0087, a\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 36.22it/s, loss=0.0127, val_loss=0.00675, \u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 20.32it/s, loss=0.00233, val_loss=0.00675,\u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:02<00:00, 26.39it/s, loss=0.00233, val_loss=0.00675,\n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 33.35it/s, loss=0.00233, val_loss=0.00675,\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 35.82it/s, loss=0.00233, val_loss=0.00373,\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 20.81it/s, loss=0.0143, val_loss=0.00373, \u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:01<00:00, 27.06it/s, loss=0.0143, val_loss=0.00373, \n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.0143, val_loss=0.00373, \u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 36.72it/s, loss=0.0143, val_loss=0.0822, a\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.24it/s, loss=0.00634, val_loss=0.0822, \u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:01<00:00, 27.67it/s, loss=0.00634, val_loss=0.0822, \n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 34.85it/s, loss=0.00634, val_loss=0.0822, \u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.00634, val_loss=0.00335,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00218, val_loss=0.00335,\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.00218, val_loss=0.00335,\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 33.90it/s, loss=0.00218, val_loss=0.00335,\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 36.39it/s, loss=0.00218, val_loss=0.00387,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00216, val_loss=0.00387,\u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:02<00:00, 26.99it/s, loss=0.00216, val_loss=0.00387,\n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 33.96it/s, loss=0.00216, val_loss=0.00387,\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 36.43it/s, loss=0.00216, val_loss=0.00295,\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.0491, val_loss=0.00295, \u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:01<00:00, 27.24it/s, loss=0.0491, val_loss=0.00295, \n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 34.32it/s, loss=0.0491, val_loss=0.00295, \u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 36.99it/s, loss=0.0491, val_loss=0.016, av\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 20.44it/s, loss=0.00316, val_loss=0.016, a\u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:02<00:00, 26.64it/s, loss=0.00316, val_loss=0.016, a\n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 33.65it/s, loss=0.00316, val_loss=0.016, a\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 36.12it/s, loss=0.00316, val_loss=0.00265,\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.0143, val_loss=0.00265, \u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.0143, val_loss=0.00265, \n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 34.03it/s, loss=0.0143, val_loss=0.00265, \u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 36.59it/s, loss=0.0143, val_loss=0.105, av\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.0103, val_loss=0.105, av\u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:02<00:00, 26.87it/s, loss=0.0103, val_loss=0.105, av\n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 33.98it/s, loss=0.0103, val_loss=0.105, av\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 36.46it/s, loss=0.0103, val_loss=0.00643, \u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 20.50it/s, loss=0.00158, val_loss=0.00643,\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:02<00:00, 26.72it/s, loss=0.00158, val_loss=0.00643,\n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 33.71it/s, loss=0.00158, val_loss=0.00643,\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 36.20it/s, loss=0.00158, val_loss=0.00273,\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 21.32it/s, loss=0.0795, val_loss=0.00273, \u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:01<00:00, 27.62it/s, loss=0.0795, val_loss=0.00273, \n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 34.97it/s, loss=0.0795, val_loss=0.00273, \u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 37.47it/s, loss=0.0795, val_loss=0.0392, a\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 21.14it/s, loss=0.00263, val_loss=0.0392, \u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:01<00:00, 27.51it/s, loss=0.00263, val_loss=0.0392, \n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 34.72it/s, loss=0.00263, val_loss=0.0392, \u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 37.16it/s, loss=0.00263, val_loss=0.00266,\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.00183, val_loss=0.00266,\u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:01<00:00, 27.22it/s, loss=0.00183, val_loss=0.00266,\n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.00183, val_loss=0.00266,\u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.84it/s, loss=0.00183, val_loss=0.00641,\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.0177, val_loss=0.00641, \u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:02<00:00, 26.85it/s, loss=0.0177, val_loss=0.00641, \n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 33.85it/s, loss=0.0177, val_loss=0.00641, \u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 36.36it/s, loss=0.0177, val_loss=0.00878, \u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.23it/s, loss=0.00937, val_loss=0.00878,\u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:02<00:00, 26.28it/s, loss=0.00937, val_loss=0.00878,\n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 33.33it/s, loss=0.00937, val_loss=0.00878,\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 35.80it/s, loss=0.00937, val_loss=0.00395,\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.00163, val_loss=0.00395,\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:02<00:00, 26.90it/s, loss=0.00163, val_loss=0.00395,\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 33.98it/s, loss=0.00163, val_loss=0.00395,\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 36.47it/s, loss=0.00163, val_loss=0.0026, \u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 21.27it/s, loss=0.0623, val_loss=0.0026, a\u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:01<00:00, 27.62it/s, loss=0.0623, val_loss=0.0026, a\n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 34.88it/s, loss=0.0623, val_loss=0.0026, a\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 37.41it/s, loss=0.0623, val_loss=0.133, av\u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 20.99it/s, loss=0.00448, val_loss=0.133, a\u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:01<00:00, 27.25it/s, loss=0.00448, val_loss=0.133, a\n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 34.43it/s, loss=0.00448, val_loss=0.133, a\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 36.94it/s, loss=0.00448, val_loss=0.00388,\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00189, val_loss=0.00388,\u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:01<00:00, 27.16it/s, loss=0.00189, val_loss=0.00388,\n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.00189, val_loss=0.00388,\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.80it/s, loss=0.00189, val_loss=0.00272,\u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.0272, val_loss=0.00272, \u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:01<00:00, 27.13it/s, loss=0.0272, val_loss=0.00272, \n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 34.26it/s, loss=0.0272, val_loss=0.00272, \u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.0272, val_loss=0.125, av\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.0128, val_loss=0.125, av\u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.0128, val_loss=0.125, av\n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.0128, val_loss=0.125, av\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 36.58it/s, loss=0.0128, val_loss=0.00413, \u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.00171, val_loss=0.00413,\u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:02<00:00, 26.54it/s, loss=0.00171, val_loss=0.00413,\n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 33.51it/s, loss=0.00171, val_loss=0.00413,\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.00171, val_loss=0.00316,\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.35it/s, loss=0.00161, val_loss=0.00316,\u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:02<00:00, 26.46it/s, loss=0.00161, val_loss=0.00316,\n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 33.49it/s, loss=0.00161, val_loss=0.00316,\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 35.99it/s, loss=0.00161, val_loss=0.00314,\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 21.25it/s, loss=0.0497, val_loss=0.00314, \u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:01<00:00, 27.68it/s, loss=0.0497, val_loss=0.00314, \n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 34.82it/s, loss=0.0497, val_loss=0.00314, \u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 37.39it/s, loss=0.0497, val_loss=0.019, av\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 20.41it/s, loss=0.00233, val_loss=0.019, a\u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.00233, val_loss=0.019, a\n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 33.50it/s, loss=0.00233, val_loss=0.019, a\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 35.98it/s, loss=0.00233, val_loss=0.00409,\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00534, val_loss=0.00409,\u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.00534, val_loss=0.00409,\n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 34.14it/s, loss=0.00534, val_loss=0.00409,\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00534, val_loss=0.0344, \u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.0422, val_loss=0.0344, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:02<00:00, 26.95it/s, loss=0.0422, val_loss=0.0344, a\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 33.96it/s, loss=0.0422, val_loss=0.0344, a\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 36.65it/s, loss=0.0422, val_loss=0.0112, a\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.00169, val_loss=0.0112, \u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:01<00:00, 27.42it/s, loss=0.00169, val_loss=0.0112, \n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 34.57it/s, loss=0.00169, val_loss=0.0112, \u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 37.00it/s, loss=0.00169, val_loss=0.00259,\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00191, val_loss=0.00259,\u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:02<00:00, 26.30it/s, loss=0.00191, val_loss=0.00259,\n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 33.22it/s, loss=0.00191, val_loss=0.00259,\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 35.64it/s, loss=0.00191, val_loss=0.00444,\u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.038, val_loss=0.00444, a\u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:01<00:00, 27.47it/s, loss=0.038, val_loss=0.00444, a\n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 34.61it/s, loss=0.038, val_loss=0.00444, a\u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 37.15it/s, loss=0.038, val_loss=0.00774, a\u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00262, val_loss=0.00774,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:  68%|▋| 54/80 [00:02<00:00, 26.77it/s, loss=0.00262, val_loss=0.00774,\n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 33.85it/s, loss=0.00262, val_loss=0.00774,\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 36.35it/s, loss=0.00262, val_loss=0.00327,\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.0681, val_loss=0.00327, \u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:02<00:00, 26.70it/s, loss=0.0681, val_loss=0.00327, \n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 33.70it/s, loss=0.0681, val_loss=0.00327, \u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 36.13it/s, loss=0.0681, val_loss=0.0392, a\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 21.25it/s, loss=0.0036, val_loss=0.0392, a\u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:01<00:00, 27.57it/s, loss=0.0036, val_loss=0.0392, a\n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 34.83it/s, loss=0.0036, val_loss=0.0392, a\u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.0036, val_loss=0.00539, \u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 20.95it/s, loss=0.00465, val_loss=0.00539,\u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:01<00:00, 27.11it/s, loss=0.00465, val_loss=0.00539,\n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 34.33it/s, loss=0.00465, val_loss=0.00539,\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 36.68it/s, loss=0.00465, val_loss=0.0231, \u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.0127, val_loss=0.0231, a\u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:01<00:00, 27.10it/s, loss=0.0127, val_loss=0.0231, a\n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.0127, val_loss=0.0231, a\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 36.75it/s, loss=0.0127, val_loss=0.00503, \u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.0665, val_loss=0.00503, \u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:02<00:00, 26.78it/s, loss=0.0665, val_loss=0.00503, \n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 33.78it/s, loss=0.0665, val_loss=0.00503, \u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.32it/s, loss=0.0665, val_loss=0.0311, a\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.0665, val_loss=0.0311, a\u001b[A\n",
      "Sizes of clusters: 341, 539, 486, 312, 322\n",
      "\n",
      "preds: [1 3 4 4 4 2 2 4 1 1 4 1 1 1 1 2 4 1 2 1 4 4 4 4 2 2 4 1 1 1 4 1 2 4 2 1 3\n",
      " 4 4 2 2 4 1 4 4 4 4 1 4 4 4 1 4 4 1 4 3 4 1 1 2 4 4 4 3 1 1 4 1 4 2 1 4 4\n",
      " 4 4 2 4 1 1 4 3 4 4 4 1 4 3 4 1 4 1 4 4 4 2 2 1 1 1 4 4 1 4 2 4 2 2 4 4 4\n",
      " 1 1 1 4 1 4 4 2 2 2 4 1 2 1 1 1 4 2 4 4 3 2 4 1 1 4 4 4 4 1 4 1 4 4 4 4 1\n",
      " 1 4 4 4 2 4 4 4 4 4 1 2 4 0 2 4 0 1 4 4 2 1 1 1 4 1 4 4 1 4 4 4 4 1 1 2 4\n",
      " 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 1 2 2 4 4 4 4 1 1 4 4 4 1 4 4 4 1 4 1 4 2\n",
      " 1 4 4 1 1 4 4 4 2 1 1 2 2 4 4 4 2 2 4 4 4 4 1 4 4 4 4 4 4 4 2 2 2 0 4 4 4\n",
      " 4 1 1 4 1 4 4 2 4 4 4 4 4 4 4 4 2 1 4 4 4 2 1 1 1 2 4 4 4 4 3 3 2 2 1 2 4\n",
      " 1 2 1 1 4 4 4 1 2 4 4 4 1 4 2 4 2 1 2 4 1 1 4 4 3 4 4 4 4 2 1 1 2 2 1 4 4\n",
      " 4 4 4 2 1 1 4 4 2 4 3 2 4 4 1 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 1 4 2 4 2 4 4\n",
      " 1 1 1 4 1 4 2 4 4 2 1 1 2 4 4 4 4 2 2 4 1 4 1 4 4 4 1 1 2 4 3 3 3 3 1 3 1\n",
      " 3 3 3 0 3 1 3 1 3 0 3 1 3 1 1 3 1 1 0 3 3 1 0 1 0 3 0 3 1 3 3 1 1 3 3 3 3\n",
      " 1 3 3 3 3 0 1 0 1 1 3 3 3 3 3 1 3 3 3 3 1 1 3 1 0 3 3 3 3 3 3 3 3 3 3 1 0\n",
      " 3 0 1 3 3 3 3 3 3 3 1 3 1 3 3 1 3 0 1 1 1 3 3 1 1 3 3 1 0 3 3 1 1 3 1 3 3\n",
      " 3 1 1 3 0 3 3 3 3 0 3 1 1 3 3 1 1 3 1 3 3 0 0 3 3 1 3 3 3 3 3 3 3 1 1 1 1\n",
      " 3 3 0 3 0 3 3 1 1 0 3 3 3 3 3 3 3 3 1 1 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 1 1 1 3 1 3 1 3 1 0 3 3 3 3 3 3 1 3 3 3 1 3 1 0 3 3 1 3 3 1 1 3 0 3\n",
      " 1 3 1 0 1 3 3 3 1 1 3 3 1 3 3 3 1 1 0 1 1 3 3 3 3 1 3 3 3 1 3 3 3 3 3 3 3\n",
      " 3 3 0 3 1 3 3 1 3 0 3 1 3 1 3 1 1 3 3 0 3 1 3 3 1 1 3 3 3 3 3 1 3 3 3 3 3\n",
      " 1 3 3 3 3 3 3 3 3 0 0 3 3 0 3 1 3 3 3 3 3 3 3 1 0 1 3 3 3 3 1 3 3 3 3 3 3\n",
      " 3 1 1 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 1 3 3 3 3 3 3 3 3 3 0 3 3\n",
      " 3 1 0 3 3 3 3 3 1 1 3 1 0 3 3 1 1 0 3 1 3 1 3 2 0 3 0 0 0 2 1 2 1 1 4 2 4\n",
      " 1 1 2 3 0 0 2 0 1 0 1 2 0 0 2 3 0 2 0 1 2 2 3 2 0 1 0 0 0 2 0 1 1 0 1 1 2\n",
      " 2 0 0 0 1 1 2 0 1 2 3 0 2 1 0 1 1 0 0 3 2 0 2 1 0 1 2 0 2 2 3 0 1 3 4 0 0\n",
      " 1 0 1 1 3 2 0 0 2 0 4 0 0 1 2 3 1 0 2 2 1 0 0 2 0 0 3 0 0 4 2 0 2 1 0 1 2\n",
      " 0 1 2 2 0 4 2 0 0 1 1 1 0 0 0 0 1 1 2 0 0 0 2 1 3 0 2 0 0 2 0 1 1 4 0 0 0\n",
      " 0 2 0 2 2 0 0 0 0 0 0 1 2 2 0 1 1 1 2 0 0 1 0 1 0 2 0 2 1 0 0 1 1 1 0 0 0\n",
      " 1 0 2 0 0 1 1 1 1 2 2 2 1 0 1 2 3 1 4 1 3 2 0 0 2 0 0 0 2 0 2 1 1 0 2 2 1\n",
      " 3 1 2 0 1 0 4 0 1 0 1 1 1 1 0 2 0 2 2 3 0 0 2 0 2 2 1 0 1 1 4 1 1 2 0 0 3\n",
      " 1 1 0 1 2 1 0 1 0 0 2 1 1 2 1 0 2 1 0 4 0 2 2 2 0 0 0 0 0 1 0 2 3 2 1 3 0\n",
      " 0 0 1 0 1 1 0 1 1 0 4 0 2 0 2 0 3 0 1 0 0 0 1 1 3 1 1 0 1 0 0 2 2 0 0 2 1\n",
      " 0 0 0 3 0 4 2 0 0 0 1 0 0 2 0 1 0 4 0 2 0 2 1 0 2 0 0 1 1 0 2 2 1 1 0 4 2\n",
      " 1 1 1 2 2 1 1 0 1 2 2 1 3 1 2 1 2 4 4 2 1 2 0 2 2 2 0 2 2 2 2 2 0 2 4 1 4\n",
      " 1 1 4 1 2 0 4 2 0 2 3 2 4 1 4 4 1 2 1 1 2 2 2 2 1 2 1 0 1 2 2 2 2 2 4 2 1\n",
      " 2 2 1 2 1 2 2 4 1 2 2 2 4 0 1 0 1 2 2 2 1 2 0 4 2 4 4 2 4 2 1 4 4 4 2 2 1\n",
      " 4 1 2 0 1 2 2 2 2 2 4 1 4 4 0 2 2 1 1 1 2 0 4 2 1 0 0 4 2 2 1 1 4 4 0 0 2\n",
      " 2 2 2 0 4 1 2 1 2 3 0 2 2 2 1 2 0 2 1 2 0 0 2 2 1 1 0 2 1 4 4 4 1 2 2 2 4\n",
      " 1 2 0 2 4 4 2 1 4 2 1 2 1 4 2 0 2 1 2 2 2 1 2 0 4 2 2 1 2 2 0 2 1 2 4 1 0\n",
      " 2 0 2 2 2 0 4 2 2 2 4 2 2 4 2 2 4 2 4 2 4 1 0 2 3 4 4 1 0 2 4 1 1 1 1 2 1\n",
      " 1 1 4 4 2 1 1 2 3 4 2 2 4 2 2 1 1 4 4 4 2 3 1 2 1 2 2 2 2 2 2 1 4 2 1 2 2\n",
      " 2 1 2 2 2 1 2 2 2 0 1 0 1 1 2 1 1 2 4 4 1 0 1 2 2 2 1 4 1 0 4 2 0 2 2 1 3\n",
      " 2 2 1 1 0 1 2 0 0 0 1 2 0 1 2 2 2 2 1 1 1 1 2 2 1 1 4 4 2 1 1 4 2 2 1 1 4\n",
      " 2 2 3 4 2 2 2 2 2 1 2 2 2 2 2 2 1 1 1 1 2 1 1 2 4 0 2 1 2 2 4 4 2 2 2 1 2\n",
      " 0 0 1 1 2 0 1 1 1 1 4 1 2 1 2 4 0 2 1 0 2 2 1 4 0 1 1 1 2 1 0 0 2 2 2 2 4\n",
      " 2 1 1 2 0 0 2 2 1 0 1 1 1 1 1 0 3 0 2 0 2 1 0 1 3 0 1 0 1 1 4 1 1 2 1 4 4\n",
      " 1 2 2 1 1 0 2 1 1 1 0 2 4 0 2 1 2 0 0 0 3 1 4 2 0 0 2 2 2 2 1 0 3 1 0 2 2\n",
      " 0 1 1 0 1 0 2 2 2 0 2 3 2 1 1 1 2 2 2 2 2 0 1 2 2 2 1 1 2 0 4 2 0 0 3 2 1\n",
      " 0 1 1 4 0 2 1 0 2 0 2 2 1 0 1 2 0 1 2 3 1 0 2 1 4 2 1 2 1 2 2 0 0 2 2 1 2\n",
      " 1 1 0 2 2 2 3 2 2 0 2 4 0 1 0 0 0 2 4 1 2 2 2 1 2 1 0 1 2 4 4 0 1 2 0 2 0\n",
      " 0 2 4 2 2 0 2 0 2 2 0 2 1 2 2 2 1 1 4 1 1 0 1 0 2 1 3 4 0 2 2 2 0 1 2 2 1\n",
      " 0 0 0 1 1 1 2 2 3 2 0 1 1 2 2 2 2 1 0 2 2 1 1 2 4 4 2 0 1 1 4 2 2 2 1 2 1\n",
      " 4 4 1 0 0 2 2 1 1 2 0 0 0 2 2 0 2 1 1 0 0 2 2 0 2 1 1 2 2 2 0 2 1 2 1 0 0\n",
      " 0 1 2 1 2 3 2 0 0 1 0 1 2 0 0 2 1 0 0 0 2 2 2 2 2 1 2 2 1 2 0 0 0 1 1 1 1\n",
      " 1 3 1 1 2 1 1 2 1 2 2 0 0 0 2 0 0 3 1 2 0 0 1 0 2 2 2 2 2 2 2 2 0 4 0 2 0\n",
      " 1 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.4600\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.73, val_loss=0.0653, avg_\n",
      "Epoch 0:  52%|▌| 42/80 [00:01<00:01, 21.86it/s, loss=0.73, val_loss=0.0653, avg_\n",
      "Epoch 0:  75%|▊| 60/80 [00:02<00:00, 29.67it/s, loss=0.73, val_loss=0.0653, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.73, val_loss=0.591, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.63it/s, loss=0.0526, val_loss=0.591, avg\u001b[A\n",
      "Epoch 1:  68%|▋| 54/80 [00:02<00:00, 26.78it/s, loss=0.0526, val_loss=0.591, avg\n",
      "Epoch 1:  90%|▉| 72/80 [00:02<00:00, 33.83it/s, loss=0.0526, val_loss=0.591, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 36.36it/s, loss=0.0526, val_loss=0.054, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.95it/s, loss=0.0249, val_loss=0.054, avg\u001b[A\n",
      "Epoch 2:  68%|▋| 54/80 [00:01<00:00, 27.29it/s, loss=0.0249, val_loss=0.054, avg\n",
      "Epoch 2:  90%|▉| 72/80 [00:02<00:00, 34.41it/s, loss=0.0249, val_loss=0.054, avg\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.91it/s, loss=0.0249, val_loss=0.0306, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.016, val_loss=0.0306, avg\u001b[A\n",
      "Epoch 3:  68%|▋| 54/80 [00:02<00:00, 26.77it/s, loss=0.016, val_loss=0.0306, avg\n",
      "Epoch 3:  90%|▉| 72/80 [00:02<00:00, 33.82it/s, loss=0.016, val_loss=0.0306, avg\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 36.31it/s, loss=0.016, val_loss=0.0215, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.011, val_loss=0.0215, avg\u001b[A\n",
      "Epoch 4:  68%|▋| 54/80 [00:02<00:00, 26.78it/s, loss=0.011, val_loss=0.0215, avg\n",
      "Epoch 4:  90%|▉| 72/80 [00:02<00:00, 33.91it/s, loss=0.011, val_loss=0.0215, avg\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.40it/s, loss=0.011, val_loss=0.0147, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.008, val_loss=0.0147, avg\u001b[A\n",
      "Epoch 5:  68%|▋| 54/80 [00:01<00:00, 27.31it/s, loss=0.008, val_loss=0.0147, avg\n",
      "Epoch 5:  90%|▉| 72/80 [00:02<00:00, 34.42it/s, loss=0.008, val_loss=0.0147, avg\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.008, val_loss=0.0104, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.62it/s, loss=0.00609, val_loss=0.0104, a\u001b[A\n",
      "Epoch 6:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00609, val_loss=0.0104, a\n",
      "Epoch 6:  90%|▉| 72/80 [00:02<00:00, 33.82it/s, loss=0.00609, val_loss=0.0104, a\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.30it/s, loss=0.00609, val_loss=0.00773, \u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.00482, val_loss=0.00773, \u001b[A\n",
      "Epoch 7:  68%|▋| 54/80 [00:01<00:00, 27.41it/s, loss=0.00482, val_loss=0.00773, \n",
      "Epoch 7:  90%|▉| 72/80 [00:02<00:00, 34.65it/s, loss=0.00482, val_loss=0.00773, \u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.06it/s, loss=0.00482, val_loss=0.006, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00394, val_loss=0.006, av\u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:02<00:00, 26.87it/s, loss=0.00394, val_loss=0.006, av\n",
      "Epoch 8:  90%|▉| 72/80 [00:02<00:00, 33.96it/s, loss=0.00394, val_loss=0.006, av\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00394, val_loss=0.00485, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00332, val_loss=0.00485, \u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:01<00:00, 27.11it/s, loss=0.00332, val_loss=0.00485, \n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 34.19it/s, loss=0.00332, val_loss=0.00485, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 36.69it/s, loss=0.00332, val_loss=0.00404, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.52it/s, loss=0.00287, val_loss=0.00404,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00287, val_loss=0.00404,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 33.68it/s, loss=0.00287, val_loss=0.00404,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.25it/s, loss=0.00287, val_loss=0.00351,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.00255, val_loss=0.00351,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:02<00:00, 26.90it/s, loss=0.00255, val_loss=0.00351,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.00255, val_loss=0.00351,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 36.43it/s, loss=0.00255, val_loss=0.0031, \u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.0023, val_loss=0.0031, a\u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:01<00:00, 27.21it/s, loss=0.0023, val_loss=0.0031, a\n",
      "Epoch 12:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.0023, val_loss=0.0031, a\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.0023, val_loss=0.00281, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 20.13it/s, loss=0.00212, val_loss=0.00281,\u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:02<00:00, 26.26it/s, loss=0.00212, val_loss=0.00281,\n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 33.17it/s, loss=0.00212, val_loss=0.00281,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 35.54it/s, loss=0.00212, val_loss=0.00259,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.09it/s, loss=0.00197, val_loss=0.00259,\u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 27.39it/s, loss=0.00197, val_loss=0.00259,\n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 34.55it/s, loss=0.00197, val_loss=0.00259,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.00197, val_loss=0.00243,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00185, val_loss=0.00243,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:01<00:00, 28.36it/s, loss=0.00185, val_loss=0.00243,\n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 35.68it/s, loss=0.00185, val_loss=0.00243,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00185, val_loss=0.00229,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00176, val_loss=0.00229,\u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:01<00:00, 28.27it/s, loss=0.00176, val_loss=0.00229,\n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00176, val_loss=0.00229,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00176, val_loss=0.00218,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00169, val_loss=0.00218,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:01<00:00, 28.54it/s, loss=0.00169, val_loss=0.00218,\n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 35.88it/s, loss=0.00169, val_loss=0.00218,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00169, val_loss=0.00209,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00162, val_loss=0.00209,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:01<00:00, 28.41it/s, loss=0.00162, val_loss=0.00209,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 35.73it/s, loss=0.00162, val_loss=0.00209,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00162, val_loss=0.002, a\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00157, val_loss=0.002, a\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:01<00:00, 28.32it/s, loss=0.00157, val_loss=0.002, a\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 35.63it/s, loss=0.00157, val_loss=0.002, a\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00157, val_loss=0.00195,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00152, val_loss=0.00195,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.00152, val_loss=0.00195,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00152, val_loss=0.00195,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00152, val_loss=0.00189,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00149, val_loss=0.00189,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00149, val_loss=0.00189,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00149, val_loss=0.00189,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.00149, val_loss=0.00185,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00145, val_loss=0.00185,\u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 28.54it/s, loss=0.00145, val_loss=0.00185,\n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 35.90it/s, loss=0.00145, val_loss=0.00185,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00145, val_loss=0.00182,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00142, val_loss=0.00182,\u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 28.48it/s, loss=0.00142, val_loss=0.00182,\n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 35.82it/s, loss=0.00142, val_loss=0.00182,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00142, val_loss=0.00178,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.0014, val_loss=0.00178, \u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 28.55it/s, loss=0.0014, val_loss=0.00178, \n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 35.90it/s, loss=0.0014, val_loss=0.00178, \u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.0014, val_loss=0.00174, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00138, val_loss=0.00174,\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 28.50it/s, loss=0.00138, val_loss=0.00174,\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 35.84it/s, loss=0.00138, val_loss=0.00174,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.00138, val_loss=0.00171,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00136, val_loss=0.00171,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:01<00:00, 28.41it/s, loss=0.00136, val_loss=0.00171,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 35.74it/s, loss=0.00136, val_loss=0.00171,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00136, val_loss=0.00169,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.00134, val_loss=0.00169,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:01<00:00, 28.40it/s, loss=0.00134, val_loss=0.00169,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.00134, val_loss=0.00169,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00134, val_loss=0.00168,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00133, val_loss=0.00168,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:01<00:00, 28.41it/s, loss=0.00133, val_loss=0.00168,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 35.73it/s, loss=0.00133, val_loss=0.00168,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.00133, val_loss=0.00165,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00131, val_loss=0.00165,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00131, val_loss=0.00165,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00131, val_loss=0.00165,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.00131, val_loss=0.00163,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.0013, val_loss=0.00163, \u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 28.54it/s, loss=0.0013, val_loss=0.00163, \n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 35.88it/s, loss=0.0013, val_loss=0.00163, \u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.0013, val_loss=0.00164, \u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00129, val_loss=0.00164,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:01<00:00, 28.44it/s, loss=0.00129, val_loss=0.00164,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00129, val_loss=0.00164,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00129, val_loss=0.00161,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.59it/s, loss=0.00128, val_loss=0.00161,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:01<00:00, 28.01it/s, loss=0.00128, val_loss=0.00161,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 35.32it/s, loss=0.00128, val_loss=0.00161,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 37.87it/s, loss=0.00128, val_loss=0.0016, \u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00127, val_loss=0.0016, \u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:01<00:00, 28.28it/s, loss=0.00127, val_loss=0.0016, \n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 35.57it/s, loss=0.00127, val_loss=0.0016, \u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00127, val_loss=0.00157,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00126, val_loss=0.00157,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 28.46it/s, loss=0.00126, val_loss=0.00157,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 35.78it/s, loss=0.00126, val_loss=0.00157,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.00126, val_loss=0.00155,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00125, val_loss=0.00155,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 28.57it/s, loss=0.00125, val_loss=0.00155,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 35.91it/s, loss=0.00125, val_loss=0.00155,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00125, val_loss=0.00153,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00125, val_loss=0.00153,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:01<00:00, 28.53it/s, loss=0.00125, val_loss=0.00153,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 35.88it/s, loss=0.00125, val_loss=0.00153,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00125, val_loss=0.00155,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.00124, val_loss=0.00155,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 28.41it/s, loss=0.00124, val_loss=0.00155,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 35.73it/s, loss=0.00124, val_loss=0.00155,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.00124, val_loss=0.00153,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00123, val_loss=0.00153,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:01<00:00, 28.52it/s, loss=0.00123, val_loss=0.00153,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 35.86it/s, loss=0.00123, val_loss=0.00153,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00123, val_loss=0.00155,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00123, val_loss=0.00155,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 28.56it/s, loss=0.00123, val_loss=0.00155,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 35.90it/s, loss=0.00123, val_loss=0.00155,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00123, val_loss=0.00153,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 22.03it/s, loss=0.00122, val_loss=0.00153,\u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:01<00:00, 28.66it/s, loss=0.00122, val_loss=0.00153,\n",
      "Epoch 40:  90%|▉| 72/80 [00:01<00:00, 36.02it/s, loss=0.00122, val_loss=0.00153,\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 38.57it/s, loss=0.00122, val_loss=0.00156,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00122, val_loss=0.00156,\u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:01<00:00, 28.52it/s, loss=0.00122, val_loss=0.00156,\n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 35.87it/s, loss=0.00122, val_loss=0.00156,\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.00122, val_loss=0.00155,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00121, val_loss=0.00155,\u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:01<00:00, 28.45it/s, loss=0.00121, val_loss=0.00155,\n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00121, val_loss=0.00155,\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00121, val_loss=0.00155,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00121, val_loss=0.00155,\u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:01<00:00, 28.42it/s, loss=0.00121, val_loss=0.00155,\n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 35.77it/s, loss=0.00121, val_loss=0.00155,\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00121, val_loss=0.00156,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00121, val_loss=0.00156,\u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:01<00:00, 28.11it/s, loss=0.00121, val_loss=0.00156,\n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 35.38it/s, loss=0.00121, val_loss=0.00156,\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 37.91it/s, loss=0.00121, val_loss=0.00162,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00121, val_loss=0.00162,\u001b[A\n",
      "Epoch 45:  68%|▋| 54/80 [00:01<00:00, 28.44it/s, loss=0.00121, val_loss=0.00162,\n",
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00121, val_loss=0.00162,\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00121, val_loss=0.00164,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.0012, val_loss=0.00164, \u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:01<00:00, 28.45it/s, loss=0.0012, val_loss=0.00164, \n",
      "Epoch 46:  90%|▉| 72/80 [00:02<00:00, 35.79it/s, loss=0.0012, val_loss=0.00164, \u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.0012, val_loss=0.00165, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.0012, val_loss=0.00165, \u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:01<00:00, 28.44it/s, loss=0.0012, val_loss=0.00165, \n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 35.77it/s, loss=0.0012, val_loss=0.00165, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.0012, val_loss=0.00167, \u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.0012, val_loss=0.00167, \u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:01<00:00, 28.49it/s, loss=0.0012, val_loss=0.00167, \n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 35.84it/s, loss=0.0012, val_loss=0.00167, \u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.0012, val_loss=0.00167, \u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00119, val_loss=0.00167,\u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:01<00:00, 28.47it/s, loss=0.00119, val_loss=0.00167,\n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 35.80it/s, loss=0.00119, val_loss=0.00167,\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 22.02it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:01<00:00, 28.65it/s, loss=0.00119, val_loss=0.00164,\n",
      "Epoch 50:  90%|▉| 72/80 [00:01<00:00, 36.00it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 38.56it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:01<00:00, 28.46it/s, loss=0.00119, val_loss=0.00164,\n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 35.79it/s, loss=0.00119, val_loss=0.00164,\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.00119, val_loss=0.00163,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00119, val_loss=0.00163,\u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00119, val_loss=0.00163,\n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 35.59it/s, loss=0.00119, val_loss=0.00163,\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00119, val_loss=0.00168,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00121, val_loss=0.00168,\u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:01<00:00, 28.28it/s, loss=0.00121, val_loss=0.00168,\n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00121, val_loss=0.00168,\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00121, val_loss=0.00189,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.0215, val_loss=0.00189, \u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.0215, val_loss=0.00189, \n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 35.75it/s, loss=0.0215, val_loss=0.00189, \u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.0215, val_loss=0.00278, \u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00146, val_loss=0.00278,\u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:01<00:00, 28.53it/s, loss=0.00146, val_loss=0.00278,\n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 35.86it/s, loss=0.00146, val_loss=0.00278,\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00146, val_loss=0.00177,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00118, val_loss=0.00177,\u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:01<00:00, 28.56it/s, loss=0.00118, val_loss=0.00177,\n",
      "Epoch 56:  90%|▉| 72/80 [00:02<00:00, 35.91it/s, loss=0.00118, val_loss=0.00177,\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.00118, val_loss=0.00171,\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00118, val_loss=0.00171,\u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00118, val_loss=0.00171,\n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 35.59it/s, loss=0.00118, val_loss=0.00171,\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00118, val_loss=0.00179,\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00118, val_loss=0.00179,\u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:01<00:00, 28.35it/s, loss=0.00118, val_loss=0.00179,\n",
      "Epoch 58:  90%|▉| 72/80 [00:02<00:00, 35.65it/s, loss=0.00118, val_loss=0.00179,\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 38.20it/s, loss=0.00118, val_loss=0.0018, \u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.0012, val_loss=0.0018, a\u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:01<00:00, 28.45it/s, loss=0.0012, val_loss=0.0018, a\n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 35.78it/s, loss=0.0012, val_loss=0.0018, a\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.0012, val_loss=0.00211, \u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.0706, val_loss=0.00211, \u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:01<00:00, 28.62it/s, loss=0.0706, val_loss=0.00211, \n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 35.98it/s, loss=0.0706, val_loss=0.00211, \u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 38.53it/s, loss=0.0706, val_loss=0.0333, a\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00184, val_loss=0.0333, \u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:01<00:00, 28.50it/s, loss=0.00184, val_loss=0.0333, \n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 35.83it/s, loss=0.00184, val_loss=0.0333, \u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00184, val_loss=0.00219,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00117, val_loss=0.00219,\u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:01<00:00, 28.62it/s, loss=0.00117, val_loss=0.00219,\n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 35.97it/s, loss=0.00117, val_loss=0.00219,\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 38.53it/s, loss=0.00117, val_loss=0.00183,\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00116, val_loss=0.00183,\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:01<00:00, 28.47it/s, loss=0.00116, val_loss=0.00183,\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 35.81it/s, loss=0.00116, val_loss=0.00183,\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.00116, val_loss=0.00186,\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.0481, val_loss=0.00186, \u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:01<00:00, 28.25it/s, loss=0.0481, val_loss=0.00186, \n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 35.54it/s, loss=0.0481, val_loss=0.00186, \u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.0481, val_loss=0.399, av\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00674, val_loss=0.399, a\u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:01<00:00, 28.49it/s, loss=0.00674, val_loss=0.399, a\n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 35.83it/s, loss=0.00674, val_loss=0.399, a\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00674, val_loss=0.00363,\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00124, val_loss=0.00363,\u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:01<00:00, 28.21it/s, loss=0.00124, val_loss=0.00363,\n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 35.46it/s, loss=0.00124, val_loss=0.00363,\u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 38.02it/s, loss=0.00124, val_loss=0.00185,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00117, val_loss=0.00185,\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:01<00:00, 28.27it/s, loss=0.00117, val_loss=0.00185,\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 35.57it/s, loss=0.00117, val_loss=0.00185,\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00117, val_loss=0.00189,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00117, val_loss=0.00189,\u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:01<00:00, 28.27it/s, loss=0.00117, val_loss=0.00189,\n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00117, val_loss=0.00189,\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00117, val_loss=0.00193,\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00123, val_loss=0.00193,\u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:01<00:00, 28.52it/s, loss=0.00123, val_loss=0.00193,\n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 35.86it/s, loss=0.00123, val_loss=0.00193,\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00123, val_loss=0.00257,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.0321, val_loss=0.00257, \u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:01<00:00, 28.41it/s, loss=0.0321, val_loss=0.00257, \n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.0321, val_loss=0.00257, \u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.0321, val_loss=0.0143, a\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00166, val_loss=0.0143, \u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:01<00:00, 28.23it/s, loss=0.00166, val_loss=0.0143, \n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 35.51it/s, loss=0.00166, val_loss=0.0143, \u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 38.06it/s, loss=0.00166, val_loss=0.00213,\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00116, val_loss=0.00213,\u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:01<00:00, 28.26it/s, loss=0.00116, val_loss=0.00213,\n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 35.37it/s, loss=0.00116, val_loss=0.00213,\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.00116, val_loss=0.00199,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00116, val_loss=0.00199,\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:01<00:00, 28.42it/s, loss=0.00116, val_loss=0.00199,\n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 35.73it/s, loss=0.00116, val_loss=0.00199,\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.00116, val_loss=0.00199,\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00117, val_loss=0.00199,\u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:01<00:00, 28.28it/s, loss=0.00117, val_loss=0.00199,\n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 35.54it/s, loss=0.00117, val_loss=0.00199,\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00117, val_loss=0.00202,\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.123, val_loss=0.00202, a\u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.123, val_loss=0.00202, a\n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.123, val_loss=0.00202, a\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.123, val_loss=0.0856, av\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00362, val_loss=0.0856, \u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:01<00:00, 28.33it/s, loss=0.00362, val_loss=0.0856, \n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 35.64it/s, loss=0.00362, val_loss=0.0856, \u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 38.18it/s, loss=0.00362, val_loss=0.00291,\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.0012, val_loss=0.00291, \u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:01<00:00, 28.48it/s, loss=0.0012, val_loss=0.00291, \n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 35.81it/s, loss=0.0012, val_loss=0.00291, \u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.0012, val_loss=0.00205, \u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00116, val_loss=0.00205,\u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.00116, val_loss=0.00205,\n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00116, val_loss=0.00205,\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00116, val_loss=0.00208,\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.127, val_loss=0.00208, a\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:01<00:00, 28.49it/s, loss=0.127, val_loss=0.00208, a\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 35.77it/s, loss=0.127, val_loss=0.00208, a\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.127, val_loss=0.191, avg\u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.0057, val_loss=0.191, av\u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:01<00:00, 28.59it/s, loss=0.0057, val_loss=0.191, av\n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 35.95it/s, loss=0.0057, val_loss=0.191, av\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.0057, val_loss=0.00422, \u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.00124, val_loss=0.00422,\u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:01<00:00, 28.40it/s, loss=0.00124, val_loss=0.00422,\n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.00124, val_loss=0.00422,\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00124, val_loss=0.00203,\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00117, val_loss=0.00203,\u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:01<00:00, 28.39it/s, loss=0.00117, val_loss=0.00203,\n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 35.71it/s, loss=0.00117, val_loss=0.00203,\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.00117, val_loss=0.00209,\u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00118, val_loss=0.00209,\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.00118, val_loss=0.00209,\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00118, val_loss=0.00209,\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.00118, val_loss=0.00243,\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.061, val_loss=0.00243, a\u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:01<00:00, 28.26it/s, loss=0.061, val_loss=0.00243, a\n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 35.50it/s, loss=0.061, val_loss=0.00243, a\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.061, val_loss=0.018, avg\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00197, val_loss=0.018, a\u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:01<00:00, 28.48it/s, loss=0.00197, val_loss=0.018, a\n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 35.83it/s, loss=0.00197, val_loss=0.018, a\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00197, val_loss=0.00213,\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00118, val_loss=0.00213,\u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:01<00:00, 28.24it/s, loss=0.00118, val_loss=0.00213,\n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 35.53it/s, loss=0.00118, val_loss=0.00213,\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00118, val_loss=0.00213,\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.0937, val_loss=0.00213, \u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:01<00:00, 28.49it/s, loss=0.0937, val_loss=0.00213, \n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 35.83it/s, loss=0.0937, val_loss=0.00213, \u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.0937, val_loss=0.0414, a\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.00326, val_loss=0.0414, \u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:01<00:00, 28.37it/s, loss=0.00326, val_loss=0.0414, \n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 35.69it/s, loss=0.00326, val_loss=0.0414, \u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00326, val_loss=0.00277,\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.0012, val_loss=0.00277, \u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:01<00:00, 28.26it/s, loss=0.0012, val_loss=0.00277, \n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 35.56it/s, loss=0.0012, val_loss=0.00277, \u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.0012, val_loss=0.00215, \u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.131, val_loss=0.00215, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:01<00:00, 28.37it/s, loss=0.131, val_loss=0.00215, a\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 35.69it/s, loss=0.131, val_loss=0.00215, a\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.131, val_loss=0.0513, av\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00268, val_loss=0.0513, \u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:01<00:00, 28.42it/s, loss=0.00268, val_loss=0.0513, \n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 35.74it/s, loss=0.00268, val_loss=0.0513, \u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00268, val_loss=0.00255,\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00136, val_loss=0.00255,\u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:01<00:00, 28.44it/s, loss=0.00136, val_loss=0.00255,\n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 35.76it/s, loss=0.00136, val_loss=0.00255,\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00136, val_loss=0.00345,\u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.0115, val_loss=0.00345, \u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.0115, val_loss=0.00345, \n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 35.78it/s, loss=0.0115, val_loss=0.00345, \u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.0115, val_loss=0.00679, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00135, val_loss=0.00679,\u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:01<00:00, 28.63it/s, loss=0.00135, val_loss=0.00679,\n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 35.99it/s, loss=0.00135, val_loss=0.00679,\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 38.55it/s, loss=0.00135, val_loss=0.00213,\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00118, val_loss=0.00213,\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:01<00:00, 28.59it/s, loss=0.00118, val_loss=0.00213,\n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 35.94it/s, loss=0.00118, val_loss=0.00213,\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 38.49it/s, loss=0.00118, val_loss=0.00217,\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.0927, val_loss=0.00217, \u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:01<00:00, 28.42it/s, loss=0.0927, val_loss=0.00217, \n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 35.73it/s, loss=0.0927, val_loss=0.00217, \u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.0927, val_loss=0.00855, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00225, val_loss=0.00855,\u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:01<00:00, 28.47it/s, loss=0.00225, val_loss=0.00855,\n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 35.80it/s, loss=0.00225, val_loss=0.00855,\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00225, val_loss=0.00227,\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 21.37it/s, loss=0.00128, val_loss=0.00227,\u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:01<00:00, 27.83it/s, loss=0.00128, val_loss=0.00227,\n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 35.03it/s, loss=0.00128, val_loss=0.00227,\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 37.56it/s, loss=0.00128, val_loss=0.00287,\u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.0633, val_loss=0.00287, \u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:01<00:00, 28.24it/s, loss=0.0633, val_loss=0.00287, \n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 35.53it/s, loss=0.0633, val_loss=0.00287, \u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.0633, val_loss=0.017, av\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 37.83it/s, loss=0.0633, val_loss=0.017, av\u001b[A\n",
      "Sizes of clusters: 564, 336, 116, 669, 315\n",
      "\n",
      "preds: [0 2 4 2 2 3 3 4 2 2 4 2 0 4 4 3 4 0 0 0 0 2 4 0 0 0 4 4 0 0 4 4 3 4 4 4 2\n",
      " 2 4 1 4 4 0 2 4 4 2 4 2 4 2 4 4 4 2 4 2 4 0 4 3 0 4 4 2 2 4 4 0 4 3 4 0 4\n",
      " 4 0 0 4 0 0 4 2 4 4 0 0 2 2 4 0 2 4 0 2 0 3 0 2 2 0 0 4 4 2 3 4 3 4 0 4 4\n",
      " 0 0 4 4 4 2 2 3 3 0 4 2 0 2 4 4 2 3 4 4 2 3 2 2 0 4 2 4 2 0 2 4 4 4 2 2 0\n",
      " 4 0 4 2 0 0 0 4 2 4 2 4 4 1 2 2 3 0 4 2 4 2 0 0 2 4 4 2 0 0 4 4 4 0 0 0 2\n",
      " 3 4 0 0 4 2 2 4 4 2 0 4 4 4 0 2 4 3 2 4 2 4 4 2 4 2 4 4 0 0 4 2 0 0 4 0 3\n",
      " 4 2 2 4 4 4 4 4 3 4 2 0 3 2 0 4 0 0 0 4 4 4 0 4 4 4 2 4 4 4 3 0 3 3 4 2 4\n",
      " 2 4 4 4 4 4 4 3 4 4 2 4 2 4 2 0 0 4 4 2 0 4 0 2 2 3 4 4 4 2 2 4 3 3 0 0 4\n",
      " 4 3 2 4 2 0 4 0 3 2 4 0 0 4 0 4 3 0 3 2 4 2 2 4 4 0 4 4 4 3 2 0 3 4 0 0 2\n",
      " 0 4 0 0 4 0 4 0 0 4 2 0 4 0 2 4 2 4 2 4 4 2 2 4 0 4 4 2 4 0 4 2 0 2 3 4 4\n",
      " 4 2 4 4 4 4 0 4 4 4 2 2 0 4 0 0 4 4 1 0 4 4 0 4 4 4 4 2 3 4 3 3 4 0 0 4 0\n",
      " 3 3 3 1 0 4 3 4 0 1 0 0 3 0 0 4 0 0 1 3 0 0 1 0 1 4 1 3 0 3 2 0 0 3 4 3 3\n",
      " 0 3 0 3 0 3 0 3 3 0 4 0 0 3 0 0 0 3 3 3 0 0 0 0 1 0 3 0 4 3 0 0 3 1 2 4 3\n",
      " 4 1 0 2 0 3 3 3 3 4 0 0 0 3 4 4 3 1 0 0 0 0 0 0 0 0 0 4 1 2 0 0 0 0 4 0 4\n",
      " 2 0 4 0 1 4 3 3 0 1 3 0 0 2 0 4 0 3 0 3 3 1 1 0 0 0 3 3 3 0 0 0 4 0 4 0 4\n",
      " 3 2 1 0 1 0 0 4 4 1 4 3 3 0 3 3 0 0 1 0 3 4 0 0 4 0 3 3 3 3 3 3 0 0 3 0 3\n",
      " 0 4 4 4 0 0 0 4 3 0 4 4 3 0 4 0 3 3 4 4 0 3 3 0 0 0 1 3 0 4 2 0 4 3 3 1 3\n",
      " 4 3 3 1 4 0 0 3 4 3 3 3 1 4 4 3 0 3 1 4 0 3 4 3 0 0 4 3 3 4 0 0 3 3 3 4 0\n",
      " 3 4 1 3 3 4 0 0 3 1 3 4 0 4 4 3 1 3 4 3 4 3 3 3 0 3 3 4 3 0 0 0 3 4 0 3 3\n",
      " 0 3 0 0 0 4 3 3 0 3 1 0 3 1 0 0 0 4 4 2 4 3 3 3 1 0 3 3 0 3 0 3 4 0 0 3 4\n",
      " 3 0 0 3 3 3 2 4 0 3 4 2 0 3 0 0 3 4 0 3 4 4 3 4 3 4 4 3 3 0 3 3 3 4 1 3 3\n",
      " 3 0 1 2 0 4 3 4 1 0 2 0 1 0 3 4 0 1 0 0 3 0 0 3 1 3 1 1 1 1 3 3 0 0 4 3 0\n",
      " 0 0 3 0 1 1 3 3 0 1 0 3 1 1 1 3 1 3 1 0 1 3 0 3 1 0 1 1 1 3 1 0 0 1 0 0 3\n",
      " 1 1 1 1 0 0 3 1 0 3 3 3 1 0 1 0 3 1 1 3 3 1 3 0 1 0 3 1 1 3 4 1 0 3 0 1 3\n",
      " 3 1 0 0 0 3 1 3 3 3 0 1 3 0 3 0 1 1 3 3 3 1 1 3 1 1 4 3 3 0 3 1 3 3 3 0 3\n",
      " 1 0 3 1 1 0 1 1 1 3 3 0 1 3 1 1 3 3 0 1 1 3 3 3 3 1 3 1 1 1 1 0 3 0 3 3 1\n",
      " 1 3 1 1 3 1 1 1 3 1 1 3 3 3 1 0 3 0 1 1 1 0 1 3 1 3 1 3 0 3 1 0 0 0 1 3 1\n",
      " 3 1 3 1 3 0 0 0 0 3 3 3 0 1 0 1 3 0 0 0 3 3 1 1 3 1 1 1 1 1 3 0 1 1 1 3 3\n",
      " 3 0 1 3 0 3 0 1 0 1 3 0 3 0 1 3 1 3 3 4 3 3 1 1 1 1 0 1 3 0 0 0 0 3 1 1 3\n",
      " 0 1 3 0 3 0 1 0 1 1 1 0 0 3 3 3 3 3 1 0 3 3 3 1 1 1 3 1 1 0 1 3 4 1 0 3 1\n",
      " 1 1 0 1 3 0 1 3 0 1 0 1 1 1 3 1 3 1 0 1 1 1 3 3 3 0 0 1 3 3 1 3 3 1 1 1 0\n",
      " 1 1 3 3 1 0 1 1 1 1 0 1 3 1 1 0 1 0 1 3 1 3 0 1 3 3 1 3 1 1 1 1 0 0 1 0 1\n",
      " 3 0 0 3 3 3 0 1 0 1 1 3 0 3 3 0 3 0 0 3 4 3 1 3 3 3 3 3 3 1 3 3 1 3 4 3 0\n",
      " 0 0 4 0 1 3 4 3 3 3 4 0 0 0 0 4 0 3 2 0 3 3 3 1 0 3 0 3 0 3 3 1 3 0 4 3 0\n",
      " 3 3 0 3 4 3 1 4 0 3 3 3 4 1 4 3 4 3 3 1 0 3 3 0 3 4 0 3 2 3 0 4 4 2 3 3 0\n",
      " 0 0 0 3 0 3 3 3 3 3 2 0 4 0 3 3 3 0 0 0 0 1 0 3 0 3 3 4 3 3 0 0 0 0 3 1 3\n",
      " 3 0 3 1 4 4 3 0 3 3 3 3 3 3 0 3 3 3 0 3 1 3 3 3 0 0 3 3 0 4 4 0 0 3 3 3 0\n",
      " 4 3 3 3 0 0 3 0 4 3 0 3 0 4 3 1 3 0 1 3 3 0 3 3 4 3 3 0 3 3 1 3 0 3 0 0 3\n",
      " 3 3 3 3 1 3 0 0 1 3 0 3 1 0 3 3 4 3 4 3 4 0 3 3 4 0 4 0 3 3 0 0 0 0 0 3 0\n",
      " 0 0 0 0 3 0 0 3 3 0 3 3 4 3 3 4 0 4 2 0 3 0 0 3 0 1 1 3 3 3 3 0 0 3 4 3 3\n",
      " 3 4 3 3 1 0 3 3 3 1 0 1 0 0 3 0 0 3 0 2 3 3 0 3 1 3 0 2 4 3 0 1 1 3 3 0 4\n",
      " 3 3 0 4 1 0 3 3 3 3 0 3 3 2 3 3 3 3 4 4 4 4 3 3 0 0 0 0 3 0 0 4 3 3 0 0 0\n",
      " 1 3 0 4 1 3 3 3 1 0 3 3 3 1 3 3 0 0 0 0 3 0 4 0 0 1 3 0 3 1 4 0 3 3 3 4 0\n",
      " 0 3 3 4 3 1 0 2 0 0 0 0 3 0 1 4 3 3 3 3 1 3 0 4 1 3 0 0 3 0 1 3 1 3 3 1 0\n",
      " 1 3 3 1 3 1 1 1 3 3 0 0 3 0 3 3 4 1 3 3 3 0 1 0 4 1 0 3 3 0 4 3 3 3 0 4 0\n",
      " 0 0 3 0 0 1 3 0 0 3 3 3 0 3 1 0 0 3 1 3 3 0 0 1 3 3 3 1 1 1 0 3 0 3 1 3 3\n",
      " 3 0 0 1 3 3 1 3 3 1 1 2 1 0 3 3 3 1 3 3 1 3 0 3 1 3 0 0 3 1 0 3 0 1 3 3 0\n",
      " 1 0 0 0 3 1 0 3 3 3 3 3 3 3 0 1 3 0 1 0 3 3 1 0 0 1 0 3 3 3 3 1 1 1 1 0 3\n",
      " 0 0 0 3 1 3 3 1 3 3 1 4 3 3 3 3 1 3 0 3 3 3 1 0 3 3 1 0 1 0 0 1 0 3 1 3 1\n",
      " 3 3 0 3 1 3 3 1 3 1 3 3 0 1 1 3 3 0 0 0 0 1 0 3 1 0 3 4 1 3 1 1 1 0 1 1 4\n",
      " 3 1 1 3 0 0 3 3 3 1 1 3 3 3 3 1 1 0 1 1 3 0 3 1 0 4 1 3 3 0 0 1 1 1 0 3 0\n",
      " 0 4 3 3 3 3 1 0 0 3 3 3 3 1 1 3 3 0 0 3 1 1 1 3 3 0 3 3 3 1 3 3 0 1 3 1 1\n",
      " 1 0 3 4 1 4 3 3 3 0 3 0 3 3 3 3 3 3 1 1 3 3 3 3 3 0 1 1 0 1 3 3 3 3 0 3 3\n",
      " 3 3 3 0 3 3 0 1 0 3 3 1 1 3 3 0 3 0 0 3 3 3 0 3 3 1 3 3 3 3 1 3 3 0 3 3 1\n",
      " 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3795\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.629, val_loss=0.0822, avg\n",
      "Epoch 0:  64%|▋| 51/80 [00:01<00:01, 26.00it/s, loss=0.629, val_loss=0.0822, avg\n",
      "Epoch 0:  86%|▊| 69/80 [00:02<00:00, 33.41it/s, loss=0.629, val_loss=0.0822, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.04it/s, loss=0.629, val_loss=0.407, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.45it/s, loss=0.0587, val_loss=0.407, avg\u001b[A\n",
      "Epoch 1:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.0587, val_loss=0.407, avg\n",
      "Epoch 1:  90%|▉| 72/80 [00:02<00:00, 33.49it/s, loss=0.0587, val_loss=0.407, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 36.07it/s, loss=0.0587, val_loss=0.0533, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.0355, val_loss=0.0533, av\u001b[A\n",
      "Epoch 2:  68%|▋| 54/80 [00:01<00:00, 27.43it/s, loss=0.0355, val_loss=0.0533, av\n",
      "Epoch 2:  90%|▉| 72/80 [00:02<00:00, 34.52it/s, loss=0.0355, val_loss=0.0533, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.0355, val_loss=0.0382, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.0273, val_loss=0.0382, av\u001b[A\n",
      "Epoch 3:  68%|▋| 54/80 [00:02<00:00, 26.89it/s, loss=0.0273, val_loss=0.0382, av\n",
      "Epoch 3:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.0273, val_loss=0.0382, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.0273, val_loss=0.0301, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.0219, val_loss=0.0301, av\u001b[A\n",
      "Epoch 4:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.0219, val_loss=0.0301, av\n",
      "Epoch 4:  90%|▉| 72/80 [00:02<00:00, 34.27it/s, loss=0.0219, val_loss=0.0301, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.0219, val_loss=0.0247, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 20.68it/s, loss=0.0178, val_loss=0.0247, av\u001b[A\n",
      "Epoch 5:  68%|▋| 54/80 [00:02<00:00, 26.92it/s, loss=0.0178, val_loss=0.0247, av\n",
      "Epoch 5:  90%|▉| 72/80 [00:02<00:00, 33.96it/s, loss=0.0178, val_loss=0.0247, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 36.47it/s, loss=0.0178, val_loss=0.0199, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.32it/s, loss=0.0146, val_loss=0.0199, av\u001b[A\n",
      "Epoch 6:  68%|▋| 54/80 [00:02<00:00, 26.49it/s, loss=0.0146, val_loss=0.0199, av\n",
      "Epoch 6:  90%|▉| 72/80 [00:02<00:00, 33.39it/s, loss=0.0146, val_loss=0.0199, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 35.92it/s, loss=0.0146, val_loss=0.0171, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 20.34it/s, loss=0.0119, val_loss=0.0171, av\u001b[A\n",
      "Epoch 7:  68%|▋| 54/80 [00:02<00:00, 26.44it/s, loss=0.0119, val_loss=0.0171, av\n",
      "Epoch 7:  90%|▉| 72/80 [00:02<00:00, 33.51it/s, loss=0.0119, val_loss=0.0171, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 35.84it/s, loss=0.0119, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.26it/s, loss=0.00983, val_loss=0.0147, a\u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:02<00:00, 26.35it/s, loss=0.00983, val_loss=0.0147, a\n",
      "Epoch 8:  90%|▉| 72/80 [00:02<00:00, 33.35it/s, loss=0.00983, val_loss=0.0147, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 35.86it/s, loss=0.00983, val_loss=0.0118, a\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00813, val_loss=0.0118, a\u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:02<00:00, 26.36it/s, loss=0.00813, val_loss=0.0118, a\n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 33.27it/s, loss=0.00813, val_loss=0.0118, a\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 35.77it/s, loss=0.00813, val_loss=0.00997, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.80it/s, loss=0.00678, val_loss=0.00997,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:01<00:00, 27.12it/s, loss=0.00678, val_loss=0.00997,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.00678, val_loss=0.00997,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.70it/s, loss=0.00678, val_loss=0.00825,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00572, val_loss=0.00825,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:02<00:00, 26.44it/s, loss=0.00572, val_loss=0.00825,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 33.55it/s, loss=0.00572, val_loss=0.00825,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 35.95it/s, loss=0.00572, val_loss=0.00744,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.37it/s, loss=0.0049, val_loss=0.00744, \u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:02<00:00, 26.47it/s, loss=0.0049, val_loss=0.00744, \n",
      "Epoch 12:  90%|▉| 72/80 [00:02<00:00, 33.37it/s, loss=0.0049, val_loss=0.00744, \u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 35.90it/s, loss=0.0049, val_loss=0.00815, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00427, val_loss=0.00815,\u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:01<00:00, 27.21it/s, loss=0.00427, val_loss=0.00815,\n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 34.24it/s, loss=0.00427, val_loss=0.00815,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 36.79it/s, loss=0.00427, val_loss=0.00563,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 20.35it/s, loss=0.00378, val_loss=0.00563,\u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:02<00:00, 26.36it/s, loss=0.00378, val_loss=0.00563,\n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 33.33it/s, loss=0.00378, val_loss=0.00563,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 35.91it/s, loss=0.00378, val_loss=0.00511,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.0034, val_loss=0.00511, \u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:02<00:00, 26.98it/s, loss=0.0034, val_loss=0.00511, \n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 34.12it/s, loss=0.0034, val_loss=0.00511, \u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 36.58it/s, loss=0.0034, val_loss=0.00458, \u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.0031, val_loss=0.00458, \u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:02<00:00, 26.64it/s, loss=0.0031, val_loss=0.00458, \n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 33.44it/s, loss=0.0031, val_loss=0.00458, \u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 36.01it/s, loss=0.0031, val_loss=0.00571, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 20.81it/s, loss=0.00286, val_loss=0.00571,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:01<00:00, 27.10it/s, loss=0.00286, val_loss=0.00571,\n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 34.08it/s, loss=0.00286, val_loss=0.00571,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 36.67it/s, loss=0.00286, val_loss=0.00587,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00268, val_loss=0.00587,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00268, val_loss=0.00587,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 33.73it/s, loss=0.00268, val_loss=0.00587,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 36.25it/s, loss=0.00268, val_loss=0.00464,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.00252, val_loss=0.00464,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00252, val_loss=0.00464,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 33.76it/s, loss=0.00252, val_loss=0.00464,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 36.26it/s, loss=0.00252, val_loss=0.00411,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.40it/s, loss=0.0024, val_loss=0.00411, \u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:02<00:00, 26.47it/s, loss=0.0024, val_loss=0.00411, \n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 33.52it/s, loss=0.0024, val_loss=0.00411, \u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 36.02it/s, loss=0.0024, val_loss=0.00398, \u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.68it/s, loss=0.00229, val_loss=0.00398,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:02<00:00, 26.97it/s, loss=0.00229, val_loss=0.00398,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 34.03it/s, loss=0.00229, val_loss=0.00398,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00229, val_loss=0.00374,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 20.68it/s, loss=0.0022, val_loss=0.00374, \u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:02<00:00, 26.80it/s, loss=0.0022, val_loss=0.00374, \n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 33.92it/s, loss=0.0022, val_loss=0.00374, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 36.40it/s, loss=0.0022, val_loss=0.0042, a\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00212, val_loss=0.0042, \u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 27.17it/s, loss=0.00212, val_loss=0.0042, \n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 34.26it/s, loss=0.00212, val_loss=0.0042, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.00212, val_loss=0.0037, \u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 20.11it/s, loss=0.00206, val_loss=0.0037, \u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:02<00:00, 26.14it/s, loss=0.00206, val_loss=0.0037, \n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 33.11it/s, loss=0.00206, val_loss=0.0037, \u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 35.59it/s, loss=0.00206, val_loss=0.0035, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.21it/s, loss=0.002, val_loss=0.0035, av\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 27.62it/s, loss=0.002, val_loss=0.0035, av\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 34.82it/s, loss=0.002, val_loss=0.0035, av\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 37.34it/s, loss=0.002, val_loss=0.00369, a\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.00194, val_loss=0.00369,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:02<00:00, 26.76it/s, loss=0.00194, val_loss=0.00369,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 33.88it/s, loss=0.00194, val_loss=0.00369,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00194, val_loss=0.00298,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00189, val_loss=0.00298,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:02<00:00, 26.43it/s, loss=0.00189, val_loss=0.00298,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 33.42it/s, loss=0.00189, val_loss=0.00298,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 35.92it/s, loss=0.00189, val_loss=0.00427,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.00185, val_loss=0.00427,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:02<00:00, 26.07it/s, loss=0.00185, val_loss=0.00427,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 33.01it/s, loss=0.00185, val_loss=0.00427,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 35.57it/s, loss=0.00185, val_loss=0.00274,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.00181, val_loss=0.00274,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:02<00:00, 26.65it/s, loss=0.00181, val_loss=0.00274,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 33.74it/s, loss=0.00181, val_loss=0.00274,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 36.26it/s, loss=0.00181, val_loss=0.00323,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 20.49it/s, loss=0.00177, val_loss=0.00323,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:02<00:00, 26.58it/s, loss=0.00177, val_loss=0.00323,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 33.65it/s, loss=0.00177, val_loss=0.00323,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 36.13it/s, loss=0.00177, val_loss=0.0044, \u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.39it/s, loss=0.00173, val_loss=0.0044, \u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:02<00:00, 26.46it/s, loss=0.00173, val_loss=0.0044, \n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 33.43it/s, loss=0.00173, val_loss=0.0044, \u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 35.76it/s, loss=0.00173, val_loss=0.00254,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 20.06it/s, loss=0.0017, val_loss=0.00254, \u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:02<00:00, 26.18it/s, loss=0.0017, val_loss=0.00254, \n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 32.94it/s, loss=0.0017, val_loss=0.00254, \u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 35.50it/s, loss=0.0017, val_loss=0.00266, \u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.00167, val_loss=0.00266,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:02<00:00, 26.57it/s, loss=0.00167, val_loss=0.00266,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 33.62it/s, loss=0.00167, val_loss=0.00266,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 36.10it/s, loss=0.00167, val_loss=0.00346,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00164, val_loss=0.00346,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 27.12it/s, loss=0.00164, val_loss=0.00346,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.00164, val_loss=0.00346,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.89it/s, loss=0.00164, val_loss=0.00254,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00161, val_loss=0.00254,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:02<00:00, 26.79it/s, loss=0.00161, val_loss=0.00254,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 33.66it/s, loss=0.00161, val_loss=0.00254,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 36.31it/s, loss=0.00161, val_loss=0.00246,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00159, val_loss=0.00246,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:02<00:00, 26.87it/s, loss=0.00159, val_loss=0.00246,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 33.89it/s, loss=0.00159, val_loss=0.00246,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00159, val_loss=0.00257,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 20.82it/s, loss=0.00156, val_loss=0.00257,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:02<00:00, 26.98it/s, loss=0.00156, val_loss=0.00257,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 33.99it/s, loss=0.00156, val_loss=0.00257,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 36.50it/s, loss=0.00156, val_loss=0.00311,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 20.60it/s, loss=0.00154, val_loss=0.00311,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:02<00:00, 26.71it/s, loss=0.00154, val_loss=0.00311,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 33.68it/s, loss=0.00154, val_loss=0.00311,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 36.21it/s, loss=0.00154, val_loss=0.00243,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 20.37it/s, loss=0.00152, val_loss=0.00243,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:02<00:00, 26.21it/s, loss=0.00152, val_loss=0.00243,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 33.29it/s, loss=0.00152, val_loss=0.00243,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 35.73it/s, loss=0.00152, val_loss=0.00276,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.0015, val_loss=0.00276, \u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.0015, val_loss=0.00276, \n",
      "Epoch 40:  90%|▉| 72/80 [00:02<00:00, 34.23it/s, loss=0.0015, val_loss=0.00276, \u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.0015, val_loss=0.00275, \u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.14it/s, loss=0.00148, val_loss=0.00275,\u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:01<00:00, 27.47it/s, loss=0.00148, val_loss=0.00275,\n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 34.52it/s, loss=0.00148, val_loss=0.00275,\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 37.23it/s, loss=0.00148, val_loss=0.00229,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.00146, val_loss=0.00229,\u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00146, val_loss=0.00229,\n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 33.55it/s, loss=0.00146, val_loss=0.00229,\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 36.21it/s, loss=0.00146, val_loss=0.00224,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.00145, val_loss=0.00224,\u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:02<00:00, 26.42it/s, loss=0.00145, val_loss=0.00224,\n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 33.50it/s, loss=0.00145, val_loss=0.00224,\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 35.98it/s, loss=0.00145, val_loss=0.00224,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00143, val_loss=0.00224,\u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:02<00:00, 26.89it/s, loss=0.00143, val_loss=0.00224,\n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 33.88it/s, loss=0.00143, val_loss=0.00224,\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 36.47it/s, loss=0.00143, val_loss=0.00223,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.00142, val_loss=0.00223,\u001b[A\n",
      "Epoch 45:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.00142, val_loss=0.00223,\n",
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 34.21it/s, loss=0.00142, val_loss=0.00223,\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 36.75it/s, loss=0.00142, val_loss=0.00224,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.0014, val_loss=0.00224, \u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.0014, val_loss=0.00224, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.42it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 36.70it/s, loss=0.0014, val_loss=0.00214, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00139, val_loss=0.00214,\u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:02<00:00, 26.94it/s, loss=0.00139, val_loss=0.00214,\n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 34.12it/s, loss=0.00139, val_loss=0.00214,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00139, val_loss=0.00214,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.50it/s, loss=0.00138, val_loss=0.00214,\u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00138, val_loss=0.00214,\n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 33.77it/s, loss=0.00138, val_loss=0.00214,\u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 36.17it/s, loss=0.00138, val_loss=0.00209,\u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.00136, val_loss=0.00209,\u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:02<00:00, 26.86it/s, loss=0.00136, val_loss=0.00209,\n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 33.83it/s, loss=0.00136, val_loss=0.00209,\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 36.39it/s, loss=0.00136, val_loss=0.00208,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00135, val_loss=0.00208,\u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:01<00:00, 27.54it/s, loss=0.00135, val_loss=0.00208,\n",
      "Epoch 50:  90%|▉| 72/80 [00:02<00:00, 34.73it/s, loss=0.00135, val_loss=0.00208,\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 37.28it/s, loss=0.00135, val_loss=0.00209,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 20.31it/s, loss=0.00134, val_loss=0.00209,\u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:02<00:00, 26.38it/s, loss=0.00134, val_loss=0.00209,\n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 33.42it/s, loss=0.00134, val_loss=0.00209,\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 35.91it/s, loss=0.00134, val_loss=0.00214,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.61it/s, loss=0.00133, val_loss=0.00214,\u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:02<00:00, 26.77it/s, loss=0.00133, val_loss=0.00214,\n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 33.86it/s, loss=0.00133, val_loss=0.00214,\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 36.35it/s, loss=0.00133, val_loss=0.00209,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00132, val_loss=0.00209,\u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:01<00:00, 27.10it/s, loss=0.00132, val_loss=0.00209,\n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 34.13it/s, loss=0.00132, val_loss=0.00209,\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 36.69it/s, loss=0.00132, val_loss=0.0021, \u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 20.44it/s, loss=0.00376, val_loss=0.0021, \u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:02<00:00, 26.67it/s, loss=0.00376, val_loss=0.0021, \n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 33.67it/s, loss=0.00376, val_loss=0.0021, \u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.00376, val_loss=0.0217, \u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 21.28it/s, loss=0.00471, val_loss=0.0217, \u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:01<00:00, 27.62it/s, loss=0.00471, val_loss=0.0217, \n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 34.72it/s, loss=0.00471, val_loss=0.0217, \u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 37.42it/s, loss=0.00471, val_loss=0.00265,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00646, val_loss=0.00265,\u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.00646, val_loss=0.00265,\n",
      "Validating:  40%|████████████                  | 16/40 [00:00<00:00, 146.17it/s]\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 35.91it/s, loss=0.00646, val_loss=0.0308, \u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00291, val_loss=0.0308, \u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:01<00:00, 27.02it/s, loss=0.00291, val_loss=0.0308, \n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 34.11it/s, loss=0.00291, val_loss=0.0308, \u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 36.63it/s, loss=0.00291, val_loss=0.00296,\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00132, val_loss=0.00296,\u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:02<00:00, 26.72it/s, loss=0.00132, val_loss=0.00296,\n",
      "Epoch 58:  90%|▉| 72/80 [00:02<00:00, 33.87it/s, loss=0.00132, val_loss=0.00296,\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 36.36it/s, loss=0.00132, val_loss=0.00215,\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.0611, val_loss=0.00215, \u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:02<00:00, 26.57it/s, loss=0.0611, val_loss=0.00215, \n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 33.53it/s, loss=0.0611, val_loss=0.00215, \u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 36.10it/s, loss=0.0611, val_loss=0.0647, a\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.0039, val_loss=0.0647, a\u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:02<00:00, 26.92it/s, loss=0.0039, val_loss=0.0647, a\n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 33.88it/s, loss=0.0039, val_loss=0.0647, a\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 36.47it/s, loss=0.0039, val_loss=0.003, av\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00131, val_loss=0.003, a\u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:02<00:00, 26.55it/s, loss=0.00131, val_loss=0.003, a\n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 33.55it/s, loss=0.00131, val_loss=0.003, a\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.00131, val_loss=0.00216,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.00126, val_loss=0.00216,\u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:01<00:00, 27.37it/s, loss=0.00126, val_loss=0.00216,\n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 34.66it/s, loss=0.00126, val_loss=0.00216,\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00126, val_loss=0.00216,\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.0569, val_loss=0.00216, \u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.0569, val_loss=0.00216, \n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 33.86it/s, loss=0.0569, val_loss=0.00216, \u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 36.29it/s, loss=0.0569, val_loss=0.0462, a\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.17it/s, loss=0.00251, val_loss=0.0462, \u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:01<00:00, 27.58it/s, loss=0.00251, val_loss=0.0462, \n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 34.57it/s, loss=0.00251, val_loss=0.0462, \u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 37.20it/s, loss=0.00251, val_loss=0.00223,\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 20.82it/s, loss=0.00126, val_loss=0.00223,\u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:01<00:00, 27.02it/s, loss=0.00126, val_loss=0.00223,\n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 34.06it/s, loss=0.00126, val_loss=0.00223,\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00126, val_loss=0.00207,\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.0312, val_loss=0.00207, \u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.0312, val_loss=0.00207, \n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 33.94it/s, loss=0.0312, val_loss=0.00207, \u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.0312, val_loss=0.21, avg\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 20.42it/s, loss=0.00589, val_loss=0.21, av\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.00589, val_loss=0.21, av\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 33.48it/s, loss=0.00589, val_loss=0.21, av\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 36.01it/s, loss=0.00589, val_loss=0.0036, \u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.0013, val_loss=0.0036, a\u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:02<00:00, 26.94it/s, loss=0.0013, val_loss=0.0036, a\n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 33.88it/s, loss=0.0013, val_loss=0.0036, a\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 36.49it/s, loss=0.0013, val_loss=0.00208, \u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.20it/s, loss=0.00122, val_loss=0.00208,\u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:01<00:00, 27.52it/s, loss=0.00122, val_loss=0.00208,\n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 34.80it/s, loss=0.00122, val_loss=0.00208,\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 37.31it/s, loss=0.00122, val_loss=0.00204,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.00122, val_loss=0.00204,\u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00122, val_loss=0.00204,\n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 33.69it/s, loss=0.00122, val_loss=0.00204,\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 36.11it/s, loss=0.00122, val_loss=0.00211,\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.107, val_loss=0.00211, a\u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:02<00:00, 26.33it/s, loss=0.107, val_loss=0.00211, a\n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 33.18it/s, loss=0.107, val_loss=0.00211, a\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 35.72it/s, loss=0.107, val_loss=0.0568, av\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00255, val_loss=0.0568, \u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:02<00:00, 26.86it/s, loss=0.00255, val_loss=0.0568, \n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 33.89it/s, loss=0.00255, val_loss=0.0568, \u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00255, val_loss=0.00277,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.00124, val_loss=0.00277,\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:01<00:00, 27.28it/s, loss=0.00124, val_loss=0.00277,\n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 34.43it/s, loss=0.00124, val_loss=0.00277,\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.00124, val_loss=0.00211,\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.106, val_loss=0.00211, a\u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:02<00:00, 26.94it/s, loss=0.106, val_loss=0.00211, a\n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 33.90it/s, loss=0.106, val_loss=0.00211, a\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 36.48it/s, loss=0.106, val_loss=0.012, avg\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 20.99it/s, loss=0.00215, val_loss=0.012, a\u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:01<00:00, 27.13it/s, loss=0.00215, val_loss=0.012, a\n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 34.32it/s, loss=0.00215, val_loss=0.012, a\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.00215, val_loss=0.0025, \u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.83it/s, loss=0.00121, val_loss=0.0025, \u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.00121, val_loss=0.0025, \n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 34.25it/s, loss=0.00121, val_loss=0.0025, \u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00121, val_loss=0.00201,\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 20.34it/s, loss=0.0173, val_loss=0.00201, \u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.0173, val_loss=0.00201, \n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 33.49it/s, loss=0.0173, val_loss=0.00201, \u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 35.98it/s, loss=0.0173, val_loss=0.15, avg\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.0151, val_loss=0.15, avg\u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.0151, val_loss=0.15, avg\n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 34.23it/s, loss=0.0151, val_loss=0.15, avg\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 36.67it/s, loss=0.0151, val_loss=0.0086, a\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 21.24it/s, loss=0.0014, val_loss=0.0086, a\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:01<00:00, 27.57it/s, loss=0.0014, val_loss=0.0086, a\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 34.85it/s, loss=0.0014, val_loss=0.0086, a\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 37.37it/s, loss=0.0014, val_loss=0.00206, \u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.00118, val_loss=0.00206,\u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:02<00:00, 26.78it/s, loss=0.00118, val_loss=0.00206,\n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 33.77it/s, loss=0.00118, val_loss=0.00206,\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 36.34it/s, loss=0.00118, val_loss=0.00188,\u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.00117, val_loss=0.00188,\u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:02<00:00, 26.73it/s, loss=0.00117, val_loss=0.00188,\n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 33.78it/s, loss=0.00117, val_loss=0.00188,\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 36.25it/s, loss=0.00117, val_loss=0.0019, \u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00117, val_loss=0.0019, \u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:01<00:00, 27.09it/s, loss=0.00117, val_loss=0.0019, \n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 34.27it/s, loss=0.00117, val_loss=0.0019, \u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.78it/s, loss=0.00117, val_loss=0.0019, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.61it/s, loss=0.0139, val_loss=0.0019, a\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:02<00:00, 26.73it/s, loss=0.0139, val_loss=0.0019, a\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 33.85it/s, loss=0.0139, val_loss=0.0019, a\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.0139, val_loss=0.158, av\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.27it/s, loss=0.015, val_loss=0.158, avg\u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:02<00:00, 26.31it/s, loss=0.015, val_loss=0.158, avg\n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 33.12it/s, loss=0.015, val_loss=0.158, avg\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 35.67it/s, loss=0.015, val_loss=0.00826, a\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 20.37it/s, loss=0.00137, val_loss=0.00826,\u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:02<00:00, 26.58it/s, loss=0.00137, val_loss=0.00826,\n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 33.54it/s, loss=0.00137, val_loss=0.00826,\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 36.04it/s, loss=0.00137, val_loss=0.00194,\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.00122, val_loss=0.00194,\u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:01<00:00, 27.33it/s, loss=0.00122, val_loss=0.00194,\n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 34.45it/s, loss=0.00122, val_loss=0.00194,\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.00122, val_loss=0.00222,\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.69it/s, loss=0.0552, val_loss=0.00222, \u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.0552, val_loss=0.00222, \n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 33.90it/s, loss=0.0552, val_loss=0.00222, \u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 36.40it/s, loss=0.0552, val_loss=0.0156, a\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00175, val_loss=0.0156, \u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:01<00:00, 27.23it/s, loss=0.00175, val_loss=0.0156, \n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 34.34it/s, loss=0.00175, val_loss=0.0156, \u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 36.84it/s, loss=0.00175, val_loss=0.00192,\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 21.05it/s, loss=0.00116, val_loss=0.00192,\u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:01<00:00, 27.28it/s, loss=0.00116, val_loss=0.00192,\n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 34.44it/s, loss=0.00116, val_loss=0.00192,\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.00116, val_loss=0.00185,\u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 20.33it/s, loss=0.059, val_loss=0.00185, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:02<00:00, 26.31it/s, loss=0.059, val_loss=0.00185, a\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 33.35it/s, loss=0.059, val_loss=0.00185, a\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 35.82it/s, loss=0.059, val_loss=0.0801, av\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00355, val_loss=0.0801, \u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:01<00:00, 27.10it/s, loss=0.00355, val_loss=0.0801, \n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 34.27it/s, loss=0.00355, val_loss=0.0801, \u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 36.78it/s, loss=0.00355, val_loss=0.00247,\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 21.17it/s, loss=0.0012, val_loss=0.00247, \u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:01<00:00, 27.38it/s, loss=0.0012, val_loss=0.00247, \n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 34.56it/s, loss=0.0012, val_loss=0.00247, \u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 37.18it/s, loss=0.0012, val_loss=0.00181, \u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.0131, val_loss=0.00181, \u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:01<00:00, 27.32it/s, loss=0.0131, val_loss=0.00181, \n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 34.29it/s, loss=0.0131, val_loss=0.00181, \u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.0131, val_loss=0.111, av\u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.17it/s, loss=0.0101, val_loss=0.111, av\u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:02<00:00, 26.24it/s, loss=0.0101, val_loss=0.111, av\n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 33.21it/s, loss=0.0101, val_loss=0.111, av\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 35.61it/s, loss=0.0101, val_loss=0.00401, \u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.00132, val_loss=0.00401,\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:01<00:00, 27.26it/s, loss=0.00132, val_loss=0.00401,\n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 34.35it/s, loss=0.00132, val_loss=0.00401,\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 36.88it/s, loss=0.00132, val_loss=0.00188,\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.55it/s, loss=0.0818, val_loss=0.00188, \u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:02<00:00, 26.80it/s, loss=0.0818, val_loss=0.00188, \n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 33.80it/s, loss=0.0818, val_loss=0.00188, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 36.28it/s, loss=0.0818, val_loss=0.0169, a\u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00246, val_loss=0.0169, \u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:01<00:00, 27.20it/s, loss=0.00246, val_loss=0.0169, \n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 34.30it/s, loss=0.00246, val_loss=0.0169, \u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.00246, val_loss=0.0021, \u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00117, val_loss=0.0021, \u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:01<00:00, 27.09it/s, loss=0.00117, val_loss=0.0021, \n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 34.11it/s, loss=0.00117, val_loss=0.0021, \u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 36.66it/s, loss=0.00117, val_loss=0.00178,\u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 21.02it/s, loss=0.118, val_loss=0.00178, a\u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:01<00:00, 27.39it/s, loss=0.118, val_loss=0.00178, a\n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 34.52it/s, loss=0.118, val_loss=0.00178, a\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.118, val_loss=0.0329, av\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.70it/s, loss=0.118, val_loss=0.0329, av\u001b[A\n",
      "Sizes of clusters: 284, 311, 508, 384, 513\n",
      "\n",
      "preds: [2 0 2 0 0 4 4 0 0 0 0 0 2 2 0 4 2 2 4 2 1 0 0 1 2 1 2 0 2 2 0 2 4 2 2 0 0\n",
      " 0 2 3 2 2 2 0 2 2 0 2 0 2 0 0 2 2 0 2 0 0 1 0 4 1 2 2 0 0 2 0 1 2 4 0 1 2\n",
      " 2 1 2 2 2 2 0 0 0 2 1 2 0 0 0 1 0 2 2 0 1 4 4 0 0 1 2 2 2 0 4 2 4 2 2 2 2\n",
      " 1 2 0 2 0 0 2 4 4 4 0 0 1 0 2 0 0 4 2 2 0 3 2 0 2 2 0 2 0 2 0 2 2 2 0 0 1\n",
      " 0 1 0 0 4 2 1 2 2 2 0 2 2 4 0 0 4 1 2 0 0 0 1 1 0 0 2 0 2 1 0 2 0 2 2 4 0\n",
      " 4 2 1 1 2 0 0 2 0 0 2 0 2 2 1 0 2 4 0 2 0 2 2 0 0 0 2 2 2 2 2 0 2 2 2 1 4\n",
      " 0 0 0 2 0 2 2 2 4 2 0 1 4 0 1 0 4 1 1 2 2 2 1 2 0 0 0 2 2 2 4 4 4 4 2 0 0\n",
      " 0 2 2 0 2 0 2 4 2 2 0 2 0 2 0 1 4 2 2 0 1 2 2 0 0 4 2 0 2 0 0 0 4 4 2 1 0\n",
      " 0 4 0 0 2 1 2 2 4 0 0 1 2 2 1 0 4 1 4 0 2 0 0 2 0 1 0 2 2 4 0 2 4 2 1 2 0\n",
      " 1 2 1 1 0 2 2 1 2 2 0 1 2 1 0 2 0 2 0 2 2 0 0 2 1 0 2 0 2 1 2 0 4 0 3 2 2\n",
      " 2 0 2 0 0 2 1 0 2 0 0 0 4 2 2 1 2 0 3 1 2 0 2 2 0 2 0 0 4 2 2 2 0 2 2 2 2\n",
      " 2 2 2 4 0 0 2 0 2 4 0 2 4 2 2 0 2 2 3 2 2 2 4 2 3 0 4 4 1 1 0 1 2 4 0 2 2\n",
      " 2 2 0 2 0 1 1 1 1 2 0 2 2 2 0 1 2 4 2 4 1 2 2 1 4 2 4 2 0 4 0 2 2 4 0 0 1\n",
      " 0 4 2 0 2 4 4 2 1 2 1 2 2 4 0 0 4 4 1 2 2 2 0 1 2 2 0 0 4 0 0 2 2 2 0 2 0\n",
      " 0 2 0 2 3 0 4 2 2 3 2 1 1 0 2 0 2 2 2 2 2 3 4 2 2 2 2 2 2 0 2 2 2 1 0 2 0\n",
      " 2 0 3 2 3 0 0 0 0 4 0 2 2 2 4 1 0 2 3 2 2 0 2 2 0 2 2 4 2 2 2 2 2 2 2 2 2\n",
      " 0 0 2 0 2 2 0 0 2 2 0 0 1 0 2 0 4 1 0 0 2 2 1 1 2 1 3 2 0 0 0 2 0 1 4 3 2\n",
      " 0 4 1 4 0 2 2 4 0 1 2 2 3 2 0 2 2 1 4 0 1 2 0 2 0 2 0 2 2 0 2 2 2 2 2 0 2\n",
      " 4 0 4 4 1 0 0 1 4 4 4 0 2 0 0 2 3 4 0 1 2 1 2 2 2 1 2 2 2 2 2 2 2 0 0 4 2\n",
      " 2 1 0 2 0 0 4 4 0 4 3 2 4 4 2 2 2 0 0 0 0 2 4 1 4 2 2 2 2 4 1 2 0 2 2 1 0\n",
      " 2 2 2 2 4 2 0 0 2 1 0 0 2 2 2 2 2 0 1 2 0 0 2 0 1 0 0 2 2 2 2 2 4 0 3 4 4\n",
      " 2 2 4 0 2 0 1 0 3 2 0 2 4 2 2 0 2 4 2 2 2 1 2 4 3 1 3 3 3 3 4 1 1 1 2 3 1\n",
      " 2 2 3 2 3 3 3 4 2 3 1 3 4 3 3 2 3 4 3 1 3 4 2 3 3 2 3 3 3 4 3 2 2 3 2 1 3\n",
      " 3 4 3 3 2 1 4 3 2 3 1 4 3 1 3 2 4 3 3 1 4 3 3 2 3 2 4 4 3 3 2 3 1 1 1 3 3\n",
      " 1 3 2 1 2 4 3 4 3 4 1 3 4 2 3 2 3 3 3 3 4 3 3 3 3 4 2 4 4 1 3 3 3 4 4 1 3\n",
      " 3 2 4 3 3 1 3 3 3 4 4 2 3 4 3 3 4 4 1 3 3 4 4 4 1 3 3 3 3 3 3 1 4 1 4 4 3\n",
      " 3 4 3 3 3 3 3 3 3 3 3 2 4 3 3 2 4 2 3 3 3 2 3 4 3 3 4 1 2 4 3 2 1 2 3 3 4\n",
      " 4 3 4 3 4 2 1 2 1 3 4 4 1 3 1 3 4 2 1 2 4 3 3 3 4 3 3 3 3 3 4 1 3 3 3 3 4\n",
      " 4 2 3 4 1 4 1 3 2 3 4 1 4 1 3 3 3 4 4 2 4 3 3 3 3 3 2 3 2 2 1 1 2 4 3 3 1\n",
      " 2 3 4 2 4 2 3 1 3 3 3 2 1 4 4 3 4 4 4 1 3 4 4 3 3 3 4 4 3 1 3 3 2 3 1 4 3\n",
      " 3 3 1 3 4 1 3 1 1 4 1 3 3 4 3 3 1 3 2 4 3 3 4 1 1 1 2 3 4 4 4 4 3 3 3 3 2\n",
      " 3 3 4 1 3 1 3 3 3 3 2 3 4 3 3 1 3 1 3 4 3 1 2 3 3 4 3 4 3 3 3 3 2 2 3 1 3\n",
      " 4 2 1 3 3 4 2 3 2 3 3 4 2 4 4 2 4 2 2 4 0 4 4 4 4 4 4 4 4 3 4 3 3 4 2 1 1\n",
      " 1 2 0 1 3 4 2 4 4 4 0 4 2 2 2 2 1 4 0 2 4 4 4 3 1 4 1 4 1 4 4 3 4 2 2 4 2\n",
      " 4 4 2 4 0 4 3 0 1 4 4 4 0 4 0 4 2 4 4 3 1 4 4 2 4 2 1 4 0 4 2 2 1 0 4 4 2\n",
      " 1 1 2 4 1 4 4 4 4 4 0 1 2 1 4 4 4 2 1 2 1 3 2 3 2 4 4 2 4 4 1 1 2 1 4 4 4\n",
      " 3 1 4 3 0 0 4 2 4 1 4 4 4 4 1 3 4 4 1 4 4 4 4 4 1 1 4 4 1 2 2 1 2 4 4 4 1\n",
      " 0 4 4 4 1 1 4 1 2 3 1 4 2 2 4 4 4 1 3 4 4 1 4 4 2 4 3 2 4 4 4 4 2 4 2 2 4\n",
      " 4 4 4 4 3 4 2 4 3 4 1 4 3 2 4 4 2 4 2 4 2 1 4 4 0 1 0 2 4 4 2 1 1 1 2 4 1\n",
      " 1 1 1 2 4 1 2 4 1 1 4 4 0 4 4 2 2 2 0 1 4 2 2 4 1 3 3 4 3 4 4 2 2 4 2 4 4\n",
      " 4 0 4 4 3 1 4 4 4 3 1 3 1 2 4 2 2 4 1 0 4 4 2 1 3 4 1 0 0 4 1 3 3 4 4 1 0\n",
      " 4 4 1 2 4 2 4 4 4 4 2 4 4 0 4 4 3 4 0 0 2 0 4 4 1 1 2 1 4 2 2 2 4 4 2 1 2\n",
      " 3 4 2 0 3 4 4 4 3 1 4 4 4 3 4 4 1 1 1 1 4 1 0 1 1 4 4 1 4 3 0 2 4 4 3 0 1\n",
      " 1 4 1 0 4 3 2 0 1 2 1 2 4 2 3 2 3 3 4 4 3 4 1 2 3 4 2 1 4 1 3 4 3 4 1 3 1\n",
      " 3 4 4 3 3 3 3 3 4 4 1 1 4 1 4 4 2 3 4 4 3 1 3 1 0 3 1 4 4 1 2 4 4 4 1 2 1\n",
      " 1 4 3 1 1 3 4 1 1 4 4 3 1 4 3 1 1 4 3 4 4 1 1 3 4 4 3 3 3 3 1 4 2 4 3 3 4\n",
      " 4 2 1 4 4 4 3 3 3 3 3 0 3 1 4 4 4 3 4 3 3 4 2 3 3 4 1 1 3 3 4 3 1 3 4 4 2\n",
      " 3 1 2 1 4 3 1 4 4 4 3 4 4 4 2 3 4 1 3 2 4 4 3 1 1 3 1 4 4 4 3 3 4 3 3 1 4\n",
      " 1 1 1 3 3 4 4 3 4 4 3 2 4 4 4 4 4 4 1 4 3 3 3 1 4 4 3 2 3 1 1 3 2 3 4 3 3\n",
      " 4 4 1 3 3 4 4 3 3 3 4 4 1 3 3 3 4 1 1 1 1 3 2 4 3 2 4 2 3 3 3 3 3 1 3 3 2\n",
      " 4 3 4 4 1 1 3 3 1 3 3 4 4 4 3 3 3 1 3 3 4 1 4 3 1 2 3 4 4 1 1 3 3 3 2 3 1\n",
      " 1 2 4 4 4 4 3 2 1 3 4 4 1 3 3 4 4 1 1 4 3 3 3 4 4 1 4 3 4 3 4 3 2 3 4 3 3\n",
      " 3 1 3 2 3 2 4 4 4 1 4 1 3 4 4 3 4 4 3 3 3 3 4 4 4 1 3 3 1 3 4 4 3 4 1 4 4\n",
      " 4 1 4 2 3 4 1 3 2 3 3 3 3 4 4 4 4 1 1 3 4 3 1 4 4 3 4 4 4 3 3 4 4 4 4 3 3\n",
      " 4 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3855\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  51%|▌| 41/80 [00:01<00:01, 21.57it/s, loss=1.01, val_loss=0.0808, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  75%|▊| 60/80 [00:02<00:00, 29.83it/s, loss=1.01, val_loss=0.0808, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.11it/s, loss=1.01, val_loss=3.39, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.0662, val_loss=3.39, avg_\u001b[A\n",
      "Epoch 1:  71%|▋| 57/80 [00:02<00:00, 28.48it/s, loss=0.0662, val_loss=3.39, avg_\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 173.12it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 36.85it/s, loss=0.0662, val_loss=0.0827, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.0353, val_loss=0.0827, av\u001b[A\n",
      "Epoch 2:  71%|▋| 57/80 [00:02<00:00, 28.47it/s, loss=0.0353, val_loss=0.0827, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.38it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.0353, val_loss=0.0386, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.0251, val_loss=0.0386, av\u001b[A\n",
      "Epoch 3:  71%|▋| 57/80 [00:02<00:00, 28.39it/s, loss=0.0251, val_loss=0.0386, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.11it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 36.74it/s, loss=0.0251, val_loss=0.0275, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.0184, val_loss=0.0275, av\u001b[A\n",
      "Epoch 4:  71%|▋| 57/80 [00:01<00:00, 28.68it/s, loss=0.0184, val_loss=0.0275, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.50it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.0184, val_loss=0.0208, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.0138, val_loss=0.0208, av\u001b[A\n",
      "Epoch 5:  71%|▋| 57/80 [00:01<00:00, 29.41it/s, loss=0.0138, val_loss=0.0208, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.12it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.0138, val_loss=0.0159, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.0106, val_loss=0.0159, av\u001b[A\n",
      "Epoch 6:  71%|▋| 57/80 [00:02<00:00, 27.78it/s, loss=0.0106, val_loss=0.0159, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.99it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.18it/s, loss=0.0106, val_loss=0.0117, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.00823, val_loss=0.0117, a\u001b[A\n",
      "Epoch 7:  71%|▋| 57/80 [00:02<00:00, 28.10it/s, loss=0.00823, val_loss=0.0117, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 166.41it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 36.48it/s, loss=0.00823, val_loss=0.009, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00653, val_loss=0.009, av\u001b[A\n",
      "Epoch 8:  71%|▋| 57/80 [00:02<00:00, 28.03it/s, loss=0.00653, val_loss=0.009, av\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.48it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 36.32it/s, loss=0.00653, val_loss=0.00717, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00529, val_loss=0.00717, \u001b[A\n",
      "Epoch 9:  71%|▋| 57/80 [00:02<00:00, 28.18it/s, loss=0.00529, val_loss=0.00717, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.80it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00529, val_loss=0.0058, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00438, val_loss=0.0058, \u001b[A\n",
      "Epoch 10:  71%|▋| 57/80 [00:02<00:00, 27.92it/s, loss=0.00438, val_loss=0.0058, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.76it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.18it/s, loss=0.00438, val_loss=0.00481,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00371, val_loss=0.00481,\u001b[A\n",
      "Epoch 11:  71%|▋| 57/80 [00:01<00:00, 28.82it/s, loss=0.00371, val_loss=0.00481,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.67it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 37.26it/s, loss=0.00371, val_loss=0.00413,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.26it/s, loss=0.00321, val_loss=0.00413,\u001b[A\n",
      "Epoch 12:  71%|▋| 57/80 [00:01<00:00, 28.95it/s, loss=0.00321, val_loss=0.00413,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.55it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.42it/s, loss=0.00321, val_loss=0.0036, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00284, val_loss=0.0036, \u001b[A\n",
      "Epoch 13:  71%|▋| 57/80 [00:02<00:00, 27.94it/s, loss=0.00284, val_loss=0.0036, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 172.91it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 36.21it/s, loss=0.00284, val_loss=0.00324,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.00257, val_loss=0.00324,\u001b[A\n",
      "Epoch 14:  71%|▋| 57/80 [00:02<00:00, 28.45it/s, loss=0.00257, val_loss=0.00324,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.79it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 36.79it/s, loss=0.00257, val_loss=0.00301,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00236, val_loss=0.00301,\u001b[A\n",
      "Epoch 15:  71%|▋| 57/80 [00:01<00:00, 28.59it/s, loss=0.00236, val_loss=0.00301,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.31it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00236, val_loss=0.0028, \u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.0022, val_loss=0.0028, a\u001b[A\n",
      "Epoch 16:  71%|▋| 57/80 [00:02<00:00, 28.12it/s, loss=0.0022, val_loss=0.0028, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 156.29it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 36.57it/s, loss=0.0022, val_loss=0.00264, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00208, val_loss=0.00264,\u001b[A\n",
      "Epoch 17:  71%|▋| 57/80 [00:02<00:00, 28.05it/s, loss=0.00208, val_loss=0.00264,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 163.33it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 36.33it/s, loss=0.00208, val_loss=0.00257,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00198, val_loss=0.00257,\u001b[A\n",
      "Epoch 18:  71%|▋| 57/80 [00:02<00:00, 27.55it/s, loss=0.00198, val_loss=0.00257,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 172.88it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 35.71it/s, loss=0.00198, val_loss=0.00245,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 20.45it/s, loss=0.0019, val_loss=0.00245, \u001b[A\n",
      "Epoch 19:  71%|▋| 57/80 [00:02<00:00, 27.89it/s, loss=0.0019, val_loss=0.00245, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.99it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.0019, val_loss=0.00237, \u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.34it/s, loss=0.00184, val_loss=0.00237,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  71%|▋| 57/80 [00:01<00:00, 28.70it/s, loss=0.00184, val_loss=0.00237,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 37.34it/s, loss=0.00184, val_loss=0.00233,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00179, val_loss=0.00233,\u001b[A\n",
      "Epoch 21:  71%|▋| 57/80 [00:02<00:00, 27.97it/s, loss=0.00179, val_loss=0.00233,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 164.85it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 36.41it/s, loss=0.00179, val_loss=0.00226,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 20.37it/s, loss=0.00175, val_loss=0.00226,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  71%|▋| 57/80 [00:02<00:00, 27.50it/s, loss=0.00175, val_loss=0.00226,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 35.75it/s, loss=0.00175, val_loss=0.00222,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.94it/s, loss=0.00171, val_loss=0.00222,\u001b[A\n",
      "Epoch 23:  71%|▋| 57/80 [00:01<00:00, 28.52it/s, loss=0.00171, val_loss=0.00222,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.98it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.90it/s, loss=0.00171, val_loss=0.00218,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00168, val_loss=0.00218,\u001b[A\n",
      "Epoch 24:  71%|▋| 57/80 [00:01<00:00, 28.58it/s, loss=0.00168, val_loss=0.00218,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 170.34it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00168, val_loss=0.00214,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.05it/s, loss=0.00165, val_loss=0.00214,\u001b[A\n",
      "Epoch 25:  71%|▋| 57/80 [00:01<00:00, 28.64it/s, loss=0.00165, val_loss=0.00214,\n",
      "Epoch 25:  95%|▉| 76/80 [00:02<00:00, 36.04it/s, loss=0.00165, val_loss=0.00214,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.00165, val_loss=0.00213,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00162, val_loss=0.00213,\u001b[A\n",
      "Epoch 26:  71%|▋| 57/80 [00:02<00:00, 28.13it/s, loss=0.00162, val_loss=0.00213,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.61it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 36.60it/s, loss=0.00162, val_loss=0.0021, \u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.0016, val_loss=0.0021, a\u001b[A\n",
      "Epoch 27:  71%|▋| 57/80 [00:02<00:00, 28.28it/s, loss=0.0016, val_loss=0.0021, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.68it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 36.69it/s, loss=0.0016, val_loss=0.00207, \u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.23it/s, loss=0.00158, val_loss=0.00207,\u001b[A\n",
      "Epoch 28:  71%|▋| 57/80 [00:01<00:00, 28.92it/s, loss=0.00158, val_loss=0.00207,\n",
      "Epoch 28:  95%|▉| 76/80 [00:02<00:00, 36.35it/s, loss=0.00158, val_loss=0.00207,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.00158, val_loss=0.00205,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.13it/s, loss=0.00156, val_loss=0.00205,\u001b[A\n",
      "Epoch 29:  71%|▋| 57/80 [00:01<00:00, 28.79it/s, loss=0.00156, val_loss=0.00205,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.89it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.21it/s, loss=0.00156, val_loss=0.00204,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 20.95it/s, loss=0.00155, val_loss=0.00204,\u001b[A\n",
      "Epoch 30:  71%|▋| 57/80 [00:02<00:00, 28.50it/s, loss=0.00155, val_loss=0.00204,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.73it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 36.92it/s, loss=0.00155, val_loss=0.00202,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00154, val_loss=0.00202,\u001b[A\n",
      "Epoch 31:  71%|▋| 57/80 [00:02<00:00, 28.45it/s, loss=0.00154, val_loss=0.00202,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.60it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 36.82it/s, loss=0.00154, val_loss=0.00218,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00152, val_loss=0.00218,\u001b[A\n",
      "Epoch 32:  71%|▋| 57/80 [00:01<00:00, 28.84it/s, loss=0.00152, val_loss=0.00218,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.68it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 37.28it/s, loss=0.00152, val_loss=0.00204,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:02<00:02, 19.98it/s, loss=0.00151, val_loss=0.00204,\u001b[A\n",
      "Epoch 33:  71%|▋| 57/80 [00:02<00:00, 27.26it/s, loss=0.00151, val_loss=0.00204,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.37it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 35.41it/s, loss=0.00151, val_loss=0.00199,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.73it/s, loss=0.0015, val_loss=0.00199, \u001b[A\n",
      "Epoch 34:  71%|▋| 57/80 [00:02<00:00, 28.17it/s, loss=0.0015, val_loss=0.00199, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.95it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.52it/s, loss=0.0015, val_loss=0.00198, \u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.98it/s, loss=0.00149, val_loss=0.00198,\u001b[A\n",
      "Epoch 35:  71%|▋| 57/80 [00:02<00:00, 28.47it/s, loss=0.00149, val_loss=0.00198,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 169.55it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 36.84it/s, loss=0.00149, val_loss=0.00196,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.19it/s, loss=0.00149, val_loss=0.00196,\u001b[A\n",
      "Epoch 36:  71%|▋| 57/80 [00:02<00:00, 27.46it/s, loss=0.00149, val_loss=0.00196,\n",
      "Epoch 36:  95%|▉| 76/80 [00:02<00:00, 34.64it/s, loss=0.00149, val_loss=0.00196,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 35.73it/s, loss=0.00149, val_loss=0.00196,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.00147, val_loss=0.00196,\u001b[A\n",
      "Epoch 37:  71%|▋| 57/80 [00:01<00:00, 28.75it/s, loss=0.00147, val_loss=0.00196,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.77it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.17it/s, loss=0.00147, val_loss=0.00194,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.00146, val_loss=0.00194,\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  71%|▋| 57/80 [00:01<00:00, 29.22it/s, loss=0.00146, val_loss=0.00194,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.64it/s, loss=0.00146, val_loss=0.00192,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00145, val_loss=0.00192,\u001b[A\n",
      "Epoch 39:  71%|▋| 57/80 [00:01<00:00, 29.27it/s, loss=0.00145, val_loss=0.00192,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.30it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.77it/s, loss=0.00145, val_loss=0.00191,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00145, val_loss=0.00191,\u001b[A\n",
      "Epoch 40:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00145, val_loss=0.00191,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.66it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.00145, val_loss=0.00192,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.52it/s, loss=0.00143, val_loss=0.00192,\u001b[A\n",
      "Epoch 41:  71%|▋| 57/80 [00:01<00:00, 29.16it/s, loss=0.00143, val_loss=0.00192,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 169.62it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 37.64it/s, loss=0.00143, val_loss=0.00192,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 21.52it/s, loss=0.00142, val_loss=0.00192,\u001b[A\n",
      "Epoch 42:  71%|▋| 57/80 [00:01<00:00, 29.28it/s, loss=0.00142, val_loss=0.00192,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.30it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 37.78it/s, loss=0.00142, val_loss=0.00202,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.00142, val_loss=0.00202,\u001b[A\n",
      "Epoch 43:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.00142, val_loss=0.00202,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.84it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00142, val_loss=0.0023, \u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00142, val_loss=0.0023, \u001b[A\n",
      "Epoch 44:  71%|▋| 57/80 [00:01<00:00, 29.76it/s, loss=0.00142, val_loss=0.0023, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.14it/s]\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.00142, val_loss=0.00189,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00141, val_loss=0.00189,\u001b[A\n",
      "Epoch 45:  71%|▋| 57/80 [00:01<00:00, 29.80it/s, loss=0.00141, val_loss=0.00189,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.97it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00141, val_loss=0.00216,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.0014, val_loss=0.00216, \u001b[A\n",
      "Epoch 46:  71%|▋| 57/80 [00:01<00:00, 29.63it/s, loss=0.0014, val_loss=0.00216, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.35it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.0014, val_loss=0.00195, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00139, val_loss=0.00195,\u001b[A\n",
      "Epoch 47:  71%|▋| 57/80 [00:01<00:00, 29.60it/s, loss=0.00139, val_loss=0.00195,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.76it/s]\u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 38.18it/s, loss=0.00139, val_loss=0.00272,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00138, val_loss=0.00272,\u001b[A\n",
      "Epoch 48:  71%|▋| 57/80 [00:01<00:00, 29.68it/s, loss=0.00138, val_loss=0.00272,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.85it/s]\u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00138, val_loss=0.00192,\u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00138, val_loss=0.00192,\u001b[A\n",
      "Epoch 49:  71%|▋| 57/80 [00:01<00:00, 29.71it/s, loss=0.00138, val_loss=0.00192,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.39it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.00138, val_loss=0.00248,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00137, val_loss=0.00248,\u001b[A\n",
      "Epoch 50:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00137, val_loss=0.00248,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.48it/s]\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00137, val_loss=0.00264,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00137, val_loss=0.00264,\u001b[A\n",
      "Epoch 51:  71%|▋| 57/80 [00:01<00:00, 29.56it/s, loss=0.00137, val_loss=0.00264,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 166.94it/s]\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00137, val_loss=0.00202,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.00136, val_loss=0.00202,\u001b[A\n",
      "Epoch 52:  71%|▋| 57/80 [00:01<00:00, 29.43it/s, loss=0.00136, val_loss=0.00202,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.00it/s]\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00136, val_loss=0.00237,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00136, val_loss=0.00237,\u001b[A\n",
      "Epoch 53:  71%|▋| 57/80 [00:01<00:00, 29.49it/s, loss=0.00136, val_loss=0.00237,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.46it/s]\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.00136, val_loss=0.00278,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 21.55it/s, loss=0.00136, val_loss=0.00278,\u001b[A\n",
      "Epoch 54:  71%|▋| 57/80 [00:01<00:00, 29.32it/s, loss=0.00136, val_loss=0.00278,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.23it/s]\u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 37.85it/s, loss=0.00136, val_loss=0.00232,\u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.0721, val_loss=0.00232, \u001b[A\n",
      "Epoch 55:  71%|▋| 57/80 [00:01<00:00, 29.69it/s, loss=0.0721, val_loss=0.00232, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.78it/s]\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.0721, val_loss=0.0524, a\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.00314, val_loss=0.0524, \u001b[A\n",
      "Epoch 56:  71%|▋| 57/80 [00:01<00:00, 29.37it/s, loss=0.00314, val_loss=0.0524, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.12it/s]\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 37.89it/s, loss=0.00314, val_loss=0.0106, \u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00135, val_loss=0.0106, \u001b[A\n",
      "Epoch 57:  71%|▋| 57/80 [00:01<00:00, 29.58it/s, loss=0.00135, val_loss=0.0106, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.15it/s]\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.00135, val_loss=0.00182,\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00131, val_loss=0.00182,\u001b[A\n",
      "Epoch 58:  71%|▋| 57/80 [00:01<00:00, 29.59it/s, loss=0.00131, val_loss=0.00182,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.33it/s]\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 38.17it/s, loss=0.00131, val_loss=0.00307,\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00131, val_loss=0.00307,\u001b[A\n",
      "Epoch 59:  71%|▋| 57/80 [00:01<00:00, 29.76it/s, loss=0.00131, val_loss=0.00307,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.18it/s]\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00131, val_loss=0.00185,\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00131, val_loss=0.00185,\u001b[A\n",
      "Epoch 60:  71%|▋| 57/80 [00:01<00:00, 29.78it/s, loss=0.00131, val_loss=0.00185,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.90it/s]\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00131, val_loss=0.00383,\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00132, val_loss=0.00383,\u001b[A\n",
      "Epoch 61:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.00132, val_loss=0.00383,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.72it/s]\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00132, val_loss=0.00508,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.0385, val_loss=0.00508, \u001b[A\n",
      "Epoch 62:  71%|▋| 57/80 [00:01<00:00, 29.79it/s, loss=0.0385, val_loss=0.00508, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.60it/s]\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.0385, val_loss=0.039, av\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00163, val_loss=0.039, a\u001b[A\n",
      "Epoch 63:  71%|▋| 57/80 [00:01<00:00, 29.68it/s, loss=0.00163, val_loss=0.039, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.97it/s]\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00163, val_loss=0.0121, \u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00129, val_loss=0.0121, \u001b[A\n",
      "Epoch 64:  71%|▋| 57/80 [00:01<00:00, 29.64it/s, loss=0.00129, val_loss=0.0121, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.01it/s]\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00129, val_loss=0.00547,\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.0455, val_loss=0.00547, \u001b[A\n",
      "Epoch 65:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.0455, val_loss=0.00547, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.07it/s]\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.0455, val_loss=0.0524, a\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00334, val_loss=0.0524, \u001b[A\n",
      "Epoch 66:  71%|▋| 57/80 [00:01<00:00, 29.66it/s, loss=0.00334, val_loss=0.0524, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.55it/s]\u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00334, val_loss=0.00324,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00131, val_loss=0.00324,\u001b[A\n",
      "Epoch 67:  71%|▋| 57/80 [00:01<00:00, 29.64it/s, loss=0.00131, val_loss=0.00324,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.10it/s]\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.00131, val_loss=0.0019, \u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.00127, val_loss=0.0019, \u001b[A\n",
      "Epoch 68:  71%|▋| 57/80 [00:01<00:00, 29.67it/s, loss=0.00127, val_loss=0.0019, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.74it/s]\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00127, val_loss=0.00243,\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00126, val_loss=0.00243,\u001b[A\n",
      "Epoch 69:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00126, val_loss=0.00243,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.42it/s]\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00126, val_loss=0.00264,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.0359, val_loss=0.00264, \u001b[A\n",
      "Epoch 70:  71%|▋| 57/80 [00:01<00:00, 29.62it/s, loss=0.0359, val_loss=0.00264, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.62it/s]\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 38.20it/s, loss=0.0359, val_loss=0.265, av\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00778, val_loss=0.265, a\u001b[A\n",
      "Epoch 71:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00778, val_loss=0.265, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.98it/s]\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.00778, val_loss=0.023, a\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00136, val_loss=0.023, a\u001b[A\n",
      "Epoch 72:  71%|▋| 57/80 [00:01<00:00, 29.56it/s, loss=0.00136, val_loss=0.023, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.56it/s]\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00136, val_loss=0.0117, \u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 21.62it/s, loss=0.00124, val_loss=0.0117, \u001b[A\n",
      "Epoch 73:  71%|▋| 57/80 [00:01<00:00, 29.40it/s, loss=0.00124, val_loss=0.0117, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.75it/s]\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00124, val_loss=0.0017, \u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 21.50it/s, loss=0.00124, val_loss=0.0017, \u001b[A\n",
      "Epoch 74:  71%|▋| 57/80 [00:01<00:00, 29.25it/s, loss=0.00124, val_loss=0.0017, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.66it/s]\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 37.77it/s, loss=0.00124, val_loss=0.00193,\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.0728, val_loss=0.00193, \u001b[A\n",
      "Epoch 75:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.0728, val_loss=0.00193, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.41it/s]\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.0728, val_loss=0.0278, a\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00212, val_loss=0.0278, \u001b[A\n",
      "Epoch 76:  71%|▋| 57/80 [00:01<00:00, 29.62it/s, loss=0.00212, val_loss=0.0278, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.06it/s]\u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00212, val_loss=0.00379,\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00125, val_loss=0.00379,\u001b[A\n",
      "Epoch 77:  71%|▋| 57/80 [00:01<00:00, 29.87it/s, loss=0.00125, val_loss=0.00379,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.71it/s]\u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.00125, val_loss=0.0193, \u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.0784, val_loss=0.0193, a\u001b[A\n",
      "Epoch 78:  71%|▋| 57/80 [00:01<00:00, 29.62it/s, loss=0.0784, val_loss=0.0193, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 173.39it/s]\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.0784, val_loss=0.0824, a\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00204, val_loss=0.0824, \u001b[A\n",
      "Epoch 79:  71%|▋| 57/80 [00:01<00:00, 29.60it/s, loss=0.00204, val_loss=0.0824, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.43it/s]\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 38.19it/s, loss=0.00204, val_loss=0.00259,\u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00123, val_loss=0.00259,\u001b[A\n",
      "Epoch 80:  71%|▋| 57/80 [00:01<00:00, 29.67it/s, loss=0.00123, val_loss=0.00259,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.63it/s]\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00123, val_loss=0.061, a\u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00121, val_loss=0.061, a\u001b[A\n",
      "Epoch 81:  71%|▋| 57/80 [00:01<00:00, 29.56it/s, loss=0.00121, val_loss=0.061, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.73it/s]\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00121, val_loss=0.0271, \u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00122, val_loss=0.0271, \u001b[A\n",
      "Epoch 82:  71%|▋| 57/80 [00:01<00:00, 29.74it/s, loss=0.00122, val_loss=0.0271, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.74it/s]\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00122, val_loss=0.0251, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.163, val_loss=0.0251, av\u001b[A\n",
      "Epoch 83:  71%|▋| 57/80 [00:01<00:00, 29.75it/s, loss=0.163, val_loss=0.0251, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.30it/s]\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.163, val_loss=1.22, avg_\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00256, val_loss=1.22, av\u001b[A\n",
      "Epoch 84:  71%|▋| 57/80 [00:01<00:00, 29.49it/s, loss=0.00256, val_loss=1.22, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.90it/s]\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00256, val_loss=0.00296,\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.00122, val_loss=0.00296,\u001b[A\n",
      "Epoch 85:  71%|▋| 57/80 [00:01<00:00, 29.67it/s, loss=0.00122, val_loss=0.00296,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.03it/s]\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.00122, val_loss=0.00176,\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00121, val_loss=0.00176,\u001b[A\n",
      "Epoch 86:  71%|▋| 57/80 [00:01<00:00, 29.30it/s, loss=0.00121, val_loss=0.00176,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.11it/s]\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 37.82it/s, loss=0.00121, val_loss=0.00213,\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.0078, val_loss=0.00213, \u001b[A\n",
      "Epoch 87:  71%|▋| 57/80 [00:01<00:00, 29.60it/s, loss=0.0078, val_loss=0.00213, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.46it/s]\u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 38.17it/s, loss=0.0078, val_loss=0.112, av\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.0151, val_loss=0.112, av\u001b[A\n",
      "Epoch 88:  71%|▋| 57/80 [00:01<00:00, 29.45it/s, loss=0.0151, val_loss=0.112, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.33it/s]\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.0151, val_loss=0.0239, a\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.0014, val_loss=0.0239, a\u001b[A\n",
      "Epoch 89:  71%|▋| 57/80 [00:01<00:00, 29.66it/s, loss=0.0014, val_loss=0.0239, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.77it/s]\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.0014, val_loss=0.00954, \u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.0012, val_loss=0.00954, \u001b[A\n",
      "Epoch 90:  71%|▋| 57/80 [00:01<00:00, 29.63it/s, loss=0.0012, val_loss=0.00954, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.21it/s]\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.0012, val_loss=0.0237, a\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.113, val_loss=0.0237, av\u001b[A\n",
      "Epoch 91:  71%|▋| 57/80 [00:01<00:00, 29.62it/s, loss=0.113, val_loss=0.0237, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.72it/s]\u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.113, val_loss=0.0498, av\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00226, val_loss=0.0498, \u001b[A\n",
      "Epoch 92:  71%|▋| 57/80 [00:01<00:00, 29.58it/s, loss=0.00226, val_loss=0.0498, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.62it/s]\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00226, val_loss=0.0114, \u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00121, val_loss=0.0114, \u001b[A\n",
      "Epoch 93:  71%|▋| 57/80 [00:01<00:00, 29.68it/s, loss=0.00121, val_loss=0.0114, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.25it/s]\u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00121, val_loss=0.0857, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 21.40it/s, loss=0.112, val_loss=0.0857, av\u001b[A\n",
      "Epoch 94:  71%|▋| 57/80 [00:01<00:00, 29.13it/s, loss=0.112, val_loss=0.0857, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.71it/s]\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 37.62it/s, loss=0.112, val_loss=0.0331, av\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00221, val_loss=0.0331, \u001b[A\n",
      "Epoch 95:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00221, val_loss=0.0331, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.19it/s]\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00221, val_loss=0.00428,\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 21.57it/s, loss=0.00119, val_loss=0.00428,\u001b[A\n",
      "Epoch 96:  71%|▋| 57/80 [00:01<00:00, 29.35it/s, loss=0.00119, val_loss=0.00428,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.08it/s]\u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 37.79it/s, loss=0.00119, val_loss=0.234, a\u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.011, val_loss=0.234, avg\u001b[A\n",
      "Epoch 97:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.011, val_loss=0.234, avg\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.11it/s]\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.011, val_loss=0.15, avg_\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00849, val_loss=0.15, av\u001b[A\n",
      "Epoch 98:  71%|▋| 57/80 [00:01<00:00, 29.68it/s, loss=0.00849, val_loss=0.15, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.21it/s]\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00849, val_loss=0.0738, \u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00128, val_loss=0.0738, \u001b[A\n",
      "Epoch 99:  71%|▋| 57/80 [00:01<00:00, 29.61it/s, loss=0.00128, val_loss=0.0738, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.58it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 38.20it/s, loss=0.00128, val_loss=0.00382,\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00128, val_loss=0.00382,\u001b[A\n",
      "Sizes of clusters: 317, 669, 565, 113, 336\n",
      "\n",
      "preds: [2 3 0 3 3 1 1 0 3 3 0 3 2 0 0 1 0 2 2 2 2 3 0 2 2 2 0 0 2 2 0 0 1 0 0 0 3\n",
      " 3 0 4 0 0 2 3 0 0 3 0 3 0 3 0 0 0 3 0 3 0 2 0 1 2 0 0 3 3 0 0 2 0 1 0 2 0\n",
      " 0 2 2 0 2 2 0 3 0 0 2 2 3 3 0 2 3 0 2 3 2 1 2 3 3 2 2 0 0 3 1 0 1 0 2 0 0\n",
      " 2 2 0 0 0 3 3 1 1 2 0 3 2 3 0 0 3 1 0 0 3 1 3 3 2 0 3 0 3 2 3 0 0 0 3 3 2\n",
      " 0 2 0 3 2 2 2 0 3 0 3 0 0 4 3 3 1 2 0 3 0 3 2 2 3 0 0 3 2 2 0 0 0 2 2 2 3\n",
      " 1 0 2 2 0 3 3 0 0 3 2 0 0 0 2 3 0 1 3 0 3 0 0 3 0 3 0 0 2 2 0 3 2 2 0 2 1\n",
      " 0 3 3 0 0 0 0 0 1 0 3 2 1 3 2 0 2 2 2 0 0 0 2 0 0 0 3 0 0 0 1 2 1 1 0 3 0\n",
      " 3 0 0 0 0 0 0 1 0 0 3 0 3 0 3 2 2 0 0 3 2 0 2 3 3 1 0 0 0 3 3 0 1 1 2 2 0\n",
      " 0 1 3 0 3 2 0 2 1 3 0 2 2 0 2 0 1 2 1 3 0 3 3 0 0 2 0 0 0 1 3 2 1 0 2 2 3\n",
      " 2 0 2 2 0 2 0 2 2 0 3 2 0 2 3 0 3 0 3 0 0 3 3 0 2 0 0 3 0 2 0 3 2 3 1 0 0\n",
      " 0 3 0 0 0 0 2 0 0 0 3 3 2 0 2 2 0 0 4 2 0 0 2 0 0 0 0 3 1 0 1 1 0 2 2 0 2\n",
      " 1 1 1 4 2 0 1 0 2 4 2 2 1 2 2 0 2 2 4 1 2 2 4 2 4 0 4 1 2 1 3 2 2 1 0 1 1\n",
      " 2 1 2 1 2 1 2 1 1 2 0 2 2 1 2 2 2 1 1 1 2 2 2 2 4 2 1 2 0 1 2 2 1 4 3 0 1\n",
      " 0 4 2 3 2 1 1 1 1 0 2 2 2 1 0 0 1 4 2 2 2 2 2 2 2 2 2 0 4 3 2 2 2 2 0 2 0\n",
      " 0 2 0 2 4 0 1 1 2 4 1 2 2 3 2 0 2 1 2 1 1 4 4 2 2 2 1 1 1 2 2 2 0 2 0 2 0\n",
      " 1 3 4 2 4 2 2 0 0 4 0 1 1 2 1 1 2 2 4 2 1 0 2 2 0 2 1 1 1 1 1 1 2 2 1 2 1\n",
      " 2 0 0 0 2 2 2 0 1 2 0 0 1 2 0 2 1 1 0 2 2 1 1 2 2 2 4 1 2 0 0 2 0 1 1 4 1\n",
      " 0 1 1 4 0 2 2 1 0 1 1 1 4 0 0 1 2 1 4 0 2 1 0 1 2 2 0 1 1 0 2 2 1 1 1 0 2\n",
      " 1 0 4 1 1 0 2 2 1 4 1 0 2 0 0 1 4 1 0 1 0 1 1 1 2 1 1 0 1 2 2 2 1 0 2 1 1\n",
      " 2 1 2 2 2 0 1 1 2 1 4 2 1 4 2 2 2 0 0 3 0 1 1 1 4 2 1 1 2 1 2 1 0 2 2 1 0\n",
      " 1 2 2 1 1 1 3 0 2 1 0 3 2 1 2 2 1 0 2 1 0 0 1 0 1 0 0 1 1 2 1 1 1 0 4 1 1\n",
      " 1 2 4 0 2 0 1 0 4 2 3 2 4 2 1 0 2 4 2 2 1 2 2 1 4 1 4 4 4 4 1 1 2 2 0 1 2\n",
      " 2 2 1 2 4 4 1 1 2 4 2 1 4 4 4 1 4 1 4 2 4 1 2 1 4 2 4 4 4 1 4 2 2 4 2 2 1\n",
      " 4 4 4 4 2 2 1 4 2 1 1 1 4 2 4 2 1 4 4 1 1 4 1 2 4 2 1 4 4 1 0 4 2 1 2 4 1\n",
      " 1 4 2 2 2 1 4 1 1 1 2 4 1 2 1 2 4 4 1 1 1 4 4 1 4 4 0 1 1 2 1 4 1 1 1 2 1\n",
      " 4 2 1 4 4 2 4 4 4 1 1 2 4 1 4 4 1 1 2 4 4 1 1 1 1 4 1 4 4 4 4 2 1 2 1 1 4\n",
      " 4 1 4 4 1 4 4 4 1 4 4 1 1 1 4 2 1 2 4 4 4 2 4 1 4 1 4 1 2 1 4 2 2 2 4 1 4\n",
      " 1 4 1 4 1 2 2 2 2 1 1 1 2 4 2 4 1 2 2 2 1 1 4 4 1 4 4 4 4 4 1 2 4 4 4 1 1\n",
      " 1 2 4 1 2 1 2 4 2 4 1 2 1 2 4 1 4 1 1 0 1 1 4 4 4 4 2 4 1 2 2 2 2 1 4 4 1\n",
      " 2 4 1 2 1 2 4 2 4 4 4 2 2 1 1 1 1 1 4 2 1 1 1 4 4 4 1 4 4 2 4 1 0 4 2 1 4\n",
      " 4 4 2 4 1 2 4 1 2 4 2 4 4 4 1 4 1 4 2 4 4 4 1 1 1 2 2 4 1 1 4 1 1 4 4 4 2\n",
      " 4 4 1 1 4 2 4 4 4 4 2 4 1 4 4 2 4 2 4 1 4 1 2 4 1 1 4 1 4 4 4 4 2 2 4 2 4\n",
      " 1 2 2 1 1 1 2 4 2 4 4 1 2 1 1 2 1 2 2 1 0 1 4 1 1 1 1 1 1 4 1 1 4 1 0 1 2\n",
      " 2 2 0 2 4 1 0 1 1 1 0 2 2 2 2 0 2 1 3 2 1 1 1 4 2 1 2 1 2 1 1 4 1 2 0 1 2\n",
      " 1 1 2 1 0 1 4 0 2 1 1 1 0 4 0 1 0 1 1 4 2 1 1 2 1 0 2 1 3 1 2 0 0 3 1 1 2\n",
      " 2 2 2 1 2 1 1 1 1 1 3 2 0 2 1 1 1 2 2 2 2 4 2 1 2 1 1 0 1 1 2 2 2 2 1 4 1\n",
      " 1 2 1 4 0 0 1 2 1 1 1 1 1 1 2 1 1 1 2 1 4 1 1 1 2 2 1 1 2 0 0 2 2 1 1 1 2\n",
      " 0 1 1 1 2 2 1 2 0 1 2 1 2 0 1 4 1 2 4 1 1 2 1 1 0 1 1 2 1 1 4 1 2 1 2 2 1\n",
      " 1 1 1 1 4 1 2 2 4 1 2 1 4 2 1 1 0 1 0 1 0 2 1 1 0 2 0 2 1 1 2 2 2 2 2 1 2\n",
      " 2 2 2 2 1 2 2 1 1 2 1 1 0 1 1 0 2 0 3 2 1 2 2 1 2 4 4 1 1 1 1 2 2 1 0 1 1\n",
      " 1 0 1 1 4 2 1 1 1 4 2 4 2 2 1 2 2 1 2 3 1 1 2 1 4 1 2 3 0 1 2 4 4 1 1 2 0\n",
      " 1 1 2 0 4 2 1 1 1 1 2 1 1 3 1 1 1 1 0 0 0 0 1 1 2 2 2 2 1 2 2 0 1 1 2 2 2\n",
      " 4 1 2 0 4 1 1 1 4 2 1 1 1 4 1 1 2 2 2 2 1 2 0 2 2 4 1 2 1 4 0 2 1 1 1 0 2\n",
      " 2 1 1 0 1 4 2 3 2 2 2 2 1 2 4 0 1 1 1 1 4 1 2 0 4 1 2 2 1 2 4 1 4 1 1 4 2\n",
      " 4 1 1 4 1 4 4 4 1 1 2 2 1 2 1 1 0 4 1 1 1 2 4 2 0 4 2 1 1 2 0 1 1 1 2 0 2\n",
      " 2 2 1 2 2 4 1 2 2 1 1 1 2 1 4 2 2 1 4 1 1 2 2 4 1 1 1 4 4 4 2 1 2 1 4 1 1\n",
      " 1 2 2 4 1 1 4 1 1 4 4 3 4 2 1 1 1 4 1 1 4 1 2 1 4 1 2 2 1 4 2 1 2 4 1 1 2\n",
      " 4 2 2 2 1 4 2 1 1 1 1 1 1 1 2 4 1 2 4 2 1 1 4 2 2 4 2 1 1 1 1 4 4 4 4 2 1\n",
      " 2 2 2 1 4 1 1 4 1 1 4 0 1 1 1 1 4 1 2 1 1 1 4 2 1 1 4 2 4 2 2 4 2 1 4 1 4\n",
      " 1 1 2 1 4 1 1 4 1 4 1 1 2 4 4 1 1 2 2 2 2 4 2 1 4 2 1 0 4 1 4 4 4 2 4 4 0\n",
      " 1 4 4 1 2 2 1 1 1 4 4 1 1 1 1 4 4 2 4 4 1 2 1 4 2 0 4 1 1 2 2 4 4 4 2 1 2\n",
      " 2 0 1 1 1 1 4 2 2 1 1 1 1 4 4 1 1 2 2 1 4 4 4 1 1 2 1 1 1 4 1 1 2 4 1 4 4\n",
      " 4 2 1 0 4 0 1 1 1 2 1 2 1 1 1 1 1 1 4 4 1 1 1 1 1 2 4 4 2 4 1 1 1 1 2 1 1\n",
      " 1 1 1 2 1 1 2 4 2 1 1 4 4 1 1 2 1 2 2 1 1 1 2 1 1 4 1 1 1 1 4 1 1 2 1 1 4\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.4255\r\n",
      "Purity: 0.39690000000000003+-0.03163131359902715\r\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K5_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 19.69it/s, loss=144, val_loss=0.0434, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 34.81it/s, loss=144, val_loss=2.44, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 20.20it/s, loss=2.53, val_loss=2.44, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 35.21it/s, loss=2.53, val_loss=0.906, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 20.51it/s, loss=0.45, val_loss=0.906, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 35.98it/s, loss=0.45, val_loss=0.341, avg_v\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 18.42it/s, loss=0.121, val_loss=0.341, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 32.78it/s, loss=0.121, val_loss=0.101, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 19.96it/s, loss=0.0456, val_loss=0.101, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 34.83it/s, loss=0.0456, val_loss=0.039, avg\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 20.12it/s, loss=0.0287, val_loss=0.039, avg\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 35.52it/s, loss=0.0287, val_loss=0.0289, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 19.70it/s, loss=0.0239, val_loss=0.0289, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 34.75it/s, loss=0.0239, val_loss=0.0268, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 20.40it/s, loss=0.0216, val_loss=0.0268, av\n",
      "Epoch 7:  62%|▋| 20/32 [00:00<00:00, 24.74it/s, loss=0.0216, val_loss=0.0268, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 35.40it/s, loss=0.0216, val_loss=0.0253, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 20.67it/s, loss=0.0201, val_loss=0.0253, av\u001b[A\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 36.34it/s, loss=0.0201, val_loss=0.0236, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 20.96it/s, loss=0.0189, val_loss=0.0236, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 36.86it/s, loss=0.0189, val_loss=0.0224, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 22.16it/s, loss=0.0179, val_loss=0.0224, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.63it/s, loss=0.0179, val_loss=0.0214, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.0171, val_loss=0.0214, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.45it/s, loss=0.0171, val_loss=0.0205, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0163, val_loss=0.0205, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.0163, val_loss=0.0196, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 20.99it/s, loss=0.0156, val_loss=0.0196, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 36.91it/s, loss=0.0156, val_loss=0.0189, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.03it/s, loss=0.015, val_loss=0.0189, av\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 36.96it/s, loss=0.015, val_loss=0.0181, av\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 20.56it/s, loss=0.0144, val_loss=0.0181, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 36.21it/s, loss=0.0144, val_loss=0.0174, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=0.0139, val_loss=0.0174, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 36.04it/s, loss=0.0139, val_loss=0.0168, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 20.40it/s, loss=0.0134, val_loss=0.0168, a\n",
      "Epoch 17:  62%|▋| 20/32 [00:00<00:00, 24.69it/s, loss=0.0134, val_loss=0.0168, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 35.63it/s, loss=0.0134, val_loss=0.0163, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.013, val_loss=0.0163, av\u001b[A\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 35.59it/s, loss=0.013, val_loss=0.0157, av\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0126, val_loss=0.0157, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.96it/s, loss=0.0126, val_loss=0.0152, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.0122, val_loss=0.0152, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.43it/s, loss=0.0122, val_loss=0.0147, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0118, val_loss=0.0147, a\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.0118, val_loss=0.0143, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.52it/s, loss=0.0115, val_loss=0.0143, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.60it/s, loss=0.0115, val_loss=0.0139, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 20.68it/s, loss=0.0112, val_loss=0.0139, a\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 36.22it/s, loss=0.0112, val_loss=0.0135, a\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 20.15it/s, loss=0.0109, val_loss=0.0135, a\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 35.61it/s, loss=0.0109, val_loss=0.0132, a\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 20.87it/s, loss=0.0107, val_loss=0.0132, a\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 36.41it/s, loss=0.0107, val_loss=0.0129, a\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 20.67it/s, loss=0.0104, val_loss=0.0129, a\n",
      "Epoch 26:  62%|▋| 20/32 [00:00<00:00, 25.03it/s, loss=0.0104, val_loss=0.0129, a\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 35.98it/s, loss=0.0104, val_loss=0.0126, a\u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 19.97it/s, loss=0.0102, val_loss=0.0126, a\u001b[A\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 35.23it/s, loss=0.0102, val_loss=0.0124, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.00998, val_loss=0.0124, \n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.11it/s, loss=0.00998, val_loss=0.0121, \n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 22.17it/s, loss=0.00978, val_loss=0.0121, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00978, val_loss=0.0119, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.0096, val_loss=0.0119, a\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.0096, val_loss=0.0118, a\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.07it/s, loss=0.00943, val_loss=0.0118, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 36.96it/s, loss=0.00943, val_loss=0.0116, \n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.35it/s, loss=0.00927, val_loss=0.0116, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.43it/s, loss=0.00927, val_loss=0.0114, \n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.20it/s, loss=0.00912, val_loss=0.0114, \n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.14it/s, loss=0.00912, val_loss=0.0113, \n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 19.97it/s, loss=0.00899, val_loss=0.0113, \n",
      "Epoch 34:  62%|▋| 20/32 [00:00<00:00, 24.46it/s, loss=0.00899, val_loss=0.0113, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 35.11it/s, loss=0.00899, val_loss=0.0111, \u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 18.93it/s, loss=0.00886, val_loss=0.0111, \u001b[A\n",
      "Epoch 35:  62%|▋| 20/32 [00:00<00:00, 23.07it/s, loss=0.00886, val_loss=0.0111, \n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 32.86it/s, loss=0.00886, val_loss=0.011, a\u001b[A\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 19.65it/s, loss=0.00874, val_loss=0.011, a\u001b[A\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 34.79it/s, loss=0.00874, val_loss=0.0109, \n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.00864, val_loss=0.0109, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 35.82it/s, loss=0.00864, val_loss=0.0108, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 20.47it/s, loss=0.00854, val_loss=0.0108, \n",
      "Epoch 38:  62%|▋| 20/32 [00:00<00:00, 25.16it/s, loss=0.00854, val_loss=0.0108, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.00854, val_loss=0.0107, \u001b[A\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 20.28it/s, loss=0.00844, val_loss=0.0107, \u001b[A\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 35.71it/s, loss=0.00844, val_loss=0.0106, \n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 19.76it/s, loss=0.00836, val_loss=0.0106, \n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 34.60it/s, loss=0.00836, val_loss=0.0106, \n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 19.00it/s, loss=0.00828, val_loss=0.0106, \n",
      "Epoch 41:  62%|▋| 20/32 [00:00<00:00, 23.27it/s, loss=0.00828, val_loss=0.0106, \n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 32.34it/s, loss=0.00828, val_loss=0.0105, \u001b[A\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 18.45it/s, loss=0.0082, val_loss=0.0105, a\u001b[A\n",
      "Epoch 42:  62%|▋| 20/32 [00:00<00:00, 22.55it/s, loss=0.0082, val_loss=0.0105, a\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 32.52it/s, loss=0.0082, val_loss=0.0104, a\u001b[A\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 19.94it/s, loss=0.00813, val_loss=0.0104, \u001b[A\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 35.25it/s, loss=0.00813, val_loss=0.0104, \n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 21.10it/s, loss=0.00807, val_loss=0.0104, \n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 37.07it/s, loss=0.00807, val_loss=0.0103, \n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 20.76it/s, loss=0.00801, val_loss=0.0103, \n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 36.37it/s, loss=0.00801, val_loss=0.0103, \n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 19.75it/s, loss=0.00796, val_loss=0.0103, \n",
      "Epoch 46:  62%|▋| 20/32 [00:00<00:00, 23.93it/s, loss=0.00796, val_loss=0.0103, \n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 33.06it/s, loss=0.00796, val_loss=0.0102, \u001b[A\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 18.37it/s, loss=0.0079, val_loss=0.0102, a\u001b[A\n",
      "Epoch 47:  62%|▋| 20/32 [00:00<00:00, 22.48it/s, loss=0.0079, val_loss=0.0102, a\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 32.28it/s, loss=0.0079, val_loss=0.0102, a\u001b[A\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 20.41it/s, loss=0.00786, val_loss=0.0102, \u001b[A\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 35.89it/s, loss=0.00786, val_loss=0.0101, \n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 20.09it/s, loss=0.00781, val_loss=0.0101, \n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 35.40it/s, loss=0.00781, val_loss=0.0101, \n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00777, val_loss=0.0101, \n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.00777, val_loss=0.01, av\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00773, val_loss=0.01, av\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00773, val_loss=0.01, av\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00769, val_loss=0.01, av\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.03it/s, loss=0.00769, val_loss=0.00997,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.00766, val_loss=0.00997,\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.00766, val_loss=0.00993,\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.00762, val_loss=0.00993,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00762, val_loss=0.00989,\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 22.07it/s, loss=0.00759, val_loss=0.00989,\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 38.40it/s, loss=0.00759, val_loss=0.00985,\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.00756, val_loss=0.00985,\n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 36.74it/s, loss=0.00756, val_loss=0.00981,\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00753, val_loss=0.00981,\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 37.67it/s, loss=0.00753, val_loss=0.00978,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 20.45it/s, loss=0.00751, val_loss=0.00978,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 35.86it/s, loss=0.00751, val_loss=0.00974,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 20.57it/s, loss=0.00748, val_loss=0.00974,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 35.98it/s, loss=0.00748, val_loss=0.0097, \n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 20.48it/s, loss=0.00746, val_loss=0.0097, \n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 36.09it/s, loss=0.00746, val_loss=0.00967,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 20.54it/s, loss=0.00744, val_loss=0.00967,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.00744, val_loss=0.00963,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 19.80it/s, loss=0.00741, val_loss=0.00963,\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 34.96it/s, loss=0.00741, val_loss=0.00959,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 20.88it/s, loss=0.00739, val_loss=0.00959,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 36.46it/s, loss=0.00739, val_loss=0.00956,\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 20.29it/s, loss=0.00737, val_loss=0.00956,\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 35.21it/s, loss=0.00737, val_loss=0.00952,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 19.71it/s, loss=0.00735, val_loss=0.00952,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 34.71it/s, loss=0.00735, val_loss=0.00949,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 19.63it/s, loss=0.00733, val_loss=0.00949,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 34.45it/s, loss=0.00733, val_loss=0.00945,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 20.82it/s, loss=0.00732, val_loss=0.00945,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 36.50it/s, loss=0.00732, val_loss=0.00942,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 20.26it/s, loss=0.0073, val_loss=0.00942, \n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 35.79it/s, loss=0.0073, val_loss=0.00938, \n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 20.75it/s, loss=0.00728, val_loss=0.00938,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 36.50it/s, loss=0.00728, val_loss=0.00935,\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 20.15it/s, loss=0.00727, val_loss=0.00935,\n",
      "Epoch 70:  62%|▋| 20/32 [00:00<00:00, 24.55it/s, loss=0.00727, val_loss=0.00935,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 34.54it/s, loss=0.00727, val_loss=0.00931,\u001b[A\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 17.95it/s, loss=0.00725, val_loss=0.00931,\u001b[A\n",
      "Epoch 71:  62%|▋| 20/32 [00:00<00:00, 21.83it/s, loss=0.00725, val_loss=0.00931,\n",
      "Epoch 71: 100%|█| 32/32 [00:01<00:00, 31.47it/s, loss=0.00725, val_loss=0.00928,\u001b[A\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 20.40it/s, loss=0.00724, val_loss=0.00928,\u001b[A\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 35.84it/s, loss=0.00724, val_loss=0.00925,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 20.27it/s, loss=0.00722, val_loss=0.00925,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 35.53it/s, loss=0.00722, val_loss=0.00922,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.00721, val_loss=0.00922,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.00721, val_loss=0.00919,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 22.25it/s, loss=0.00719, val_loss=0.00919,\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.67it/s, loss=0.00719, val_loss=0.00916,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.00718, val_loss=0.00916,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 36.99it/s, loss=0.00718, val_loss=0.00913,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 22.16it/s, loss=0.00717, val_loss=0.00913,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 38.66it/s, loss=0.00717, val_loss=0.0091, \n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.40it/s, loss=0.00716, val_loss=0.0091, \n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 37.51it/s, loss=0.00716, val_loss=0.00907,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.00714, val_loss=0.00907,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 37.28it/s, loss=0.00714, val_loss=0.00904,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.00713, val_loss=0.00904,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 36.84it/s, loss=0.00713, val_loss=0.00901,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 19.87it/s, loss=0.00712, val_loss=0.00901,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 34.78it/s, loss=0.00712, val_loss=0.00898,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 20.69it/s, loss=0.00711, val_loss=0.00898,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 36.06it/s, loss=0.00711, val_loss=0.00896,\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 20.87it/s, loss=0.0071, val_loss=0.00896, \n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 36.31it/s, loss=0.0071, val_loss=0.00893, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 19.63it/s, loss=0.00709, val_loss=0.00893,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 34.48it/s, loss=0.00709, val_loss=0.0089, \n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 20.36it/s, loss=0.00708, val_loss=0.0089, \n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 35.90it/s, loss=0.00708, val_loss=0.00887,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 19.54it/s, loss=0.00707, val_loss=0.00887,\n",
      "Epoch 86:  62%|▋| 20/32 [00:00<00:00, 23.76it/s, loss=0.00707, val_loss=0.00887,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 33.62it/s, loss=0.00707, val_loss=0.00884,\u001b[A\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 19.83it/s, loss=0.00706, val_loss=0.00884,\u001b[A\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 35.10it/s, loss=0.00706, val_loss=0.00882,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 20.56it/s, loss=0.00706, val_loss=0.00882,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 36.24it/s, loss=0.00706, val_loss=0.00879,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 21.15it/s, loss=0.00705, val_loss=0.00879,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 37.13it/s, loss=0.00705, val_loss=0.00876,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 20.34it/s, loss=0.00704, val_loss=0.00876,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 35.60it/s, loss=0.00704, val_loss=0.00873,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 20.17it/s, loss=0.00703, val_loss=0.00873,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 35.28it/s, loss=0.00703, val_loss=0.00871,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.00703, val_loss=0.00871,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 35.55it/s, loss=0.00703, val_loss=0.00868,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 20.94it/s, loss=0.00702, val_loss=0.00868,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 36.79it/s, loss=0.00702, val_loss=0.00865,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 20.28it/s, loss=0.00701, val_loss=0.00865,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 35.76it/s, loss=0.00701, val_loss=0.00862,\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 20.01it/s, loss=0.00701, val_loss=0.00862,\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 35.31it/s, loss=0.00701, val_loss=0.0086, \n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 20.20it/s, loss=0.007, val_loss=0.0086, av\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 35.37it/s, loss=0.007, val_loss=0.00858, a\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.00699, val_loss=0.00858,\n",
      "Epoch 97:  62%|▋| 20/32 [00:00<00:00, 25.80it/s, loss=0.00699, val_loss=0.00858,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 36.90it/s, loss=0.00699, val_loss=0.00855,\u001b[A\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.00698, val_loss=0.00855,\u001b[A\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 37.62it/s, loss=0.00698, val_loss=0.00853,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00697, val_loss=0.00853,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00697, val_loss=0.0085, \n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 37.58it/s, loss=0.00697, val_loss=0.0085, \n",
      "Sizes of clusters: 400, 400\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 1.0000\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=141, val_loss=0.0616, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=141, val_loss=4.67, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=1.89, val_loss=4.67, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=1.89, val_loss=10.9, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.342, val_loss=10.9, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.38it/s, loss=0.342, val_loss=3.34, avg_v\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 20.97it/s, loss=0.0931, val_loss=3.34, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 36.77it/s, loss=0.0931, val_loss=0.38, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.04it/s, loss=0.0401, val_loss=0.38, avg_\n",
      "Epoch 4:  81%|▊| 26/32 [00:00<00:00, 31.26it/s, loss=0.0401, val_loss=0.38, avg_\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 35.38it/s, loss=0.0401, val_loss=0.0647, av\u001b[A\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 19.67it/s, loss=0.0272, val_loss=0.0647, av\u001b[A\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 34.77it/s, loss=0.0272, val_loss=0.0378, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 20.14it/s, loss=0.0226, val_loss=0.0378, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 35.47it/s, loss=0.0226, val_loss=0.0339, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 20.10it/s, loss=0.0202, val_loss=0.0339, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 35.20it/s, loss=0.0202, val_loss=0.0303, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 20.26it/s, loss=0.0186, val_loss=0.0303, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 35.67it/s, loss=0.0186, val_loss=0.0277, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 19.32it/s, loss=0.0173, val_loss=0.0277, av\n",
      "Epoch 9:  81%|▊| 26/32 [00:00<00:00, 28.73it/s, loss=0.0173, val_loss=0.0277, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 32.79it/s, loss=0.0173, val_loss=0.0259, av\u001b[A\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 18.80it/s, loss=0.0163, val_loss=0.0259, a\u001b[A\n",
      "Epoch 10:  81%|▊| 26/32 [00:00<00:00, 27.83it/s, loss=0.0163, val_loss=0.0259, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 32.35it/s, loss=0.0163, val_loss=0.0244, a\u001b[A\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.13it/s, loss=0.0154, val_loss=0.0244, a\u001b[A\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 36.96it/s, loss=0.0154, val_loss=0.0229, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 20.47it/s, loss=0.0146, val_loss=0.0229, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 35.68it/s, loss=0.0146, val_loss=0.0216, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.11it/s, loss=0.014, val_loss=0.0216, av\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 36.88it/s, loss=0.014, val_loss=0.0204, av\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 19.88it/s, loss=0.0134, val_loss=0.0204, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 35.11it/s, loss=0.0134, val_loss=0.0195, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 17.96it/s, loss=0.0129, val_loss=0.0195, a\n",
      "Epoch 15:  81%|▊| 26/32 [00:00<00:00, 26.78it/s, loss=0.0129, val_loss=0.0195, a\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 31.14it/s, loss=0.0129, val_loss=0.0187, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 19.66it/s, loss=0.0124, val_loss=0.0187, a\u001b[A\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 34.58it/s, loss=0.0124, val_loss=0.018, av\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=0.0119, val_loss=0.018, av\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 35.91it/s, loss=0.0119, val_loss=0.0174, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 20.11it/s, loss=0.0116, val_loss=0.0174, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 35.48it/s, loss=0.0116, val_loss=0.0168, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 20.39it/s, loss=0.0112, val_loss=0.0168, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 35.77it/s, loss=0.0112, val_loss=0.0163, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.0109, val_loss=0.0163, a\n",
      "Epoch 20:  81%|▊| 26/32 [00:00<00:00, 29.70it/s, loss=0.0109, val_loss=0.0163, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 34.58it/s, loss=0.0109, val_loss=0.0158, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 20.70it/s, loss=0.0106, val_loss=0.0158, a\u001b[A\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 36.43it/s, loss=0.0106, val_loss=0.0154, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 22.00it/s, loss=0.0103, val_loss=0.0154, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.42it/s, loss=0.0103, val_loss=0.015, av\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.22it/s, loss=0.01, val_loss=0.015, avg_\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.77it/s, loss=0.01, val_loss=0.0147, avg\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.0098, val_loss=0.0147, a\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.0098, val_loss=0.0143, a\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.00958, val_loss=0.0143, \n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.00958, val_loss=0.014, a\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 20.73it/s, loss=0.00938, val_loss=0.014, a\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 36.31it/s, loss=0.00938, val_loss=0.0137, \n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 20.53it/s, loss=0.0092, val_loss=0.0137, a\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 36.13it/s, loss=0.0092, val_loss=0.0135, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.06it/s, loss=0.00903, val_loss=0.0135, \n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 36.98it/s, loss=0.00903, val_loss=0.0133, \n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.00888, val_loss=0.0133, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 36.83it/s, loss=0.00888, val_loss=0.0131, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 20.87it/s, loss=0.00874, val_loss=0.0131, \n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 36.70it/s, loss=0.00874, val_loss=0.0128, \n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.0086, val_loss=0.0128, a\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.0086, val_loss=0.0126, a\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.00848, val_loss=0.0126, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.74it/s, loss=0.00848, val_loss=0.0125, \n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=0.00837, val_loss=0.0125, \n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.73it/s, loss=0.00837, val_loss=0.0123, \n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 20.97it/s, loss=0.00827, val_loss=0.0123, \n",
      "Epoch 34:  81%|▊| 26/32 [00:00<00:00, 31.54it/s, loss=0.00827, val_loss=0.0123, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 36.36it/s, loss=0.00827, val_loss=0.0122, \u001b[A\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.11it/s, loss=0.00817, val_loss=0.0122, \u001b[A\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.07it/s, loss=0.00817, val_loss=0.0121, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 20.30it/s, loss=0.00808, val_loss=0.0121, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 35.66it/s, loss=0.00808, val_loss=0.012, a\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 19.49it/s, loss=0.008, val_loss=0.012, avg\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 34.55it/s, loss=0.008, val_loss=0.0119, av\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 20.51it/s, loss=0.00792, val_loss=0.0119, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 35.57it/s, loss=0.00792, val_loss=0.0117, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.00785, val_loss=0.0117, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 36.71it/s, loss=0.00785, val_loss=0.0116, \n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 20.96it/s, loss=0.00779, val_loss=0.0116, \n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 36.77it/s, loss=0.00779, val_loss=0.0116, \n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00773, val_loss=0.0116, \n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 38.53it/s, loss=0.00773, val_loss=0.0115, \n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=0.00767, val_loss=0.0115, \n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 38.36it/s, loss=0.00767, val_loss=0.0114, \n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 20.06it/s, loss=0.00762, val_loss=0.0114, \n",
      "Epoch 43:  81%|▊| 26/32 [00:00<00:00, 30.38it/s, loss=0.00762, val_loss=0.0114, \n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 34.90it/s, loss=0.00762, val_loss=0.0113, \u001b[A\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 21.01it/s, loss=0.00757, val_loss=0.0113, \u001b[A\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 36.87it/s, loss=0.00757, val_loss=0.0113, \n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00753, val_loss=0.0113, \n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.00753, val_loss=0.0112, \n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.19it/s, loss=0.00748, val_loss=0.0112, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 36.99it/s, loss=0.00748, val_loss=0.0111, \n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 20.17it/s, loss=0.00744, val_loss=0.0111, \n",
      "Epoch 47:  81%|▊| 26/32 [00:00<00:00, 30.61it/s, loss=0.00744, val_loss=0.0111, \n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 35.51it/s, loss=0.00744, val_loss=0.0111, \u001b[A\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 19.45it/s, loss=0.00741, val_loss=0.0111, \u001b[A\n",
      "Epoch 48:  81%|▊| 26/32 [00:00<00:00, 29.36it/s, loss=0.00741, val_loss=0.0111, \n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 33.78it/s, loss=0.00741, val_loss=0.011, a\u001b[A\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 18.98it/s, loss=0.00737, val_loss=0.011, a\u001b[A\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 33.53it/s, loss=0.00737, val_loss=0.0109, \n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 21.00it/s, loss=0.00734, val_loss=0.0109, \n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 36.84it/s, loss=0.00734, val_loss=0.0109, \n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 20.05it/s, loss=0.00731, val_loss=0.0109, \n",
      "Epoch 51:  81%|▊| 26/32 [00:00<00:00, 30.53it/s, loss=0.00731, val_loss=0.0109, \n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 35.20it/s, loss=0.00731, val_loss=0.0108, \u001b[A\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 20.33it/s, loss=0.00728, val_loss=0.0108, \u001b[A\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 35.86it/s, loss=0.00728, val_loss=0.0108, \n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 20.40it/s, loss=0.00726, val_loss=0.0108, \n",
      "Epoch 53:  81%|▊| 26/32 [00:00<00:00, 30.86it/s, loss=0.00726, val_loss=0.0108, \n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 35.65it/s, loss=0.00726, val_loss=0.0107, \u001b[A\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 18.48it/s, loss=0.00724, val_loss=0.0107, \u001b[A\n",
      "Epoch 54:  81%|▊| 26/32 [00:00<00:00, 27.07it/s, loss=0.00724, val_loss=0.0107, \n",
      "Epoch 54: 100%|█| 32/32 [00:01<00:00, 31.06it/s, loss=0.00724, val_loss=0.0107, \u001b[A\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 20.44it/s, loss=0.00721, val_loss=0.0107, \u001b[A\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.00721, val_loss=0.0106, \n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 20.21it/s, loss=0.00719, val_loss=0.0106, \n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 35.53it/s, loss=0.00719, val_loss=0.0106, \n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.00717, val_loss=0.0106, \n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 36.02it/s, loss=0.00717, val_loss=0.0105, \n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 20.84it/s, loss=0.00715, val_loss=0.0105, \n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 36.60it/s, loss=0.00715, val_loss=0.0105, \n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 18.31it/s, loss=0.00714, val_loss=0.0105, \n",
      "Epoch 59:  81%|▊| 26/32 [00:00<00:00, 27.44it/s, loss=0.00714, val_loss=0.0105, \n",
      "Epoch 59: 100%|█| 32/32 [00:01<00:00, 31.98it/s, loss=0.00714, val_loss=0.0104, \u001b[A\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 19.88it/s, loss=0.00712, val_loss=0.0104, \u001b[A\n",
      "Epoch 60:  81%|▊| 26/32 [00:00<00:00, 30.08it/s, loss=0.00712, val_loss=0.0104, \n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 34.77it/s, loss=0.00712, val_loss=0.0104, \u001b[A\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 20.97it/s, loss=0.0071, val_loss=0.0104, a\u001b[A\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 36.84it/s, loss=0.0071, val_loss=0.0104, a\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 19.77it/s, loss=0.00709, val_loss=0.0104, \n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 34.87it/s, loss=0.00709, val_loss=0.0104, \n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00707, val_loss=0.0104, \n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.00707, val_loss=0.0103, \n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00706, val_loss=0.0103, \n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00706, val_loss=0.0102, \n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.00705, val_loss=0.0102, \n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=0.00705, val_loss=0.0101, \n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 22.08it/s, loss=0.00704, val_loss=0.0101, \n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00704, val_loss=0.0101, \n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 20.84it/s, loss=0.00703, val_loss=0.0101, \n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 36.61it/s, loss=0.00703, val_loss=0.0101, \n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.09it/s, loss=0.00701, val_loss=0.0101, \n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 37.05it/s, loss=0.00701, val_loss=0.0101, \n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.007, val_loss=0.0101, av\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.007, val_loss=0.01, avg_\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.00699, val_loss=0.01, av\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 36.70it/s, loss=0.00699, val_loss=0.00997,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.00698, val_loss=0.00997,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 36.13it/s, loss=0.00698, val_loss=0.00996,\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 20.55it/s, loss=0.00698, val_loss=0.00996,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 36.01it/s, loss=0.00698, val_loss=0.00999,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 19.42it/s, loss=0.00697, val_loss=0.00999,\n",
      "Epoch 73:  81%|▊| 26/32 [00:00<00:00, 29.34it/s, loss=0.00697, val_loss=0.00999,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 34.09it/s, loss=0.00697, val_loss=0.00995,\u001b[A\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 19.62it/s, loss=0.00696, val_loss=0.00995,\u001b[A\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 34.38it/s, loss=0.00696, val_loss=0.0099, \n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 20.21it/s, loss=0.00695, val_loss=0.0099, \n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 35.60it/s, loss=0.00695, val_loss=0.00989,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 20.16it/s, loss=0.00694, val_loss=0.00989,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 35.46it/s, loss=0.00694, val_loss=0.00986,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 19.79it/s, loss=0.00694, val_loss=0.00986,\n",
      "Epoch 77:  81%|▊| 26/32 [00:00<00:00, 29.71it/s, loss=0.00694, val_loss=0.00986,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 34.50it/s, loss=0.00694, val_loss=0.00985,\u001b[A\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 17.82it/s, loss=0.00693, val_loss=0.00985,\u001b[A\n",
      "Epoch 78: 100%|█| 32/32 [00:01<00:00, 31.43it/s, loss=0.00693, val_loss=0.00982,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 19.43it/s, loss=0.00692, val_loss=0.00982,\n",
      "Epoch 79:  81%|▊| 26/32 [00:00<00:00, 29.64it/s, loss=0.00692, val_loss=0.00982,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 34.24it/s, loss=0.00692, val_loss=0.00982,\u001b[A\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 20.15it/s, loss=0.00692, val_loss=0.00982,\u001b[A\n",
      "Epoch 80:  81%|▊| 26/32 [00:00<00:00, 30.43it/s, loss=0.00692, val_loss=0.00982,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 34.84it/s, loss=0.00692, val_loss=0.0098, \u001b[A\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 19.81it/s, loss=0.00691, val_loss=0.0098, \u001b[A\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 34.95it/s, loss=0.00691, val_loss=0.00973,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 20.73it/s, loss=0.0069, val_loss=0.00973, \n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 36.26it/s, loss=0.0069, val_loss=0.00976, \n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 19.22it/s, loss=0.0069, val_loss=0.00976, \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83: 100%|█| 32/32 [00:01<00:00, 31.29it/s, loss=0.0069, val_loss=0.00975, \u001b[A\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 17.62it/s, loss=0.00689, val_loss=0.00975,\u001b[A\n",
      "Epoch 84: 100%|█| 32/32 [00:01<00:00, 31.43it/s, loss=0.00689, val_loss=0.0097, \n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 20.45it/s, loss=0.00689, val_loss=0.0097, \n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 35.84it/s, loss=0.00689, val_loss=0.00967,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 20.15it/s, loss=0.00688, val_loss=0.00967,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 35.37it/s, loss=0.00688, val_loss=0.00968,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00688, val_loss=0.00968,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 38.50it/s, loss=0.00688, val_loss=0.00963,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 21.29it/s, loss=0.00687, val_loss=0.00963,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 36.97it/s, loss=0.00687, val_loss=0.00963,\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 21.78it/s, loss=0.00687, val_loss=0.00963,\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00687, val_loss=0.00969,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.00686, val_loss=0.00969,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 38.18it/s, loss=0.00686, val_loss=0.00968,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.06it/s, loss=0.00686, val_loss=0.00968,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.22it/s, loss=0.00686, val_loss=0.0097, \n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 21.28it/s, loss=0.00685, val_loss=0.0097, \n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 36.96it/s, loss=0.00685, val_loss=0.00968,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 20.00it/s, loss=0.00685, val_loss=0.00968,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 35.26it/s, loss=0.00685, val_loss=0.0096, \n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.00684, val_loss=0.0096, \n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.00684, val_loss=0.0096, \n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 20.96it/s, loss=0.00684, val_loss=0.0096, \n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 36.83it/s, loss=0.00684, val_loss=0.00964,\n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 20.44it/s, loss=0.00684, val_loss=0.00964,\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.00684, val_loss=0.00957,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 20.04it/s, loss=0.00683, val_loss=0.00957,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 35.17it/s, loss=0.00683, val_loss=0.00951,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 20.78it/s, loss=0.00683, val_loss=0.00951,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 36.21it/s, loss=0.00683, val_loss=0.00958,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 19.90it/s, loss=0.00682, val_loss=0.00958,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 34.86it/s, loss=0.00682, val_loss=0.00963,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 34.63it/s, loss=0.00682, val_loss=0.00963,\n",
      "Sizes of clusters: 399, 401\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9738\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.18it/s, loss=129, val_loss=0.0559, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 37.18it/s, loss=129, val_loss=1.13, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 20.84it/s, loss=2.31, val_loss=1.13, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 36.51it/s, loss=2.31, val_loss=1.12, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 20.82it/s, loss=0.423, val_loss=1.12, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 36.48it/s, loss=0.423, val_loss=0.215, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 20.44it/s, loss=0.106, val_loss=0.215, avg_\n",
      "Epoch 3:  75%|▊| 24/32 [00:00<00:00, 29.00it/s, loss=0.106, val_loss=0.215, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 35.80it/s, loss=0.106, val_loss=0.0951, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.01it/s, loss=0.0468, val_loss=0.0951, av\u001b[A\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 36.92it/s, loss=0.0468, val_loss=0.053, avg\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 20.40it/s, loss=0.031, val_loss=0.053, avg_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 35.79it/s, loss=0.031, val_loss=0.0387, avg\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 19.66it/s, loss=0.0256, val_loss=0.0387, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 34.74it/s, loss=0.0256, val_loss=0.0331, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 19.98it/s, loss=0.0226, val_loss=0.0331, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 35.30it/s, loss=0.0226, val_loss=0.0297, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 19.98it/s, loss=0.0205, val_loss=0.0297, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 34.85it/s, loss=0.0205, val_loss=0.0272, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 20.75it/s, loss=0.0189, val_loss=0.0272, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 36.48it/s, loss=0.0189, val_loss=0.025, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.0176, val_loss=0.025, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.0176, val_loss=0.0231, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 20.25it/s, loss=0.0164, val_loss=0.0231, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 35.69it/s, loss=0.0164, val_loss=0.0215, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.40it/s, loss=0.0155, val_loss=0.0215, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.52it/s, loss=0.0155, val_loss=0.02, avg\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=0.0147, val_loss=0.02, avg\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.0147, val_loss=0.0188, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.0139, val_loss=0.0188, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.0139, val_loss=0.0177, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 20.66it/s, loss=0.0133, val_loss=0.0177, a\n",
      "Epoch 15:  75%|▊| 24/32 [00:00<00:00, 28.74it/s, loss=0.0133, val_loss=0.0177, a\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 29.26it/s, loss=0.0133, val_loss=0.0167, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 20.93it/s, loss=0.0128, val_loss=0.0167, a\u001b[A\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 36.66it/s, loss=0.0128, val_loss=0.0158, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 20.73it/s, loss=0.0123, val_loss=0.0158, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 36.44it/s, loss=0.0123, val_loss=0.0151, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 20.08it/s, loss=0.0118, val_loss=0.0151, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 35.43it/s, loss=0.0118, val_loss=0.0144, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 20.55it/s, loss=0.0114, val_loss=0.0144, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 36.19it/s, loss=0.0114, val_loss=0.0137, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 19.34it/s, loss=0.0111, val_loss=0.0137, a\n",
      "Epoch 20:  75%|▊| 24/32 [00:00<00:00, 26.69it/s, loss=0.0111, val_loss=0.0137, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 32.17it/s, loss=0.0111, val_loss=0.0132, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 18.86it/s, loss=0.0107, val_loss=0.0132, a\u001b[A\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 33.44it/s, loss=0.0107, val_loss=0.0127, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 20.67it/s, loss=0.0104, val_loss=0.0127, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 36.35it/s, loss=0.0104, val_loss=0.0122, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 19.51it/s, loss=0.0102, val_loss=0.0122, a\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 34.18it/s, loss=0.0102, val_loss=0.0118, a\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 20.48it/s, loss=0.00991, val_loss=0.0118, \n",
      "Epoch 24:  75%|▊| 24/32 [00:00<00:00, 28.97it/s, loss=0.00991, val_loss=0.0118, \n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 35.75it/s, loss=0.00991, val_loss=0.0114, \u001b[A\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 20.96it/s, loss=0.00968, val_loss=0.0114, \u001b[A\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 36.64it/s, loss=0.00968, val_loss=0.0111, \n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 18.91it/s, loss=0.00947, val_loss=0.0111, \n",
      "Epoch 26:  75%|▊| 24/32 [00:00<00:00, 26.71it/s, loss=0.00947, val_loss=0.0111, \n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 32.62it/s, loss=0.00947, val_loss=0.0108, \u001b[A\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 20.28it/s, loss=0.00927, val_loss=0.0108, \u001b[A\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 35.47it/s, loss=0.00927, val_loss=0.0105, \n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 20.06it/s, loss=0.00909, val_loss=0.0105, \n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 35.13it/s, loss=0.00909, val_loss=0.0103, \n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 20.43it/s, loss=0.00892, val_loss=0.0103, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 35.40it/s, loss=0.00892, val_loss=0.0101, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 20.30it/s, loss=0.00877, val_loss=0.0101, \n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 35.49it/s, loss=0.00877, val_loss=0.00986,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 19.71it/s, loss=0.00863, val_loss=0.00986,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 34.74it/s, loss=0.00863, val_loss=0.00968,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 20.66it/s, loss=0.0085, val_loss=0.00968, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 36.40it/s, loss=0.0085, val_loss=0.0095, a\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 22.28it/s, loss=0.00838, val_loss=0.0095, \n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.80it/s, loss=0.00838, val_loss=0.00933,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.00826, val_loss=0.00933,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.00826, val_loss=0.00918,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 22.15it/s, loss=0.00816, val_loss=0.00918,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 38.66it/s, loss=0.00816, val_loss=0.00904,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.00807, val_loss=0.00904,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.00807, val_loss=0.00891,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 20.26it/s, loss=0.00798, val_loss=0.00891,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 35.66it/s, loss=0.00798, val_loss=0.0088, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.0079, val_loss=0.0088, a\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.11it/s, loss=0.0079, val_loss=0.00869, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.27it/s, loss=0.00782, val_loss=0.00869,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.00782, val_loss=0.00859,\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 20.56it/s, loss=0.00775, val_loss=0.00859,\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 36.06it/s, loss=0.00775, val_loss=0.00849,\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 20.93it/s, loss=0.00769, val_loss=0.00849,\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 36.58it/s, loss=0.00769, val_loss=0.00839,\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 20.50it/s, loss=0.00763, val_loss=0.00839,\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 35.69it/s, loss=0.00763, val_loss=0.0083, \n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 20.85it/s, loss=0.00757, val_loss=0.0083, \n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 36.17it/s, loss=0.00757, val_loss=0.00822,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 19.24it/s, loss=0.00752, val_loss=0.00822,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 34.06it/s, loss=0.00752, val_loss=0.00816,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 19.05it/s, loss=0.00747, val_loss=0.00816,\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 33.78it/s, loss=0.00747, val_loss=0.00809,\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 20.26it/s, loss=0.00743, val_loss=0.00809,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 35.22it/s, loss=0.00743, val_loss=0.00803,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 19.63it/s, loss=0.00738, val_loss=0.00803,\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 34.75it/s, loss=0.00738, val_loss=0.00797,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 20.14it/s, loss=0.00734, val_loss=0.00797,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 35.46it/s, loss=0.00734, val_loss=0.00793,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 19.87it/s, loss=0.00731, val_loss=0.00793,\n",
      "Epoch 49:  75%|▊| 24/32 [00:00<00:00, 28.39it/s, loss=0.00731, val_loss=0.00793,\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 34.88it/s, loss=0.00731, val_loss=0.00788,\u001b[A\n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 18.32it/s, loss=0.00727, val_loss=0.00788,\u001b[A\n",
      "Epoch 50:  75%|▊| 24/32 [00:00<00:00, 26.32it/s, loss=0.00727, val_loss=0.00788,\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 32.18it/s, loss=0.00727, val_loss=0.00784,\u001b[A\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 19.47it/s, loss=0.00724, val_loss=0.00784,\u001b[A\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 34.16it/s, loss=0.00724, val_loss=0.0078, \n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 20.42it/s, loss=0.00721, val_loss=0.0078, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 35.99it/s, loss=0.00721, val_loss=0.00777,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 20.47it/s, loss=0.00718, val_loss=0.00777,\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 35.94it/s, loss=0.00718, val_loss=0.00773,\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 19.70it/s, loss=0.00716, val_loss=0.00773,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 34.75it/s, loss=0.00716, val_loss=0.0077, \n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 20.01it/s, loss=0.00713, val_loss=0.0077, \n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 35.00it/s, loss=0.00713, val_loss=0.00767,\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 16.58it/s, loss=0.00711, val_loss=0.00767,\n",
      "Epoch 56:  75%|▊| 24/32 [00:01<00:00, 23.22it/s, loss=0.00711, val_loss=0.00767,\n",
      "Epoch 56: 100%|█| 32/32 [00:01<00:00, 28.77it/s, loss=0.00711, val_loss=0.00765,\u001b[A\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 21.13it/s, loss=0.00709, val_loss=0.00765,\u001b[A\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 37.11it/s, loss=0.00709, val_loss=0.00762,\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00707, val_loss=0.00762,\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 38.48it/s, loss=0.00707, val_loss=0.00759,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.00705, val_loss=0.00759,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.00705, val_loss=0.00757,\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 21.52it/s, loss=0.00703, val_loss=0.00757,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.00703, val_loss=0.00755,\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.00701, val_loss=0.00755,\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.00701, val_loss=0.00753,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.007, val_loss=0.00753, a\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.007, val_loss=0.00751, a\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 20.51it/s, loss=0.00698, val_loss=0.00751,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 35.94it/s, loss=0.00698, val_loss=0.00749,\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 21.09it/s, loss=0.00697, val_loss=0.00749,\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 36.87it/s, loss=0.00697, val_loss=0.00747,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.00696, val_loss=0.00747,\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 35.67it/s, loss=0.00696, val_loss=0.00745,\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 20.53it/s, loss=0.00695, val_loss=0.00745,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 36.08it/s, loss=0.00695, val_loss=0.00744,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 20.76it/s, loss=0.00694, val_loss=0.00744,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 36.52it/s, loss=0.00694, val_loss=0.00743,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00693, val_loss=0.00743,\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.00693, val_loss=0.00741,\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00692, val_loss=0.00741,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 38.00it/s, loss=0.00692, val_loss=0.0074, \n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00691, val_loss=0.0074, \n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 37.51it/s, loss=0.00691, val_loss=0.00738,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 20.79it/s, loss=0.0069, val_loss=0.00738, \n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 36.38it/s, loss=0.0069, val_loss=0.00737, \n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.00689, val_loss=0.00737,\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 36.27it/s, loss=0.00689, val_loss=0.00736,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 20.14it/s, loss=0.00688, val_loss=0.00736,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 35.15it/s, loss=0.00688, val_loss=0.00735,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 20.90it/s, loss=0.00687, val_loss=0.00735,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 36.73it/s, loss=0.00687, val_loss=0.00734,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 20.45it/s, loss=0.00687, val_loss=0.00734,\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 35.61it/s, loss=0.00687, val_loss=0.00734,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 20.71it/s, loss=0.00686, val_loss=0.00734,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 36.46it/s, loss=0.00686, val_loss=0.00732,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00685, val_loss=0.00732,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00685, val_loss=0.00731,\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.04it/s, loss=0.00685, val_loss=0.00731,\n",
      "Epoch 78:  75%|▊| 24/32 [00:00<00:00, 29.77it/s, loss=0.00685, val_loss=0.00731,\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 36.66it/s, loss=0.00685, val_loss=0.0073, \u001b[A\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 20.22it/s, loss=0.00684, val_loss=0.0073, \u001b[A\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 35.65it/s, loss=0.00684, val_loss=0.00729,\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 21.42it/s, loss=0.00683, val_loss=0.00729,\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 37.28it/s, loss=0.00683, val_loss=0.00728,\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.00683, val_loss=0.00728,\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 37.00it/s, loss=0.00683, val_loss=0.00727,\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00682, val_loss=0.00727,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 37.78it/s, loss=0.00682, val_loss=0.00727,\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 19.09it/s, loss=0.00682, val_loss=0.00727,\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 33.70it/s, loss=0.00682, val_loss=0.00726,\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 18.79it/s, loss=0.00681, val_loss=0.00726,\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 33.38it/s, loss=0.00681, val_loss=0.00725,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 20.24it/s, loss=0.0068, val_loss=0.00725, \n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 35.73it/s, loss=0.0068, val_loss=0.00724, \n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 20.81it/s, loss=0.0068, val_loss=0.00724, \n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 36.56it/s, loss=0.0068, val_loss=0.00723, \n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 20.64it/s, loss=0.00679, val_loss=0.00723,\n",
      "Epoch 87:  75%|▊| 24/32 [00:00<00:00, 29.11it/s, loss=0.00679, val_loss=0.00723,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 35.90it/s, loss=0.00679, val_loss=0.00722,\u001b[A\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 20.11it/s, loss=0.00679, val_loss=0.00722,\u001b[A\n",
      "Epoch 88:  75%|▊| 24/32 [00:00<00:00, 28.31it/s, loss=0.00679, val_loss=0.00722,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 34.43it/s, loss=0.00679, val_loss=0.00722,\u001b[A\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 18.24it/s, loss=0.00679, val_loss=0.00722,\u001b[A\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 32.41it/s, loss=0.00679, val_loss=0.00721,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 19.58it/s, loss=0.00678, val_loss=0.00721,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 34.57it/s, loss=0.00678, val_loss=0.0072, \n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=0.00678, val_loss=0.0072, \n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 35.74it/s, loss=0.00678, val_loss=0.00719,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 20.93it/s, loss=0.00677, val_loss=0.00719,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 36.76it/s, loss=0.00677, val_loss=0.00719,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.24it/s, loss=0.00677, val_loss=0.00719,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 37.02it/s, loss=0.00677, val_loss=0.00718,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 19.79it/s, loss=0.00676, val_loss=0.00718,\n",
      "Epoch 94:  75%|▊| 24/32 [00:00<00:00, 28.01it/s, loss=0.00676, val_loss=0.00718,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 34.17it/s, loss=0.00676, val_loss=0.00717,\u001b[A\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 18.98it/s, loss=0.00676, val_loss=0.00717,\u001b[A\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 33.58it/s, loss=0.00676, val_loss=0.00716,\n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 19.62it/s, loss=0.00676, val_loss=0.00716,\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 34.65it/s, loss=0.00676, val_loss=0.00715,\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 20.32it/s, loss=0.00675, val_loss=0.00715,\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 35.81it/s, loss=0.00675, val_loss=0.00715,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 20.88it/s, loss=0.00675, val_loss=0.00715,\n",
      "Epoch 98:  75%|▊| 24/32 [00:00<00:00, 29.46it/s, loss=0.00675, val_loss=0.00715,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 36.20it/s, loss=0.00675, val_loss=0.00715,\u001b[A\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 20.36it/s, loss=0.00674, val_loss=0.00715,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 35.90it/s, loss=0.00674, val_loss=0.00714,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 35.65it/s, loss=0.00674, val_loss=0.00714,\n",
      "Sizes of clusters: 386, 414\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9750\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 22.19it/s, loss=146, val_loss=0.0808, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.74it/s, loss=146, val_loss=4.93, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 22.30it/s, loss=2.06, val_loss=4.93, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.92it/s, loss=2.06, val_loss=1.15, avg_va\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 22.26it/s, loss=0.388, val_loss=1.15, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.84it/s, loss=0.388, val_loss=0.349, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.0991, val_loss=0.349, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.0991, val_loss=0.0822, av\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.0416, val_loss=0.0822, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.0416, val_loss=0.0513, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0273, val_loss=0.0513, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.75it/s, loss=0.0273, val_loss=0.0434, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.0225, val_loss=0.0434, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 36.49it/s, loss=0.0225, val_loss=0.0374, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 20.39it/s, loss=0.0199, val_loss=0.0374, av\n",
      "Epoch 7:  81%|▊| 26/32 [00:00<00:00, 30.69it/s, loss=0.0199, val_loss=0.0374, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 35.20it/s, loss=0.0199, val_loss=0.0338, av\u001b[A\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=0.0181, val_loss=0.0338, av\u001b[A\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 35.98it/s, loss=0.0181, val_loss=0.031, avg\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 19.94it/s, loss=0.0167, val_loss=0.031, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 34.89it/s, loss=0.0167, val_loss=0.0287, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 20.59it/s, loss=0.0155, val_loss=0.0287, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 36.07it/s, loss=0.0155, val_loss=0.0266, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 20.01it/s, loss=0.0145, val_loss=0.0266, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 35.20it/s, loss=0.0145, val_loss=0.025, av\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 19.67it/s, loss=0.0136, val_loss=0.025, av\n",
      "Epoch 12:  81%|▊| 26/32 [00:00<00:00, 29.59it/s, loss=0.0136, val_loss=0.025, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 34.43it/s, loss=0.0136, val_loss=0.0232, a\u001b[A\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 19.05it/s, loss=0.0129, val_loss=0.0232, a\u001b[A\n",
      "Epoch 13:  81%|▊| 26/32 [00:00<00:00, 29.09it/s, loss=0.0129, val_loss=0.0232, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 33.62it/s, loss=0.0129, val_loss=0.0215, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 20.64it/s, loss=0.0123, val_loss=0.0215, a\u001b[A\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 36.31it/s, loss=0.0123, val_loss=0.02, avg\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 20.33it/s, loss=0.0117, val_loss=0.02, avg\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 35.73it/s, loss=0.0117, val_loss=0.019, av\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 20.85it/s, loss=0.0112, val_loss=0.019, av\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 36.52it/s, loss=0.0112, val_loss=0.0182, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 20.13it/s, loss=0.0108, val_loss=0.0182, a\n",
      "Epoch 17:  81%|▊| 26/32 [00:00<00:00, 30.30it/s, loss=0.0108, val_loss=0.0182, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 34.95it/s, loss=0.0108, val_loss=0.0167, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 18.96it/s, loss=0.0104, val_loss=0.0167, a\u001b[A\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 33.39it/s, loss=0.0104, val_loss=0.016, av\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 19.01it/s, loss=0.01, val_loss=0.016, avg_\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 33.59it/s, loss=0.01, val_loss=0.0152, avg\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=0.00974, val_loss=0.0152, \n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 35.78it/s, loss=0.00974, val_loss=0.0146, \n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 19.99it/s, loss=0.00947, val_loss=0.0146, \n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 35.11it/s, loss=0.00947, val_loss=0.0141, \n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.00924, val_loss=0.0141, \n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.75it/s, loss=0.00924, val_loss=0.0136, \n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 22.11it/s, loss=0.00903, val_loss=0.0136, \n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.59it/s, loss=0.00903, val_loss=0.0132, \n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.00884, val_loss=0.0132, \n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 38.24it/s, loss=0.00884, val_loss=0.0129, \n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 22.09it/s, loss=0.00867, val_loss=0.0129, \n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.56it/s, loss=0.00867, val_loss=0.0126, \n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00852, val_loss=0.0126, \n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.00852, val_loss=0.0123, \n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.48it/s, loss=0.00838, val_loss=0.0123, \n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.64it/s, loss=0.00838, val_loss=0.012, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 20.72it/s, loss=0.00826, val_loss=0.012, a\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 36.36it/s, loss=0.00826, val_loss=0.0118, \n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.18it/s, loss=0.00815, val_loss=0.0118, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 36.99it/s, loss=0.00815, val_loss=0.0116, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 20.03it/s, loss=0.00805, val_loss=0.0116, \n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 35.05it/s, loss=0.00805, val_loss=0.0114, \n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 20.54it/s, loss=0.00796, val_loss=0.0114, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 35.91it/s, loss=0.00796, val_loss=0.0114, \n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 20.60it/s, loss=0.00787, val_loss=0.0114, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 36.15it/s, loss=0.00787, val_loss=0.011, a\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 20.17it/s, loss=0.0078, val_loss=0.011, av\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 35.57it/s, loss=0.0078, val_loss=0.0108, a\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 19.89it/s, loss=0.00774, val_loss=0.0108, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 35.17it/s, loss=0.00774, val_loss=0.0107, \n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 20.59it/s, loss=0.00768, val_loss=0.0107, \n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 36.09it/s, loss=0.00768, val_loss=0.0105, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 20.47it/s, loss=0.00762, val_loss=0.0105, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 35.84it/s, loss=0.00762, val_loss=0.0104, \n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 19.53it/s, loss=0.00757, val_loss=0.0104, \n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 34.21it/s, loss=0.00757, val_loss=0.0103, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 19.66it/s, loss=0.00753, val_loss=0.0103, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 34.80it/s, loss=0.00753, val_loss=0.0102, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 20.30it/s, loss=0.00749, val_loss=0.0102, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 35.74it/s, loss=0.00749, val_loss=0.0101, \n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 19.32it/s, loss=0.00745, val_loss=0.0101, \n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 33.92it/s, loss=0.00745, val_loss=0.0101, \n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 20.83it/s, loss=0.00742, val_loss=0.0101, \n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 36.56it/s, loss=0.00742, val_loss=0.0101, \n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 20.24it/s, loss=0.00739, val_loss=0.0101, \n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 35.70it/s, loss=0.00739, val_loss=0.00993,\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 19.99it/s, loss=0.00735, val_loss=0.00993,\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 35.23it/s, loss=0.00735, val_loss=0.00985,\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 20.75it/s, loss=0.00732, val_loss=0.00985,\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 36.48it/s, loss=0.00732, val_loss=0.00974,\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.0073, val_loss=0.00974, \n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.0073, val_loss=0.00972, \n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00727, val_loss=0.00972,\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 38.17it/s, loss=0.00727, val_loss=0.00967,\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 22.18it/s, loss=0.00724, val_loss=0.00967,\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 38.68it/s, loss=0.00724, val_loss=0.00959,\n",
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 22.13it/s, loss=0.00722, val_loss=0.00959,\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.00722, val_loss=0.00961,\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.0072, val_loss=0.00961, \n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.0072, val_loss=0.00959, \n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 20.82it/s, loss=0.00718, val_loss=0.00959,\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 36.56it/s, loss=0.00718, val_loss=0.0095, \n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 21.07it/s, loss=0.00716, val_loss=0.0095, \n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 36.94it/s, loss=0.00716, val_loss=0.00952,\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 21.24it/s, loss=0.00715, val_loss=0.00952,\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 37.22it/s, loss=0.00715, val_loss=0.00959,\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 20.43it/s, loss=0.00713, val_loss=0.00959,\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.00713, val_loss=0.00951,\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 19.82it/s, loss=0.00712, val_loss=0.00951,\n",
      "Epoch 54:  81%|▊| 26/32 [00:00<00:00, 30.19it/s, loss=0.00712, val_loss=0.00951,\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 34.68it/s, loss=0.00712, val_loss=0.00946,\u001b[A\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 20.05it/s, loss=0.0071, val_loss=0.00946, \u001b[A\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 35.42it/s, loss=0.0071, val_loss=0.00933, \n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 19.92it/s, loss=0.00709, val_loss=0.00933,\n",
      "Epoch 56:  81%|▊| 26/32 [00:00<00:00, 29.93it/s, loss=0.00709, val_loss=0.00933,\n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 34.67it/s, loss=0.00709, val_loss=0.00938,\u001b[A\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 20.10it/s, loss=0.00708, val_loss=0.00938,\u001b[A\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 35.47it/s, loss=0.00708, val_loss=0.0093, \n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 20.24it/s, loss=0.00707, val_loss=0.0093, \n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 35.47it/s, loss=0.00707, val_loss=0.00914,\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 19.96it/s, loss=0.00705, val_loss=0.00914,\n",
      "Epoch 59:  81%|▊| 26/32 [00:00<00:00, 30.33it/s, loss=0.00705, val_loss=0.00914,\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 35.03it/s, loss=0.00705, val_loss=0.00909,\u001b[A\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 20.36it/s, loss=0.00704, val_loss=0.00909,\u001b[A\n",
      "Epoch 60:  81%|▊| 26/32 [00:00<00:00, 30.28it/s, loss=0.00704, val_loss=0.00909,\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 34.91it/s, loss=0.00704, val_loss=0.00908,\u001b[A\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 20.01it/s, loss=0.00703, val_loss=0.00908,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 35.34it/s, loss=0.00703, val_loss=0.00905,\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 19.85it/s, loss=0.00702, val_loss=0.00905,\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 35.05it/s, loss=0.00702, val_loss=0.00901,\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 20.11it/s, loss=0.00701, val_loss=0.00901,\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 35.02it/s, loss=0.00701, val_loss=0.00898,\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 20.32it/s, loss=0.00701, val_loss=0.00898,\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 35.57it/s, loss=0.00701, val_loss=0.00894,\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 19.84it/s, loss=0.007, val_loss=0.00894, a\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 34.70it/s, loss=0.007, val_loss=0.00904, a\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.00699, val_loss=0.00904,\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 35.70it/s, loss=0.00699, val_loss=0.00902,\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 20.54it/s, loss=0.00698, val_loss=0.00902,\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 35.96it/s, loss=0.00698, val_loss=0.00887,\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00697, val_loss=0.00887,\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.00697, val_loss=0.00887,\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.00697, val_loss=0.00887,\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 38.61it/s, loss=0.00697, val_loss=0.00885,\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 22.04it/s, loss=0.00696, val_loss=0.00885,\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 38.49it/s, loss=0.00696, val_loss=0.00881,\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.00695, val_loss=0.00881,\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.00695, val_loss=0.0088, \n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.00695, val_loss=0.0088, \n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 37.56it/s, loss=0.00695, val_loss=0.00883,\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.00694, val_loss=0.00883,\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.00694, val_loss=0.00877,\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.00693, val_loss=0.00877,\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 36.98it/s, loss=0.00693, val_loss=0.00874,\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 21.13it/s, loss=0.00693, val_loss=0.00874,\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 36.70it/s, loss=0.00693, val_loss=0.00881,\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 20.55it/s, loss=0.00692, val_loss=0.00881,\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 36.13it/s, loss=0.00692, val_loss=0.00868,\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 20.47it/s, loss=0.00692, val_loss=0.00868,\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 35.88it/s, loss=0.00692, val_loss=0.00866,\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 19.92it/s, loss=0.00691, val_loss=0.00866,\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 35.09it/s, loss=0.00691, val_loss=0.00858,\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 20.44it/s, loss=0.00691, val_loss=0.00858,\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 35.79it/s, loss=0.00691, val_loss=0.0086, \n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 20.27it/s, loss=0.0069, val_loss=0.0086, a\n",
      "Epoch 80:  81%|▊| 26/32 [00:00<00:00, 30.61it/s, loss=0.0069, val_loss=0.0086, a\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 35.38it/s, loss=0.0069, val_loss=0.00856, \u001b[A\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 20.15it/s, loss=0.0069, val_loss=0.00856, \u001b[A\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 35.42it/s, loss=0.0069, val_loss=0.00857, \n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 19.90it/s, loss=0.00689, val_loss=0.00857,\n",
      "Epoch 82:  81%|▊| 26/32 [00:00<00:00, 30.18it/s, loss=0.00689, val_loss=0.00857,\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 34.77it/s, loss=0.00689, val_loss=0.00855,\u001b[A\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 20.16it/s, loss=0.00689, val_loss=0.00855,\u001b[A\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 35.44it/s, loss=0.00689, val_loss=0.0086, \n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=0.00689, val_loss=0.0086, \n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 35.46it/s, loss=0.00689, val_loss=0.00858,\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 20.53it/s, loss=0.00688, val_loss=0.00858,\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 35.94it/s, loss=0.00688, val_loss=0.00867,\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 20.14it/s, loss=0.00688, val_loss=0.00867,\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 35.48it/s, loss=0.00688, val_loss=0.00854,\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 19.42it/s, loss=0.00687, val_loss=0.00854,\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 34.29it/s, loss=0.00687, val_loss=0.00853,\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 19.29it/s, loss=0.00687, val_loss=0.00853,\n",
      "Epoch 88:  81%|▊| 26/32 [00:00<00:00, 29.07it/s, loss=0.00687, val_loss=0.00853,\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 33.90it/s, loss=0.00687, val_loss=0.00852,\u001b[A\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 20.33it/s, loss=0.00687, val_loss=0.00852,\u001b[A\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 35.79it/s, loss=0.00687, val_loss=0.00853,\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 20.12it/s, loss=0.00686, val_loss=0.00853,\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 35.53it/s, loss=0.00686, val_loss=0.00853,\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 22.12it/s, loss=0.00686, val_loss=0.00853,\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 38.57it/s, loss=0.00686, val_loss=0.00855,\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 22.03it/s, loss=0.00685, val_loss=0.00855,\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.00685, val_loss=0.00851,\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00685, val_loss=0.00851,\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00685, val_loss=0.00848,\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00685, val_loss=0.00848,\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.00685, val_loss=0.00854,\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.00685, val_loss=0.00854,\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.00685, val_loss=0.0085, \n",
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 20.86it/s, loss=0.00684, val_loss=0.0085, \n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 36.43it/s, loss=0.00684, val_loss=0.0084, \n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 21.29it/s, loss=0.00684, val_loss=0.0084, \n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.00684, val_loss=0.00842,\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 20.72it/s, loss=0.00684, val_loss=0.00842,\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 36.11it/s, loss=0.00684, val_loss=0.00845,\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 19.93it/s, loss=0.00683, val_loss=0.00845,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 35.19it/s, loss=0.00683, val_loss=0.00841,\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 34.97it/s, loss=0.00683, val_loss=0.00841,\n",
      "Sizes of clusters: 391, 409\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.9738\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.53it/s, loss=176, val_loss=0.0557, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 37.31it/s, loss=176, val_loss=63.7, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 20.86it/s, loss=2.82, val_loss=63.7, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 36.23it/s, loss=2.82, val_loss=373, avg_val\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 20.57it/s, loss=0.63, val_loss=373, avg_val\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 36.02it/s, loss=0.63, val_loss=105, avg_val\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 19.74it/s, loss=0.288, val_loss=105, avg_va\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 34.71it/s, loss=0.288, val_loss=8.91, avg_v\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 20.63it/s, loss=0.203, val_loss=8.91, avg_v\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 36.13it/s, loss=0.203, val_loss=0.523, avg_\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 19.70it/s, loss=0.188, val_loss=0.523, avg_\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 34.76it/s, loss=0.188, val_loss=0.297, avg_\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 20.51it/s, loss=0.231, val_loss=0.297, avg_\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 36.00it/s, loss=0.231, val_loss=0.475, avg_\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 20.29it/s, loss=0.226, val_loss=0.475, avg_\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 35.79it/s, loss=0.226, val_loss=0.181, avg_\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 20.88it/s, loss=0.199, val_loss=0.181, avg_\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 36.54it/s, loss=0.199, val_loss=0.118, avg_\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 19.75it/s, loss=0.191, val_loss=0.118, avg_\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 34.87it/s, loss=0.191, val_loss=0.0915, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 19.53it/s, loss=0.173, val_loss=0.0915, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 34.27it/s, loss=0.173, val_loss=0.192, avg\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.172, val_loss=0.192, avg\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 36.74it/s, loss=0.172, val_loss=0.145, avg\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.169, val_loss=0.145, avg\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.96it/s, loss=0.169, val_loss=0.0778, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.171, val_loss=0.0778, av\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.171, val_loss=0.0679, av\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.181, val_loss=0.0679, av\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.181, val_loss=0.083, avg\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.48it/s, loss=0.196, val_loss=0.083, avg\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.61it/s, loss=0.196, val_loss=0.1, avg_v\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.48it/s, loss=0.215, val_loss=0.1, avg_v\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.37it/s, loss=0.215, val_loss=0.0754, av\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.243, val_loss=0.0754, av\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.02it/s, loss=0.243, val_loss=0.0836, av\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 20.14it/s, loss=0.282, val_loss=0.0836, av\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 35.55it/s, loss=0.282, val_loss=0.0915, av\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 20.82it/s, loss=0.336, val_loss=0.0915, av\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 36.48it/s, loss=0.336, val_loss=0.116, avg\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.31it/s, loss=0.409, val_loss=0.116, avg\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.26it/s, loss=0.409, val_loss=0.131, avg\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 20.58it/s, loss=0.506, val_loss=0.131, avg\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 36.23it/s, loss=0.506, val_loss=0.249, avg\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.647, val_loss=0.249, avg\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.647, val_loss=0.179, avg\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.871, val_loss=0.179, avg\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.05it/s, loss=0.871, val_loss=0.618, avg\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=1.25, val_loss=0.618, avg_\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.21it/s, loss=1.25, val_loss=0.337, avg_\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.01it/s, loss=1.68, val_loss=0.337, avg_\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 36.69it/s, loss=1.68, val_loss=1.25, avg_v\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 20.35it/s, loss=2.31, val_loss=1.25, avg_v\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 35.89it/s, loss=2.31, val_loss=2.04, avg_v\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 20.94it/s, loss=2.55, val_loss=2.04, avg_v\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 36.62it/s, loss=2.55, val_loss=1.37, avg_v\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 20.72it/s, loss=1.83, val_loss=1.37, avg_v\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 36.40it/s, loss=1.83, val_loss=0.988, avg_\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 20.96it/s, loss=0.968, val_loss=0.988, avg\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 36.43it/s, loss=0.968, val_loss=0.356, avg\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 20.81it/s, loss=0.581, val_loss=0.356, avg\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 36.62it/s, loss=0.581, val_loss=0.355, avg\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.437, val_loss=0.355, avg\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.437, val_loss=0.257, avg\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.26it/s, loss=0.36, val_loss=0.257, avg_\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.23it/s, loss=0.36, val_loss=0.209, avg_\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.20it/s, loss=0.319, val_loss=0.209, avg\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.15it/s, loss=0.319, val_loss=0.171, avg\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.06it/s, loss=0.295, val_loss=0.171, avg\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 36.94it/s, loss=0.295, val_loss=0.136, avg\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.313, val_loss=0.136, avg\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.01it/s, loss=0.313, val_loss=0.137, avg\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 20.16it/s, loss=0.411, val_loss=0.137, avg\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 35.55it/s, loss=0.411, val_loss=0.192, avg\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 19.25it/s, loss=0.673, val_loss=0.192, avg\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 33.75it/s, loss=0.673, val_loss=0.414, avg\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 20.11it/s, loss=1.29, val_loss=0.414, avg_\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 35.28it/s, loss=1.29, val_loss=1.04, avg_v\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 20.90it/s, loss=1.96, val_loss=1.04, avg_v\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 36.54it/s, loss=1.96, val_loss=1.33, avg_v\n",
      "Epoch 40:  50%|▌| 16/32 [00:00<00:00, 19.84it/s, loss=1.09, val_loss=1.33, avg_v\n",
      "Epoch 40: 100%|█| 32/32 [00:00<00:00, 34.96it/s, loss=1.09, val_loss=0.438, avg_\n",
      "Epoch 41:  50%|▌| 16/32 [00:00<00:00, 20.38it/s, loss=0.669, val_loss=0.438, avg\n",
      "Epoch 41: 100%|█| 32/32 [00:00<00:00, 35.86it/s, loss=0.669, val_loss=0.383, avg\n",
      "Epoch 42:  50%|▌| 16/32 [00:00<00:00, 20.44it/s, loss=0.491, val_loss=0.383, avg\n",
      "Epoch 42: 100%|█| 32/32 [00:00<00:00, 35.86it/s, loss=0.491, val_loss=0.33, avg_\n",
      "Epoch 43:  50%|▌| 16/32 [00:00<00:00, 19.96it/s, loss=0.442, val_loss=0.33, avg_\n",
      "Epoch 43: 100%|█| 32/32 [00:00<00:00, 35.15it/s, loss=0.442, val_loss=0.301, avg\n",
      "Epoch 44:  50%|▌| 16/32 [00:00<00:00, 20.70it/s, loss=0.656, val_loss=0.301, avg\n",
      "Epoch 44: 100%|█| 32/32 [00:00<00:00, 36.16it/s, loss=0.656, val_loss=0.323, avg\n",
      "Epoch 45:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=1.32, val_loss=0.323, avg_\n",
      "Epoch 45: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=1.32, val_loss=0.89, avg_v\n",
      "Epoch 46:  50%|▌| 16/32 [00:00<00:00, 20.59it/s, loss=1.97, val_loss=0.89, avg_v\n",
      "Epoch 46: 100%|█| 32/32 [00:00<00:00, 36.09it/s, loss=1.97, val_loss=0.853, avg_\n",
      "Epoch 47:  50%|▌| 16/32 [00:00<00:00, 20.46it/s, loss=2.16, val_loss=0.853, avg_\n",
      "Epoch 47: 100%|█| 32/32 [00:00<00:00, 35.91it/s, loss=2.16, val_loss=1.49, avg_v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  50%|▌| 16/32 [00:00<00:00, 20.54it/s, loss=2.26, val_loss=1.49, avg_v\n",
      "Epoch 48: 100%|█| 32/32 [00:00<00:00, 36.04it/s, loss=2.26, val_loss=3.35, avg_v\n",
      "Epoch 49:  50%|▌| 16/32 [00:00<00:00, 19.66it/s, loss=1.89, val_loss=3.35, avg_v\n",
      "Epoch 49: 100%|█| 32/32 [00:00<00:00, 34.77it/s, loss=1.89, val_loss=2.48, avg_v\n",
      "Epoch 50:  50%|▌| 16/32 [00:00<00:00, 20.69it/s, loss=1.66, val_loss=2.48, avg_v\n",
      "Epoch 50: 100%|█| 32/32 [00:00<00:00, 36.07it/s, loss=1.66, val_loss=1.14, avg_v\n",
      "Epoch 51:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=2.49, val_loss=1.14, avg_v\n",
      "Epoch 51: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=2.49, val_loss=0.839, avg_\n",
      "Epoch 52:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=2.84, val_loss=0.839, avg_\n",
      "Epoch 52: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=2.84, val_loss=1.42, avg_v\n",
      "Epoch 53:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=1.53, val_loss=1.42, avg_v\n",
      "Epoch 53: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=1.53, val_loss=0.599, avg_\n",
      "Epoch 54:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=2, val_loss=0.599, avg_val\n",
      "Epoch 54: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=2, val_loss=0.357, avg_val\n",
      "Epoch 55:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=2.45, val_loss=0.357, avg_\n",
      "Epoch 55: 100%|█| 32/32 [00:00<00:00, 37.63it/s, loss=2.45, val_loss=1.22, avg_v\n",
      "Epoch 56:  50%|▌| 16/32 [00:00<00:00, 21.19it/s, loss=3.83, val_loss=1.22, avg_v\n",
      "Epoch 56: 100%|█| 32/32 [00:00<00:00, 37.10it/s, loss=3.83, val_loss=1.04, avg_v\n",
      "Epoch 57:  50%|▌| 16/32 [00:00<00:00, 22.13it/s, loss=3.42, val_loss=1.04, avg_v\n",
      "Epoch 57: 100%|█| 32/32 [00:00<00:00, 38.60it/s, loss=3.42, val_loss=4.43, avg_v\n",
      "Epoch 58:  50%|▌| 16/32 [00:00<00:00, 20.43it/s, loss=4.05, val_loss=4.43, avg_v\n",
      "Epoch 58: 100%|█| 32/32 [00:00<00:00, 35.96it/s, loss=4.05, val_loss=3.73, avg_v\n",
      "Epoch 59:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=3.3, val_loss=3.73, avg_va\n",
      "Epoch 59: 100%|█| 32/32 [00:00<00:00, 35.45it/s, loss=3.3, val_loss=5.71, avg_va\n",
      "Epoch 60:  50%|▌| 16/32 [00:00<00:00, 19.79it/s, loss=3.83, val_loss=5.71, avg_v\n",
      "Epoch 60: 100%|█| 32/32 [00:00<00:00, 34.92it/s, loss=3.83, val_loss=5.31, avg_v\n",
      "Epoch 61:  50%|▌| 16/32 [00:00<00:00, 19.84it/s, loss=3, val_loss=5.31, avg_val_\n",
      "Epoch 61: 100%|█| 32/32 [00:00<00:00, 34.70it/s, loss=3, val_loss=3.16, avg_val_\n",
      "Epoch 62:  50%|▌| 16/32 [00:00<00:00, 20.23it/s, loss=1.66, val_loss=3.16, avg_v\n",
      "Epoch 62: 100%|█| 32/32 [00:00<00:00, 35.63it/s, loss=1.66, val_loss=1.25, avg_v\n",
      "Epoch 63:  50%|▌| 16/32 [00:00<00:00, 19.77it/s, loss=0.908, val_loss=1.25, avg_\n",
      "Epoch 63: 100%|█| 32/32 [00:00<00:00, 34.85it/s, loss=0.908, val_loss=0.407, avg\n",
      "Epoch 64:  50%|▌| 16/32 [00:00<00:00, 20.22it/s, loss=0.766, val_loss=0.407, avg\n",
      "Epoch 64: 100%|█| 32/32 [00:00<00:00, 35.55it/s, loss=0.766, val_loss=0.502, avg\n",
      "Epoch 65:  50%|▌| 16/32 [00:00<00:00, 20.04it/s, loss=1, val_loss=0.502, avg_val\n",
      "Epoch 65:  75%|▊| 24/32 [00:00<00:00, 28.13it/s, loss=1, val_loss=0.502, avg_val\n",
      "Epoch 65: 100%|█| 32/32 [00:00<00:00, 34.69it/s, loss=1, val_loss=1.18, avg_val_\u001b[A\n",
      "Epoch 66:  50%|▌| 16/32 [00:00<00:00, 20.69it/s, loss=1.02, val_loss=1.18, avg_v\u001b[A\n",
      "Epoch 66: 100%|█| 32/32 [00:00<00:00, 36.41it/s, loss=1.02, val_loss=1.49, avg_v\n",
      "Epoch 67:  50%|▌| 16/32 [00:00<00:00, 20.67it/s, loss=0.614, val_loss=1.49, avg_\n",
      "Epoch 67: 100%|█| 32/32 [00:00<00:00, 35.88it/s, loss=0.614, val_loss=0.656, avg\n",
      "Epoch 68:  50%|▌| 16/32 [00:00<00:00, 20.25it/s, loss=0.33, val_loss=0.656, avg_\n",
      "Epoch 68: 100%|█| 32/32 [00:00<00:00, 35.50it/s, loss=0.33, val_loss=0.167, avg_\n",
      "Epoch 69:  50%|▌| 16/32 [00:00<00:00, 20.94it/s, loss=0.346, val_loss=0.167, avg\n",
      "Epoch 69: 100%|█| 32/32 [00:00<00:00, 36.76it/s, loss=0.346, val_loss=0.15, avg_\n",
      "Epoch 70:  50%|▌| 16/32 [00:00<00:00, 20.31it/s, loss=0.471, val_loss=0.15, avg_\n",
      "Epoch 70: 100%|█| 32/32 [00:00<00:00, 35.82it/s, loss=0.471, val_loss=0.143, avg\n",
      "Epoch 71:  50%|▌| 16/32 [00:00<00:00, 19.94it/s, loss=0.808, val_loss=0.143, avg\n",
      "Epoch 71:  75%|▊| 24/32 [00:00<00:00, 28.58it/s, loss=0.808, val_loss=0.143, avg\n",
      "Epoch 71: 100%|█| 32/32 [00:00<00:00, 34.66it/s, loss=0.808, val_loss=0.267, avg\u001b[A\n",
      "Epoch 72:  50%|▌| 16/32 [00:00<00:00, 20.56it/s, loss=1.75, val_loss=0.267, avg_\u001b[A\n",
      "Epoch 72: 100%|█| 32/32 [00:00<00:00, 36.21it/s, loss=1.75, val_loss=0.608, avg_\n",
      "Epoch 73:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=2.74, val_loss=0.608, avg_\n",
      "Epoch 73: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=2.74, val_loss=0.847, avg_\n",
      "Epoch 74:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.77, val_loss=0.847, avg_\n",
      "Epoch 74: 100%|█| 32/32 [00:00<00:00, 37.56it/s, loss=0.77, val_loss=0.151, avg_\n",
      "Epoch 75:  50%|▌| 16/32 [00:00<00:00, 21.89it/s, loss=0.312, val_loss=0.151, avg\n",
      "Epoch 75: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.312, val_loss=0.197, avg\n",
      "Epoch 76:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.664, val_loss=0.197, avg\n",
      "Epoch 76: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.664, val_loss=0.164, avg\n",
      "Epoch 77:  50%|▌| 16/32 [00:00<00:00, 21.17it/s, loss=1.24, val_loss=0.164, avg_\n",
      "Epoch 77: 100%|█| 32/32 [00:00<00:00, 37.11it/s, loss=1.24, val_loss=0.534, avg_\n",
      "Epoch 78:  50%|▌| 16/32 [00:00<00:00, 21.17it/s, loss=3.07, val_loss=0.534, avg_\n",
      "Epoch 78: 100%|█| 32/32 [00:00<00:00, 37.08it/s, loss=3.07, val_loss=0.996, avg_\n",
      "Epoch 79:  50%|▌| 16/32 [00:00<00:00, 21.35it/s, loss=7.5, val_loss=0.996, avg_v\n",
      "Epoch 79: 100%|█| 32/32 [00:00<00:00, 36.95it/s, loss=7.5, val_loss=6.33, avg_va\n",
      "Epoch 80:  50%|▌| 16/32 [00:00<00:00, 20.99it/s, loss=13, val_loss=6.33, avg_val\n",
      "Epoch 80: 100%|█| 32/32 [00:00<00:00, 36.79it/s, loss=13, val_loss=18.6, avg_val\n",
      "Epoch 81:  50%|▌| 16/32 [00:00<00:00, 19.72it/s, loss=10.4, val_loss=18.6, avg_v\n",
      "Epoch 81: 100%|█| 32/32 [00:00<00:00, 34.89it/s, loss=10.4, val_loss=10.5, avg_v\n",
      "Epoch 82:  50%|▌| 16/32 [00:00<00:00, 21.00it/s, loss=7.53, val_loss=10.5, avg_v\n",
      "Epoch 82: 100%|█| 32/32 [00:00<00:00, 36.66it/s, loss=7.53, val_loss=10.3, avg_v\n",
      "Epoch 83:  50%|▌| 16/32 [00:00<00:00, 21.15it/s, loss=8.5, val_loss=10.3, avg_va\n",
      "Epoch 83: 100%|█| 32/32 [00:00<00:00, 36.84it/s, loss=8.5, val_loss=6.91, avg_va\n",
      "Epoch 84:  50%|▌| 16/32 [00:00<00:00, 19.75it/s, loss=9.03, val_loss=6.91, avg_v\n",
      "Epoch 84:  75%|▊| 24/32 [00:00<00:00, 28.08it/s, loss=9.03, val_loss=6.91, avg_v\n",
      "Epoch 84: 100%|█| 32/32 [00:00<00:00, 34.52it/s, loss=9.03, val_loss=6.86, avg_v\u001b[A\n",
      "Epoch 85:  50%|▌| 16/32 [00:00<00:00, 20.41it/s, loss=21.6, val_loss=6.86, avg_v\u001b[A\n",
      "Epoch 85: 100%|█| 32/32 [00:00<00:00, 35.77it/s, loss=21.6, val_loss=58, avg_val\n",
      "Epoch 86:  50%|▌| 16/32 [00:00<00:00, 20.83it/s, loss=22.8, val_loss=58, avg_val\n",
      "Epoch 86: 100%|█| 32/32 [00:00<00:00, 36.56it/s, loss=22.8, val_loss=19.4, avg_v\n",
      "Epoch 87:  50%|▌| 16/32 [00:00<00:00, 20.20it/s, loss=9.85, val_loss=19.4, avg_v\n",
      "Epoch 87: 100%|█| 32/32 [00:00<00:00, 35.50it/s, loss=9.85, val_loss=11.9, avg_v\n",
      "Epoch 88:  50%|▌| 16/32 [00:00<00:00, 20.20it/s, loss=7.99, val_loss=11.9, avg_v\n",
      "Epoch 88: 100%|█| 32/32 [00:00<00:00, 35.31it/s, loss=7.99, val_loss=5.33, avg_v\n",
      "Epoch 89:  50%|▌| 16/32 [00:00<00:00, 20.30it/s, loss=4.77, val_loss=5.33, avg_v\n",
      "Epoch 89: 100%|█| 32/32 [00:00<00:00, 35.26it/s, loss=4.77, val_loss=2.91, avg_v\n",
      "Epoch 90:  50%|▌| 16/32 [00:00<00:00, 20.43it/s, loss=2.04, val_loss=2.91, avg_v\n",
      "Epoch 90: 100%|█| 32/32 [00:00<00:00, 35.64it/s, loss=2.04, val_loss=1.52, avg_v\n",
      "Epoch 91:  50%|▌| 16/32 [00:00<00:00, 20.00it/s, loss=1.08, val_loss=1.52, avg_v\n",
      "Epoch 91: 100%|█| 32/32 [00:00<00:00, 35.27it/s, loss=1.08, val_loss=0.503, avg_\n",
      "Epoch 92:  50%|▌| 16/32 [00:00<00:00, 19.74it/s, loss=0.344, val_loss=0.503, avg\n",
      "Epoch 92: 100%|█| 32/32 [00:00<00:00, 34.79it/s, loss=0.344, val_loss=0.109, avg\n",
      "Epoch 93:  50%|▌| 16/32 [00:00<00:00, 20.16it/s, loss=0.101, val_loss=0.109, avg\n",
      "Epoch 93:  75%|▊| 24/32 [00:00<00:00, 28.69it/s, loss=0.101, val_loss=0.109, avg\n",
      "Epoch 93: 100%|█| 32/32 [00:00<00:00, 35.30it/s, loss=0.101, val_loss=0.0482, av\u001b[A\n",
      "Epoch 94:  50%|▌| 16/32 [00:00<00:00, 20.66it/s, loss=0.0557, val_loss=0.0482, a\u001b[A\n",
      "Epoch 94: 100%|█| 32/32 [00:00<00:00, 36.37it/s, loss=0.0557, val_loss=0.045, av\n",
      "Epoch 95:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=0.0493, val_loss=0.045, av\n",
      "Epoch 95: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.0493, val_loss=0.0483, a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.0517, val_loss=0.0483, a\n",
      "Epoch 96: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.0517, val_loss=0.0498, a\n",
      "Epoch 97:  50%|▌| 16/32 [00:00<00:00, 22.02it/s, loss=0.0556, val_loss=0.0498, a\n",
      "Epoch 97: 100%|█| 32/32 [00:00<00:00, 38.46it/s, loss=0.0556, val_loss=0.0516, a\n",
      "Epoch 98:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.0595, val_loss=0.0516, a\n",
      "Epoch 98: 100%|█| 32/32 [00:00<00:00, 38.21it/s, loss=0.0595, val_loss=0.0533, a\n",
      "Epoch 99:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.0648, val_loss=0.0533, a\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 36.93it/s, loss=0.0648, val_loss=0.0568, a\n",
      "Epoch 99: 100%|█| 32/32 [00:00<00:00, 36.68it/s, loss=0.0648, val_loss=0.0568, a\n",
      "Sizes of clusters: 400, 400\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 1.0000\n",
      "\n",
      "Consistency: 0.9401\n",
      "Purity: 0.9844999999999999+-0.012663925141913925\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K2_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=7.22, val_loss=0.0861, avg_\n",
      "Epoch 0:  71%|▋| 34/48 [00:01<00:00, 27.47it/s, loss=7.22, val_loss=0.0861, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 35.80it/s, loss=7.22, val_loss=6.38, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=0.289, val_loss=6.38, avg_v\u001b[A\n",
      "Epoch 1:  69%|▋| 33/48 [00:01<00:00, 27.66it/s, loss=0.289, val_loss=6.38, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 36.66it/s, loss=0.289, val_loss=0.241, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 19.73it/s, loss=0.051, val_loss=0.241, avg_\u001b[A\n",
      "Epoch 2:  62%|▋| 30/48 [00:01<00:00, 24.15it/s, loss=0.051, val_loss=0.241, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 34.93it/s, loss=0.051, val_loss=0.0427, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 20.31it/s, loss=0.0246, val_loss=0.0427, av\u001b[A\n",
      "Epoch 3:  67%|▋| 32/48 [00:01<00:00, 26.17it/s, loss=0.0246, val_loss=0.0427, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 35.84it/s, loss=0.0246, val_loss=0.0239, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.0184, val_loss=0.0239, av\u001b[A\n",
      "Epoch 4:  67%|▋| 32/48 [00:01<00:00, 26.11it/s, loss=0.0184, val_loss=0.0239, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 35.61it/s, loss=0.0184, val_loss=0.0193, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 20.08it/s, loss=0.0153, val_loss=0.0193, av\u001b[A\n",
      "Epoch 5:  67%|▋| 32/48 [00:01<00:00, 26.08it/s, loss=0.0153, val_loss=0.0193, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 35.48it/s, loss=0.0153, val_loss=0.0165, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.0132, val_loss=0.0165, av\u001b[A\n",
      "Epoch 6:  67%|▋| 32/48 [00:01<00:00, 26.27it/s, loss=0.0132, val_loss=0.0165, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 35.73it/s, loss=0.0132, val_loss=0.0143, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.0116, val_loss=0.0143, av\u001b[A\n",
      "Epoch 7:  67%|▋| 32/48 [00:01<00:00, 28.70it/s, loss=0.0116, val_loss=0.0143, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.0116, val_loss=0.0126, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.0103, val_loss=0.0126, av\u001b[A\n",
      "Epoch 8:  67%|▋| 32/48 [00:01<00:00, 28.30it/s, loss=0.0103, val_loss=0.0126, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.0103, val_loss=0.0113, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.37it/s, loss=0.00919, val_loss=0.0113, a\u001b[A\n",
      "Epoch 9:  67%|▋| 32/48 [00:01<00:00, 27.54it/s, loss=0.00919, val_loss=0.0113, a\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 37.53it/s, loss=0.00919, val_loss=0.0101, a\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.03it/s, loss=0.00828, val_loss=0.0101, \u001b[A\n",
      "Epoch 10:  67%|▋| 32/48 [00:01<00:00, 27.16it/s, loss=0.00828, val_loss=0.0101, \n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 36.78it/s, loss=0.00828, val_loss=0.00904,\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.06it/s, loss=0.0075, val_loss=0.00904, \u001b[A\n",
      "Epoch 11:  67%|▋| 32/48 [00:01<00:00, 27.35it/s, loss=0.0075, val_loss=0.00904, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 36.86it/s, loss=0.0075, val_loss=0.00811, \u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 20.09it/s, loss=0.00682, val_loss=0.00811,\u001b[A\n",
      "Epoch 12:  67%|▋| 32/48 [00:01<00:00, 25.80it/s, loss=0.00682, val_loss=0.00811,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 35.31it/s, loss=0.00682, val_loss=0.00737,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00623, val_loss=0.00737,\u001b[A\n",
      "Epoch 13:  67%|▋| 32/48 [00:01<00:00, 26.21it/s, loss=0.00623, val_loss=0.00737,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 36.02it/s, loss=0.00623, val_loss=0.00676,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 20.06it/s, loss=0.00573, val_loss=0.00676,\u001b[A\n",
      "Epoch 14:  67%|▋| 32/48 [00:01<00:00, 26.06it/s, loss=0.00573, val_loss=0.00676,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 35.47it/s, loss=0.00573, val_loss=0.00618,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00529, val_loss=0.00618,\u001b[A\n",
      "Epoch 15:  67%|▋| 32/48 [00:01<00:00, 26.24it/s, loss=0.00529, val_loss=0.00618,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 35.90it/s, loss=0.00529, val_loss=0.00571,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00492, val_loss=0.00571,\u001b[A\n",
      "Epoch 16:  67%|▋| 32/48 [00:01<00:00, 25.60it/s, loss=0.00492, val_loss=0.00571,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 35.12it/s, loss=0.00492, val_loss=0.00526,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 20.57it/s, loss=0.00461, val_loss=0.00526,\u001b[A\n",
      "Epoch 17:  67%|▋| 32/48 [00:01<00:00, 26.09it/s, loss=0.00461, val_loss=0.00526,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 35.81it/s, loss=0.00461, val_loss=0.00489,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.00434, val_loss=0.00489,\u001b[A\n",
      "Epoch 18:  67%|▋| 32/48 [00:01<00:00, 26.06it/s, loss=0.00434, val_loss=0.00489,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 35.64it/s, loss=0.00434, val_loss=0.00458,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00411, val_loss=0.00458,\u001b[A\n",
      "Epoch 19:  67%|▋| 32/48 [00:01<00:00, 26.31it/s, loss=0.00411, val_loss=0.00458,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 35.63it/s, loss=0.00411, val_loss=0.00433,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 19.72it/s, loss=0.00392, val_loss=0.00433,\u001b[A\n",
      "Epoch 20:  67%|▋| 32/48 [00:01<00:00, 25.33it/s, loss=0.00392, val_loss=0.00433,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 34.92it/s, loss=0.00392, val_loss=0.0041, \u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.00376, val_loss=0.0041, \u001b[A\n",
      "Epoch 21:  67%|▋| 32/48 [00:01<00:00, 27.80it/s, loss=0.00376, val_loss=0.0041, \n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.00376, val_loss=0.0039, \u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.00362, val_loss=0.0039, \u001b[A\n",
      "Epoch 22:  67%|▋| 32/48 [00:01<00:00, 28.51it/s, loss=0.00362, val_loss=0.0039, \n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00362, val_loss=0.00375,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.00351, val_loss=0.00375,\u001b[A\n",
      "Epoch 23:  67%|▋| 32/48 [00:01<00:00, 28.41it/s, loss=0.00351, val_loss=0.00375,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.00351, val_loss=0.00363,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.46it/s, loss=0.00342, val_loss=0.00363,\u001b[A\n",
      "Epoch 24:  67%|▋| 32/48 [00:01<00:00, 27.73it/s, loss=0.00342, val_loss=0.00363,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00342, val_loss=0.00353,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 20.55it/s, loss=0.00334, val_loss=0.00353,\u001b[A\n",
      "Epoch 25:  67%|▋| 32/48 [00:01<00:00, 26.42it/s, loss=0.00334, val_loss=0.00353,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 36.09it/s, loss=0.00334, val_loss=0.00344,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 20.78it/s, loss=0.00327, val_loss=0.00344,\u001b[A\n",
      "Epoch 26:  67%|▋| 32/48 [00:01<00:00, 26.83it/s, loss=0.00327, val_loss=0.00344,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 36.58it/s, loss=0.00327, val_loss=0.00337,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00321, val_loss=0.00337,\u001b[A\n",
      "Epoch 27:  67%|▋| 32/48 [00:01<00:00, 26.65it/s, loss=0.00321, val_loss=0.00337,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 36.20it/s, loss=0.00321, val_loss=0.0033, \u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 22.16it/s, loss=0.00317, val_loss=0.0033, \u001b[A\n",
      "Epoch 28:  67%|▋| 32/48 [00:01<00:00, 28.73it/s, loss=0.00317, val_loss=0.0033, \n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.73it/s, loss=0.00317, val_loss=0.00324,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.00312, val_loss=0.00324,\u001b[A\n",
      "Epoch 29:  67%|▋| 32/48 [00:01<00:00, 27.74it/s, loss=0.00312, val_loss=0.00324,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.57it/s, loss=0.00312, val_loss=0.0032, \u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 20.60it/s, loss=0.00309, val_loss=0.0032, \u001b[A\n",
      "Epoch 30:  67%|▋| 32/48 [00:01<00:00, 26.51it/s, loss=0.00309, val_loss=0.0032, \n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 36.08it/s, loss=0.00309, val_loss=0.00315,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 20.09it/s, loss=0.00305, val_loss=0.00315,\u001b[A\n",
      "Epoch 31:  67%|▋| 32/48 [00:01<00:00, 25.93it/s, loss=0.00305, val_loss=0.00315,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 35.45it/s, loss=0.00305, val_loss=0.00311,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 20.69it/s, loss=0.00302, val_loss=0.00311,\u001b[A\n",
      "Epoch 32:  67%|▋| 32/48 [00:01<00:00, 26.63it/s, loss=0.00302, val_loss=0.00311,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 36.41it/s, loss=0.00302, val_loss=0.00308,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.15it/s, loss=0.003, val_loss=0.00308, a\u001b[A\n",
      "Epoch 33:  67%|▋| 32/48 [00:01<00:00, 27.45it/s, loss=0.003, val_loss=0.00308, a\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.18it/s, loss=0.003, val_loss=0.00305, a\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00297, val_loss=0.00305,\u001b[A\n",
      "Epoch 34:  67%|▋| 32/48 [00:01<00:00, 28.56it/s, loss=0.00297, val_loss=0.00305,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.54it/s, loss=0.00297, val_loss=0.00303,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 20.99it/s, loss=0.00295, val_loss=0.00303,\u001b[A\n",
      "Epoch 35:  67%|▋| 32/48 [00:01<00:00, 27.27it/s, loss=0.00295, val_loss=0.00303,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 36.95it/s, loss=0.00295, val_loss=0.00301,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.22it/s, loss=0.00293, val_loss=0.00301,\u001b[A\n",
      "Epoch 36:  67%|▋| 32/48 [00:01<00:00, 27.48it/s, loss=0.00293, val_loss=0.00301,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.20it/s, loss=0.00293, val_loss=0.00299,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00291, val_loss=0.00299,\u001b[A\n",
      "Epoch 37:  67%|▋| 32/48 [00:01<00:00, 26.09it/s, loss=0.00291, val_loss=0.00299,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 35.58it/s, loss=0.00291, val_loss=0.00297,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 20.25it/s, loss=0.0029, val_loss=0.00297, \u001b[A\n",
      "Epoch 38:  67%|▋| 32/48 [00:01<00:00, 26.15it/s, loss=0.0029, val_loss=0.00297, \n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 35.59it/s, loss=0.0029, val_loss=0.00295, \u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00288, val_loss=0.00295,\u001b[A\n",
      "Epoch 39:  67%|▋| 32/48 [00:01<00:00, 26.28it/s, loss=0.00288, val_loss=0.00295,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 35.78it/s, loss=0.00288, val_loss=0.00294,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.00287, val_loss=0.00294,\u001b[A\n",
      "Epoch 40:  67%|▋| 32/48 [00:01<00:00, 26.16it/s, loss=0.00287, val_loss=0.00294,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 35.84it/s, loss=0.00287, val_loss=0.00293,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 20.08it/s, loss=0.00286, val_loss=0.00293,\u001b[A\n",
      "Epoch 41:  67%|▋| 32/48 [00:01<00:00, 26.10it/s, loss=0.00286, val_loss=0.00293,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 35.52it/s, loss=0.00286, val_loss=0.00292,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 20.42it/s, loss=0.00284, val_loss=0.00292,\u001b[A\n",
      "Epoch 42:  67%|▋| 32/48 [00:01<00:00, 26.26it/s, loss=0.00284, val_loss=0.00292,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 35.81it/s, loss=0.00284, val_loss=0.00291,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00283, val_loss=0.00291,\u001b[A\n",
      "Epoch 43:  67%|▋| 32/48 [00:01<00:00, 26.47it/s, loss=0.00283, val_loss=0.00291,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 35.99it/s, loss=0.00283, val_loss=0.00291,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 20.22it/s, loss=0.00282, val_loss=0.00291,\u001b[A\n",
      "Epoch 44:  67%|▋| 32/48 [00:01<00:00, 26.17it/s, loss=0.00282, val_loss=0.00291,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 35.65it/s, loss=0.00282, val_loss=0.0029, \u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 20.18it/s, loss=0.00281, val_loss=0.0029, \u001b[A\n",
      "Epoch 45:  67%|▋| 32/48 [00:01<00:00, 26.18it/s, loss=0.00281, val_loss=0.0029, \n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 35.61it/s, loss=0.00281, val_loss=0.0029, \u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 20.81it/s, loss=0.0028, val_loss=0.0029, a\u001b[A\n",
      "Epoch 46:  67%|▋| 32/48 [00:01<00:00, 26.83it/s, loss=0.0028, val_loss=0.0029, a\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 36.44it/s, loss=0.0028, val_loss=0.0029, a\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00279, val_loss=0.0029, \u001b[A\n",
      "Epoch 47:  67%|▋| 32/48 [00:01<00:00, 28.45it/s, loss=0.00279, val_loss=0.0029, \n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 38.40it/s, loss=0.00279, val_loss=0.0029, \u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 22.00it/s, loss=0.00278, val_loss=0.0029, \u001b[A\n",
      "Epoch 48:  67%|▋| 32/48 [00:01<00:00, 28.52it/s, loss=0.00278, val_loss=0.0029, \n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 38.49it/s, loss=0.00278, val_loss=0.0029, \u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00277, val_loss=0.0029, \u001b[A\n",
      "Epoch 49:  67%|▋| 32/48 [00:01<00:00, 28.09it/s, loss=0.00277, val_loss=0.0029, \n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 37.79it/s, loss=0.00277, val_loss=0.00289,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00276, val_loss=0.00289,\u001b[A\n",
      "Epoch 50:  67%|▋| 32/48 [00:01<00:00, 27.96it/s, loss=0.00276, val_loss=0.00289,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00276, val_loss=0.00289,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 21.09it/s, loss=0.00276, val_loss=0.00289,\u001b[A\n",
      "Epoch 51:  67%|▋| 32/48 [00:01<00:00, 27.19it/s, loss=0.00276, val_loss=0.00289,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 37.04it/s, loss=0.00276, val_loss=0.00289,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 20.19it/s, loss=0.00275, val_loss=0.00289,\u001b[A\n",
      "Epoch 52:  67%|▋| 32/48 [00:01<00:00, 26.17it/s, loss=0.00275, val_loss=0.00289,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 35.60it/s, loss=0.00275, val_loss=0.00289,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 20.22it/s, loss=0.00274, val_loss=0.00289,\u001b[A\n",
      "Epoch 53:  67%|▋| 32/48 [00:01<00:00, 26.16it/s, loss=0.00274, val_loss=0.00289,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 35.68it/s, loss=0.00274, val_loss=0.00289,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00274, val_loss=0.00289,\u001b[A\n",
      "Epoch 54:  67%|▋| 32/48 [00:01<00:00, 26.27it/s, loss=0.00274, val_loss=0.00289,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 35.64it/s, loss=0.00274, val_loss=0.0029, \u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.00273, val_loss=0.0029, \u001b[A\n",
      "Epoch 55:  67%|▋| 32/48 [00:01<00:00, 26.14it/s, loss=0.00273, val_loss=0.0029, \n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 35.55it/s, loss=0.00273, val_loss=0.0029, \u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00272, val_loss=0.0029, \u001b[A\n",
      "Epoch 56:  67%|▋| 32/48 [00:01<00:00, 26.08it/s, loss=0.00272, val_loss=0.0029, \n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 35.52it/s, loss=0.00272, val_loss=0.00289,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 19.95it/s, loss=0.00272, val_loss=0.00289,\u001b[A\n",
      "Epoch 57:  67%|▋| 32/48 [00:01<00:00, 25.84it/s, loss=0.00272, val_loss=0.00289,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 35.28it/s, loss=0.00272, val_loss=0.00289,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=0.00271, val_loss=0.00289,\u001b[A\n",
      "Epoch 58:  67%|▋| 32/48 [00:01<00:00, 26.32it/s, loss=0.00271, val_loss=0.00289,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 36.05it/s, loss=0.00271, val_loss=0.0029, \u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 20.66it/s, loss=0.00271, val_loss=0.0029, \u001b[A\n",
      "Epoch 59:  67%|▋| 32/48 [00:01<00:00, 26.69it/s, loss=0.00271, val_loss=0.0029, \n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 36.36it/s, loss=0.00271, val_loss=0.00291,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 19.66it/s, loss=0.0027, val_loss=0.00291, \u001b[A\n",
      "Epoch 60:  67%|▋| 32/48 [00:01<00:00, 25.44it/s, loss=0.0027, val_loss=0.00291, \n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 34.63it/s, loss=0.0027, val_loss=0.00291, \u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 20.47it/s, loss=0.0027, val_loss=0.00291, \u001b[A\n",
      "Epoch 61:  67%|▋| 32/48 [00:01<00:00, 26.62it/s, loss=0.0027, val_loss=0.00291, \n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 36.16it/s, loss=0.0027, val_loss=0.00292, \u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 22.17it/s, loss=0.00269, val_loss=0.00292,\u001b[A\n",
      "Epoch 62:  67%|▋| 32/48 [00:01<00:00, 28.75it/s, loss=0.00269, val_loss=0.00292,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 38.76it/s, loss=0.00269, val_loss=0.00293,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 22.16it/s, loss=0.00269, val_loss=0.00293,\u001b[A\n",
      "Epoch 63:  67%|▋| 32/48 [00:01<00:00, 28.75it/s, loss=0.00269, val_loss=0.00293,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 38.76it/s, loss=0.00269, val_loss=0.00293,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00269, val_loss=0.00293,\u001b[A\n",
      "Epoch 64:  67%|▋| 32/48 [00:01<00:00, 27.92it/s, loss=0.00269, val_loss=0.00293,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00269, val_loss=0.00294,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00268, val_loss=0.00294,\u001b[A\n",
      "Epoch 65:  67%|▋| 32/48 [00:01<00:00, 27.90it/s, loss=0.00268, val_loss=0.00294,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00268, val_loss=0.00295,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 21.16it/s, loss=0.00268, val_loss=0.00295,\u001b[A\n",
      "Epoch 66:  67%|▋| 32/48 [00:01<00:00, 27.46it/s, loss=0.00268, val_loss=0.00295,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 37.16it/s, loss=0.00268, val_loss=0.00296,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 20.37it/s, loss=0.00267, val_loss=0.00296,\u001b[A\n",
      "Epoch 67:  67%|▋| 32/48 [00:01<00:00, 26.43it/s, loss=0.00267, val_loss=0.00296,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 35.97it/s, loss=0.00267, val_loss=0.00297,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 20.32it/s, loss=0.00267, val_loss=0.00297,\u001b[A\n",
      "Epoch 68:  67%|▋| 32/48 [00:01<00:00, 26.30it/s, loss=0.00267, val_loss=0.00297,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 35.90it/s, loss=0.00267, val_loss=0.00298,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.00267, val_loss=0.00298,\u001b[A\n",
      "Epoch 69:  67%|▋| 32/48 [00:01<00:00, 26.24it/s, loss=0.00267, val_loss=0.00298,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 35.81it/s, loss=0.00267, val_loss=0.00299,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 20.13it/s, loss=0.00267, val_loss=0.00299,\u001b[A\n",
      "Epoch 70:  67%|▋| 32/48 [00:01<00:00, 26.05it/s, loss=0.00267, val_loss=0.00299,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 35.50it/s, loss=0.00267, val_loss=0.003, a\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 20.50it/s, loss=0.00266, val_loss=0.003, a\u001b[A\n",
      "Epoch 71:  67%|▋| 32/48 [00:01<00:00, 26.24it/s, loss=0.00266, val_loss=0.003, a\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 35.99it/s, loss=0.00266, val_loss=0.00302,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 19.76it/s, loss=0.00266, val_loss=0.00302,\u001b[A\n",
      "Epoch 72:  67%|▋| 32/48 [00:01<00:00, 25.56it/s, loss=0.00266, val_loss=0.00302,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 34.77it/s, loss=0.00266, val_loss=0.00303,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 20.49it/s, loss=0.00266, val_loss=0.00303,\u001b[A\n",
      "Epoch 73:  67%|▋| 32/48 [00:01<00:00, 26.54it/s, loss=0.00266, val_loss=0.00303,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 36.05it/s, loss=0.00266, val_loss=0.00304,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 20.16it/s, loss=0.00266, val_loss=0.00304,\u001b[A\n",
      "Epoch 74:  67%|▋| 32/48 [00:01<00:00, 25.99it/s, loss=0.00266, val_loss=0.00304,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 35.52it/s, loss=0.00266, val_loss=0.00306,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 19.84it/s, loss=0.00266, val_loss=0.00306,\u001b[A\n",
      "Epoch 75:  67%|▋| 32/48 [00:01<00:00, 25.71it/s, loss=0.00266, val_loss=0.00306,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 35.06it/s, loss=0.00266, val_loss=0.00307,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 21.26it/s, loss=0.00265, val_loss=0.00307,\u001b[A\n",
      "Epoch 76:  67%|▋| 32/48 [00:01<00:00, 27.60it/s, loss=0.00265, val_loss=0.00307,\n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 37.38it/s, loss=0.00265, val_loss=0.00309,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 21.86it/s, loss=0.00265, val_loss=0.00309,\u001b[A\n",
      "Epoch 77:  67%|▋| 32/48 [00:01<00:00, 28.37it/s, loss=0.00265, val_loss=0.00309,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00265, val_loss=0.0031, \u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 22.36it/s, loss=0.00265, val_loss=0.0031, \u001b[A\n",
      "Epoch 78:  67%|▋| 32/48 [00:01<00:00, 28.99it/s, loss=0.00265, val_loss=0.0031, \n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 39.05it/s, loss=0.00265, val_loss=0.00312,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 21.41it/s, loss=0.00265, val_loss=0.00312,\u001b[A\n",
      "Epoch 79:  67%|▋| 32/48 [00:01<00:00, 27.78it/s, loss=0.00265, val_loss=0.00312,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 37.58it/s, loss=0.00265, val_loss=0.00313,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 21.46it/s, loss=0.00265, val_loss=0.00313,\u001b[A\n",
      "Epoch 80:  67%|▋| 32/48 [00:01<00:00, 27.82it/s, loss=0.00265, val_loss=0.00313,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00265, val_loss=0.00315,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00265, val_loss=0.00315,\u001b[A\n",
      "Epoch 81:  67%|▋| 32/48 [00:01<00:00, 26.72it/s, loss=0.00265, val_loss=0.00315,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00265, val_loss=0.00317,\u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 20.01it/s, loss=0.00265, val_loss=0.00317,\u001b[A\n",
      "Epoch 82:  67%|▋| 32/48 [00:01<00:00, 25.59it/s, loss=0.00265, val_loss=0.00317,\n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 34.98it/s, loss=0.00265, val_loss=0.00318,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 20.06it/s, loss=0.00264, val_loss=0.00318,\u001b[A\n",
      "Epoch 83:  67%|▋| 32/48 [00:01<00:00, 25.63it/s, loss=0.00264, val_loss=0.00318,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 34.96it/s, loss=0.00264, val_loss=0.0032, \u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 20.39it/s, loss=0.00264, val_loss=0.0032, \u001b[A\n",
      "Epoch 84:  67%|▋| 32/48 [00:01<00:00, 26.34it/s, loss=0.00264, val_loss=0.0032, \n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 35.82it/s, loss=0.00264, val_loss=0.00321,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 19.45it/s, loss=0.00264, val_loss=0.00321,\u001b[A\n",
      "Epoch 85:  67%|▋| 32/48 [00:01<00:00, 25.30it/s, loss=0.00264, val_loss=0.00321,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 34.37it/s, loss=0.00264, val_loss=0.00322,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00264, val_loss=0.00322,\u001b[A\n",
      "Epoch 86:  67%|▋| 32/48 [00:01<00:00, 26.60it/s, loss=0.00264, val_loss=0.00322,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 36.22it/s, loss=0.00264, val_loss=0.00324,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 20.04it/s, loss=0.00264, val_loss=0.00324,\u001b[A\n",
      "Epoch 87:  67%|▋| 32/48 [00:01<00:00, 26.06it/s, loss=0.00264, val_loss=0.00324,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 35.48it/s, loss=0.00264, val_loss=0.00325,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 20.47it/s, loss=0.00264, val_loss=0.00325,\u001b[A\n",
      "Epoch 88:  67%|▋| 32/48 [00:01<00:00, 26.48it/s, loss=0.00264, val_loss=0.00325,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 36.10it/s, loss=0.00264, val_loss=0.00327,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 19.42it/s, loss=0.00264, val_loss=0.00327,\u001b[A\n",
      "Epoch 89:  67%|▋| 32/48 [00:01<00:00, 24.94it/s, loss=0.00264, val_loss=0.00327,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 34.28it/s, loss=0.00264, val_loss=0.00327,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 20.39it/s, loss=0.00264, val_loss=0.00327,\u001b[A\n",
      "Epoch 90:  67%|▋| 32/48 [00:01<00:00, 26.17it/s, loss=0.00264, val_loss=0.00327,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 35.78it/s, loss=0.00264, val_loss=0.00328,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00264, val_loss=0.00328,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91:  67%|▋| 32/48 [00:01<00:00, 27.95it/s, loss=0.00264, val_loss=0.00328,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00264, val_loss=0.00329,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00264, val_loss=0.00329,\u001b[A\n",
      "Epoch 92:  67%|▋| 32/48 [00:01<00:00, 28.70it/s, loss=0.00264, val_loss=0.00329,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 38.70it/s, loss=0.00264, val_loss=0.00331,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00264, val_loss=0.00331,\u001b[A\n",
      "Epoch 93:  67%|▋| 32/48 [00:01<00:00, 27.97it/s, loss=0.00264, val_loss=0.00331,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00264, val_loss=0.00331,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.00264, val_loss=0.00331,\u001b[A\n",
      "Epoch 94:  67%|▋| 32/48 [00:01<00:00, 27.80it/s, loss=0.00264, val_loss=0.00331,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 37.52it/s, loss=0.00264, val_loss=0.00332,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 21.14it/s, loss=0.00264, val_loss=0.00332,\u001b[A\n",
      "Epoch 95:  67%|▋| 32/48 [00:01<00:00, 27.43it/s, loss=0.00264, val_loss=0.00332,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 37.13it/s, loss=0.00264, val_loss=0.00332,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 20.40it/s, loss=0.00265, val_loss=0.00332,\u001b[A\n",
      "Epoch 96:  67%|▋| 32/48 [00:01<00:00, 26.20it/s, loss=0.00265, val_loss=0.00332,\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 35.75it/s, loss=0.00265, val_loss=0.00334,\u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 20.32it/s, loss=0.00265, val_loss=0.00334,\u001b[A\n",
      "Epoch 97:  67%|▋| 32/48 [00:01<00:00, 26.37it/s, loss=0.00265, val_loss=0.00334,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 35.86it/s, loss=0.00265, val_loss=0.00336,\u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 20.92it/s, loss=0.00264, val_loss=0.00336,\u001b[A\n",
      "Epoch 98:  67%|▋| 32/48 [00:01<00:00, 26.93it/s, loss=0.00264, val_loss=0.00336,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 36.83it/s, loss=0.00264, val_loss=0.00335,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 19.53it/s, loss=0.00264, val_loss=0.00335,\u001b[A\n",
      "Epoch 99:  67%|▋| 32/48 [00:01<00:00, 25.29it/s, loss=0.00264, val_loss=0.00335,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 34.65it/s, loss=0.00264, val_loss=0.00335,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 34.30it/s, loss=0.00264, val_loss=0.00335,\u001b[A\n",
      "Sizes of clusters: 280, 535, 385\n",
      "\n",
      "preds: [1 1 1 2 1 1 1 2 1 1 1 2 1 1 2 2 2 1 1 1 2 1 1 1 1 2 2 2 2 1 2 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 1 1 1\n",
      " 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 2 1 0 1 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 2 1 1 1 2 2 1 1 1 2 1 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 2 1 2 1 2 2 1 1 1 1 1 1 1 2 2 2 1 1 1 2 1 2 2 2 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 2 1 1 1 1 1 1 2 2 2 1 1 1 2 1 1 2 2 1 2\n",
      " 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2\n",
      " 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 2 2 2 1 1 1 2 2 2 1 1 0 0 2 2 0 0 0\n",
      " 0 2 0 2 0 2 0 0 0 2 2 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2\n",
      " 2 0 2 0 0 2 0 2 2 0 2 0 0 2 0 2 0 1 2 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 2\n",
      " 2 0 0 2 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 0 0 2 2 2 0 0 0 0 2 0 0\n",
      " 0 2 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 2 0 0 2 0 0 2 2\n",
      " 0 0 0 0 0 2 0 2 0 0 0 2 0 2 0 0 2 0 2 2 0 0 2 0 2 0 0 0 0 2 2 0 0 2 0 2 0\n",
      " 0 2 0 0 0 0 2 2 0 0 0 0 0 0 2 2 2 0 2 2 0 2 2 0 0 2 0 0 2 0 0 0 2 0 2 0 0\n",
      " 0 2 0 0 0 2 1 0 0 2 0 2 0 0 2 0 2 2 2 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 2 2 0\n",
      " 2 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0\n",
      " 0 2 2 2 2 2 0 2 0 0 0 0 0 0 2 0 2 0 2 0 2 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 0\n",
      " 0 0 2 2 2 0 2 0 0 2 0 2 0 0 0 0 0 0 0 2 2 2 0 1 0 0 2 2 2 2 2 2 0 0 2 0 2\n",
      " 0 0 0 0 2 0 0 0 2 0 0 2 2 0 2 0 0 0 0 0 0 0 2 1 2 1 1 2 1 1 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 1 2 1 2 0 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2\n",
      " 2 1 2 2 2 2 1 2 2 2 1 1 2 2 1 1 1 1 1 2 1 2 2 2 1 1 1 0 1 2 1 2 1 2 2 1 1\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2\n",
      " 2 1 2 1 2 2 1 2 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 2 1 2 1 2 2 2 1 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 1 1 2 1 2 1 1 2 1 2 1 1 2 2 1 1\n",
      " 1 1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1 1 2 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1\n",
      " 2 2 1 2 0 1 1 1 2 2 1 2 2 1 1 2 1 1 2 1 1 2 1 1 1 2 1 1 1 1 2 2 1 2 2 1 1\n",
      " 2 1 2 1 1 1 2 1 2 2 2 2 1 1 1 0 2 1 1 1 1 1 2 2 1 2 1 2 1 2 2 1 1 1 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 1 2 2 1 0 2 1 2 1 2 2 0 1 2 1 1 1 1 1 1 2 1 1 2 1 1 1\n",
      " 2 2 1 2 1 1 2 1 1 2 2 2 2 2 1 1 2 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 1 1 2 2\n",
      " 1 1 2 1 1 1 2 1 1 1 1 1 2 2 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5900\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 20.12it/s, loss=5.65, val_loss=0.0633, avg_\n",
      "Epoch 0:  88%|▉| 42/48 [00:01<00:00, 32.48it/s, loss=5.65, val_loss=0.0633, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 35.34it/s, loss=5.65, val_loss=6.6, avg_val\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 20.01it/s, loss=0.223, val_loss=6.6, avg_va\u001b[A\n",
      "Epoch 1:  75%|▊| 36/48 [00:01<00:00, 28.49it/s, loss=0.223, val_loss=6.6, avg_va\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 35.36it/s, loss=0.223, val_loss=1.47, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 20.29it/s, loss=0.0514, val_loss=1.47, avg_\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 28.92it/s, loss=0.0514, val_loss=1.47, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 35.79it/s, loss=0.0514, val_loss=0.0671, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 19.80it/s, loss=0.0286, val_loss=0.0671, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 28.32it/s, loss=0.0286, val_loss=0.0671, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 34.98it/s, loss=0.0286, val_loss=0.03, avg_\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.0215, val_loss=0.03, avg_\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 30.55it/s, loss=0.0215, val_loss=0.03, avg_\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.54it/s, loss=0.0215, val_loss=0.0233, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.0176, val_loss=0.0233, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.33it/s, loss=0.0176, val_loss=0.0233, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.43it/s, loss=0.0176, val_loss=0.0196, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.0149, val_loss=0.0196, av\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 30.81it/s, loss=0.0149, val_loss=0.0196, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.0149, val_loss=0.0167, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.013, val_loss=0.0167, avg\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.013, val_loss=0.0167, avg\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 37.96it/s, loss=0.013, val_loss=0.0147, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.24it/s, loss=0.0116, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 30.35it/s, loss=0.0116, val_loss=0.0147, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.16it/s, loss=0.0116, val_loss=0.0127, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.03it/s, loss=0.0104, val_loss=0.0127, av\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 30.05it/s, loss=0.0104, val_loss=0.0127, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 36.93it/s, loss=0.0104, val_loss=0.0113, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00943, val_loss=0.0113, \u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 28.75it/s, loss=0.00943, val_loss=0.0113, \n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 35.51it/s, loss=0.00943, val_loss=0.0103, \u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=0.00858, val_loss=0.0103, \u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 29.31it/s, loss=0.00858, val_loss=0.0103, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 36.19it/s, loss=0.00858, val_loss=0.00909,\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=0.00783, val_loss=0.00909,\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 29.20it/s, loss=0.00783, val_loss=0.00909,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 36.17it/s, loss=0.00783, val_loss=0.00833,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 20.29it/s, loss=0.00717, val_loss=0.00833,\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 28.56it/s, loss=0.00717, val_loss=0.00833,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 35.55it/s, loss=0.00717, val_loss=0.00764,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 19.90it/s, loss=0.00658, val_loss=0.00764,\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 28.26it/s, loss=0.00658, val_loss=0.00764,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 35.03it/s, loss=0.00658, val_loss=0.00705,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 19.95it/s, loss=0.00606, val_loss=0.00705,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 28.59it/s, loss=0.00606, val_loss=0.00705,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 35.19it/s, loss=0.00606, val_loss=0.00656,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 20.27it/s, loss=0.0056, val_loss=0.00656, \u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 28.74it/s, loss=0.0056, val_loss=0.00656, \n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 35.60it/s, loss=0.0056, val_loss=0.00614, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 20.34it/s, loss=0.0052, val_loss=0.00614, \u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 29.01it/s, loss=0.0052, val_loss=0.00614, \n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 35.80it/s, loss=0.0052, val_loss=0.00573, \u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 19.95it/s, loss=0.00486, val_loss=0.00573,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 28.37it/s, loss=0.00486, val_loss=0.00573,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 35.08it/s, loss=0.00486, val_loss=0.00536,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00457, val_loss=0.00536,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 30.96it/s, loss=0.00457, val_loss=0.00536,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.00457, val_loss=0.00512,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00433, val_loss=0.00512,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 31.28it/s, loss=0.00433, val_loss=0.00512,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00433, val_loss=0.00488,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00413, val_loss=0.00488,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 31.07it/s, loss=0.00413, val_loss=0.00488,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00413, val_loss=0.00466,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.30it/s, loss=0.00397, val_loss=0.00466,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 30.27it/s, loss=0.00397, val_loss=0.00466,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.38it/s, loss=0.00397, val_loss=0.00454,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.00383, val_loss=0.00454,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 30.62it/s, loss=0.00383, val_loss=0.00454,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.54it/s, loss=0.00383, val_loss=0.0044, \u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 20.02it/s, loss=0.00372, val_loss=0.0044, \u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 28.67it/s, loss=0.00372, val_loss=0.0044, \n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 35.40it/s, loss=0.00372, val_loss=0.00429,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00363, val_loss=0.00429,\u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 28.84it/s, loss=0.00363, val_loss=0.00429,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 35.52it/s, loss=0.00363, val_loss=0.00423,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 20.12it/s, loss=0.00356, val_loss=0.00423,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 28.72it/s, loss=0.00356, val_loss=0.00423,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 35.45it/s, loss=0.00356, val_loss=0.00426,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 20.46it/s, loss=0.00349, val_loss=0.00426,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 29.17it/s, loss=0.00349, val_loss=0.00426,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 36.11it/s, loss=0.00349, val_loss=0.00408,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00344, val_loss=0.00408,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 28.59it/s, loss=0.00344, val_loss=0.00408,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00344, val_loss=0.00422,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 20.07it/s, loss=0.00339, val_loss=0.00422,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 28.63it/s, loss=0.00339, val_loss=0.00422,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 35.47it/s, loss=0.00339, val_loss=0.00392,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 19.99it/s, loss=0.00335, val_loss=0.00392,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 28.38it/s, loss=0.00335, val_loss=0.00392,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 35.11it/s, loss=0.00335, val_loss=0.00399,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00331, val_loss=0.00399,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 29.09it/s, loss=0.00331, val_loss=0.00399,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 36.10it/s, loss=0.00331, val_loss=0.00385,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 20.25it/s, loss=0.00327, val_loss=0.00385,\u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 28.87it/s, loss=0.00327, val_loss=0.00385,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 35.76it/s, loss=0.00327, val_loss=0.00379,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.00324, val_loss=0.00379,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 29.47it/s, loss=0.00324, val_loss=0.00379,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 36.39it/s, loss=0.00324, val_loss=0.0037, \u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00322, val_loss=0.0037, \u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 31.28it/s, loss=0.00322, val_loss=0.0037, \n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00322, val_loss=0.00361,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00319, val_loss=0.00361,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 31.30it/s, loss=0.00319, val_loss=0.00361,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.00319, val_loss=0.00364,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.36it/s, loss=0.00317, val_loss=0.00364,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 30.50it/s, loss=0.00317, val_loss=0.00364,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.48it/s, loss=0.00317, val_loss=0.00361,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.30it/s, loss=0.00314, val_loss=0.00361,\u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 30.29it/s, loss=0.00314, val_loss=0.00361,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.39it/s, loss=0.00314, val_loss=0.00361,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=0.00312, val_loss=0.00361,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 29.73it/s, loss=0.00312, val_loss=0.00361,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 36.69it/s, loss=0.00312, val_loss=0.00355,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.0031, val_loss=0.00355, \u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 28.84it/s, loss=0.0031, val_loss=0.00355, \n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 35.73it/s, loss=0.0031, val_loss=0.00359, \u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 21.00it/s, loss=0.00308, val_loss=0.00359,\u001b[A\n",
      "Epoch 40:  75%|▊| 36/48 [00:01<00:00, 30.01it/s, loss=0.00308, val_loss=0.00359,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 36.83it/s, loss=0.00308, val_loss=0.00354,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00306, val_loss=0.00354,\u001b[A\n",
      "Epoch 41:  75%|▊| 36/48 [00:01<00:00, 28.77it/s, loss=0.00306, val_loss=0.00354,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 35.63it/s, loss=0.00306, val_loss=0.00347,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 20.48it/s, loss=0.00305, val_loss=0.00347,\u001b[A\n",
      "Epoch 42:  75%|▊| 36/48 [00:01<00:00, 29.28it/s, loss=0.00305, val_loss=0.00347,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 36.02it/s, loss=0.00305, val_loss=0.00348,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 20.25it/s, loss=0.00303, val_loss=0.00348,\u001b[A\n",
      "Epoch 43:  75%|▊| 36/48 [00:01<00:00, 28.71it/s, loss=0.00303, val_loss=0.00348,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 35.66it/s, loss=0.00303, val_loss=0.00342,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 20.46it/s, loss=0.00301, val_loss=0.00342,\u001b[A\n",
      "Epoch 44:  75%|▊| 36/48 [00:01<00:00, 29.30it/s, loss=0.00301, val_loss=0.00342,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 36.06it/s, loss=0.00301, val_loss=0.00342,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.003, val_loss=0.00342, a\u001b[A\n",
      "Epoch 45:  75%|▊| 36/48 [00:01<00:00, 28.49it/s, loss=0.003, val_loss=0.00342, a\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 35.36it/s, loss=0.003, val_loss=0.00338, a\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 20.26it/s, loss=0.00298, val_loss=0.00338,\u001b[A\n",
      "Epoch 46:  75%|▊| 36/48 [00:01<00:00, 28.82it/s, loss=0.00298, val_loss=0.00338,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 35.79it/s, loss=0.00298, val_loss=0.0033, \u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 20.25it/s, loss=0.00297, val_loss=0.0033, \u001b[A\n",
      "Epoch 47:  75%|▊| 36/48 [00:01<00:00, 28.85it/s, loss=0.00297, val_loss=0.0033, \n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.00297, val_loss=0.00327,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 21.03it/s, loss=0.00296, val_loss=0.00327,\u001b[A\n",
      "Epoch 48:  75%|▊| 36/48 [00:01<00:00, 30.06it/s, loss=0.00296, val_loss=0.00327,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 36.99it/s, loss=0.00296, val_loss=0.00326,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.00295, val_loss=0.00326,\u001b[A\n",
      "Epoch 49:  75%|▊| 36/48 [00:01<00:00, 31.29it/s, loss=0.00295, val_loss=0.00326,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 38.40it/s, loss=0.00295, val_loss=0.00322,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00294, val_loss=0.00322,\u001b[A\n",
      "Epoch 50:  75%|▊| 36/48 [00:01<00:00, 31.38it/s, loss=0.00294, val_loss=0.00322,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 38.47it/s, loss=0.00294, val_loss=0.0032, \u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00293, val_loss=0.0032, \u001b[A\n",
      "Epoch 51:  75%|▊| 36/48 [00:01<00:00, 30.81it/s, loss=0.00293, val_loss=0.0032, \n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00293, val_loss=0.00318,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 20.57it/s, loss=0.00292, val_loss=0.00318,\u001b[A\n",
      "Epoch 52:  75%|▊| 36/48 [00:01<00:00, 29.42it/s, loss=0.00292, val_loss=0.00318,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00292, val_loss=0.00317,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.00291, val_loss=0.00317,\u001b[A\n",
      "Epoch 53:  75%|▊| 36/48 [00:01<00:00, 29.14it/s, loss=0.00291, val_loss=0.00317,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 35.91it/s, loss=0.00291, val_loss=0.00314,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.0029, val_loss=0.00314, \u001b[A\n",
      "Epoch 54:  75%|▊| 36/48 [00:01<00:00, 29.44it/s, loss=0.0029, val_loss=0.00314, \n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 36.29it/s, loss=0.0029, val_loss=0.00313, \u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00289, val_loss=0.00313,\u001b[A\n",
      "Epoch 55:  75%|▊| 36/48 [00:01<00:00, 31.24it/s, loss=0.00289, val_loss=0.00313,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00289, val_loss=0.0031, \u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 20.87it/s, loss=0.00288, val_loss=0.0031, \u001b[A\n",
      "Epoch 56:  75%|▊| 36/48 [00:01<00:00, 29.32it/s, loss=0.00288, val_loss=0.0031, \n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 36.44it/s, loss=0.00288, val_loss=0.00309,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 20.66it/s, loss=0.00287, val_loss=0.00309,\u001b[A\n",
      "Epoch 57:  75%|▊| 36/48 [00:01<00:00, 29.26it/s, loss=0.00287, val_loss=0.00309,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 36.16it/s, loss=0.00287, val_loss=0.0031, \u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.00287, val_loss=0.0031, \u001b[A\n",
      "Epoch 58:  75%|▊| 36/48 [00:01<00:00, 28.91it/s, loss=0.00287, val_loss=0.0031, \n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 35.80it/s, loss=0.00287, val_loss=0.00305,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 21.10it/s, loss=0.00286, val_loss=0.00305,\u001b[A\n",
      "Epoch 59:  75%|▊| 36/48 [00:01<00:00, 29.99it/s, loss=0.00286, val_loss=0.00305,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 37.03it/s, loss=0.00286, val_loss=0.00304,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.00285, val_loss=0.00304,\u001b[A\n",
      "Epoch 60:  75%|▊| 36/48 [00:01<00:00, 31.25it/s, loss=0.00285, val_loss=0.00304,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00285, val_loss=0.00302,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 21.41it/s, loss=0.00285, val_loss=0.00302,\u001b[A\n",
      "Epoch 61:  75%|▊| 36/48 [00:01<00:00, 30.58it/s, loss=0.00285, val_loss=0.00302,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00285, val_loss=0.003, a\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 21.27it/s, loss=0.00284, val_loss=0.003, a\u001b[A\n",
      "Epoch 62:  75%|▊| 36/48 [00:01<00:00, 30.33it/s, loss=0.00284, val_loss=0.003, a\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 37.29it/s, loss=0.00284, val_loss=0.00299,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 21.24it/s, loss=0.00283, val_loss=0.00299,\u001b[A\n",
      "Epoch 63:  75%|▊| 36/48 [00:01<00:00, 30.02it/s, loss=0.00283, val_loss=0.00299,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 37.08it/s, loss=0.00283, val_loss=0.00298,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 20.68it/s, loss=0.00283, val_loss=0.00298,\u001b[A\n",
      "Epoch 64:  75%|▊| 36/48 [00:01<00:00, 29.38it/s, loss=0.00283, val_loss=0.00298,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00283, val_loss=0.00297,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00282, val_loss=0.00297,\u001b[A\n",
      "Epoch 65:  75%|▊| 36/48 [00:01<00:00, 29.38it/s, loss=0.00282, val_loss=0.00297,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 36.27it/s, loss=0.00282, val_loss=0.00294,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 19.85it/s, loss=0.00282, val_loss=0.00294,\u001b[A\n",
      "Epoch 66:  75%|▊| 36/48 [00:01<00:00, 28.12it/s, loss=0.00282, val_loss=0.00294,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 34.92it/s, loss=0.00282, val_loss=0.00294,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00281, val_loss=0.00294,\u001b[A\n",
      "Epoch 67:  75%|▊| 36/48 [00:01<00:00, 29.01it/s, loss=0.00281, val_loss=0.00294,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 35.92it/s, loss=0.00281, val_loss=0.00294,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 20.03it/s, loss=0.00281, val_loss=0.00294,\u001b[A\n",
      "Epoch 68:  75%|▊| 36/48 [00:01<00:00, 28.29it/s, loss=0.00281, val_loss=0.00294,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 35.18it/s, loss=0.00281, val_loss=0.00292,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 20.06it/s, loss=0.0028, val_loss=0.00292, \u001b[A\n",
      "Epoch 69:  75%|▊| 36/48 [00:01<00:00, 28.47it/s, loss=0.0028, val_loss=0.00292, \n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 35.31it/s, loss=0.0028, val_loss=0.00291, \u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 20.00it/s, loss=0.0028, val_loss=0.00291, \u001b[A\n",
      "Epoch 70:  75%|▊| 36/48 [00:01<00:00, 28.62it/s, loss=0.0028, val_loss=0.00291, \n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 35.20it/s, loss=0.0028, val_loss=0.00289, \u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 20.14it/s, loss=0.0028, val_loss=0.00289, \u001b[A\n",
      "Epoch 71:  75%|▊| 36/48 [00:01<00:00, 28.71it/s, loss=0.0028, val_loss=0.00289, \n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 35.60it/s, loss=0.0028, val_loss=0.00289, \u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 19.80it/s, loss=0.00279, val_loss=0.00289,\u001b[A\n",
      "Epoch 72:  75%|▊| 36/48 [00:01<00:00, 28.25it/s, loss=0.00279, val_loss=0.00289,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 34.77it/s, loss=0.00279, val_loss=0.00286,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 20.95it/s, loss=0.00278, val_loss=0.00286,\u001b[A\n",
      "Epoch 73:  75%|▊| 36/48 [00:01<00:00, 29.97it/s, loss=0.00278, val_loss=0.00286,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 36.88it/s, loss=0.00278, val_loss=0.00288,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.00278, val_loss=0.00288,\u001b[A\n",
      "Epoch 74:  75%|▊| 36/48 [00:01<00:00, 31.46it/s, loss=0.00278, val_loss=0.00288,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 38.57it/s, loss=0.00278, val_loss=0.00285,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 22.12it/s, loss=0.00278, val_loss=0.00285,\u001b[A\n",
      "Epoch 75:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.00278, val_loss=0.00285,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.00278, val_loss=0.00283,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00277, val_loss=0.00283,\u001b[A\n",
      "Epoch 76:  75%|▊| 36/48 [00:01<00:00, 31.21it/s, loss=0.00277, val_loss=0.00283,\n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00277, val_loss=0.00283,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 21.05it/s, loss=0.00277, val_loss=0.00283,\u001b[A\n",
      "Epoch 77:  75%|▊| 36/48 [00:01<00:00, 30.07it/s, loss=0.00277, val_loss=0.00283,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 36.90it/s, loss=0.00277, val_loss=0.00281,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 21.13it/s, loss=0.00277, val_loss=0.00281,\u001b[A\n",
      "Epoch 78:  75%|▊| 36/48 [00:01<00:00, 30.00it/s, loss=0.00277, val_loss=0.00281,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 37.13it/s, loss=0.00277, val_loss=0.00281,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.00276, val_loss=0.00281,\u001b[A\n",
      "Epoch 79:  75%|▊| 36/48 [00:01<00:00, 29.49it/s, loss=0.00276, val_loss=0.00281,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 36.24it/s, loss=0.00276, val_loss=0.00282,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 20.47it/s, loss=0.00276, val_loss=0.00282,\u001b[A\n",
      "Epoch 80:  75%|▊| 36/48 [00:01<00:00, 29.24it/s, loss=0.00276, val_loss=0.00282,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 36.09it/s, loss=0.00276, val_loss=0.00281,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.15it/s, loss=0.00276, val_loss=0.00281,\u001b[A\n",
      "Epoch 81:  75%|▊| 36/48 [00:01<00:00, 28.62it/s, loss=0.00276, val_loss=0.00281,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 35.58it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 20.03it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 82:  75%|▊| 36/48 [00:01<00:00, 28.43it/s, loss=0.00276, val_loss=0.0028, \n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 35.42it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 19.83it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 83:  75%|▊| 36/48 [00:01<00:00, 28.34it/s, loss=0.00276, val_loss=0.0028, \n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 35.13it/s, loss=0.00276, val_loss=0.00279,\u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00276, val_loss=0.00279,\u001b[A\n",
      "Epoch 84:  75%|▊| 36/48 [00:01<00:00, 28.57it/s, loss=0.00276, val_loss=0.00279,\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 35.50it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 20.37it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 85:  75%|▊| 36/48 [00:01<00:00, 29.08it/s, loss=0.00276, val_loss=0.0028, \n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 35.68it/s, loss=0.00276, val_loss=0.0029, \u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 20.66it/s, loss=0.00938, val_loss=0.0029, \u001b[A\n",
      "Epoch 86:  75%|▊| 36/48 [00:01<00:00, 29.24it/s, loss=0.00938, val_loss=0.0029, \n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 35.93it/s, loss=0.00938, val_loss=0.0271, \u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 19.53it/s, loss=0.00516, val_loss=0.0271, \u001b[A\n",
      "Epoch 87:  75%|▊| 36/48 [00:01<00:00, 27.83it/s, loss=0.00516, val_loss=0.0271, \n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 34.41it/s, loss=0.00516, val_loss=0.00285,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00311, val_loss=0.00285,\u001b[A\n",
      "Epoch 88:  75%|▊| 36/48 [00:01<00:00, 30.91it/s, loss=0.00311, val_loss=0.00285,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00311, val_loss=0.00283,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00283, val_loss=0.00283,\u001b[A\n",
      "Epoch 89:  75%|▊| 36/48 [00:01<00:00, 31.37it/s, loss=0.00283, val_loss=0.00283,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 38.46it/s, loss=0.00283, val_loss=0.00295,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00295, val_loss=0.00295,\u001b[A\n",
      "Epoch 90:  75%|▊| 36/48 [00:01<00:00, 31.06it/s, loss=0.00295, val_loss=0.00295,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.00295, val_loss=0.00407,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.0183, val_loss=0.00407, \u001b[A\n",
      "Epoch 91:  75%|▊| 36/48 [00:01<00:00, 30.54it/s, loss=0.0183, val_loss=0.00407, \n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 37.49it/s, loss=0.0183, val_loss=0.015, av\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.00406, val_loss=0.015, a\u001b[A\n",
      "Epoch 92:  75%|▊| 36/48 [00:01<00:00, 30.53it/s, loss=0.00406, val_loss=0.015, a\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 37.51it/s, loss=0.00406, val_loss=0.00321,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 20.33it/s, loss=0.00287, val_loss=0.00321,\u001b[A\n",
      "Epoch 93:  75%|▊| 36/48 [00:01<00:00, 29.00it/s, loss=0.00287, val_loss=0.00321,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 35.61it/s, loss=0.00287, val_loss=0.00286,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 20.22it/s, loss=0.00276, val_loss=0.00286,\u001b[A\n",
      "Epoch 94:  75%|▊| 36/48 [00:01<00:00, 28.80it/s, loss=0.00276, val_loss=0.00286,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.00276, val_loss=0.00286,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 20.43it/s, loss=0.00283, val_loss=0.00286,\u001b[A\n",
      "Epoch 95:  75%|▊| 36/48 [00:01<00:00, 29.19it/s, loss=0.00283, val_loss=0.00286,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 35.97it/s, loss=0.00283, val_loss=0.0033, \u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 19.83it/s, loss=0.0249, val_loss=0.0033, a\u001b[A\n",
      "Epoch 96:  75%|▊| 36/48 [00:01<00:00, 28.30it/s, loss=0.0249, val_loss=0.0033, a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.0249, val_loss=0.00343, \u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 19.40it/s, loss=0.00686, val_loss=0.00343,\u001b[A\n",
      "Epoch 97:  75%|▊| 36/48 [00:01<00:00, 27.64it/s, loss=0.00686, val_loss=0.00343,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 34.25it/s, loss=0.00686, val_loss=0.00318,\u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 20.73it/s, loss=0.00306, val_loss=0.00318,\u001b[A\n",
      "Epoch 98:  75%|▊| 36/48 [00:01<00:00, 29.67it/s, loss=0.00306, val_loss=0.00318,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 36.47it/s, loss=0.00306, val_loss=0.00281,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 20.49it/s, loss=0.00278, val_loss=0.00281,\u001b[A\n",
      "Epoch 99:  75%|▊| 36/48 [00:01<00:00, 29.15it/s, loss=0.00278, val_loss=0.00281,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.99it/s, loss=0.00278, val_loss=0.00286,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00278, val_loss=0.00286,\u001b[A\n",
      "Sizes of clusters: 455, 355, 390\n",
      "\n",
      "preds: [2 2 2 0 2 0 2 0 0 0 2 0 2 2 2 0 0 2 0 2 0 0 2 2 2 0 2 0 0 2 2 0 0 2 2 0 2\n",
      " 2 2 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 0 0 2 0 2 0 2 2 0 2 0 0 2 0 2 2 2 2 2 0\n",
      " 0 2 0 0 0 0 2 2 0 2 2 2 2 0 2 2 2 0 0 0 0 2 0 2 2 0 2 0 0 0 2 2 0 0 2 2 0\n",
      " 0 2 2 2 0 0 0 2 2 2 0 2 0 2 2 2 2 2 2 0 0 0 0 2 2 2 2 0 2 2 0 2 2 2 2 2 0\n",
      " 2 0 2 0 0 0 2 0 2 2 2 0 2 0 2 2 1 0 2 2 2 0 0 0 0 0 2 2 1 2 0 0 0 2 0 2 2\n",
      " 2 0 2 2 2 0 0 2 0 2 0 2 0 2 2 2 2 0 2 0 2 2 0 0 2 2 2 0 2 2 2 0 2 2 2 2 0\n",
      " 2 2 0 0 0 2 2 0 2 2 0 2 0 2 2 0 2 0 2 0 0 2 0 0 0 2 2 2 2 0 0 0 0 0 2 0 0\n",
      " 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 0 0 2 2 0 0 2 0 2 0 2 2 2 0 0 0 2 0\n",
      " 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 0 0 2 2 0 0 2 2 2 2 0 2 2 2 2 2 0 2 2\n",
      " 0 2 0 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 2 0 2 2 0 2 2 2 2 0 0 2 2 2 2 2 2 2 2\n",
      " 2 0 2 2 2 2 2 0 2 0 0 2 2 2 2 2 2 2 0 0 0 0 2 2 2 0 0 0 0 2 0 1 0 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 2 2 0 0 2 0 0 0 0\n",
      " 0 2 0 2 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0 2 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 1 0 0 0 2 0 0 0 0 0 0 2 0 2 0 0 2 2 2 1 2 0 0 1 2 2 0 0 2 0 0 2 0 0 0 0 0\n",
      " 0 0 0 2 2 2 2 2 2 0 0 2 2 0 2 2 0 1 0 2 0 0 2 0 0 0 2 0 2 2 2 2 2 2 0 0 0\n",
      " 0 2 2 0 2 2 2 0 2 2 0 2 0 0 0 0 0 2 0 0 2 2 2 0 2 0 2 0 2 2 0 2 0 0 2 0 2\n",
      " 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 2 2 0 0 2 0 0 2 0 0 0 0 2 0 0 2 0 0 0 2 2 0\n",
      " 0 0 2 1 2 0 0 0 2 2 1 2 0 0 2 0 2 0 0 2 2 0 0 2 0 2 0 2 0 0 0 0 0 0 0 2 2\n",
      " 0 0 2 2 1 0 2 2 0 0 2 1 0 0 2 0 0 2 0 0 2 0 0 2 0 0 0 0 0 0 0 0 2 0 0 2 0\n",
      " 2 0 0 0 2 2 0 0 0 0 2 0 0 2 2 0 0 0 0 0 0 2 0 2 2 0 2 0 0 1 0 0 2 2 2 0 0\n",
      " 2 2 0 2 2 2 2 2 2 2 2 0 0 0 1 0 2 0 2 1 0 1 0 0 0 2 2 0 2 2 2 0 2 2 0 0 0\n",
      " 0 0 2 0 2 2 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 2 2 2 0 0 2 2 2 2 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 0 2 2 2 0 0 0 1 0 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6858\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=18.5, val_loss=0.0843, avg_\n",
      "Epoch 0:  73%|▋| 35/48 [00:01<00:00, 29.04it/s, loss=18.5, val_loss=0.0843, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 36.59it/s, loss=18.5, val_loss=31.2, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.30it/s, loss=0.631, val_loss=31.2, avg_v\u001b[A\n",
      "Epoch 1:  90%|▉| 43/48 [00:01<00:00, 35.05it/s, loss=0.631, val_loss=31.2, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 37.43it/s, loss=0.631, val_loss=1.73, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.0893, val_loss=1.73, avg_\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.96it/s, loss=0.0893, val_loss=1.73, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.71it/s, loss=0.0893, val_loss=0.0758, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.0335, val_loss=0.0758, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.93it/s, loss=0.0335, val_loss=0.0758, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.68it/s, loss=0.0335, val_loss=0.0347, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.0248, val_loss=0.0347, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 32.02it/s, loss=0.0248, val_loss=0.0347, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.0248, val_loss=0.0282, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.37it/s, loss=0.021, val_loss=0.0282, avg\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 31.72it/s, loss=0.021, val_loss=0.0282, avg\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 37.49it/s, loss=0.021, val_loss=0.0241, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.0183, val_loss=0.0241, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 30.27it/s, loss=0.0183, val_loss=0.0241, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 35.82it/s, loss=0.0183, val_loss=0.021, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.0163, val_loss=0.021, avg\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 30.78it/s, loss=0.0163, val_loss=0.021, avg\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 36.32it/s, loss=0.0163, val_loss=0.0186, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 20.63it/s, loss=0.0146, val_loss=0.0186, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 30.72it/s, loss=0.0146, val_loss=0.0186, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 36.25it/s, loss=0.0146, val_loss=0.0166, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 20.36it/s, loss=0.0131, val_loss=0.0166, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 30.23it/s, loss=0.0131, val_loss=0.0166, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 35.69it/s, loss=0.0131, val_loss=0.0148, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.0119, val_loss=0.0148, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 30.26it/s, loss=0.0119, val_loss=0.0148, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 35.93it/s, loss=0.0119, val_loss=0.0134, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.0108, val_loss=0.0134, a\u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 30.32it/s, loss=0.0108, val_loss=0.0134, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.0108, val_loss=0.0121, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00983, val_loss=0.0121, \u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 30.86it/s, loss=0.00983, val_loss=0.0121, \n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 36.49it/s, loss=0.00983, val_loss=0.011, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 20.16it/s, loss=0.00901, val_loss=0.011, a\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 29.89it/s, loss=0.00901, val_loss=0.011, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 35.50it/s, loss=0.00901, val_loss=0.0101, \u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 19.74it/s, loss=0.00829, val_loss=0.0101, \u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 29.53it/s, loss=0.00829, val_loss=0.0101, \n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 34.93it/s, loss=0.00829, val_loss=0.00922,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 20.05it/s, loss=0.00766, val_loss=0.00922,\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 29.99it/s, loss=0.00766, val_loss=0.00922,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00766, val_loss=0.00849,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00711, val_loss=0.00849,\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.00711, val_loss=0.00849,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.00711, val_loss=0.00793,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.21it/s, loss=0.00663, val_loss=0.00793,\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 33.04it/s, loss=0.00663, val_loss=0.00793,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.79it/s, loss=0.00663, val_loss=0.00736,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.00621, val_loss=0.00736,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 31.92it/s, loss=0.00621, val_loss=0.00736,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00621, val_loss=0.00697,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00584, val_loss=0.00697,\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.29it/s, loss=0.00584, val_loss=0.00697,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00584, val_loss=0.00657,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00551, val_loss=0.00657,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 30.16it/s, loss=0.00551, val_loss=0.00657,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 35.69it/s, loss=0.00551, val_loss=0.00623,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 20.39it/s, loss=0.00522, val_loss=0.00623,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 30.36it/s, loss=0.00522, val_loss=0.00623,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 35.91it/s, loss=0.00522, val_loss=0.00586,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=0.00497, val_loss=0.00586,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 30.65it/s, loss=0.00497, val_loss=0.00586,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 36.18it/s, loss=0.00497, val_loss=0.00551,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 20.40it/s, loss=0.00475, val_loss=0.00551,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 30.37it/s, loss=0.00475, val_loss=0.00551,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 35.72it/s, loss=0.00475, val_loss=0.00532,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 19.31it/s, loss=0.00456, val_loss=0.00532,\u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 28.92it/s, loss=0.00456, val_loss=0.00532,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 34.22it/s, loss=0.00456, val_loss=0.0051, \u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00438, val_loss=0.0051, \u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 29.79it/s, loss=0.00438, val_loss=0.0051, \n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 35.09it/s, loss=0.00438, val_loss=0.00487,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 20.15it/s, loss=0.00423, val_loss=0.00487,\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 29.79it/s, loss=0.00423, val_loss=0.00487,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 35.42it/s, loss=0.00423, val_loss=0.00474,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 20.11it/s, loss=0.0041, val_loss=0.00474, \u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 29.97it/s, loss=0.0041, val_loss=0.00474, \n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 35.48it/s, loss=0.0041, val_loss=0.00453, \u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 20.53it/s, loss=0.00398, val_loss=0.00453,\u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 30.54it/s, loss=0.00398, val_loss=0.00453,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 36.20it/s, loss=0.00398, val_loss=0.00443,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 20.59it/s, loss=0.00387, val_loss=0.00443,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 30.58it/s, loss=0.00387, val_loss=0.00443,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 36.08it/s, loss=0.00387, val_loss=0.00431,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00377, val_loss=0.00431,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.41it/s, loss=0.00377, val_loss=0.00431,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00377, val_loss=0.00421,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.00368, val_loss=0.00421,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.72it/s, loss=0.00368, val_loss=0.00421,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 38.41it/s, loss=0.00368, val_loss=0.00413,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.00361, val_loss=0.00413,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.44it/s, loss=0.00361, val_loss=0.00413,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.00361, val_loss=0.00404,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.34it/s, loss=0.00354, val_loss=0.00404,\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 31.83it/s, loss=0.00354, val_loss=0.00404,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.44it/s, loss=0.00354, val_loss=0.00394,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 20.94it/s, loss=0.00347, val_loss=0.00394,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 31.24it/s, loss=0.00347, val_loss=0.00394,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 36.76it/s, loss=0.00347, val_loss=0.0039, \u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 20.12it/s, loss=0.00341, val_loss=0.0039, \u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 29.86it/s, loss=0.00341, val_loss=0.0039, \n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 35.34it/s, loss=0.00341, val_loss=0.00385,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 20.00it/s, loss=0.00336, val_loss=0.00385,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 29.95it/s, loss=0.00336, val_loss=0.00385,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 35.39it/s, loss=0.00336, val_loss=0.0038, \u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.68it/s, loss=0.00331, val_loss=0.0038, \u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 30.61it/s, loss=0.00331, val_loss=0.0038, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 36.15it/s, loss=0.00331, val_loss=0.00373,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 20.58it/s, loss=0.00327, val_loss=0.00373,\u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 30.68it/s, loss=0.00327, val_loss=0.00373,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 36.20it/s, loss=0.00327, val_loss=0.00367,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 20.20it/s, loss=0.00322, val_loss=0.00367,\u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 29.97it/s, loss=0.00322, val_loss=0.00367,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00322, val_loss=0.00367,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 20.80it/s, loss=0.00319, val_loss=0.00367,\u001b[A\n",
      "Epoch 40:  79%|▊| 38/48 [00:01<00:00, 31.05it/s, loss=0.00319, val_loss=0.00367,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 36.58it/s, loss=0.00319, val_loss=0.00361,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 20.12it/s, loss=0.00315, val_loss=0.00361,\u001b[A\n",
      "Epoch 41:  79%|▊| 38/48 [00:01<00:00, 29.49it/s, loss=0.00315, val_loss=0.00361,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 35.26it/s, loss=0.00315, val_loss=0.00362,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 19.77it/s, loss=0.00312, val_loss=0.00362,\u001b[A\n",
      "Epoch 42:  79%|▊| 38/48 [00:01<00:00, 29.61it/s, loss=0.00312, val_loss=0.00362,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 34.97it/s, loss=0.00312, val_loss=0.00355,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 20.26it/s, loss=0.00309, val_loss=0.00355,\u001b[A\n",
      "Epoch 43:  79%|▊| 38/48 [00:01<00:00, 30.12it/s, loss=0.00309, val_loss=0.00355,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 35.58it/s, loss=0.00309, val_loss=0.00355,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 21.12it/s, loss=0.00306, val_loss=0.00355,\u001b[A\n",
      "Epoch 44:  79%|▊| 38/48 [00:01<00:00, 31.52it/s, loss=0.00306, val_loss=0.00355,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 37.13it/s, loss=0.00306, val_loss=0.00357,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00304, val_loss=0.00357,\u001b[A\n",
      "Epoch 45:  79%|▊| 38/48 [00:01<00:00, 32.55it/s, loss=0.00304, val_loss=0.00357,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 38.25it/s, loss=0.00304, val_loss=0.00356,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00302, val_loss=0.00356,\u001b[A\n",
      "Epoch 46:  79%|▊| 38/48 [00:01<00:00, 32.54it/s, loss=0.00302, val_loss=0.00356,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 38.20it/s, loss=0.00302, val_loss=0.0035, \u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 20.99it/s, loss=0.003, val_loss=0.0035, av\u001b[A\n",
      "Epoch 47:  79%|▊| 38/48 [00:01<00:00, 31.35it/s, loss=0.003, val_loss=0.0035, av\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 36.91it/s, loss=0.003, val_loss=0.00353, a\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00298, val_loss=0.00353,\u001b[A\n",
      "Epoch 48:  79%|▊| 38/48 [00:01<00:00, 31.98it/s, loss=0.00298, val_loss=0.00353,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 37.43it/s, loss=0.00298, val_loss=0.00349,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 20.63it/s, loss=0.00296, val_loss=0.00349,\u001b[A\n",
      "Epoch 49:  79%|▊| 38/48 [00:01<00:00, 30.75it/s, loss=0.00296, val_loss=0.00349,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 36.35it/s, loss=0.00296, val_loss=0.00346,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 19.93it/s, loss=0.00294, val_loss=0.00346,\u001b[A\n",
      "Epoch 50:  79%|▊| 38/48 [00:01<00:00, 29.56it/s, loss=0.00294, val_loss=0.00346,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 34.92it/s, loss=0.00294, val_loss=0.00343,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 20.56it/s, loss=0.00292, val_loss=0.00343,\u001b[A\n",
      "Epoch 51:  79%|▊| 38/48 [00:01<00:00, 30.48it/s, loss=0.00292, val_loss=0.00343,\n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 36.03it/s, loss=0.00292, val_loss=0.00345,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 20.33it/s, loss=0.00291, val_loss=0.00345,\u001b[A\n",
      "Epoch 52:  79%|▊| 38/48 [00:01<00:00, 30.13it/s, loss=0.00291, val_loss=0.00345,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 35.71it/s, loss=0.00291, val_loss=0.0034, \u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 20.55it/s, loss=0.00289, val_loss=0.0034, \u001b[A\n",
      "Epoch 53:  79%|▊| 38/48 [00:01<00:00, 30.58it/s, loss=0.00289, val_loss=0.0034, \n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 36.03it/s, loss=0.00289, val_loss=0.00335,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 19.75it/s, loss=0.00288, val_loss=0.00335,\u001b[A\n",
      "Epoch 54:  79%|▊| 38/48 [00:01<00:00, 29.47it/s, loss=0.00288, val_loss=0.00335,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 34.91it/s, loss=0.00288, val_loss=0.00336,\u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 20.03it/s, loss=0.00287, val_loss=0.00336,\u001b[A\n",
      "Epoch 55:  79%|▊| 38/48 [00:01<00:00, 29.69it/s, loss=0.00287, val_loss=0.00336,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 35.24it/s, loss=0.00287, val_loss=0.00333,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 20.36it/s, loss=0.00285, val_loss=0.00333,\u001b[A\n",
      "Epoch 56:  79%|▊| 38/48 [00:01<00:00, 30.44it/s, loss=0.00285, val_loss=0.00333,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 35.92it/s, loss=0.00285, val_loss=0.00331,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 20.37it/s, loss=0.00284, val_loss=0.00331,\u001b[A\n",
      "Epoch 57:  79%|▊| 38/48 [00:01<00:00, 30.35it/s, loss=0.00284, val_loss=0.00331,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 35.93it/s, loss=0.00284, val_loss=0.00331,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 20.12it/s, loss=0.00283, val_loss=0.00331,\u001b[A\n",
      "Epoch 58:  79%|▊| 38/48 [00:01<00:00, 29.68it/s, loss=0.00283, val_loss=0.00331,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 35.29it/s, loss=0.00283, val_loss=0.0033, \u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 22.18it/s, loss=0.00282, val_loss=0.0033, \u001b[A\n",
      "Epoch 59:  79%|▊| 38/48 [00:01<00:00, 33.01it/s, loss=0.00282, val_loss=0.0033, \n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 38.74it/s, loss=0.00282, val_loss=0.00326,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00281, val_loss=0.00326,\u001b[A\n",
      "Epoch 60:  79%|▊| 38/48 [00:01<00:00, 32.65it/s, loss=0.00281, val_loss=0.00326,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.00281, val_loss=0.00323,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0028, val_loss=0.00323, \u001b[A\n",
      "Epoch 61:  79%|▊| 38/48 [00:01<00:00, 32.31it/s, loss=0.0028, val_loss=0.00323, \n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 37.98it/s, loss=0.0028, val_loss=0.00325, \u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00279, val_loss=0.00325,\u001b[A\n",
      "Epoch 62:  79%|▊| 38/48 [00:01<00:00, 32.28it/s, loss=0.00279, val_loss=0.00325,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00279, val_loss=0.00323,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.00278, val_loss=0.00323,\u001b[A\n",
      "Epoch 63:  79%|▊| 38/48 [00:01<00:00, 31.84it/s, loss=0.00278, val_loss=0.00323,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 37.48it/s, loss=0.00278, val_loss=0.00323,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 20.63it/s, loss=0.00278, val_loss=0.00323,\u001b[A\n",
      "Epoch 64:  79%|▊| 38/48 [00:01<00:00, 30.71it/s, loss=0.00278, val_loss=0.00323,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 36.18it/s, loss=0.00278, val_loss=0.00323,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00277, val_loss=0.00323,\u001b[A\n",
      "Epoch 65:  79%|▊| 38/48 [00:01<00:00, 30.35it/s, loss=0.00277, val_loss=0.00323,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 36.05it/s, loss=0.00277, val_loss=0.00322,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 19.88it/s, loss=0.00276, val_loss=0.00322,\u001b[A\n",
      "Epoch 66:  79%|▊| 38/48 [00:01<00:00, 29.66it/s, loss=0.00276, val_loss=0.00322,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 35.11it/s, loss=0.00276, val_loss=0.0032, \u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 20.37it/s, loss=0.00275, val_loss=0.0032, \u001b[A\n",
      "Epoch 67:  79%|▊| 38/48 [00:01<00:00, 30.29it/s, loss=0.00275, val_loss=0.0032, \n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 35.80it/s, loss=0.00275, val_loss=0.00314,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 19.94it/s, loss=0.00275, val_loss=0.00314,\u001b[A\n",
      "Epoch 68:  79%|▊| 38/48 [00:01<00:00, 29.76it/s, loss=0.00275, val_loss=0.00314,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 35.29it/s, loss=0.00275, val_loss=0.00317,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.00274, val_loss=0.00317,\u001b[A\n",
      "Epoch 69:  79%|▊| 38/48 [00:01<00:00, 30.58it/s, loss=0.00274, val_loss=0.00317,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 36.09it/s, loss=0.00274, val_loss=0.00322,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00273, val_loss=0.00322,\u001b[A\n",
      "Epoch 70:  79%|▊| 38/48 [00:01<00:00, 29.63it/s, loss=0.00273, val_loss=0.00322,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 35.31it/s, loss=0.00273, val_loss=0.00313,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00273, val_loss=0.00313,\u001b[A\n",
      "Epoch 71:  79%|▊| 38/48 [00:01<00:00, 29.66it/s, loss=0.00273, val_loss=0.00313,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 35.19it/s, loss=0.00273, val_loss=0.00313,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 19.56it/s, loss=0.00272, val_loss=0.00313,\u001b[A\n",
      "Epoch 72:  79%|▊| 38/48 [00:01<00:00, 29.01it/s, loss=0.00272, val_loss=0.00313,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 34.49it/s, loss=0.00272, val_loss=0.00307,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 21.32it/s, loss=0.00272, val_loss=0.00307,\u001b[A\n",
      "Epoch 73:  79%|▊| 38/48 [00:01<00:00, 31.79it/s, loss=0.00272, val_loss=0.00307,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 37.43it/s, loss=0.00272, val_loss=0.00314,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00271, val_loss=0.00314,\u001b[A\n",
      "Epoch 74:  79%|▊| 38/48 [00:01<00:00, 32.66it/s, loss=0.00271, val_loss=0.00314,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.00271, val_loss=0.00313,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00271, val_loss=0.00313,\u001b[A\n",
      "Epoch 75:  79%|▊| 38/48 [00:01<00:00, 32.85it/s, loss=0.00271, val_loss=0.00313,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00271, val_loss=0.00314,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.0027, val_loss=0.00314, \u001b[A\n",
      "Epoch 76:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.0027, val_loss=0.00314, \n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 37.66it/s, loss=0.0027, val_loss=0.00318, \u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 20.47it/s, loss=0.0027, val_loss=0.00318, \u001b[A\n",
      "Epoch 77:  79%|▊| 38/48 [00:01<00:00, 30.35it/s, loss=0.0027, val_loss=0.00318, \n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 35.91it/s, loss=0.0027, val_loss=0.00309, \u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 21.33it/s, loss=0.00269, val_loss=0.00309,\u001b[A\n",
      "Epoch 78:  79%|▊| 38/48 [00:01<00:00, 31.82it/s, loss=0.00269, val_loss=0.00309,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 37.29it/s, loss=0.00269, val_loss=0.00306,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 21.00it/s, loss=0.00269, val_loss=0.00306,\u001b[A\n",
      "Epoch 79:  79%|▊| 38/48 [00:01<00:00, 31.35it/s, loss=0.00269, val_loss=0.00306,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 36.93it/s, loss=0.00269, val_loss=0.00314,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00268, val_loss=0.00314,\u001b[A\n",
      "Epoch 80:  79%|▊| 38/48 [00:01<00:00, 32.29it/s, loss=0.00268, val_loss=0.00314,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 37.96it/s, loss=0.00268, val_loss=0.0031, \u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 21.32it/s, loss=0.00268, val_loss=0.0031, \u001b[A\n",
      "Epoch 81:  79%|▊| 38/48 [00:01<00:00, 31.75it/s, loss=0.00268, val_loss=0.0031, \n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 37.37it/s, loss=0.00268, val_loss=0.0032, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 20.96it/s, loss=0.00268, val_loss=0.0032, \u001b[A\n",
      "Epoch 82:  79%|▊| 38/48 [00:01<00:00, 31.06it/s, loss=0.00268, val_loss=0.0032, \n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 36.63it/s, loss=0.00268, val_loss=0.00309,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 20.24it/s, loss=0.00267, val_loss=0.00309,\u001b[A\n",
      "Epoch 83:  79%|▊| 38/48 [00:01<00:00, 30.15it/s, loss=0.00267, val_loss=0.00309,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 35.75it/s, loss=0.00267, val_loss=0.0031, \u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00267, val_loss=0.0031, \u001b[A\n",
      "Epoch 84:  79%|▊| 38/48 [00:01<00:00, 30.18it/s, loss=0.00267, val_loss=0.0031, \n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 35.64it/s, loss=0.00267, val_loss=0.00311,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00267, val_loss=0.00311,\u001b[A\n",
      "Epoch 85:  79%|▊| 38/48 [00:01<00:00, 32.16it/s, loss=0.00267, val_loss=0.00311,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00267, val_loss=0.00312,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00266, val_loss=0.00312,\u001b[A\n",
      "Epoch 86:  79%|▊| 38/48 [00:01<00:00, 32.22it/s, loss=0.00266, val_loss=0.00312,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.00266, val_loss=0.0031, \u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 20.94it/s, loss=0.00266, val_loss=0.0031, \u001b[A\n",
      "Epoch 87:  79%|▊| 38/48 [00:01<00:00, 31.25it/s, loss=0.00266, val_loss=0.0031, \n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 36.79it/s, loss=0.00266, val_loss=0.00313,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 20.86it/s, loss=0.00266, val_loss=0.00313,\u001b[A\n",
      "Epoch 88:  79%|▊| 38/48 [00:01<00:00, 30.91it/s, loss=0.00266, val_loss=0.00313,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 36.63it/s, loss=0.00266, val_loss=0.00309,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00265, val_loss=0.00309,\u001b[A\n",
      "Epoch 89:  79%|▊| 38/48 [00:01<00:00, 30.37it/s, loss=0.00265, val_loss=0.00309,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 35.88it/s, loss=0.00265, val_loss=0.00309,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 19.90it/s, loss=0.00265, val_loss=0.00309,\u001b[A\n",
      "Epoch 90:  79%|▊| 38/48 [00:01<00:00, 29.72it/s, loss=0.00265, val_loss=0.00309,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 35.12it/s, loss=0.00265, val_loss=0.00312,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 19.96it/s, loss=0.00265, val_loss=0.00312,\u001b[A\n",
      "Epoch 91:  79%|▊| 38/48 [00:01<00:00, 29.63it/s, loss=0.00265, val_loss=0.00312,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 35.20it/s, loss=0.00265, val_loss=0.00314,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 20.01it/s, loss=0.00265, val_loss=0.00314,\u001b[A\n",
      "Epoch 92:  79%|▊| 38/48 [00:01<00:00, 29.76it/s, loss=0.00265, val_loss=0.00314,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 35.17it/s, loss=0.00265, val_loss=0.0031, \u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 19.49it/s, loss=0.00264, val_loss=0.0031, \u001b[A\n",
      "Epoch 93:  79%|▊| 38/48 [00:01<00:00, 28.60it/s, loss=0.00264, val_loss=0.0031, \n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 34.11it/s, loss=0.00264, val_loss=0.00308,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 20.09it/s, loss=0.00264, val_loss=0.00308,\u001b[A\n",
      "Epoch 94:  79%|▊| 38/48 [00:01<00:00, 29.75it/s, loss=0.00264, val_loss=0.00308,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 35.34it/s, loss=0.00264, val_loss=0.00306,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 20.63it/s, loss=0.00264, val_loss=0.00306,\u001b[A\n",
      "Epoch 95:  79%|▊| 38/48 [00:01<00:00, 30.64it/s, loss=0.00264, val_loss=0.00306,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 36.32it/s, loss=0.00264, val_loss=0.00309,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00264, val_loss=0.00309,\u001b[A\n",
      "Epoch 96:  79%|▊| 38/48 [00:01<00:00, 30.45it/s, loss=0.00264, val_loss=0.00309,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 36.01it/s, loss=0.00264, val_loss=0.0031, \u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 20.18it/s, loss=0.00264, val_loss=0.0031, \u001b[A\n",
      "Epoch 97:  79%|▊| 38/48 [00:01<00:00, 30.04it/s, loss=0.00264, val_loss=0.0031, \n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 35.58it/s, loss=0.00264, val_loss=0.00311,\u001b[A\n",
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 20.92it/s, loss=0.00263, val_loss=0.00311,\u001b[A\n",
      "Epoch 98:  79%|▊| 38/48 [00:01<00:00, 31.23it/s, loss=0.00263, val_loss=0.00311,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 36.81it/s, loss=0.00263, val_loss=0.00315,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 21.86it/s, loss=0.00263, val_loss=0.00315,\u001b[A\n",
      "Epoch 99:  79%|▊| 38/48 [00:01<00:00, 32.55it/s, loss=0.00263, val_loss=0.00315,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.00263, val_loss=0.00306,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.00263, val_loss=0.00306,\u001b[A\n",
      "Sizes of clusters: 154, 574, 472\n",
      "\n",
      "preds: [1 1 1 2 1 1 2 2 2 1 1 2 1 1 0 2 0 1 2 1 2 1 1 1 1 2 2 2 2 1 2 2 0 1 1 1 1\n",
      " 2 1 2 1 2 2 2 1 2 2 1 1 1 1 2 1 2 2 2 1 0 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1\n",
      " 2 1 2 2 2 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1 2 1 0 2 1 2 1 1 2 2 1 1 0 1 1 1 1\n",
      " 1 2 1 1 2 2 0 1 1 1 2 1 2 2 1 1 1 1 2 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 1 2 1 1 1 2 1 1 1 2 1 1 2 1 1 2 1 1 2 2 2 2 1 1 2 1 2 2 2 2 1 1 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 2 2 1 2 1 1 1 1 1 2 2 0 2 1 1 2 1 1 2 0 1 1 1 1 2\n",
      " 1 1 1 2 1 1 1 1 1 1 2 1 2 2 1 1 1 2 1 1 1 1 1 0 1 1 1 1 1 1 2 2 2 1 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 2 1 1 2 2 2 1 2 2 1 1 2 1 2 1 0 2 2 1 2 1 2 1 1 2 2 2 0\n",
      " 1 1 2 1 2 2 0 1 1 2 2 1 2 1 1 1 2 1 0 1 1 1 2 1 1 1 1 1 0 1 1 1 2 1 1 1 2\n",
      " 2 1 2 1 2 1 2 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2\n",
      " 1 1 1 1 2 2 2 0 1 2 2 1 2 1 1 1 1 1 2 2 0 2 1 1 2 1 1 0 1 1 2 0 1 2 0 2 2\n",
      " 0 2 0 2 0 2 2 2 2 1 2 2 0 0 0 2 2 2 1 0 0 0 2 0 2 2 2 2 0 2 2 2 0 0 0 2 2\n",
      " 2 0 1 0 2 2 2 1 2 0 2 2 2 2 2 2 2 1 2 2 0 0 2 2 0 2 2 0 2 0 2 0 2 0 0 2 2\n",
      " 1 0 0 1 2 0 1 0 2 0 2 0 0 2 2 2 0 0 2 2 2 2 2 0 2 2 0 1 1 2 0 0 0 0 2 2 0\n",
      " 2 2 2 2 0 2 2 2 1 0 2 2 2 2 2 0 0 2 2 2 2 0 2 2 0 2 0 0 0 2 0 0 2 0 0 2 1\n",
      " 2 2 0 2 2 2 0 2 0 0 0 2 2 1 2 0 2 0 2 2 2 0 2 2 2 2 2 2 2 1 2 2 2 2 0 2 2\n",
      " 0 1 0 2 2 0 1 2 2 2 0 2 0 2 2 2 2 2 1 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 0 0\n",
      " 2 2 0 0 2 1 1 0 2 1 0 2 0 0 2 0 1 2 2 2 1 2 0 2 2 0 2 2 0 2 0 2 2 0 1 2 0\n",
      " 2 2 2 2 2 0 2 0 0 0 2 0 2 0 0 2 0 2 0 0 2 0 2 2 2 0 1 0 2 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 2 2 0 2 0 2 0 2 2 0 2 2 2 2 2 2 1 0 2 0 2 2 0 2 2 2 2 1 0 2 0 0 0\n",
      " 0 0 2 2 2 0 2 0 0 2 0 2 0 0 2 2 0 2 2 2 2 2 2 1 2 2 2 2 0 2 2 2 2 0 2 0 1\n",
      " 2 2 0 2 2 0 2 0 2 2 0 1 2 2 2 2 0 0 0 0 2 0 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1\n",
      " 1 1 1 1 2 1 1 2 1 2 0 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 2 2 1 2 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 1 1 2 1 1 1\n",
      " 2 1 2 1 1 2 1 2 1 1 1 1 1 1 1 1 2 2 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 2 1 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1\n",
      " 1 1 1 2 1 2 2 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 2 1 1 1 2 2 1 0 1 1 1 2 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1\n",
      " 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 2 0 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 2 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5658\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=12.6, val_loss=0.0536, avg_\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 31.48it/s, loss=12.6, val_loss=0.0536, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=12.6, val_loss=7.11, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.398, val_loss=7.11, avg_v\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.59it/s, loss=0.398, val_loss=7.11, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.398, val_loss=1.04, avg_v\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 20.98it/s, loss=0.0616, val_loss=1.04, avg_\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 29.80it/s, loss=0.0616, val_loss=1.04, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 36.89it/s, loss=0.0616, val_loss=0.0899, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 20.38it/s, loss=0.0251, val_loss=0.0899, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 29.03it/s, loss=0.0251, val_loss=0.0899, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 35.90it/s, loss=0.0251, val_loss=0.0363, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 19.66it/s, loss=0.0184, val_loss=0.0363, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 28.07it/s, loss=0.0184, val_loss=0.0363, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 34.61it/s, loss=0.0184, val_loss=0.0275, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.0152, val_loss=0.0275, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 29.17it/s, loss=0.0152, val_loss=0.0275, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 36.10it/s, loss=0.0152, val_loss=0.0229, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 19.77it/s, loss=0.013, val_loss=0.0229, avg\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 28.32it/s, loss=0.013, val_loss=0.0229, avg\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 34.96it/s, loss=0.013, val_loss=0.0192, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 19.57it/s, loss=0.0114, val_loss=0.0192, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 27.87it/s, loss=0.0114, val_loss=0.0192, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 34.54it/s, loss=0.0114, val_loss=0.0165, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 20.24it/s, loss=0.0101, val_loss=0.0165, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 28.93it/s, loss=0.0101, val_loss=0.0165, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 35.68it/s, loss=0.0101, val_loss=0.0143, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 20.69it/s, loss=0.00913, val_loss=0.0143, a\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 29.58it/s, loss=0.00913, val_loss=0.0143, a\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 36.34it/s, loss=0.00913, val_loss=0.0125, a\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00829, val_loss=0.0125, \u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 28.39it/s, loss=0.00829, val_loss=0.0125, \n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 35.10it/s, loss=0.00829, val_loss=0.0112, \u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 20.91it/s, loss=0.00758, val_loss=0.0112, \u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 29.74it/s, loss=0.00758, val_loss=0.0112, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 36.76it/s, loss=0.00758, val_loss=0.01, av\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.00697, val_loss=0.01, av\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 31.49it/s, loss=0.00697, val_loss=0.01, av\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.00697, val_loss=0.00902,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00643, val_loss=0.00902,\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 31.46it/s, loss=0.00643, val_loss=0.00902,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.58it/s, loss=0.00643, val_loss=0.00816,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00596, val_loss=0.00816,\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 30.63it/s, loss=0.00596, val_loss=0.00816,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.54it/s, loss=0.00596, val_loss=0.00755,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.25it/s, loss=0.00556, val_loss=0.00755,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 30.35it/s, loss=0.00556, val_loss=0.00755,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.33it/s, loss=0.00556, val_loss=0.00698,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 20.77it/s, loss=0.0052, val_loss=0.00698, \u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 29.49it/s, loss=0.0052, val_loss=0.00698, \n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 36.55it/s, loss=0.0052, val_loss=0.00649, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 20.62it/s, loss=0.00489, val_loss=0.00649,\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 29.33it/s, loss=0.00489, val_loss=0.00649,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 36.30it/s, loss=0.00489, val_loss=0.00606,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 19.63it/s, loss=0.00462, val_loss=0.00606,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 27.85it/s, loss=0.00462, val_loss=0.00606,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 34.39it/s, loss=0.00462, val_loss=0.0057, \u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 20.13it/s, loss=0.00439, val_loss=0.0057, \u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 28.49it/s, loss=0.00439, val_loss=0.0057, \n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 35.50it/s, loss=0.00439, val_loss=0.00543,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 20.46it/s, loss=0.00419, val_loss=0.00543,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 29.18it/s, loss=0.00419, val_loss=0.00543,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 35.99it/s, loss=0.00419, val_loss=0.00518,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 20.69it/s, loss=0.00402, val_loss=0.00518,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 29.39it/s, loss=0.00402, val_loss=0.00518,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 36.22it/s, loss=0.00402, val_loss=0.00499,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 19.92it/s, loss=0.00387, val_loss=0.00499,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 28.21it/s, loss=0.00387, val_loss=0.00499,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 34.98it/s, loss=0.00387, val_loss=0.00477,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 20.13it/s, loss=0.00375, val_loss=0.00477,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 28.70it/s, loss=0.00375, val_loss=0.00477,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 35.57it/s, loss=0.00375, val_loss=0.0046, \u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 19.78it/s, loss=0.00364, val_loss=0.0046, \u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 28.05it/s, loss=0.00364, val_loss=0.0046, \n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.00364, val_loss=0.00444,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00354, val_loss=0.00444,\u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 28.74it/s, loss=0.00354, val_loss=0.00444,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 35.55it/s, loss=0.00354, val_loss=0.00431,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 20.85it/s, loss=0.00346, val_loss=0.00431,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 29.82it/s, loss=0.00346, val_loss=0.00431,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 36.71it/s, loss=0.00346, val_loss=0.00417,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.00338, val_loss=0.00417,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 31.20it/s, loss=0.00338, val_loss=0.00417,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00338, val_loss=0.00406,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00332, val_loss=0.00406,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 31.26it/s, loss=0.00332, val_loss=0.00406,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.00332, val_loss=0.00396,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.00326, val_loss=0.00396,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 30.57it/s, loss=0.00326, val_loss=0.00396,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.55it/s, loss=0.00326, val_loss=0.00387,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.46it/s, loss=0.00321, val_loss=0.00387,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 30.66it/s, loss=0.00321, val_loss=0.00387,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00321, val_loss=0.00378,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 20.68it/s, loss=0.00317, val_loss=0.00378,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 29.47it/s, loss=0.00317, val_loss=0.00378,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 36.31it/s, loss=0.00317, val_loss=0.00371,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00313, val_loss=0.00371,\u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 28.77it/s, loss=0.00313, val_loss=0.00371,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 35.47it/s, loss=0.00313, val_loss=0.00364,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 20.18it/s, loss=0.00309, val_loss=0.00364,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 28.66it/s, loss=0.00309, val_loss=0.00364,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 35.49it/s, loss=0.00309, val_loss=0.00357,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 19.75it/s, loss=0.00306, val_loss=0.00357,\u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 28.20it/s, loss=0.00306, val_loss=0.00357,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 34.97it/s, loss=0.00306, val_loss=0.00351,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 20.38it/s, loss=0.00303, val_loss=0.00351,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 28.83it/s, loss=0.00303, val_loss=0.00351,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 35.76it/s, loss=0.00303, val_loss=0.00346,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 20.27it/s, loss=0.00301, val_loss=0.00346,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 28.47it/s, loss=0.00301, val_loss=0.00346,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 35.39it/s, loss=0.00301, val_loss=0.0034, \u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.00298, val_loss=0.0034, \u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 28.71it/s, loss=0.00298, val_loss=0.0034, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 35.68it/s, loss=0.00298, val_loss=0.00335,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 19.87it/s, loss=0.00296, val_loss=0.00335,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 28.14it/s, loss=0.00296, val_loss=0.00335,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 34.90it/s, loss=0.00296, val_loss=0.0033, \u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 20.11it/s, loss=0.00294, val_loss=0.0033, \u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 28.50it/s, loss=0.00294, val_loss=0.0033, \n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00294, val_loss=0.00326,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 20.64it/s, loss=0.00292, val_loss=0.00326,\u001b[A\n",
      "Epoch 40:  75%|▊| 36/48 [00:01<00:00, 29.37it/s, loss=0.00292, val_loss=0.00326,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 36.34it/s, loss=0.00292, val_loss=0.00321,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.0029, val_loss=0.00321, \u001b[A\n",
      "Epoch 41:  75%|▊| 36/48 [00:01<00:00, 31.27it/s, loss=0.0029, val_loss=0.00321, \n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 38.41it/s, loss=0.0029, val_loss=0.00317, \u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.00289, val_loss=0.00317,\u001b[A\n",
      "Epoch 42:  75%|▊| 36/48 [00:01<00:00, 31.36it/s, loss=0.00289, val_loss=0.00317,\n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 38.46it/s, loss=0.00289, val_loss=0.00313,\u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 21.33it/s, loss=0.00288, val_loss=0.00313,\u001b[A\n",
      "Epoch 43:  75%|▊| 36/48 [00:01<00:00, 30.48it/s, loss=0.00288, val_loss=0.00313,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 37.43it/s, loss=0.00288, val_loss=0.00309,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.00286, val_loss=0.00309,\u001b[A\n",
      "Epoch 44:  75%|▊| 36/48 [00:01<00:00, 30.59it/s, loss=0.00286, val_loss=0.00309,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 37.57it/s, loss=0.00286, val_loss=0.00306,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 20.78it/s, loss=0.00285, val_loss=0.00306,\u001b[A\n",
      "Epoch 45:  75%|▊| 36/48 [00:01<00:00, 29.61it/s, loss=0.00285, val_loss=0.00306,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 36.54it/s, loss=0.00285, val_loss=0.00303,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 20.90it/s, loss=0.00284, val_loss=0.00303,\u001b[A\n",
      "Epoch 46:  75%|▊| 36/48 [00:01<00:00, 29.78it/s, loss=0.00284, val_loss=0.00303,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 36.77it/s, loss=0.00284, val_loss=0.003, a\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 20.46it/s, loss=0.00282, val_loss=0.003, a\u001b[A\n",
      "Epoch 47:  75%|▊| 36/48 [00:01<00:00, 29.27it/s, loss=0.00282, val_loss=0.003, a\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 36.11it/s, loss=0.00282, val_loss=0.00298,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 19.88it/s, loss=0.00281, val_loss=0.00298,\u001b[A\n",
      "Epoch 48:  75%|▊| 36/48 [00:01<00:00, 28.14it/s, loss=0.00281, val_loss=0.00298,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.00281, val_loss=0.00295,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 19.59it/s, loss=0.0028, val_loss=0.00295, \u001b[A\n",
      "Epoch 49:  75%|▊| 36/48 [00:01<00:00, 27.83it/s, loss=0.0028, val_loss=0.00295, \n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 34.63it/s, loss=0.0028, val_loss=0.00292, \u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 20.23it/s, loss=0.00279, val_loss=0.00292,\u001b[A\n",
      "Epoch 50:  75%|▊| 36/48 [00:01<00:00, 28.87it/s, loss=0.00279, val_loss=0.00292,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 35.74it/s, loss=0.00279, val_loss=0.0029, \u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00278, val_loss=0.0029, \u001b[A\n",
      "Epoch 51:  75%|▊| 36/48 [00:01<00:00, 29.41it/s, loss=0.00278, val_loss=0.0029, \n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 36.16it/s, loss=0.00278, val_loss=0.00287,\u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 20.20it/s, loss=0.00278, val_loss=0.00287,\u001b[A\n",
      "Epoch 52:  75%|▊| 36/48 [00:01<00:00, 28.83it/s, loss=0.00278, val_loss=0.00287,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 35.61it/s, loss=0.00278, val_loss=0.00285,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 19.80it/s, loss=0.00277, val_loss=0.00285,\u001b[A\n",
      "Epoch 53:  75%|▊| 36/48 [00:01<00:00, 28.23it/s, loss=0.00277, val_loss=0.00285,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 35.03it/s, loss=0.00277, val_loss=0.00282,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 20.02it/s, loss=0.00276, val_loss=0.00282,\u001b[A\n",
      "Epoch 54:  75%|▊| 36/48 [00:01<00:00, 28.34it/s, loss=0.00276, val_loss=0.00282,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 35.18it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 21.03it/s, loss=0.00275, val_loss=0.0028, \u001b[A\n",
      "Epoch 55:  75%|▊| 36/48 [00:01<00:00, 30.01it/s, loss=0.00275, val_loss=0.0028, \n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 36.98it/s, loss=0.00275, val_loss=0.00277,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 22.10it/s, loss=0.00274, val_loss=0.00277,\u001b[A\n",
      "Epoch 56:  75%|▊| 36/48 [00:01<00:00, 31.53it/s, loss=0.00274, val_loss=0.00277,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 38.66it/s, loss=0.00274, val_loss=0.00275,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.00274, val_loss=0.00275,\u001b[A\n",
      "Epoch 57:  75%|▊| 36/48 [00:01<00:00, 31.35it/s, loss=0.00274, val_loss=0.00275,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 38.45it/s, loss=0.00274, val_loss=0.00273,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 21.29it/s, loss=0.00273, val_loss=0.00273,\u001b[A\n",
      "Epoch 58:  75%|▊| 36/48 [00:01<00:00, 30.39it/s, loss=0.00273, val_loss=0.00273,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 37.35it/s, loss=0.00273, val_loss=0.00271,\u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 21.20it/s, loss=0.00272, val_loss=0.00271,\u001b[A\n",
      "Epoch 59:  75%|▊| 36/48 [00:01<00:00, 30.27it/s, loss=0.00272, val_loss=0.00271,\n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 37.23it/s, loss=0.00272, val_loss=0.0027, \u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 21.00it/s, loss=0.00272, val_loss=0.0027, \u001b[A\n",
      "Epoch 60:  75%|▊| 36/48 [00:01<00:00, 30.01it/s, loss=0.00272, val_loss=0.0027, \n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 36.94it/s, loss=0.00272, val_loss=0.00267,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00271, val_loss=0.00267,\u001b[A\n",
      "Epoch 61:  75%|▊| 36/48 [00:01<00:00, 28.51it/s, loss=0.00271, val_loss=0.00267,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 35.19it/s, loss=0.00271, val_loss=0.00266,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 20.32it/s, loss=0.0027, val_loss=0.00266, \u001b[A\n",
      "Epoch 62:  75%|▊| 36/48 [00:01<00:00, 28.81it/s, loss=0.0027, val_loss=0.00266, \n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 35.88it/s, loss=0.0027, val_loss=0.00264, \u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 20.02it/s, loss=0.0027, val_loss=0.00264, \u001b[A\n",
      "Epoch 63:  75%|▊| 36/48 [00:01<00:00, 28.47it/s, loss=0.0027, val_loss=0.00264, \n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 35.14it/s, loss=0.0027, val_loss=0.00262, \u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 19.97it/s, loss=0.00269, val_loss=0.00262,\u001b[A\n",
      "Epoch 64:  75%|▊| 36/48 [00:01<00:00, 28.41it/s, loss=0.00269, val_loss=0.00262,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 35.30it/s, loss=0.00269, val_loss=0.0026, \u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 20.29it/s, loss=0.00269, val_loss=0.0026, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:  75%|▊| 36/48 [00:01<00:00, 28.87it/s, loss=0.00269, val_loss=0.0026, \n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 35.63it/s, loss=0.00269, val_loss=0.00259,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00268, val_loss=0.00259,\u001b[A\n",
      "Epoch 66:  75%|▊| 36/48 [00:01<00:00, 28.69it/s, loss=0.00268, val_loss=0.00259,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 35.52it/s, loss=0.00268, val_loss=0.00257,\u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 20.63it/s, loss=0.00268, val_loss=0.00257,\u001b[A\n",
      "Epoch 67:  75%|▊| 36/48 [00:01<00:00, 29.23it/s, loss=0.00268, val_loss=0.00257,\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 36.12it/s, loss=0.00268, val_loss=0.00256,\u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 20.09it/s, loss=0.00267, val_loss=0.00256,\u001b[A\n",
      "Epoch 68:  75%|▊| 36/48 [00:01<00:00, 28.60it/s, loss=0.00267, val_loss=0.00256,\n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 35.38it/s, loss=0.00267, val_loss=0.00255,\u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00267, val_loss=0.00255,\u001b[A\n",
      "Epoch 69:  75%|▊| 36/48 [00:01<00:00, 28.90it/s, loss=0.00267, val_loss=0.00255,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 35.72it/s, loss=0.00267, val_loss=0.00254,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.00267, val_loss=0.00254,\u001b[A\n",
      "Epoch 70:  75%|▊| 36/48 [00:01<00:00, 30.66it/s, loss=0.00267, val_loss=0.00254,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 37.67it/s, loss=0.00267, val_loss=0.00252,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 22.28it/s, loss=0.00266, val_loss=0.00252,\u001b[A\n",
      "Epoch 71:  75%|▊| 36/48 [00:01<00:00, 31.76it/s, loss=0.00266, val_loss=0.00252,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 38.90it/s, loss=0.00266, val_loss=0.00251,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 21.12it/s, loss=0.00266, val_loss=0.00251,\u001b[A\n",
      "Epoch 72:  75%|▊| 36/48 [00:01<00:00, 30.02it/s, loss=0.00266, val_loss=0.00251,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 37.07it/s, loss=0.00266, val_loss=0.0025, \u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 22.21it/s, loss=0.00265, val_loss=0.0025, \u001b[A\n",
      "Epoch 73:  75%|▊| 36/48 [00:01<00:00, 31.68it/s, loss=0.00265, val_loss=0.0025, \n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 38.81it/s, loss=0.00265, val_loss=0.00248,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00265, val_loss=0.00248,\u001b[A\n",
      "Epoch 74:  75%|▊| 36/48 [00:01<00:00, 29.64it/s, loss=0.00265, val_loss=0.00248,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00265, val_loss=0.00247,\u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 20.51it/s, loss=0.00265, val_loss=0.00247,\u001b[A\n",
      "Epoch 75:  75%|▊| 36/48 [00:01<00:00, 29.05it/s, loss=0.00265, val_loss=0.00247,\n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 35.96it/s, loss=0.00265, val_loss=0.00246,\u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 20.79it/s, loss=0.00264, val_loss=0.00246,\u001b[A\n",
      "Epoch 76:  75%|▊| 36/48 [00:01<00:00, 29.62it/s, loss=0.00264, val_loss=0.00246,\n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 36.57it/s, loss=0.00264, val_loss=0.00245,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 19.94it/s, loss=0.00264, val_loss=0.00245,\u001b[A\n",
      "Epoch 77:  75%|▊| 36/48 [00:01<00:00, 28.49it/s, loss=0.00264, val_loss=0.00245,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 35.26it/s, loss=0.00264, val_loss=0.00244,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 20.14it/s, loss=0.00264, val_loss=0.00244,\u001b[A\n",
      "Epoch 78:  75%|▊| 36/48 [00:01<00:00, 28.75it/s, loss=0.00264, val_loss=0.00244,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 35.54it/s, loss=0.00264, val_loss=0.00243,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 19.86it/s, loss=0.00264, val_loss=0.00243,\u001b[A\n",
      "Epoch 79:  75%|▊| 36/48 [00:01<00:00, 28.41it/s, loss=0.00264, val_loss=0.00243,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 35.17it/s, loss=0.00264, val_loss=0.00242,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 20.23it/s, loss=0.00263, val_loss=0.00242,\u001b[A\n",
      "Epoch 80:  75%|▊| 36/48 [00:01<00:00, 28.85it/s, loss=0.00263, val_loss=0.00242,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 35.66it/s, loss=0.00263, val_loss=0.00241,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.42it/s, loss=0.00263, val_loss=0.00241,\u001b[A\n",
      "Epoch 81:  75%|▊| 36/48 [00:01<00:00, 28.39it/s, loss=0.00263, val_loss=0.00241,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 35.30it/s, loss=0.00263, val_loss=0.0024, \u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 20.21it/s, loss=0.00263, val_loss=0.0024, \u001b[A\n",
      "Epoch 82:  75%|▊| 36/48 [00:01<00:00, 28.78it/s, loss=0.00263, val_loss=0.0024, \n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.00263, val_loss=0.00239,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 19.76it/s, loss=0.00263, val_loss=0.00239,\u001b[A\n",
      "Epoch 83:  75%|▊| 36/48 [00:01<00:00, 28.17it/s, loss=0.00263, val_loss=0.00239,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 34.77it/s, loss=0.00263, val_loss=0.00238,\u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00262, val_loss=0.00238,\u001b[A\n",
      "Epoch 84:  75%|▊| 36/48 [00:01<00:00, 31.04it/s, loss=0.00262, val_loss=0.00238,\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.00262, val_loss=0.00237,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.00262, val_loss=0.00237,\u001b[A\n",
      "Epoch 85:  75%|▊| 36/48 [00:01<00:00, 31.41it/s, loss=0.00262, val_loss=0.00237,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.00262, val_loss=0.00236,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 21.54it/s, loss=0.00262, val_loss=0.00236,\u001b[A\n",
      "Epoch 86:  75%|▊| 36/48 [00:01<00:00, 30.75it/s, loss=0.00262, val_loss=0.00236,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00262, val_loss=0.00236,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 21.52it/s, loss=0.00262, val_loss=0.00236,\u001b[A\n",
      "Epoch 87:  75%|▊| 36/48 [00:01<00:00, 30.74it/s, loss=0.00262, val_loss=0.00236,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00262, val_loss=0.00235,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.00262, val_loss=0.00235,\u001b[A\n",
      "Epoch 88:  75%|▊| 36/48 [00:01<00:00, 30.62it/s, loss=0.00262, val_loss=0.00235,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00262, val_loss=0.00234,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00261, val_loss=0.00234,\u001b[A\n",
      "Epoch 89:  75%|▊| 36/48 [00:01<00:00, 29.31it/s, loss=0.00261, val_loss=0.00234,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 36.13it/s, loss=0.00261, val_loss=0.00233,\u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 19.90it/s, loss=0.00261, val_loss=0.00233,\u001b[A\n",
      "Epoch 90:  75%|▊| 36/48 [00:01<00:00, 28.53it/s, loss=0.00261, val_loss=0.00233,\n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 35.14it/s, loss=0.00261, val_loss=0.00234,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 19.90it/s, loss=0.00261, val_loss=0.00234,\u001b[A\n",
      "Epoch 91:  75%|▊| 36/48 [00:01<00:00, 28.42it/s, loss=0.00261, val_loss=0.00234,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 35.11it/s, loss=0.00261, val_loss=0.00232,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 19.98it/s, loss=0.00261, val_loss=0.00232,\u001b[A\n",
      "Epoch 92:  75%|▊| 36/48 [00:01<00:00, 28.31it/s, loss=0.00261, val_loss=0.00232,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 35.17it/s, loss=0.00261, val_loss=0.00232,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 19.62it/s, loss=0.00554, val_loss=0.00232,\u001b[A\n",
      "Epoch 93:  75%|▊| 36/48 [00:01<00:00, 28.02it/s, loss=0.00554, val_loss=0.00232,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 34.69it/s, loss=0.00554, val_loss=0.028, a\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00773, val_loss=0.028, a\u001b[A\n",
      "Epoch 94:  75%|▊| 36/48 [00:01<00:00, 28.76it/s, loss=0.00773, val_loss=0.028, a\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 35.66it/s, loss=0.00773, val_loss=0.00324,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00299, val_loss=0.00324,\u001b[A\n",
      "Epoch 95:  75%|▊| 36/48 [00:01<00:00, 29.11it/s, loss=0.00299, val_loss=0.00324,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 36.06it/s, loss=0.00299, val_loss=0.00239,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 20.33it/s, loss=0.00264, val_loss=0.00239,\u001b[A\n",
      "Epoch 96:  75%|▊| 36/48 [00:01<00:00, 28.93it/s, loss=0.00264, val_loss=0.00239,\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 35.88it/s, loss=0.00264, val_loss=0.0023, \u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 19.96it/s, loss=0.0026, val_loss=0.0023, a\u001b[A\n",
      "Epoch 97:  75%|▊| 36/48 [00:01<00:00, 28.41it/s, loss=0.0026, val_loss=0.0023, a\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 35.22it/s, loss=0.0026, val_loss=0.00228, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 21.05it/s, loss=0.0026, val_loss=0.00228, \u001b[A\n",
      "Epoch 98:  75%|▊| 36/48 [00:01<00:00, 30.10it/s, loss=0.0026, val_loss=0.00228, \n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 37.00it/s, loss=0.0026, val_loss=0.00227, \u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00261, val_loss=0.00227,\u001b[A\n",
      "Epoch 99:  75%|▊| 36/48 [00:01<00:00, 31.11it/s, loss=0.00261, val_loss=0.00227,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.00261, val_loss=0.00234,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00261, val_loss=0.00234,\u001b[A\n",
      "Sizes of clusters: 383, 420, 397\n",
      "\n",
      "preds: [2 2 2 1 2 2 2 1 2 1 2 1 2 2 2 1 2 2 2 2 1 2 2 2 2 1 2 1 1 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2\n",
      " 1 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 1 2 1 2 2 2 1 2 1 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 1 2 1 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 2 1 2 1 2 2 2 2 2 2\n",
      " 2 2 2 2 1 2 2 2 1 2 1 2 1 1 2 2 2 2 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 2 2 2 2 1 1 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 1 2 1 1 2 2 2 2 2 2 2 2 1 2 1 2 2 2 1 1 2 2 2 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1 2 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 2 1 0 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 2 1 1 1 1 1 2 2 2 1 2 1 1 0 2 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 2 2 2 1 2 2 1 1 1 1 1 2 1 1 0 1 2 1 1 2 1 1 1 1 0 1 2 1 2 2 1 1 1 1\n",
      " 1 2 1 1 1 1 2 0 1 2 1 1 2 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2\n",
      " 1 1 1 0 1 1 1 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 2 0 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 2 2 1 0 2 1 0 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 0 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 2 1 2 1 1\n",
      " 1 1 0 2 1 1 2 1 1 2 1 1 1 1 0 0 2 0 2 0 1 1 1 1 1 1 2 1 2 1 1 1 2 1 1 1 1\n",
      " 1 1 2 0 2 2 1 1 1 0 1 0 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 2 1 2 1 1 1 0 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.8050\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=9.95, val_loss=0.0874, avg_\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 31.18it/s, loss=9.95, val_loss=0.0874, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=9.95, val_loss=2.85, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.404, val_loss=2.85, avg_v\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.07it/s, loss=0.404, val_loss=2.85, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 37.57it/s, loss=0.404, val_loss=0.354, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=0.064, val_loss=0.354, avg_\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 29.65it/s, loss=0.064, val_loss=0.354, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 36.44it/s, loss=0.064, val_loss=0.0519, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 20.95it/s, loss=0.0276, val_loss=0.0519, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 29.82it/s, loss=0.0276, val_loss=0.0519, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 36.81it/s, loss=0.0276, val_loss=0.0285, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.29it/s, loss=0.0205, val_loss=0.0285, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 30.41it/s, loss=0.0205, val_loss=0.0285, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.39it/s, loss=0.0205, val_loss=0.0229, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0169, val_loss=0.0229, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.03it/s, loss=0.0169, val_loss=0.0229, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.0169, val_loss=0.0196, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 20.14it/s, loss=0.0144, val_loss=0.0196, av\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 28.72it/s, loss=0.0144, val_loss=0.0196, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 35.42it/s, loss=0.0144, val_loss=0.0169, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 19.96it/s, loss=0.0124, val_loss=0.0169, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 28.27it/s, loss=0.0124, val_loss=0.0169, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 35.09it/s, loss=0.0124, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 20.40it/s, loss=0.0108, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 29.09it/s, loss=0.0108, val_loss=0.0147, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 35.87it/s, loss=0.0108, val_loss=0.0128, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 20.49it/s, loss=0.00949, val_loss=0.0128, a\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 29.33it/s, loss=0.00949, val_loss=0.0128, a\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 36.17it/s, loss=0.00949, val_loss=0.0112, a\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.99it/s, loss=0.00841, val_loss=0.0112, \u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 31.35it/s, loss=0.00841, val_loss=0.0112, \n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=0.00841, val_loss=0.0098, \u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.30it/s, loss=0.00752, val_loss=0.0098, \u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 30.43it/s, loss=0.00752, val_loss=0.0098, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.40it/s, loss=0.00752, val_loss=0.00867,\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.00it/s, loss=0.00679, val_loss=0.00867,\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 29.89it/s, loss=0.00679, val_loss=0.00867,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 36.79it/s, loss=0.00679, val_loss=0.00774,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 19.76it/s, loss=0.00618, val_loss=0.00774,\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 28.17it/s, loss=0.00618, val_loss=0.00774,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 34.92it/s, loss=0.00618, val_loss=0.00696,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00567, val_loss=0.00696,\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 29.21it/s, loss=0.00567, val_loss=0.00696,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 36.12it/s, loss=0.00567, val_loss=0.00633,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.00525, val_loss=0.00633,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 29.33it/s, loss=0.00525, val_loss=0.00633,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 36.14it/s, loss=0.00525, val_loss=0.00581,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 20.54it/s, loss=0.0049, val_loss=0.00581, \u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 29.24it/s, loss=0.0049, val_loss=0.00581, \n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 36.08it/s, loss=0.0049, val_loss=0.00538, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 20.53it/s, loss=0.00461, val_loss=0.00538,\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 29.00it/s, loss=0.00461, val_loss=0.00538,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 35.96it/s, loss=0.00461, val_loss=0.00503,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 19.97it/s, loss=0.00437, val_loss=0.00503,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 28.34it/s, loss=0.00437, val_loss=0.00503,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 35.12it/s, loss=0.00437, val_loss=0.00474,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 20.18it/s, loss=0.00417, val_loss=0.00474,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 28.74it/s, loss=0.00417, val_loss=0.00474,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 35.32it/s, loss=0.00417, val_loss=0.0045, \u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 20.06it/s, loss=0.004, val_loss=0.0045, av\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 28.55it/s, loss=0.004, val_loss=0.0045, av\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 35.15it/s, loss=0.004, val_loss=0.0043, av\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 20.36it/s, loss=0.00385, val_loss=0.0043, \u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 28.98it/s, loss=0.00385, val_loss=0.0043, \n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 35.96it/s, loss=0.00385, val_loss=0.00414,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 19.95it/s, loss=0.00373, val_loss=0.00414,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 28.56it/s, loss=0.00373, val_loss=0.00414,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 35.07it/s, loss=0.00373, val_loss=0.00401,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00363, val_loss=0.00401,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 30.91it/s, loss=0.00363, val_loss=0.00401,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.96it/s, loss=0.00363, val_loss=0.0039, \u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00354, val_loss=0.0039, \u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 31.22it/s, loss=0.00354, val_loss=0.0039, \n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.00354, val_loss=0.00381,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00346, val_loss=0.00381,\u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 30.95it/s, loss=0.00346, val_loss=0.00381,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.04it/s, loss=0.00346, val_loss=0.00373,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00339, val_loss=0.00373,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 30.98it/s, loss=0.00339, val_loss=0.00373,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.00339, val_loss=0.00367,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.34it/s, loss=0.00333, val_loss=0.00367,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 30.50it/s, loss=0.00333, val_loss=0.00367,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.48it/s, loss=0.00333, val_loss=0.00359,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 20.65it/s, loss=0.00328, val_loss=0.00359,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 29.40it/s, loss=0.00328, val_loss=0.00359,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 36.28it/s, loss=0.00328, val_loss=0.00353,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 20.04it/s, loss=0.00323, val_loss=0.00353,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 28.70it/s, loss=0.00323, val_loss=0.00353,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00323, val_loss=0.00347,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 20.66it/s, loss=0.00319, val_loss=0.00347,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 29.40it/s, loss=0.00319, val_loss=0.00347,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 36.36it/s, loss=0.00319, val_loss=0.00342,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 19.87it/s, loss=0.00315, val_loss=0.00342,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 28.21it/s, loss=0.00315, val_loss=0.00342,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.00315, val_loss=0.00338,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 20.49it/s, loss=0.00312, val_loss=0.00338,\u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 28.79it/s, loss=0.00312, val_loss=0.00338,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 35.70it/s, loss=0.00312, val_loss=0.00333,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00309, val_loss=0.00333,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 29.06it/s, loss=0.00309, val_loss=0.00333,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 35.76it/s, loss=0.00309, val_loss=0.00329,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 20.56it/s, loss=0.00306, val_loss=0.00329,\u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 29.22it/s, loss=0.00306, val_loss=0.00329,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 35.96it/s, loss=0.00306, val_loss=0.00326,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 20.22it/s, loss=0.00304, val_loss=0.00326,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 28.79it/s, loss=0.00304, val_loss=0.00326,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 35.51it/s, loss=0.00304, val_loss=0.00322,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 19.71it/s, loss=0.00301, val_loss=0.00322,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 28.02it/s, loss=0.00301, val_loss=0.00322,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 34.77it/s, loss=0.00301, val_loss=0.0032, \u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.33it/s, loss=0.00299, val_loss=0.0032, \u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 29.14it/s, loss=0.00299, val_loss=0.0032, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 35.94it/s, loss=0.00299, val_loss=0.00318,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 22.26it/s, loss=0.00297, val_loss=0.00318,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 31.75it/s, loss=0.00297, val_loss=0.00318,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.89it/s, loss=0.00297, val_loss=0.00315,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00295, val_loss=0.00315,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 31.15it/s, loss=0.00295, val_loss=0.00315,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00295, val_loss=0.00312,\u001b[A\n",
      "Epoch 40:  50%|▌| 24/48 [00:01<00:01, 21.45it/s, loss=0.00293, val_loss=0.00312,\u001b[A\n",
      "Epoch 40:  75%|▊| 36/48 [00:01<00:00, 30.62it/s, loss=0.00293, val_loss=0.00312,\n",
      "Epoch 40: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00293, val_loss=0.00309,\u001b[A\n",
      "Epoch 41:  50%|▌| 24/48 [00:01<00:01, 20.86it/s, loss=0.00292, val_loss=0.00309,\u001b[A\n",
      "Epoch 41:  75%|▊| 36/48 [00:01<00:00, 29.76it/s, loss=0.00292, val_loss=0.00309,\n",
      "Epoch 41: 100%|█| 48/48 [00:01<00:00, 36.69it/s, loss=0.00292, val_loss=0.00307,\u001b[A\n",
      "Epoch 42:  50%|▌| 24/48 [00:01<00:01, 21.02it/s, loss=0.0029, val_loss=0.00307, \u001b[A\n",
      "Epoch 42:  75%|▊| 36/48 [00:01<00:00, 30.05it/s, loss=0.0029, val_loss=0.00307, \n",
      "Epoch 42: 100%|█| 48/48 [00:01<00:00, 36.97it/s, loss=0.0029, val_loss=0.00305, \u001b[A\n",
      "Epoch 43:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00289, val_loss=0.00305,\u001b[A\n",
      "Epoch 43:  75%|▊| 36/48 [00:01<00:00, 28.93it/s, loss=0.00289, val_loss=0.00305,\n",
      "Epoch 43: 100%|█| 48/48 [00:01<00:00, 35.79it/s, loss=0.00289, val_loss=0.00302,\u001b[A\n",
      "Epoch 44:  50%|▌| 24/48 [00:01<00:01, 20.11it/s, loss=0.00287, val_loss=0.00302,\u001b[A\n",
      "Epoch 44:  75%|▊| 36/48 [00:01<00:00, 28.55it/s, loss=0.00287, val_loss=0.00302,\n",
      "Epoch 44: 100%|█| 48/48 [00:01<00:00, 35.43it/s, loss=0.00287, val_loss=0.00299,\u001b[A\n",
      "Epoch 45:  50%|▌| 24/48 [00:01<00:01, 20.31it/s, loss=0.00286, val_loss=0.00299,\u001b[A\n",
      "Epoch 45:  75%|▊| 36/48 [00:01<00:00, 28.81it/s, loss=0.00286, val_loss=0.00299,\n",
      "Epoch 45: 100%|█| 48/48 [00:01<00:00, 35.73it/s, loss=0.00286, val_loss=0.00297,\u001b[A\n",
      "Epoch 46:  50%|▌| 24/48 [00:01<00:01, 20.56it/s, loss=0.00285, val_loss=0.00297,\u001b[A\n",
      "Epoch 46:  75%|▊| 36/48 [00:01<00:00, 29.21it/s, loss=0.00285, val_loss=0.00297,\n",
      "Epoch 46: 100%|█| 48/48 [00:01<00:00, 36.16it/s, loss=0.00285, val_loss=0.00295,\u001b[A\n",
      "Epoch 47:  50%|▌| 24/48 [00:01<00:01, 20.50it/s, loss=0.00284, val_loss=0.00295,\u001b[A\n",
      "Epoch 47:  75%|▊| 36/48 [00:01<00:00, 29.26it/s, loss=0.00284, val_loss=0.00295,\n",
      "Epoch 47: 100%|█| 48/48 [00:01<00:00, 36.15it/s, loss=0.00284, val_loss=0.00293,\u001b[A\n",
      "Epoch 48:  50%|▌| 24/48 [00:01<00:01, 20.45it/s, loss=0.00283, val_loss=0.00293,\u001b[A\n",
      "Epoch 48:  75%|▊| 36/48 [00:01<00:00, 29.21it/s, loss=0.00283, val_loss=0.00293,\n",
      "Epoch 48: 100%|█| 48/48 [00:01<00:00, 36.01it/s, loss=0.00283, val_loss=0.00291,\u001b[A\n",
      "Epoch 49:  50%|▌| 24/48 [00:01<00:01, 19.95it/s, loss=0.00282, val_loss=0.00291,\u001b[A\n",
      "Epoch 49:  75%|▊| 36/48 [00:01<00:00, 28.49it/s, loss=0.00282, val_loss=0.00291,\n",
      "Epoch 49: 100%|█| 48/48 [00:01<00:00, 35.19it/s, loss=0.00282, val_loss=0.00289,\u001b[A\n",
      "Epoch 50:  50%|▌| 24/48 [00:01<00:01, 20.10it/s, loss=0.00281, val_loss=0.00289,\u001b[A\n",
      "Epoch 50:  75%|▊| 36/48 [00:01<00:00, 28.76it/s, loss=0.00281, val_loss=0.00289,\n",
      "Epoch 50: 100%|█| 48/48 [00:01<00:00, 35.56it/s, loss=0.00281, val_loss=0.00288,\u001b[A\n",
      "Epoch 51:  50%|▌| 24/48 [00:01<00:01, 20.35it/s, loss=0.0028, val_loss=0.00288, \u001b[A\n",
      "Epoch 51:  75%|▊| 36/48 [00:01<00:00, 28.96it/s, loss=0.0028, val_loss=0.00288, \n",
      "Epoch 51: 100%|█| 48/48 [00:01<00:00, 35.75it/s, loss=0.0028, val_loss=0.00287, \u001b[A\n",
      "Epoch 52:  50%|▌| 24/48 [00:01<00:01, 21.12it/s, loss=0.00279, val_loss=0.00287,\u001b[A\n",
      "Epoch 52:  75%|▊| 36/48 [00:01<00:00, 30.20it/s, loss=0.00279, val_loss=0.00287,\n",
      "Epoch 52: 100%|█| 48/48 [00:01<00:00, 37.14it/s, loss=0.00279, val_loss=0.00285,\u001b[A\n",
      "Epoch 53:  50%|▌| 24/48 [00:01<00:01, 22.06it/s, loss=0.00278, val_loss=0.00285,\u001b[A\n",
      "Epoch 53:  75%|▊| 36/48 [00:01<00:00, 31.45it/s, loss=0.00278, val_loss=0.00285,\n",
      "Epoch 53: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.00278, val_loss=0.00285,\u001b[A\n",
      "Epoch 54:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00277, val_loss=0.00285,\u001b[A\n",
      "Epoch 54:  75%|▊| 36/48 [00:01<00:00, 30.97it/s, loss=0.00277, val_loss=0.00285,\n",
      "Epoch 54: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.00277, val_loss=0.00284,\u001b[A\n",
      "Epoch 55:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00277, val_loss=0.00284,\u001b[A\n",
      "Epoch 55:  75%|▊| 36/48 [00:01<00:00, 30.81it/s, loss=0.00277, val_loss=0.00284,\n",
      "Epoch 55: 100%|█| 48/48 [00:01<00:00, 37.85it/s, loss=0.00277, val_loss=0.00283,\u001b[A\n",
      "Epoch 56:  50%|▌| 24/48 [00:01<00:01, 21.31it/s, loss=0.00276, val_loss=0.00283,\u001b[A\n",
      "Epoch 56:  75%|▊| 36/48 [00:01<00:00, 30.34it/s, loss=0.00276, val_loss=0.00283,\n",
      "Epoch 56: 100%|█| 48/48 [00:01<00:00, 37.38it/s, loss=0.00276, val_loss=0.00282,\u001b[A\n",
      "Epoch 57:  50%|▌| 24/48 [00:01<00:01, 20.83it/s, loss=0.00275, val_loss=0.00282,\u001b[A\n",
      "Epoch 57:  75%|▊| 36/48 [00:01<00:00, 29.70it/s, loss=0.00275, val_loss=0.00282,\n",
      "Epoch 57: 100%|█| 48/48 [00:01<00:00, 36.57it/s, loss=0.00275, val_loss=0.00281,\u001b[A\n",
      "Epoch 58:  50%|▌| 24/48 [00:01<00:01, 20.05it/s, loss=0.00275, val_loss=0.00281,\u001b[A\n",
      "Epoch 58:  75%|▊| 36/48 [00:01<00:00, 28.54it/s, loss=0.00275, val_loss=0.00281,\n",
      "Epoch 58: 100%|█| 48/48 [00:01<00:00, 35.41it/s, loss=0.00275, val_loss=0.0028, \u001b[A\n",
      "Epoch 59:  50%|▌| 24/48 [00:01<00:01, 20.93it/s, loss=0.00274, val_loss=0.0028, \u001b[A\n",
      "Epoch 59:  75%|▊| 36/48 [00:01<00:00, 29.84it/s, loss=0.00274, val_loss=0.0028, \n",
      "Epoch 59: 100%|█| 48/48 [00:01<00:00, 36.78it/s, loss=0.00274, val_loss=0.00278,\u001b[A\n",
      "Epoch 60:  50%|▌| 24/48 [00:01<00:01, 20.29it/s, loss=0.00273, val_loss=0.00278,\u001b[A\n",
      "Epoch 60:  75%|▊| 36/48 [00:01<00:00, 28.99it/s, loss=0.00273, val_loss=0.00278,\n",
      "Epoch 60: 100%|█| 48/48 [00:01<00:00, 35.76it/s, loss=0.00273, val_loss=0.00277,\u001b[A\n",
      "Epoch 61:  50%|▌| 24/48 [00:01<00:01, 19.81it/s, loss=0.00273, val_loss=0.00277,\u001b[A\n",
      "Epoch 61:  75%|▊| 36/48 [00:01<00:00, 28.10it/s, loss=0.00273, val_loss=0.00277,\n",
      "Epoch 61: 100%|█| 48/48 [00:01<00:00, 34.86it/s, loss=0.00273, val_loss=0.00276,\u001b[A\n",
      "Epoch 62:  50%|▌| 24/48 [00:01<00:01, 20.10it/s, loss=0.00272, val_loss=0.00276,\u001b[A\n",
      "Epoch 62:  75%|▊| 36/48 [00:01<00:00, 28.46it/s, loss=0.00272, val_loss=0.00276,\n",
      "Epoch 62: 100%|█| 48/48 [00:01<00:00, 35.32it/s, loss=0.00272, val_loss=0.00275,\u001b[A\n",
      "Epoch 63:  50%|▌| 24/48 [00:01<00:01, 20.13it/s, loss=0.00272, val_loss=0.00275,\u001b[A\n",
      "Epoch 63:  75%|▊| 36/48 [00:01<00:00, 28.77it/s, loss=0.00272, val_loss=0.00275,\n",
      "Epoch 63: 100%|█| 48/48 [00:01<00:00, 35.42it/s, loss=0.00272, val_loss=0.00274,\u001b[A\n",
      "Epoch 64:  50%|▌| 24/48 [00:01<00:01, 20.34it/s, loss=0.00272, val_loss=0.00274,\u001b[A\n",
      "Epoch 64:  75%|▊| 36/48 [00:01<00:00, 28.96it/s, loss=0.00272, val_loss=0.00274,\n",
      "Epoch 64: 100%|█| 48/48 [00:01<00:00, 35.90it/s, loss=0.00272, val_loss=0.00272,\u001b[A\n",
      "Epoch 65:  50%|▌| 24/48 [00:01<00:01, 20.74it/s, loss=0.00271, val_loss=0.00272,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65:  75%|▊| 36/48 [00:01<00:00, 29.56it/s, loss=0.00271, val_loss=0.00272,\n",
      "Epoch 65: 100%|█| 48/48 [00:01<00:00, 36.29it/s, loss=0.00271, val_loss=0.00271,\u001b[A\n",
      "Epoch 66:  50%|▌| 24/48 [00:01<00:01, 20.17it/s, loss=0.00271, val_loss=0.00271,\u001b[A\n",
      "Epoch 66:  75%|▊| 36/48 [00:01<00:00, 28.70it/s, loss=0.00271, val_loss=0.00271,\n",
      "Epoch 66: 100%|█| 48/48 [00:01<00:00, 35.66it/s, loss=0.00271, val_loss=0.0027, \u001b[A\n",
      "Epoch 67:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.0027, val_loss=0.0027, a\u001b[A\n",
      "Epoch 67:  75%|▊| 36/48 [00:01<00:00, 31.32it/s, loss=0.0027, val_loss=0.0027, a\n",
      "Epoch 67: 100%|█| 48/48 [00:01<00:00, 38.43it/s, loss=0.0027, val_loss=0.00269, \u001b[A\n",
      "Epoch 68:  50%|▌| 24/48 [00:01<00:01, 22.01it/s, loss=0.0027, val_loss=0.00269, \u001b[A\n",
      "Epoch 68:  75%|▊| 36/48 [00:01<00:00, 31.40it/s, loss=0.0027, val_loss=0.00269, \n",
      "Epoch 68: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.0027, val_loss=0.00268, \u001b[A\n",
      "Epoch 69:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00269, val_loss=0.00268,\u001b[A\n",
      "Epoch 69:  75%|▊| 36/48 [00:01<00:00, 31.25it/s, loss=0.00269, val_loss=0.00268,\n",
      "Epoch 69: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.00269, val_loss=0.00267,\u001b[A\n",
      "Epoch 70:  50%|▌| 24/48 [00:01<00:01, 21.45it/s, loss=0.00269, val_loss=0.00267,\u001b[A\n",
      "Epoch 70:  75%|▊| 36/48 [00:01<00:00, 30.64it/s, loss=0.00269, val_loss=0.00267,\n",
      "Epoch 70: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00269, val_loss=0.00266,\u001b[A\n",
      "Epoch 71:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00269, val_loss=0.00266,\u001b[A\n",
      "Epoch 71:  75%|▊| 36/48 [00:01<00:00, 30.82it/s, loss=0.00269, val_loss=0.00266,\n",
      "Epoch 71: 100%|█| 48/48 [00:01<00:00, 37.86it/s, loss=0.00269, val_loss=0.00264,\u001b[A\n",
      "Epoch 72:  50%|▌| 24/48 [00:01<00:01, 20.44it/s, loss=0.00268, val_loss=0.00264,\u001b[A\n",
      "Epoch 72:  75%|▊| 36/48 [00:01<00:00, 29.12it/s, loss=0.00268, val_loss=0.00264,\n",
      "Epoch 72: 100%|█| 48/48 [00:01<00:00, 35.94it/s, loss=0.00268, val_loss=0.00263,\u001b[A\n",
      "Epoch 73:  50%|▌| 24/48 [00:01<00:01, 20.30it/s, loss=0.00268, val_loss=0.00263,\u001b[A\n",
      "Epoch 73:  75%|▊| 36/48 [00:01<00:00, 28.96it/s, loss=0.00268, val_loss=0.00263,\n",
      "Epoch 73: 100%|█| 48/48 [00:01<00:00, 35.78it/s, loss=0.00268, val_loss=0.00262,\u001b[A\n",
      "Epoch 74:  50%|▌| 24/48 [00:01<00:01, 20.16it/s, loss=0.00268, val_loss=0.00262,\u001b[A\n",
      "Epoch 74:  75%|▊| 36/48 [00:01<00:00, 28.60it/s, loss=0.00268, val_loss=0.00262,\n",
      "Epoch 74: 100%|█| 48/48 [00:01<00:00, 35.46it/s, loss=0.00268, val_loss=0.0026, \u001b[A\n",
      "Epoch 75:  50%|▌| 24/48 [00:01<00:01, 20.34it/s, loss=0.00267, val_loss=0.0026, \u001b[A\n",
      "Epoch 75:  75%|▊| 36/48 [00:01<00:00, 28.98it/s, loss=0.00267, val_loss=0.0026, \n",
      "Epoch 75: 100%|█| 48/48 [00:01<00:00, 35.77it/s, loss=0.00267, val_loss=0.0026, \u001b[A\n",
      "Epoch 76:  50%|▌| 24/48 [00:01<00:01, 19.89it/s, loss=0.00267, val_loss=0.0026, \u001b[A\n",
      "Epoch 76:  75%|▊| 36/48 [00:01<00:00, 28.33it/s, loss=0.00267, val_loss=0.0026, \n",
      "Epoch 76: 100%|█| 48/48 [00:01<00:00, 35.10it/s, loss=0.00267, val_loss=0.00258,\u001b[A\n",
      "Epoch 77:  50%|▌| 24/48 [00:01<00:01, 19.46it/s, loss=0.00267, val_loss=0.00258,\u001b[A\n",
      "Epoch 77:  75%|▊| 36/48 [00:01<00:00, 27.82it/s, loss=0.00267, val_loss=0.00258,\n",
      "Epoch 77: 100%|█| 48/48 [00:01<00:00, 34.42it/s, loss=0.00267, val_loss=0.00258,\u001b[A\n",
      "Epoch 78:  50%|▌| 24/48 [00:01<00:01, 20.36it/s, loss=0.00266, val_loss=0.00258,\u001b[A\n",
      "Epoch 78:  75%|▊| 36/48 [00:01<00:00, 28.96it/s, loss=0.00266, val_loss=0.00258,\n",
      "Epoch 78: 100%|█| 48/48 [00:01<00:00, 35.74it/s, loss=0.00266, val_loss=0.00257,\u001b[A\n",
      "Epoch 79:  50%|▌| 24/48 [00:01<00:01, 20.36it/s, loss=0.00266, val_loss=0.00257,\u001b[A\n",
      "Epoch 79:  75%|▊| 36/48 [00:01<00:00, 29.13it/s, loss=0.00266, val_loss=0.00257,\n",
      "Epoch 79: 100%|█| 48/48 [00:01<00:00, 35.93it/s, loss=0.00266, val_loss=0.00257,\u001b[A\n",
      "Epoch 80:  50%|▌| 24/48 [00:01<00:01, 20.28it/s, loss=0.00266, val_loss=0.00257,\u001b[A\n",
      "Epoch 80:  75%|▊| 36/48 [00:01<00:00, 28.79it/s, loss=0.00266, val_loss=0.00257,\n",
      "Epoch 80: 100%|█| 48/48 [00:01<00:00, 35.71it/s, loss=0.00266, val_loss=0.00256,\u001b[A\n",
      "Epoch 81:  50%|▌| 24/48 [00:01<00:01, 20.15it/s, loss=0.00265, val_loss=0.00256,\u001b[A\n",
      "Epoch 81:  75%|▊| 36/48 [00:01<00:00, 28.54it/s, loss=0.00265, val_loss=0.00256,\n",
      "Epoch 81: 100%|█| 48/48 [00:01<00:00, 35.47it/s, loss=0.00265, val_loss=0.00254,\u001b[A\n",
      "Epoch 82:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.00265, val_loss=0.00254,\u001b[A\n",
      "Epoch 82:  75%|▊| 36/48 [00:01<00:00, 31.31it/s, loss=0.00265, val_loss=0.00254,\n",
      "Epoch 82: 100%|█| 48/48 [00:01<00:00, 38.40it/s, loss=0.00265, val_loss=0.00253,\u001b[A\n",
      "Epoch 83:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00265, val_loss=0.00253,\u001b[A\n",
      "Epoch 83:  75%|▊| 36/48 [00:01<00:00, 30.89it/s, loss=0.00265, val_loss=0.00253,\n",
      "Epoch 83: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.00265, val_loss=0.00253,\u001b[A\n",
      "Epoch 84:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00265, val_loss=0.00253,\u001b[A\n",
      "Epoch 84:  75%|▊| 36/48 [00:01<00:00, 31.07it/s, loss=0.00265, val_loss=0.00253,\n",
      "Epoch 84: 100%|█| 48/48 [00:01<00:00, 38.13it/s, loss=0.00265, val_loss=0.00253,\u001b[A\n",
      "Epoch 85:  50%|▌| 24/48 [00:01<00:01, 21.22it/s, loss=0.00264, val_loss=0.00253,\u001b[A\n",
      "Epoch 85:  75%|▊| 36/48 [00:01<00:00, 30.06it/s, loss=0.00264, val_loss=0.00253,\n",
      "Epoch 85: 100%|█| 48/48 [00:01<00:00, 36.98it/s, loss=0.00264, val_loss=0.00252,\u001b[A\n",
      "Epoch 86:  50%|▌| 24/48 [00:01<00:01, 21.09it/s, loss=0.00264, val_loss=0.00252,\u001b[A\n",
      "Epoch 86:  75%|▊| 36/48 [00:01<00:00, 29.94it/s, loss=0.00264, val_loss=0.00252,\n",
      "Epoch 86: 100%|█| 48/48 [00:01<00:00, 36.99it/s, loss=0.00264, val_loss=0.00252,\u001b[A\n",
      "Epoch 87:  50%|▌| 24/48 [00:01<00:01, 19.75it/s, loss=0.00264, val_loss=0.00252,\u001b[A\n",
      "Epoch 87:  75%|▊| 36/48 [00:01<00:00, 28.22it/s, loss=0.00264, val_loss=0.00252,\n",
      "Epoch 87: 100%|█| 48/48 [00:01<00:00, 34.95it/s, loss=0.00264, val_loss=0.00251,\u001b[A\n",
      "Epoch 88:  50%|▌| 24/48 [00:01<00:01, 21.12it/s, loss=0.00264, val_loss=0.00251,\u001b[A\n",
      "Epoch 88:  75%|▊| 36/48 [00:01<00:00, 29.84it/s, loss=0.00264, val_loss=0.00251,\n",
      "Epoch 88: 100%|█| 48/48 [00:01<00:00, 36.79it/s, loss=0.00264, val_loss=0.00251,\u001b[A\n",
      "Epoch 89:  50%|▌| 24/48 [00:01<00:01, 19.84it/s, loss=0.00264, val_loss=0.00251,\u001b[A\n",
      "Epoch 89:  75%|▊| 36/48 [00:01<00:00, 28.34it/s, loss=0.00264, val_loss=0.00251,\n",
      "Epoch 89: 100%|█| 48/48 [00:01<00:00, 35.12it/s, loss=0.00264, val_loss=0.0025, \u001b[A\n",
      "Epoch 90:  50%|▌| 24/48 [00:01<00:01, 19.90it/s, loss=0.00263, val_loss=0.0025, \u001b[A\n",
      "Epoch 90:  75%|▊| 36/48 [00:01<00:00, 28.18it/s, loss=0.00263, val_loss=0.0025, \n",
      "Epoch 90: 100%|█| 48/48 [00:01<00:00, 35.01it/s, loss=0.00263, val_loss=0.00249,\u001b[A\n",
      "Epoch 91:  50%|▌| 24/48 [00:01<00:01, 20.23it/s, loss=0.00263, val_loss=0.00249,\u001b[A\n",
      "Epoch 91:  75%|▊| 36/48 [00:01<00:00, 28.91it/s, loss=0.00263, val_loss=0.00249,\n",
      "Epoch 91: 100%|█| 48/48 [00:01<00:00, 35.73it/s, loss=0.00263, val_loss=0.00249,\u001b[A\n",
      "Epoch 92:  50%|▌| 24/48 [00:01<00:01, 20.62it/s, loss=0.00263, val_loss=0.00249,\u001b[A\n",
      "Epoch 92:  75%|▊| 36/48 [00:01<00:00, 29.30it/s, loss=0.00263, val_loss=0.00249,\n",
      "Epoch 92: 100%|█| 48/48 [00:01<00:00, 36.05it/s, loss=0.00263, val_loss=0.00248,\u001b[A\n",
      "Epoch 93:  50%|▌| 24/48 [00:01<00:01, 19.74it/s, loss=0.00263, val_loss=0.00248,\u001b[A\n",
      "Epoch 93:  75%|▊| 36/48 [00:01<00:00, 28.21it/s, loss=0.00263, val_loss=0.00248,\n",
      "Epoch 93: 100%|█| 48/48 [00:01<00:00, 34.87it/s, loss=0.00263, val_loss=0.00247,\u001b[A\n",
      "Epoch 94:  50%|▌| 24/48 [00:01<00:01, 19.63it/s, loss=0.00263, val_loss=0.00247,\u001b[A\n",
      "Epoch 94:  75%|▊| 36/48 [00:01<00:00, 27.93it/s, loss=0.00263, val_loss=0.00247,\n",
      "Epoch 94: 100%|█| 48/48 [00:01<00:00, 34.73it/s, loss=0.00263, val_loss=0.00247,\u001b[A\n",
      "Epoch 95:  50%|▌| 24/48 [00:01<00:01, 19.63it/s, loss=0.00263, val_loss=0.00247,\u001b[A\n",
      "Epoch 95:  75%|▊| 36/48 [00:01<00:00, 27.79it/s, loss=0.00263, val_loss=0.00247,\n",
      "Epoch 95: 100%|█| 48/48 [00:01<00:00, 34.55it/s, loss=0.00263, val_loss=0.00247,\u001b[A\n",
      "Epoch 96:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.00262, val_loss=0.00247,\u001b[A\n",
      "Epoch 96:  75%|▊| 36/48 [00:01<00:00, 30.83it/s, loss=0.00262, val_loss=0.00247,\n",
      "Epoch 96: 100%|█| 48/48 [00:01<00:00, 37.86it/s, loss=0.00262, val_loss=0.00246,\u001b[A\n",
      "Epoch 97:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00262, val_loss=0.00246,\u001b[A\n",
      "Epoch 97:  75%|▊| 36/48 [00:01<00:00, 31.14it/s, loss=0.00262, val_loss=0.00246,\n",
      "Epoch 97: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00262, val_loss=0.00245,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00262, val_loss=0.00245,\u001b[A\n",
      "Epoch 98:  75%|▊| 36/48 [00:01<00:00, 31.23it/s, loss=0.00262, val_loss=0.00245,\n",
      "Epoch 98: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.00262, val_loss=0.00244,\u001b[A\n",
      "Epoch 99:  50%|▌| 24/48 [00:01<00:01, 21.27it/s, loss=0.00262, val_loss=0.00244,\u001b[A\n",
      "Epoch 99:  75%|▊| 36/48 [00:01<00:00, 30.36it/s, loss=0.00262, val_loss=0.00244,\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 37.31it/s, loss=0.00262, val_loss=0.00243,\u001b[A\n",
      "Epoch 99: 100%|█| 48/48 [00:01<00:00, 37.05it/s, loss=0.00262, val_loss=0.00243,\u001b[A\n",
      "Sizes of clusters: 302, 495, 403\n",
      "\n",
      "preds: [1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1\n",
      " 2 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 2 1 1 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 2 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 2\n",
      " 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 2 2 2 2 1 1 2 2 1 2 1 1 2 0 2 2 0 0 0\n",
      " 0 2 0 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 2 2 0 0 2 0 2 2 2 2 0 0 0 2 2 2 0 0 2 0 0 0 2 0 2 0 0 0 0 0 0 2 0\n",
      " 2 0 0 0 0 0 0 2 0 0 2 0 0 0 2 2 0 0 0 2 2 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 2 0 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 2 0\n",
      " 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0 2 0 0 0 0 2 2 2 0 2 2 2 2 0 0 0 2 0 2 0 0\n",
      " 0 2 0 0 0 2 1 0 2 2 0 0 0 2 2 0 0 2 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 0 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 2 2 2 2 0 0 0 2 2 0 0 0 2 0 2 0 0 0 0 0\n",
      " 0 0 2 2 0 0 2 0 0 2 0 2 0 0 2 2 0 0 0 2 2 0 2 2 0 0 2 2 0 2 0 2 0 0 2 0 0\n",
      " 0 0 0 0 2 0 0 0 2 0 0 2 2 0 0 0 0 0 0 0 0 0 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2\n",
      " 2 1 2 1 2 2 2 2 2 2 2 2 1 1 2 1 2 2 2 2 2 1 2 2 1 1 1 1 2 2 1 2 1 2 2 2 2\n",
      " 0 2 2 0 1 1 2 2 2 2 2 1 2 1 2 2 1 1 1 0 1 2 2 2 1 1 2 2 1 2 2 1 2 2 1 2 2\n",
      " 2 2 2 1 1 2 1 2 1 2 2 1 1 2 1 1 2 2 1 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2\n",
      " 2 1 1 1 1 1 2 2 1 1 1 1 2 1 2 1 2 2 2 2 1 1 1 0 1 2 1 2 1 1 1 1 1 2 1 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 1 1 2 1 1 2 2 1 2 2 2 2 1 2 2 1 2 2 2 1 1 2\n",
      " 2 1 1 2 1 2 2 2 1 1 0 2 0 2 1 2 1 2 2 1 1 2 1 1 2 1 2 1 2 2 2 2 2 2 1 1 1\n",
      " 2 2 1 1 2 2 1 1 2 2 1 0 1 2 1 1 1 1 0 2 1 2 2 1 2 2 2 2 2 2 2 1 1 0 2 1 2\n",
      " 1 2 2 2 1 1 2 1 2 2 1 2 2 1 1 2 2 2 1 2 2 1 2 1 1 2 1 2 2 0 2 2 1 1 2 2 1\n",
      " 1 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 1 2 2 2 1 0 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 2 2 1 1 2 2 2 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 1 2 2 1 2 1 1 2 2 2 2 2 2\n",
      " 1 1 2 1 2 2 0 1 1 1 2 2 2 2 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.6900\n",
      "\n",
      "Consistency: 0.4901\n",
      "Purity: 0.6673333333333333+-0.08495979441280843\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K3_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=1.75, val_loss=0.0558, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 36.65it/s, loss=1.75, val_loss=3.11, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.12it/s, loss=0.0824, val_loss=3.11, avg_\u001b[A\n",
      "Epoch 1:  56%|▌| 36/64 [00:01<00:01, 22.39it/s, loss=0.0824, val_loss=3.11, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 35.56it/s, loss=0.0824, val_loss=0.122, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.0247, val_loss=0.122, avg\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 23.29it/s, loss=0.0247, val_loss=0.122, avg\n",
      "Epoch 2:  84%|▊| 54/64 [00:01<00:00, 32.77it/s, loss=0.0247, val_loss=0.122, avg\u001b[A\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.0247, val_loss=0.0298, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.55it/s, loss=0.0193, val_loss=0.0298, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 22.91it/s, loss=0.0193, val_loss=0.0298, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 36.27it/s, loss=0.0193, val_loss=0.0241, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 20.79it/s, loss=0.0166, val_loss=0.0241, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 23.08it/s, loss=0.0166, val_loss=0.0241, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 36.56it/s, loss=0.0166, val_loss=0.0201, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.0146, val_loss=0.0201, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 23.53it/s, loss=0.0146, val_loss=0.0201, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 37.11it/s, loss=0.0146, val_loss=0.0174, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.013, val_loss=0.0174, avg\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 23.36it/s, loss=0.013, val_loss=0.0174, avg\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.013, val_loss=0.0153, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.0118, val_loss=0.0153, av\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.0118, val_loss=0.0153, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.0118, val_loss=0.0135, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.0107, val_loss=0.0135, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 23.68it/s, loss=0.0107, val_loss=0.0135, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.0107, val_loss=0.0123, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 20.61it/s, loss=0.00989, val_loss=0.0123, a\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 22.96it/s, loss=0.00989, val_loss=0.0123, a\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 36.38it/s, loss=0.00989, val_loss=0.0113, a\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.00919, val_loss=0.0113, \u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 23.08it/s, loss=0.00919, val_loss=0.0113, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 36.49it/s, loss=0.00919, val_loss=0.0104, \u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00862, val_loss=0.0104, \u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 23.56it/s, loss=0.00862, val_loss=0.0104, \n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.00862, val_loss=0.00963,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00816, val_loss=0.00963,\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 23.54it/s, loss=0.00816, val_loss=0.00963,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00816, val_loss=0.00909,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00779, val_loss=0.00909,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 23.85it/s, loss=0.00779, val_loss=0.00909,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00779, val_loss=0.00865,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.0075, val_loss=0.00865, \u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 23.42it/s, loss=0.0075, val_loss=0.00865, \n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 36.96it/s, loss=0.0075, val_loss=0.00827, \u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00727, val_loss=0.00827,\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 23.68it/s, loss=0.00727, val_loss=0.00827,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.00727, val_loss=0.00798,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.00709, val_loss=0.00798,\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 23.90it/s, loss=0.00709, val_loss=0.00798,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00709, val_loss=0.00783,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00695, val_loss=0.00783,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 23.57it/s, loss=0.00695, val_loss=0.00783,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00695, val_loss=0.00748,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.00684, val_loss=0.00748,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 23.91it/s, loss=0.00684, val_loss=0.00748,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.00684, val_loss=0.00731,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00675, val_loss=0.00731,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 23.36it/s, loss=0.00675, val_loss=0.00731,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.00675, val_loss=0.00716,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00668, val_loss=0.00716,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 23.15it/s, loss=0.00668, val_loss=0.00716,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 36.50it/s, loss=0.00668, val_loss=0.00704,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00662, val_loss=0.00704,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 23.89it/s, loss=0.00662, val_loss=0.00704,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00662, val_loss=0.00693,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00656, val_loss=0.00693,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 23.57it/s, loss=0.00656, val_loss=0.00693,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00656, val_loss=0.00686,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00652, val_loss=0.00686,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 23.40it/s, loss=0.00652, val_loss=0.00686,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 36.96it/s, loss=0.00652, val_loss=0.00677,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00648, val_loss=0.00677,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 23.57it/s, loss=0.00648, val_loss=0.00677,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.00648, val_loss=0.00667,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.00644, val_loss=0.00667,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 23.88it/s, loss=0.00644, val_loss=0.00667,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00644, val_loss=0.00665,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00641, val_loss=0.00665,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 23.56it/s, loss=0.00641, val_loss=0.00665,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.00641, val_loss=0.00653,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00639, val_loss=0.00653,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 23.13it/s, loss=0.00639, val_loss=0.00653,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 36.52it/s, loss=0.00639, val_loss=0.00655,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 20.47it/s, loss=0.00636, val_loss=0.00655,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 22.85it/s, loss=0.00636, val_loss=0.00655,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 36.16it/s, loss=0.00636, val_loss=0.00643,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00634, val_loss=0.00643,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.80it/s, loss=0.00634, val_loss=0.00643,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00634, val_loss=0.00632,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.00632, val_loss=0.00632,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.11it/s, loss=0.00632, val_loss=0.00632,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00632, val_loss=0.00632,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.0063, val_loss=0.00632, \u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 23.98it/s, loss=0.0063, val_loss=0.00632, \n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.72it/s, loss=0.0063, val_loss=0.00624, \u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.88it/s, loss=0.00628, val_loss=0.00624,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.46it/s, loss=0.00628, val_loss=0.00624,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.37it/s, loss=0.00628, val_loss=0.00616,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00626, val_loss=0.00616,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.07it/s, loss=0.00626, val_loss=0.00616,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.00626, val_loss=0.00611,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00625, val_loss=0.00611,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00625, val_loss=0.00611,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00625, val_loss=0.00609,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00623, val_loss=0.00609,\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.13it/s, loss=0.00623, val_loss=0.00609,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.87it/s, loss=0.00623, val_loss=0.00605,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00622, val_loss=0.00605,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00622, val_loss=0.00605,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.11it/s, loss=0.00622, val_loss=0.006, a\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00621, val_loss=0.006, a\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.47it/s, loss=0.00621, val_loss=0.006, a\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.43it/s, loss=0.00621, val_loss=0.00593,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.0062, val_loss=0.00593, \u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 23.72it/s, loss=0.0062, val_loss=0.00593, \n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.39it/s, loss=0.0062, val_loss=0.00594, \u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00619, val_loss=0.00594,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.84it/s, loss=0.00619, val_loss=0.00594,\n",
      "Epoch 39:  84%|▊| 54/64 [00:01<00:00, 33.38it/s, loss=0.00619, val_loss=0.00594,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00619, val_loss=0.00589,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00618, val_loss=0.00589,\u001b[A\n",
      "Epoch 40:  56%|▌| 36/64 [00:01<00:01, 23.78it/s, loss=0.00618, val_loss=0.00589,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 37.59it/s, loss=0.00618, val_loss=0.00586,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.00617, val_loss=0.00586,\u001b[A\n",
      "Epoch 41:  56%|▌| 36/64 [00:01<00:01, 23.79it/s, loss=0.00617, val_loss=0.00586,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00617, val_loss=0.0058, \u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00616, val_loss=0.0058, \u001b[A\n",
      "Epoch 42:  56%|▌| 36/64 [00:01<00:01, 23.58it/s, loss=0.00616, val_loss=0.0058, \n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.00616, val_loss=0.00579,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=0.00616, val_loss=0.00579,\u001b[A\n",
      "Epoch 43:  56%|▌| 36/64 [00:01<00:01, 23.58it/s, loss=0.00616, val_loss=0.00579,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.00616, val_loss=0.00575,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00615, val_loss=0.00575,\u001b[A\n",
      "Epoch 44:  56%|▌| 36/64 [00:01<00:01, 23.64it/s, loss=0.00615, val_loss=0.00575,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00615, val_loss=0.00577,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.00614, val_loss=0.00577,\u001b[A\n",
      "Epoch 45:  56%|▌| 36/64 [00:01<00:01, 23.92it/s, loss=0.00614, val_loss=0.00577,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00614, val_loss=0.00573,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00614, val_loss=0.00573,\u001b[A\n",
      "Epoch 46:  56%|▌| 36/64 [00:01<00:01, 23.74it/s, loss=0.00614, val_loss=0.00573,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 37.40it/s, loss=0.00614, val_loss=0.00571,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00613, val_loss=0.00571,\u001b[A\n",
      "Epoch 47:  56%|▌| 36/64 [00:01<00:01, 23.99it/s, loss=0.00613, val_loss=0.00571,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00613, val_loss=0.00567,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00613, val_loss=0.00567,\u001b[A\n",
      "Epoch 48:  56%|▌| 36/64 [00:01<00:01, 23.66it/s, loss=0.00613, val_loss=0.00567,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00613, val_loss=0.00567,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00612, val_loss=0.00567,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.95it/s, loss=0.00612, val_loss=0.00567,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 37.41it/s, loss=0.00612, val_loss=0.00566,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00612, val_loss=0.00566,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 25.03it/s, loss=0.00612, val_loss=0.00566,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00612, val_loss=0.00562,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00611, val_loss=0.00562,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 25.41it/s, loss=0.00611, val_loss=0.00562,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00611, val_loss=0.00561,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00611, val_loss=0.00561,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.95it/s, loss=0.00611, val_loss=0.00561,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00611, val_loss=0.00559,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00611, val_loss=0.00559,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.66it/s, loss=0.00611, val_loss=0.00559,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.00611, val_loss=0.00559,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00611, val_loss=0.00559,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 23.95it/s, loss=0.00611, val_loss=0.00559,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.00611, val_loss=0.0056, \u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0061, val_loss=0.0056, a\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 24.98it/s, loss=0.0061, val_loss=0.0056, a\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.0061, val_loss=0.00554, \u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.0061, val_loss=0.00554, \u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 24.19it/s, loss=0.0061, val_loss=0.00554, \n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.0061, val_loss=0.00557, \u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.0061, val_loss=0.00557, \u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 23.80it/s, loss=0.0061, val_loss=0.00557, \n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 36.07it/s, loss=0.0061, val_loss=0.00553, \u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 20.99it/s, loss=0.0061, val_loss=0.00553, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 24.62it/s, loss=0.0061, val_loss=0.00553, \n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.0061, val_loss=0.00555, \u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.0061, val_loss=0.00555, \u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.76it/s, loss=0.0061, val_loss=0.00555, \n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.84it/s, loss=0.0061, val_loss=0.00551, \n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.0061, val_loss=0.00552, \u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.0061, val_loss=0.00552, \u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.0061, val_loss=0.00552, \n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.0061, val_loss=0.00552, \u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0061, val_loss=0.00552, \u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.0061, val_loss=0.00552, \n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.55it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 25.27it/s, loss=0.0061, val_loss=0.00551, \n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 37.84it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 25.09it/s, loss=0.0061, val_loss=0.00551, \n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.0061, val_loss=0.00551, \u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.0061, val_loss=0.00551, \n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.0061, val_loss=0.00548, \u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.0061, val_loss=0.00548, \u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.0061, val_loss=0.00548, \n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 36.73it/s, loss=0.0061, val_loss=0.00547, \u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0061, val_loss=0.00547, \u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.0061, val_loss=0.00547, \n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.0061, val_loss=0.00548, \u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00611, val_loss=0.00548,\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 24.82it/s, loss=0.00611, val_loss=0.00548,\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00611, val_loss=0.00543,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.54it/s, loss=0.00611, val_loss=0.00543,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 25.29it/s, loss=0.00611, val_loss=0.00543,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 37.76it/s, loss=0.00611, val_loss=0.00545,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00611, val_loss=0.00545,\u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.00611, val_loss=0.00545,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 37.03it/s, loss=0.00611, val_loss=0.00544,\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.57it/s, loss=0.00611, val_loss=0.00544,\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 24.16it/s, loss=0.00611, val_loss=0.00544,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.34it/s, loss=0.00611, val_loss=0.00544,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.00611, val_loss=0.00544,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00611, val_loss=0.00544,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.00611, val_loss=0.00543,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00611, val_loss=0.00543,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.00611, val_loss=0.00543,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.00611, val_loss=0.00542,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00612, val_loss=0.00542,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.00612, val_loss=0.00542,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00612, val_loss=0.00541,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.00617, val_loss=0.00541,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 25.00it/s, loss=0.00617, val_loss=0.00541,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00617, val_loss=0.00571,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.0191, val_loss=0.00571, \u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 25.06it/s, loss=0.0191, val_loss=0.00571, \n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.0191, val_loss=0.0108, a\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00644, val_loss=0.0108, \u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 24.56it/s, loss=0.00644, val_loss=0.0108, \n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.00644, val_loss=0.00567,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 20.99it/s, loss=0.00613, val_loss=0.00567,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00613, val_loss=0.00567,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 36.97it/s, loss=0.00613, val_loss=0.0054, \u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 21.01it/s, loss=0.00612, val_loss=0.0054, \u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 24.59it/s, loss=0.00612, val_loss=0.0054, \n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 36.80it/s, loss=0.00612, val_loss=0.00538,\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00613, val_loss=0.00538,\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00613, val_loss=0.00538,\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00613, val_loss=0.00539,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=0.0408, val_loss=0.00539, \u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.0408, val_loss=0.00539, \n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 37.16it/s, loss=0.0408, val_loss=0.0195, a\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.00735, val_loss=0.0195, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 25.10it/s, loss=0.00735, val_loss=0.0195, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00735, val_loss=0.006, a\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00616, val_loss=0.006, a\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00616, val_loss=0.006, a\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.00616, val_loss=0.00541,\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00612, val_loss=0.00541,\u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00612, val_loss=0.00541,\n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.00612, val_loss=0.00531,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00612, val_loss=0.00531,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00612, val_loss=0.00531,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.60it/s, loss=0.00612, val_loss=0.0053, \u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00658, val_loss=0.0053, \u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 25.56it/s, loss=0.00658, val_loss=0.0053, \n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00658, val_loss=0.0102, \u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.0273, val_loss=0.0102, a\u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.59it/s, loss=0.0273, val_loss=0.0102, a\n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.80it/s, loss=0.0273, val_loss=0.00811, \u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00674, val_loss=0.00811,\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 25.28it/s, loss=0.00674, val_loss=0.00811,\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 37.84it/s, loss=0.00674, val_loss=0.00539,\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.00614, val_loss=0.00539,\u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00614, val_loss=0.00539,\n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 37.30it/s, loss=0.00614, val_loss=0.00527,\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 20.41it/s, loss=0.00613, val_loss=0.00527,\u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 23.87it/s, loss=0.00613, val_loss=0.00527,\n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 35.96it/s, loss=0.00613, val_loss=0.00526,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00616, val_loss=0.00526,\u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 25.06it/s, loss=0.00616, val_loss=0.00526,\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 37.56it/s, loss=0.00616, val_loss=0.00563,\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.0487, val_loss=0.00563, \u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.0487, val_loss=0.00563, \n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 37.11it/s, loss=0.0487, val_loss=0.0203, a\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00724, val_loss=0.0203, \u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.00724, val_loss=0.0203, \n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.79it/s, loss=0.00724, val_loss=0.00535,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.00616, val_loss=0.00535,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 24.78it/s, loss=0.00616, val_loss=0.00535,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.00616, val_loss=0.00527,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00614, val_loss=0.00527,\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.59it/s, loss=0.00614, val_loss=0.00527,\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.00614, val_loss=0.00521,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.00957, val_loss=0.00521,\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.58it/s, loss=0.00957, val_loss=0.00521,\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 37.05it/s, loss=0.00957, val_loss=0.0486, \u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.0268, val_loss=0.0486, a\u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.0268, val_loss=0.0486, a\n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.0268, val_loss=0.00824, \u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00682, val_loss=0.00824,\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.70it/s, loss=0.00682, val_loss=0.00824,\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00682, val_loss=0.00528,\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.00616, val_loss=0.00528,\u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.00616, val_loss=0.00528,\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.00616, val_loss=0.00516,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.00it/s, loss=0.00616, val_loss=0.00516,\u001b[A\n",
      "Sizes of clusters: 372, 491, 536, 201\n",
      "\n",
      "preds: [2 0 1 2 2 0 3 1 2 2 0 2 2 2 1 0 0 1 1 1 2 3 1 1 2 2 1 1 1 1 2 3 0 1 3 2 2\n",
      " 2 3 3 2 2 0 1 0 3 2 2 2 3 2 2 2 0 0 1 2 2 3 3 0 1 1 3 1 2 2 2 0 2 1 1 2 1\n",
      " 3 1 2 2 1 2 3 3 1 1 1 1 3 1 0 1 2 1 2 2 3 2 1 3 1 2 3 2 2 2 2 2 2 1 2 2 1\n",
      " 1 1 0 3 1 2 2 1 1 1 1 2 2 3 2 1 2 0 1 3 2 2 1 1 2 1 2 1 1 0 3 2 1 2 2 2 1\n",
      " 2 3 2 1 3 3 1 1 2 2 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 0 2 1 1 1 1 1 2 2 1 1 1\n",
      " 0 2 1 2 2 1 0 3 2 1 1 2 1 2 1 0 2 1 2 2 3 1 2 2 0 1 1 3 1 1 2 1 2 2 1 2 0\n",
      " 0 1 2 1 3 0 2 2 2 1 1 1 3 3 2 2 0 1 0 1 1 2 2 1 1 1 2 2 0 1 3 1 3 1 2 3 1\n",
      " 2 2 2 2 0 1 2 1 3 2 1 1 2 1 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 2 0 2 3 1 0\n",
      " 1 2 0 0 2 3 0 1 1 1 3 1 1 2 1 0 1 2 1 1 3 1 2 0 1 2 1 3 2 3 2 2 2 3 2 1 1\n",
      " 1 0 2 2 1 2 0 2 2 2 1 0 2 3 2 2 1 2 0 1 1 1 1 2 0 2 1 2 1 1 2 1 1 1 1 1 2\n",
      " 2 1 2 2 1 2 2 0 2 2 2 1 2 1 1 0 1 2 3 2 2 0 1 2 3 1 2 3 3 2 1 2 2 0 0 2 2\n",
      " 2 0 1 2 2 1 2 2 2 1 1 3 0 1 2 1 1 2 0 0 2 1 0 0 3 2 1 2 0 0 2 2 0 2 0 2 2\n",
      " 2 2 2 1 0 0 2 0 2 2 2 0 2 2 1 2 1 2 0 2 0 0 0 2 0 2 0 2 1 2 1 2 2 2 0 0 0\n",
      " 2 2 1 1 2 2 2 1 1 2 2 2 2 2 1 1 2 2 0 1 2 1 1 0 2 1 2 1 1 1 2 2 1 2 0 2 2\n",
      " 1 0 0 0 0 1 1 0 1 1 1 1 2 2 2 2 0 1 1 1 1 0 0 2 2 2 2 1 1 1 0 2 0 2 0 2 0\n",
      " 1 2 0 0 1 2 0 2 2 2 2 0 2 0 1 0 1 2 2 2 2 2 2 2 2 2 2 1 2 0 2 2 2 0 2 2 2\n",
      " 0 1 1 1 2 1 0 2 0 1 1 2 2 0 2 2 2 2 1 1 2 2 1 2 2 1 0 1 0 2 2 1 1 2 0 2 0\n",
      " 2 0 2 2 0 2 1 0 2 0 1 2 1 0 0 0 2 2 2 2 2 0 1 0 2 0 2 2 2 2 2 0 2 2 2 1 1\n",
      " 2 0 2 2 1 1 2 1 2 2 1 0 0 2 3 0 0 1 0 1 2 0 1 2 0 1 2 0 2 2 1 1 0 2 1 1 0\n",
      " 2 0 2 1 2 2 2 1 1 2 0 2 0 0 1 1 1 2 1 1 0 2 1 2 1 0 2 2 0 0 2 2 2 0 2 2 2\n",
      " 2 2 0 1 1 2 2 2 1 2 2 0 2 0 1 0 0 0 3 1 0 2 0 0 0 1 2 1 0 2 2 2 1 0 0 2 1\n",
      " 2 2 0 0 0 2 2 2 0 1 2 0 1 2 2 0 1 1 2 1 1 2 3 1 1 3 1 3 3 3 3 3 3 3 1 3 2\n",
      " 3 1 3 1 1 0 3 1 1 3 3 3 2 1 1 1 3 1 2 3 3 1 1 1 1 1 1 3 3 1 1 3 3 2 3 3 1\n",
      " 1 3 3 3 3 1 3 3 3 3 1 3 3 1 3 3 3 3 2 2 3 1 3 1 1 1 3 1 2 1 1 1 1 3 3 1 1\n",
      " 1 1 1 1 3 3 1 3 3 2 1 1 1 1 1 1 1 1 3 1 1 1 1 1 2 1 3 3 3 1 1 1 1 3 3 3 3\n",
      " 3 3 3 3 2 3 1 2 1 3 1 0 1 3 1 3 1 1 2 3 2 1 1 3 1 2 3 2 3 1 1 2 1 1 1 1 1\n",
      " 3 2 3 1 2 1 2 3 2 1 1 3 3 1 1 1 1 3 1 1 2 1 1 3 1 1 1 3 1 3 2 2 3 3 2 1 3\n",
      " 1 3 3 1 1 3 1 1 3 1 2 1 3 1 1 1 1 3 3 1 3 3 3 1 1 2 3 1 1 3 1 1 3 1 1 2 1\n",
      " 2 3 1 3 1 1 1 3 2 1 3 1 1 3 3 1 2 2 1 1 1 3 2 2 1 3 2 2 1 1 2 2 3 1 3 3 1\n",
      " 1 3 1 1 2 1 2 1 3 2 3 2 2 3 1 3 1 3 2 1 1 3 1 2 3 1 3 1 1 1 3 1 1 3 1 2 1\n",
      " 1 1 3 1 2 1 1 1 3 1 1 3 3 1 1 1 3 1 3 3 2 3 1 3 3 1 1 1 1 0 1 1 3 2 1 3 3\n",
      " 2 3 1 3 3 3 1 1 1 1 1 1 2 3 1 2 3 3 2 3 3 3 1 1 3 1 1 1 1 1 1 3 3 1 3 1 3\n",
      " 1 3 1 3 3 3 1 2 2 3 1 2 1 2 2 3 0 0 2 0 2 0 2 0 2 1 2 2 2 1 0 2 0 2 0 2 0\n",
      " 1 0 2 0 0 2 2 0 1 2 0 0 0 2 2 2 0 0 2 0 2 0 0 1 0 0 2 0 0 2 0 1 0 0 2 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 2 2 1 1 2 2 2 2 0 0 0 0 0 0 2 0 1 0 0 1 2 0 2 2 0 2\n",
      " 0 2 0 2 2 0 2 0 0 2 2 2 0 2 1 0 0 0 0 2 0 0 0 2 0 0 2 2 0 0 1 1 0 0 1 2 0\n",
      " 2 0 0 2 2 2 0 2 0 0 0 1 0 2 0 3 2 0 2 1 2 1 2 0 2 0 0 0 2 1 2 0 0 0 1 0 0\n",
      " 2 0 0 2 0 0 0 2 2 0 0 1 0 2 0 0 0 2 0 2 2 0 0 2 0 0 1 0 0 0 2 0 1 2 0 0 2\n",
      " 0 2 0 0 2 0 0 0 2 2 0 2 0 2 0 0 2 2 0 0 1 0 0 2 2 0 2 0 1 0 2 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 1 0 0 2 0 2 1 2 0 0 2 0 0 0 0 2 2 1 1 0 0 0 2 0 0 0\n",
      " 2 2 0 0 0 0 1 0 0 2 1 2 0 0 2 2 2 0 0 1 2 0 0 0 2 1 0 0 0 0 1 0 2 0 0 1 2\n",
      " 0 2 2 0 0 0 0 0 1 2 2 0 2 0 2 2 1 2 0 0 0 0 0 2 2 0 1 1 0 2 0 2 0 0 0 2 2\n",
      " 2 2 0 0 0 0 0 2 0 2 0 2 0 2 0 0 2 2 1 2 0 1 0 0 1 0 2 2 0 0 0 2 2 0 0 1 2\n",
      " 0 2 0 0 0 2 0 0 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4656\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=1.98, val_loss=0.0693, avg_\n",
      "Epoch 0:  67%|▋| 43/64 [00:01<00:00, 26.76it/s, loss=1.98, val_loss=0.0693, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=1.98, val_loss=0.826, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.0907, val_loss=0.826, avg\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 21.87it/s, loss=0.0907, val_loss=0.826, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 36.38it/s, loss=0.0907, val_loss=0.0588, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.026, val_loss=0.0588, avg\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 23.77it/s, loss=0.026, val_loss=0.0588, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.026, val_loss=0.0293, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.0201, val_loss=0.0293, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 23.28it/s, loss=0.0201, val_loss=0.0293, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.0201, val_loss=0.0242, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 20.36it/s, loss=0.0175, val_loss=0.0242, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 22.61it/s, loss=0.0175, val_loss=0.0242, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 35.88it/s, loss=0.0175, val_loss=0.021, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.0156, val_loss=0.021, avg\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 23.17it/s, loss=0.0156, val_loss=0.021, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 36.60it/s, loss=0.0156, val_loss=0.0186, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.0141, val_loss=0.0186, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 23.68it/s, loss=0.0141, val_loss=0.0186, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.0141, val_loss=0.0166, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 20.60it/s, loss=0.0129, val_loss=0.0166, av\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 22.90it/s, loss=0.0129, val_loss=0.0166, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 36.30it/s, loss=0.0129, val_loss=0.0149, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.0118, val_loss=0.0149, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 23.03it/s, loss=0.0118, val_loss=0.0149, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 36.39it/s, loss=0.0118, val_loss=0.0135, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.0109, val_loss=0.0135, av\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 22.69it/s, loss=0.0109, val_loss=0.0135, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 36.02it/s, loss=0.0109, val_loss=0.0123, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.0101, val_loss=0.0123, a\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 23.60it/s, loss=0.0101, val_loss=0.0123, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.0101, val_loss=0.0114, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00947, val_loss=0.0114, \u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 23.13it/s, loss=0.00947, val_loss=0.0114, \n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 36.56it/s, loss=0.00947, val_loss=0.0105, \u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.0089, val_loss=0.0105, a\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 22.87it/s, loss=0.0089, val_loss=0.0105, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 36.14it/s, loss=0.0089, val_loss=0.00977, \u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00841, val_loss=0.00977,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 22.65it/s, loss=0.00841, val_loss=0.00977,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 35.97it/s, loss=0.00841, val_loss=0.00916,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.26it/s, loss=0.00801, val_loss=0.00916,\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 22.63it/s, loss=0.00801, val_loss=0.00916,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 35.83it/s, loss=0.00801, val_loss=0.00863,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00767, val_loss=0.00863,\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.00767, val_loss=0.00863,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00767, val_loss=0.00822,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00739, val_loss=0.00822,\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.00739, val_loss=0.00822,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00739, val_loss=0.00789,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00716, val_loss=0.00789,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 23.64it/s, loss=0.00716, val_loss=0.00789,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00716, val_loss=0.00761,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.00698, val_loss=0.00761,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 23.90it/s, loss=0.00698, val_loss=0.00761,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00698, val_loss=0.00737,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.71it/s, loss=0.00683, val_loss=0.00737,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 23.01it/s, loss=0.00683, val_loss=0.00737,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.00683, val_loss=0.00719,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 20.68it/s, loss=0.00672, val_loss=0.00719,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 22.93it/s, loss=0.00672, val_loss=0.00719,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 36.32it/s, loss=0.00672, val_loss=0.00705,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.00663, val_loss=0.00705,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 22.84it/s, loss=0.00663, val_loss=0.00705,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.23it/s, loss=0.00663, val_loss=0.00692,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00656, val_loss=0.00692,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.06it/s, loss=0.00656, val_loss=0.00692,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.00656, val_loss=0.00683,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.0065, val_loss=0.00683, \u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 23.39it/s, loss=0.0065, val_loss=0.00683, \n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.0065, val_loss=0.00676, \u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.00645, val_loss=0.00676,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 23.91it/s, loss=0.00645, val_loss=0.00676,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.00645, val_loss=0.0067, \u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00642, val_loss=0.0067, \u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 23.89it/s, loss=0.00642, val_loss=0.0067, \n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00642, val_loss=0.00666,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00639, val_loss=0.00666,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 23.81it/s, loss=0.00639, val_loss=0.00666,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00639, val_loss=0.00662,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00636, val_loss=0.00662,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 23.50it/s, loss=0.00636, val_loss=0.00662,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.03it/s, loss=0.00636, val_loss=0.00655,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=0.00634, val_loss=0.00655,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 23.58it/s, loss=0.00634, val_loss=0.00655,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.00634, val_loss=0.00652,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00633, val_loss=0.00652,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.28it/s, loss=0.00633, val_loss=0.00652,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.00633, val_loss=0.00649,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.60it/s, loss=0.00632, val_loss=0.00649,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 22.81it/s, loss=0.00632, val_loss=0.00649,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 36.14it/s, loss=0.00632, val_loss=0.00646,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.0063, val_loss=0.00646, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 23.37it/s, loss=0.0063, val_loss=0.00646, \n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.0063, val_loss=0.0064, a\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 20.70it/s, loss=0.00629, val_loss=0.0064, \u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 23.10it/s, loss=0.00629, val_loss=0.0064, \n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.00629, val_loss=0.00636,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00629, val_loss=0.00636,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.00it/s, loss=0.00629, val_loss=0.00636,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.78it/s, loss=0.00629, val_loss=0.00634,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.00628, val_loss=0.00634,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 23.84it/s, loss=0.00628, val_loss=0.00634,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00628, val_loss=0.0063, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.00627, val_loss=0.0063, \u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 23.93it/s, loss=0.00627, val_loss=0.0063, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.66it/s, loss=0.00627, val_loss=0.0063, \u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00627, val_loss=0.0063, \u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00627, val_loss=0.0063, \n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.00627, val_loss=0.00628,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00627, val_loss=0.00628,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 23.66it/s, loss=0.00627, val_loss=0.00628,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00627, val_loss=0.00624,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00626, val_loss=0.00624,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 23.35it/s, loss=0.00626, val_loss=0.00624,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.00626, val_loss=0.00623,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.00626, val_loss=0.00623,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.53it/s, loss=0.00626, val_loss=0.00623,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.14it/s, loss=0.00626, val_loss=0.00621,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=0.00626, val_loss=0.00621,\u001b[A\n",
      "Epoch 40:  56%|▌| 36/64 [00:01<00:01, 23.37it/s, loss=0.00626, val_loss=0.00621,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 37.01it/s, loss=0.00626, val_loss=0.00619,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00626, val_loss=0.00619,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.00626, val_loss=0.00619,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 36.95it/s, loss=0.00626, val_loss=0.00614,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00626, val_loss=0.00614,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00626, val_loss=0.00614,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.11it/s, loss=0.00626, val_loss=0.00614,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00626, val_loss=0.00614,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 24.31it/s, loss=0.00626, val_loss=0.00614,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 36.45it/s, loss=0.00626, val_loss=0.00613,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00626, val_loss=0.00613,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00626, val_loss=0.00613,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.03it/s, loss=0.00626, val_loss=0.00611,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00626, val_loss=0.00611,\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00626, val_loss=0.00611,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00626, val_loss=0.00611,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00626, val_loss=0.00611,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 24.68it/s, loss=0.00626, val_loss=0.00611,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00626, val_loss=0.00606,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00626, val_loss=0.00606,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.00626, val_loss=0.00606,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 36.71it/s, loss=0.00626, val_loss=0.00608,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00626, val_loss=0.00608,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 24.68it/s, loss=0.00626, val_loss=0.00608,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00626, val_loss=0.00605,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 20.79it/s, loss=0.00626, val_loss=0.00605,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.39it/s, loss=0.00626, val_loss=0.00605,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 36.66it/s, loss=0.00626, val_loss=0.00603,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.00626, val_loss=0.00603,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 25.13it/s, loss=0.00626, val_loss=0.00603,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.66it/s, loss=0.00626, val_loss=0.00606,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00626, val_loss=0.00606,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 25.27it/s, loss=0.00626, val_loss=0.00606,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.00626, val_loss=0.00602,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00626, val_loss=0.00602,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.62it/s, loss=0.00626, val_loss=0.00602,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00626, val_loss=0.00601,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 20.79it/s, loss=0.00626, val_loss=0.00601,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00626, val_loss=0.00601,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 36.65it/s, loss=0.00626, val_loss=0.00599,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00626, val_loss=0.00599,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 24.81it/s, loss=0.00626, val_loss=0.00599,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.00626, val_loss=0.00598,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.00626, val_loss=0.00598,\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00626, val_loss=0.00598,\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00626, val_loss=0.00601,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.00627, val_loss=0.00601,\u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 25.29it/s, loss=0.00627, val_loss=0.00601,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00627, val_loss=0.00598,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 20.68it/s, loss=0.00627, val_loss=0.00598,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.08it/s, loss=0.00627, val_loss=0.00598,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 36.27it/s, loss=0.00627, val_loss=0.00597,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00627, val_loss=0.00597,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.00627, val_loss=0.00597,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00627, val_loss=0.00591,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00627, val_loss=0.00591,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00627, val_loss=0.00591,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 36.95it/s, loss=0.00627, val_loss=0.00592,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00627, val_loss=0.00592,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00627, val_loss=0.00592,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.16it/s, loss=0.00627, val_loss=0.00596,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00628, val_loss=0.00596,\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 24.81it/s, loss=0.00628, val_loss=0.00596,\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 37.45it/s, loss=0.00628, val_loss=0.00594,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00628, val_loss=0.00594,\u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 24.87it/s, loss=0.00628, val_loss=0.00594,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00628, val_loss=0.00594,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00628, val_loss=0.00594,\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 25.46it/s, loss=0.00628, val_loss=0.00594,\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00628, val_loss=0.00595,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00629, val_loss=0.00595,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 25.10it/s, loss=0.00629, val_loss=0.00595,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 37.57it/s, loss=0.00629, val_loss=0.00595,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00629, val_loss=0.00595,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00629, val_loss=0.00595,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.00629, val_loss=0.00594,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00629, val_loss=0.00594,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 25.40it/s, loss=0.00629, val_loss=0.00594,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.00629, val_loss=0.00596,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 20.85it/s, loss=0.00629, val_loss=0.00596,\u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.00629, val_loss=0.00596,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 36.74it/s, loss=0.00629, val_loss=0.00593,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.0063, val_loss=0.00593, \u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 25.13it/s, loss=0.0063, val_loss=0.00593, \n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.0063, val_loss=0.00592, \u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.0063, val_loss=0.00592, \u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 24.94it/s, loss=0.0063, val_loss=0.00592, \n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 37.41it/s, loss=0.0063, val_loss=0.00596, \u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.0063, val_loss=0.00596, \u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 25.00it/s, loss=0.0063, val_loss=0.00596, \n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.0063, val_loss=0.00599, \u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00631, val_loss=0.00599,\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00631, val_loss=0.00599,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00631, val_loss=0.00596,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 20.74it/s, loss=0.00631, val_loss=0.00596,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.00631, val_loss=0.00596,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 36.55it/s, loss=0.00631, val_loss=0.00595,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00631, val_loss=0.00595,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 24.81it/s, loss=0.00631, val_loss=0.00595,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00631, val_loss=0.00597,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00632, val_loss=0.00597,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 24.88it/s, loss=0.00632, val_loss=0.00597,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 37.47it/s, loss=0.00632, val_loss=0.00597,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.105, val_loss=0.00597, a\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.105, val_loss=0.00597, a\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.105, val_loss=0.0555, av\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.0114, val_loss=0.0555, a\u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 24.40it/s, loss=0.0114, val_loss=0.0555, a\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 36.72it/s, loss=0.0114, val_loss=0.00869, \u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00646, val_loss=0.00869,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 25.18it/s, loss=0.00646, val_loss=0.00869,\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.79it/s, loss=0.00646, val_loss=0.0057, \u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00628, val_loss=0.0057, \u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.62it/s, loss=0.00628, val_loss=0.0057, \n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 37.02it/s, loss=0.00628, val_loss=0.00573,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00629, val_loss=0.00573,\u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.00629, val_loss=0.00573,\n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00629, val_loss=0.00576,\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00631, val_loss=0.00576,\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00631, val_loss=0.00576,\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00631, val_loss=0.00593,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0791, val_loss=0.00593, \u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 25.07it/s, loss=0.0791, val_loss=0.00593, \n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.0791, val_loss=0.0196, a\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00886, val_loss=0.0196, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00886, val_loss=0.0196, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00886, val_loss=0.00606,\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00639, val_loss=0.00606,\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.98it/s, loss=0.00639, val_loss=0.00606,\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 37.59it/s, loss=0.00639, val_loss=0.00583,\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.0063, val_loss=0.00583, \u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 24.88it/s, loss=0.0063, val_loss=0.00583, \n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 37.40it/s, loss=0.0063, val_loss=0.00581, \u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.0063, val_loss=0.00581, \u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.76it/s, loss=0.0063, val_loss=0.00581, \n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 37.28it/s, loss=0.0063, val_loss=0.00582, \u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.0063, val_loss=0.00582, \u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.0063, val_loss=0.00582, \n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.0063, val_loss=0.00585, \u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.0278, val_loss=0.00585, \u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.0278, val_loss=0.00585, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.0278, val_loss=0.218, av\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.0202, val_loss=0.218, av\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.0202, val_loss=0.218, av\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 36.96it/s, loss=0.0202, val_loss=0.00974, \u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.0068, val_loss=0.00974, \u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 25.17it/s, loss=0.0068, val_loss=0.00974, \n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.0068, val_loss=0.00593, \u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00632, val_loss=0.00593,\u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.90it/s, loss=0.00632, val_loss=0.00593,\n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00632, val_loss=0.00582,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.0981, val_loss=0.00582, \u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 25.37it/s, loss=0.0981, val_loss=0.00582, \n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.0981, val_loss=0.169, av\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.0203, val_loss=0.169, av\u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.0203, val_loss=0.169, av\n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.0203, val_loss=0.00798, \u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.00665, val_loss=0.00798,\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.00665, val_loss=0.00798,\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.80it/s, loss=0.00665, val_loss=0.00547,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00628, val_loss=0.00547,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00628, val_loss=0.00547,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.00628, val_loss=0.00546,\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00627, val_loss=0.00546,\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.00627, val_loss=0.00546,\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.00627, val_loss=0.00549,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00627, val_loss=0.00549,\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.00627, val_loss=0.00549,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 37.53it/s, loss=0.00627, val_loss=0.00551,\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00627, val_loss=0.00551,\u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00627, val_loss=0.00551,\n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00627, val_loss=0.00554,\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00628, val_loss=0.00554,\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.95it/s, loss=0.00628, val_loss=0.00554,\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00628, val_loss=0.00553,\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.0572, val_loss=0.00553, \u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 24.87it/s, loss=0.0572, val_loss=0.00553, \n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.28it/s, loss=0.0572, val_loss=0.621, av\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.0572, val_loss=0.621, av\u001b[A\n",
      "Sizes of clusters: 311, 558, 247, 484\n",
      "\n",
      "preds: [1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1\n",
      " 3 1 1 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 0\n",
      " 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1\n",
      " 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 3 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 3 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0\n",
      " 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 3 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 3 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 3 3 1 1 0 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0\n",
      " 1 3 0 0 0 0 1 1 0 0 0 0 0 1 3 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 3 1 0 0 1 1 0 1 1 0 1 1 0 3 3 3 2 2 3 3\n",
      " 2 3 3 3 3 2 3 3 2 3 0 3 2 0 0 0 3 3 2 3 3 3 3 2 0 2 3 3 3 2 3 3 2 3 3 3 3\n",
      " 2 3 3 2 2 3 3 2 3 3 3 2 3 3 0 3 3 3 2 3 2 2 3 3 3 3 2 0 0 3 3 0 3 3 2 2 2\n",
      " 3 2 3 3 3 3 2 0 3 3 2 3 2 3 0 3 3 3 3 2 2 3 3 2 3 0 2 2 3 3 0 3 2 3 2 3 0\n",
      " 0 3 0 2 2 3 3 2 3 3 3 3 3 3 2 3 3 3 0 0 3 3 2 3 3 3 2 3 3 3 0 2 2 3 2 3 3\n",
      " 3 2 2 2 3 3 2 3 2 3 3 3 3 0 3 3 0 3 0 2 3 3 2 3 3 2 3 3 3 2 3 3 3 3 2 3 3\n",
      " 3 3 3 0 3 0 0 3 2 3 3 3 2 3 3 3 3 3 3 0 3 3 3 3 2 2 3 3 2 3 3 3 3 3 2 2 3\n",
      " 0 2 3 0 2 3 0 2 0 3 2 3 3 3 0 2 3 3 3 3 3 2 3 3 2 2 3 3 3 2 3 2 3 3 2 3 3\n",
      " 3 2 3 3 3 0 3 3 3 3 3 2 3 3 0 2 0 3 2 0 3 2 3 0 2 3 2 3 3 3 3 3 2 2 2 0 2\n",
      " 3 3 3 3 3 3 2 3 3 2 3 3 2 2 3 2 3 3 3 3 2 3 2 3 3 2 2 3 2 2 3 3 2 2 3 0 2\n",
      " 3 3 3 3 0 2 3 0 3 3 3 2 3 2 3 3 3 2 0 3 2 3 3 3 2 2 3 3 0 2 3 3 3 2 3 2 3\n",
      " 0 3 3 3 0 3 3 3 3 2 3 3 3 3 3 2 3 3 3 0 3 2 0 2 2 3 2 3 0 3 3 3 3 3 3 0 2\n",
      " 3 3 0 3 2 2 3 2 2 3 3 3 2 2 2 3 3 2 2 3 3 3 2 3 3 3 3 3 3 3 2 3 3 3 3 3 2\n",
      " 2 0 3 3 3 3 0 3 3 3 2 3 3 2 0 3 3 0 2 2 3 3 3 3 3 3 0 3 2 3 2 3 3 0 3 3 2\n",
      " 3 2 3 3 0 3 3 3 3 2 3 2 3 3 3 3 3 3 0 2 2 3 3 3 2 3 0 3 0 3 3 2 2 3 3 3 3\n",
      " 0 3 3 3 2 0 3 2 3 0 3 2 2 0 2 3 3 3 2 3 2 2 2 3 2 2 3 2 3 2 2 2 2 2 3 3 3\n",
      " 3 2 3 3 2 2 2 3 2 3 3 3 3 2 2 3 3 2 3 2 2 3 2 3 3 3 3 0 3 0 2 2 3 3 2 2 0\n",
      " 3 3 3 2 3 3 3 3 3 3 2 2 3 3 2 3 2 3 2 2 0 3 0 2 3 2 0 0 3 3 3 3 3 2 2 2 3\n",
      " 2 0 2 3 2 2 3 3 2 2 3 3 3 0 3 3 2 2 2 3 3 3 2 2 0 3 3 2 3 3 3 2 3 2 0 3 3\n",
      " 3 3 2 3 3 2 2 0 0 2 3 2 2 3 2 3 2 0 2 2 3 3 3 2 3 2 3 2 3 2 2 3 3 0 3 2 3\n",
      " 3 3 0 3 2 2 2 2 0 2 2 0 3 3 2 2 3 3 3 3 2 3 3 0 3 3 3 2 3 2 3 2 3 2 2 3 3\n",
      " 2 0 2 3 3 3 0 3 3 3 3 2 2 3 2 2 3 3 2 3 3 3 3 3 3 2 2 3 2 3 2 3 3 2 3 3 3\n",
      " 3 3 3 2 3 3 3 2 2 3 3 2 3 2 3 2 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 3 1 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0\n",
      " 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0\n",
      " 1 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 3 0 1 0 1 0\n",
      " 1 0 1 1 1 3 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 1 3 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 3 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4956\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  52%|▌| 33/64 [00:01<00:01, 21.49it/s, loss=3.57, val_loss=0.0481, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=3.57, val_loss=2.39, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.147, val_loss=2.39, avg_v\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 25.32it/s, loss=0.147, val_loss=2.39, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.147, val_loss=0.109, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 20.99it/s, loss=0.0278, val_loss=0.109, avg\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.0278, val_loss=0.109, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.0278, val_loss=0.0431, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.0177, val_loss=0.0431, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.26it/s, loss=0.0177, val_loss=0.0431, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.0177, val_loss=0.0304, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.0141, val_loss=0.0304, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.0141, val_loss=0.0304, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 36.99it/s, loss=0.0141, val_loss=0.0234, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.012, val_loss=0.0234, avg\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 25.11it/s, loss=0.012, val_loss=0.0234, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.012, val_loss=0.0184, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.0106, val_loss=0.0184, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.0106, val_loss=0.0184, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.0106, val_loss=0.0149, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00967, val_loss=0.0149, a\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00967, val_loss=0.0149, a\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.00967, val_loss=0.0127, a\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00901, val_loss=0.0127, a\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00901, val_loss=0.0127, a\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00901, val_loss=0.0112, a\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00852, val_loss=0.0112, a\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00852, val_loss=0.0112, a\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.29it/s, loss=0.00852, val_loss=0.0102, a\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00816, val_loss=0.0102, \u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 24.29it/s, loss=0.00816, val_loss=0.0102, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.00816, val_loss=0.00948,\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00788, val_loss=0.00948,\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 24.83it/s, loss=0.00788, val_loss=0.00948,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.49it/s, loss=0.00788, val_loss=0.00893,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.00765, val_loss=0.00893,\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.00765, val_loss=0.00893,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.05it/s, loss=0.00765, val_loss=0.00849,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00745, val_loss=0.00849,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 24.78it/s, loss=0.00745, val_loss=0.00849,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.00745, val_loss=0.00813,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00729, val_loss=0.00813,\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 24.51it/s, loss=0.00729, val_loss=0.00813,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.00729, val_loss=0.00783,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 20.47it/s, loss=0.00716, val_loss=0.00783,\u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 24.02it/s, loss=0.00716, val_loss=0.00783,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 35.95it/s, loss=0.00716, val_loss=0.00758,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00704, val_loss=0.00758,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 24.81it/s, loss=0.00704, val_loss=0.00758,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.00704, val_loss=0.00737,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00694, val_loss=0.00737,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.00694, val_loss=0.00737,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.00694, val_loss=0.00719,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.00684, val_loss=0.00719,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.00684, val_loss=0.00719,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.00684, val_loss=0.00705,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.71it/s, loss=0.00676, val_loss=0.00705,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 23.96it/s, loss=0.00676, val_loss=0.00705,\n",
      "Epoch 19:  89%|▉| 57/64 [00:01<00:00, 33.43it/s, loss=0.00676, val_loss=0.00705,\u001b[A\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.24it/s, loss=0.00676, val_loss=0.00691,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00669, val_loss=0.00691,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00669, val_loss=0.00691,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 36.78it/s, loss=0.00669, val_loss=0.0068, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00663, val_loss=0.0068, \u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00663, val_loss=0.0068, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.00663, val_loss=0.0067, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00657, val_loss=0.0067, \u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 24.47it/s, loss=0.00657, val_loss=0.0067, \n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00657, val_loss=0.00661,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.00652, val_loss=0.00661,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00652, val_loss=0.00661,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 36.95it/s, loss=0.00652, val_loss=0.00652,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.00647, val_loss=0.00652,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 24.96it/s, loss=0.00647, val_loss=0.00652,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.40it/s, loss=0.00647, val_loss=0.00645,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00643, val_loss=0.00645,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 24.62it/s, loss=0.00643, val_loss=0.00645,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00643, val_loss=0.00638,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00639, val_loss=0.00638,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 24.67it/s, loss=0.00639, val_loss=0.00638,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.00639, val_loss=0.00632,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00636, val_loss=0.00632,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00636, val_loss=0.00632,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.00636, val_loss=0.00626,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00633, val_loss=0.00626,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.38it/s, loss=0.00633, val_loss=0.00626,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.84it/s, loss=0.00633, val_loss=0.00621,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.0063, val_loss=0.00621, \u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.33it/s, loss=0.0063, val_loss=0.00621, \n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.0063, val_loss=0.00617, \u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00627, val_loss=0.00617,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.51it/s, loss=0.00627, val_loss=0.00617,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00627, val_loss=0.00613,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.00625, val_loss=0.00613,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.31it/s, loss=0.00625, val_loss=0.00613,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.00625, val_loss=0.00609,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00623, val_loss=0.00609,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 24.46it/s, loss=0.00623, val_loss=0.00609,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.00623, val_loss=0.00606,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00621, val_loss=0.00606,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 24.72it/s, loss=0.00621, val_loss=0.00606,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.00621, val_loss=0.00603,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.0062, val_loss=0.00603, \u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 24.79it/s, loss=0.0062, val_loss=0.00603, \n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.38it/s, loss=0.0062, val_loss=0.00601, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.04it/s, loss=0.00618, val_loss=0.00601,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.00618, val_loss=0.00601,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 36.84it/s, loss=0.00618, val_loss=0.00598,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00617, val_loss=0.00598,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00617, val_loss=0.00598,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00617, val_loss=0.00596,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.27it/s, loss=0.00615, val_loss=0.00596,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 24.96it/s, loss=0.00615, val_loss=0.00596,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.41it/s, loss=0.00615, val_loss=0.00594,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00614, val_loss=0.00594,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 24.96it/s, loss=0.00614, val_loss=0.00594,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.55it/s, loss=0.00614, val_loss=0.00593,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00613, val_loss=0.00593,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00613, val_loss=0.00593,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.00613, val_loss=0.00592,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.00613, val_loss=0.00592,\u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.00613, val_loss=0.00592,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.00613, val_loss=0.00592,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.00612, val_loss=0.00592,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.82it/s, loss=0.00612, val_loss=0.00592,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00612, val_loss=0.00591,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00611, val_loss=0.00591,\u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00611, val_loss=0.00591,\n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.00611, val_loss=0.00591,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00611, val_loss=0.00591,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 25.10it/s, loss=0.00611, val_loss=0.00591,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.00611, val_loss=0.00591,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.0061, val_loss=0.00591, \u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 25.48it/s, loss=0.0061, val_loss=0.00591, \n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.0061, val_loss=0.0059, a\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.0061, val_loss=0.0059, a\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.0061, val_loss=0.0059, a\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.0061, val_loss=0.00589, \u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00609, val_loss=0.00589,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 24.69it/s, loss=0.00609, val_loss=0.00589,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 37.07it/s, loss=0.00609, val_loss=0.00588,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00609, val_loss=0.00588,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00609, val_loss=0.00588,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.00609, val_loss=0.00587,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.00608, val_loss=0.00587,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00608, val_loss=0.00587,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00608, val_loss=0.00586,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00608, val_loss=0.00586,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 36.52it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 20.36it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 23.84it/s, loss=0.00608, val_loss=0.00586,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 35.98it/s, loss=0.00608, val_loss=0.00586,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00607, val_loss=0.00586,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.00607, val_loss=0.00586,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.00607, val_loss=0.00587,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.02it/s, loss=0.00607, val_loss=0.00587,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 24.66it/s, loss=0.00607, val_loss=0.00587,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.01it/s, loss=0.00607, val_loss=0.00588,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.03it/s, loss=0.00607, val_loss=0.00588,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 24.54it/s, loss=0.00607, val_loss=0.00588,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 36.97it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.00607, val_loss=0.00589,\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 20.99it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 24.63it/s, loss=0.00607, val_loss=0.00589,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.94it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.00607, val_loss=0.00589,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00607, val_loss=0.00589,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.00607, val_loss=0.0059, \u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00607, val_loss=0.0059, \u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 25.19it/s, loss=0.00607, val_loss=0.0059, \n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00607, val_loss=0.0059, \u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00607, val_loss=0.0059, \u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00607, val_loss=0.0059, \n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 37.14it/s, loss=0.00607, val_loss=0.00591,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00607, val_loss=0.00591,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00607, val_loss=0.00591,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.14it/s, loss=0.00607, val_loss=0.00591,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00607, val_loss=0.00591,\u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 25.04it/s, loss=0.00607, val_loss=0.00591,\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00607, val_loss=0.00592,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00607, val_loss=0.00592,\u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00607, val_loss=0.00592,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.00607, val_loss=0.00592,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 20.91it/s, loss=0.00607, val_loss=0.00592,\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 24.51it/s, loss=0.00607, val_loss=0.00592,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00607, val_loss=0.00593,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.00607, val_loss=0.00593,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 23.97it/s, loss=0.00607, val_loss=0.00593,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 36.19it/s, loss=0.00607, val_loss=0.00593,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00607, val_loss=0.00593,\u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 23.99it/s, loss=0.00607, val_loss=0.00593,\n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 36.19it/s, loss=0.00607, val_loss=0.00594,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.00607, val_loss=0.00594,\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00607, val_loss=0.00594,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 36.61it/s, loss=0.00607, val_loss=0.00595,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 20.08it/s, loss=0.00607, val_loss=0.00595,\u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 23.57it/s, loss=0.00607, val_loss=0.00595,\n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 35.39it/s, loss=0.00607, val_loss=0.00596,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.00607, val_loss=0.00596,\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 24.27it/s, loss=0.00607, val_loss=0.00596,\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 36.60it/s, loss=0.00607, val_loss=0.00597,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00608, val_loss=0.00597,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 24.06it/s, loss=0.00608, val_loss=0.00597,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 36.35it/s, loss=0.00608, val_loss=0.00598,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00608, val_loss=0.00598,\u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 24.33it/s, loss=0.00608, val_loss=0.00598,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 36.58it/s, loss=0.00608, val_loss=0.006, a\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=0.00608, val_loss=0.006, a\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 24.60it/s, loss=0.00608, val_loss=0.006, a\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.93it/s, loss=0.00608, val_loss=0.00601,\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 21.14it/s, loss=0.00608, val_loss=0.00601,\u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 24.70it/s, loss=0.00608, val_loss=0.00601,\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 37.05it/s, loss=0.00608, val_loss=0.00602,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.00608, val_loss=0.00602,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 24.70it/s, loss=0.00608, val_loss=0.00602,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 37.06it/s, loss=0.00608, val_loss=0.00604,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 20.57it/s, loss=0.00609, val_loss=0.00604,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 23.99it/s, loss=0.00609, val_loss=0.00604,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 36.25it/s, loss=0.00609, val_loss=0.00605,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.28it/s, loss=0.00609, val_loss=0.00605,\u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 24.99it/s, loss=0.00609, val_loss=0.00605,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00609, val_loss=0.00606,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 20.75it/s, loss=0.00609, val_loss=0.00606,\u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00609, val_loss=0.00606,\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 36.59it/s, loss=0.00609, val_loss=0.00607,\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.00609, val_loss=0.00607,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.00609, val_loss=0.00607,\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.30it/s, loss=0.00609, val_loss=0.00609,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.00609, val_loss=0.00609,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00609, val_loss=0.00609,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 37.10it/s, loss=0.00609, val_loss=0.00609,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.0061, val_loss=0.00609, \u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.0061, val_loss=0.00609, \n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 20.81it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 24.28it/s, loss=0.0061, val_loss=0.0061, a\n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 20.96it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 24.33it/s, loss=0.0061, val_loss=0.0061, a\n",
      "Epoch 81:  89%|▉| 57/64 [00:01<00:00, 34.07it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 20.34it/s, loss=0.0061, val_loss=0.0061, a\u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 23.86it/s, loss=0.0061, val_loss=0.0061, a\n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 35.88it/s, loss=0.0061, val_loss=0.00609, \u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 21.12it/s, loss=0.0061, val_loss=0.00609, \u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.0061, val_loss=0.00609, \n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 37.16it/s, loss=0.0061, val_loss=0.00609, \u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00611, val_loss=0.00609,\u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 23.99it/s, loss=0.00611, val_loss=0.00609,\n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 36.33it/s, loss=0.00611, val_loss=0.0061, \u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00611, val_loss=0.0061, \u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.45it/s, loss=0.00611, val_loss=0.0061, \n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.78it/s, loss=0.00611, val_loss=0.00612,\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 20.72it/s, loss=0.00624, val_loss=0.00612,\u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 24.30it/s, loss=0.00624, val_loss=0.00612,\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 36.54it/s, loss=0.00624, val_loss=0.0067, \u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.0213, val_loss=0.0067, a\u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.20it/s, loss=0.0213, val_loss=0.0067, a\n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.45it/s, loss=0.0213, val_loss=0.00645, \u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 20.80it/s, loss=0.00661, val_loss=0.00645,\u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 24.26it/s, loss=0.00661, val_loss=0.00645,\n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 36.57it/s, loss=0.00661, val_loss=0.00651,\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 20.84it/s, loss=0.00618, val_loss=0.00651,\u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.45it/s, loss=0.00618, val_loss=0.00651,\n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 36.74it/s, loss=0.00618, val_loss=0.00615,\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.00675, val_loss=0.00615,\u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.49it/s, loss=0.00675, val_loss=0.00615,\n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.00675, val_loss=0.00985,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.0209, val_loss=0.00985, \u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.0209, val_loss=0.00985, \n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.0209, val_loss=0.0131, a\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.81it/s, loss=0.00649, val_loss=0.0131, \u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.38it/s, loss=0.00649, val_loss=0.0131, \n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.68it/s, loss=0.00649, val_loss=0.00643,\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.00621, val_loss=0.00643,\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.00621, val_loss=0.00643,\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 36.31it/s, loss=0.00621, val_loss=0.00628,\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.00688, val_loss=0.00628,\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 25.30it/s, loss=0.00688, val_loss=0.00628,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 37.85it/s, loss=0.00688, val_loss=0.0125, \u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.0379, val_loss=0.0125, a\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.63it/s, loss=0.0379, val_loss=0.0125, a\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.0379, val_loss=0.00941, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.00684, val_loss=0.00941,\u001b[A\n",
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.00684, val_loss=0.00941,\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 36.92it/s, loss=0.00684, val_loss=0.00619,\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.00it/s, loss=0.00648, val_loss=0.00619,\u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 24.42it/s, loss=0.00648, val_loss=0.00619,\n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 36.73it/s, loss=0.00648, val_loss=0.00809,\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.0284, val_loss=0.00809, \u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.0284, val_loss=0.00809, \n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 37.56it/s, loss=0.0284, val_loss=0.00798, \u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00677, val_loss=0.00798,\u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 25.08it/s, loss=0.00677, val_loss=0.00798,\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.56it/s, loss=0.00677, val_loss=0.00633,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00677, val_loss=0.00633,\u001b[A\n",
      "Sizes of clusters: 297, 368, 453, 482\n",
      "\n",
      "preds: [2 1 2 1 1 1 2 2 2 1 1 1 2 2 2 1 1 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1\n",
      " 2 2 2 1 1 1 2 1 2 1 1 2 2 1 2 1 1 1 2 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 2 1 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 2 3 2 1 2 1 2 2 1 2 1 2 2 2 2\n",
      " 2 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 1 1 2\n",
      " 1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2\n",
      " 1 2 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 2 1 2 2 2 2 2 1 1 1 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 1 2 2\n",
      " 1 2 1 1 1 2 2 2 2 1 2 2 1 2 1 2 2 2 1 2 2 1 2 1 1 2 2 2 2 2 2 1 1 2 2 2 1\n",
      " 2 1 1 1 2 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 2 2 1 2 1 2 2 1 2 1 2 1 2 2 2 2\n",
      " 2 1 1 1 2 2 1 1 2 1 2 1 2 2 2 1 2 1 1 2 2 2 3 2 1 2 2 1 2 2 1 2 2 2 2 2 1\n",
      " 1 2 2 1 2 1 2 1 1 2 2 2 1 2 2 1 2 2 2 1 2 1 2 1 2 2 2 2 2 2 3 3 3 0 0 0 3\n",
      " 0 0 3 0 3 3 3 3 3 3 3 3 0 3 3 3 3 3 0 2 3 3 0 0 3 0 3 3 0 0 3 0 0 0 0 3 3\n",
      " 3 3 0 3 0 2 3 0 3 3 3 0 3 3 3 3 3 0 0 3 0 0 2 3 0 3 0 3 3 3 0 3 3 3 0 0 0\n",
      " 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 0 3 3\n",
      " 3 2 2 0 0 3 3 0 3 3 3 3 0 3 0 3 0 3 3 3 3 0 0 3 0 0 0 3 3 3 2 0 0 3 0 3 0\n",
      " 3 0 0 0 3 3 0 3 3 3 0 0 0 2 3 0 2 3 3 0 3 3 3 3 3 3 3 3 3 0 3 3 3 2 3 3 3\n",
      " 0 3 3 3 3 3 2 3 0 3 3 3 3 0 3 0 3 0 3 3 3 3 3 0 3 3 2 3 0 0 3 3 3 0 0 0 0\n",
      " 3 0 3 3 0 3 3 0 3 2 3 3 3 0 2 0 3 3 0 3 3 0 3 0 3 0 0 3 3 3 3 0 3 3 3 3 3\n",
      " 3 0 3 3 3 3 3 3 3 3 3 0 0 0 3 0 2 3 0 3 0 0 3 3 0 3 0 2 3 0 3 3 0 3 3 3 0\n",
      " 3 2 3 3 0 3 3 3 3 3 0 3 0 0 3 3 3 3 3 3 0 0 3 3 3 0 3 3 0 1 0 3 0 0 3 3 3\n",
      " 3 0 0 3 3 3 3 3 3 3 3 0 3 0 3 0 2 1 3 3 0 3 0 1 0 3 3 3 2 3 3 3 3 0 0 0 3\n",
      " 3 3 0 2 2 3 3 3 0 3 0 0 3 3 3 0 0 3 3 3 3 3 3 0 0 3 0 3 3 3 3 3 3 3 0 3 0\n",
      " 3 3 3 0 0 0 3 0 0 3 3 3 0 3 0 3 3 0 0 3 3 3 0 0 3 3 3 3 3 0 0 3 3 0 3 3 0\n",
      " 0 3 3 3 3 3 3 3 3 3 0 3 3 0 3 3 3 3 0 0 3 0 3 3 3 3 3 3 0 0 0 3 3 3 3 0 0\n",
      " 3 0 3 3 3 3 3 3 3 0 3 0 0 3 3 3 0 3 3 0 3 3 3 0 0 3 3 3 3 3 0 0 0 3 3 3 3\n",
      " 3 3 3 3 0 3 0 0 0 3 3 0 0 3 0 3 0 0 0 3 0 0 0 3 0 0 3 0 3 0 3 0 0 0 3 3 3\n",
      " 3 0 3 3 0 0 0 3 0 0 3 3 3 0 0 3 3 3 3 0 0 3 0 3 3 3 3 3 3 3 0 0 3 3 0 0 3\n",
      " 3 3 3 0 0 3 3 0 3 0 0 0 3 0 0 3 0 3 3 0 3 3 3 0 3 0 3 0 3 3 3 3 3 0 0 0 0\n",
      " 0 3 0 3 0 0 3 3 0 0 3 3 3 3 3 3 0 0 0 0 0 3 0 0 0 3 0 0 3 3 0 0 3 0 3 3 0\n",
      " 0 3 0 3 0 0 0 2 3 0 3 0 0 3 0 3 0 3 0 0 3 3 0 0 3 0 3 0 3 0 3 0 3 3 3 0 0\n",
      " 3 0 3 0 0 0 0 0 3 0 0 3 3 3 0 0 3 3 3 3 0 3 0 3 3 0 0 3 3 0 3 0 3 0 0 3 3\n",
      " 0 3 0 3 3 3 0 3 0 3 3 0 0 3 0 0 3 3 0 3 3 3 3 3 3 0 0 3 0 3 0 3 3 0 3 3 3\n",
      " 0 3 0 3 3 3 3 0 0 3 0 0 3 0 0 3 1 1 1 2 2 1 1 2 2 1 2 2 2 2 1 1 1 2 1 2 1\n",
      " 2 1 2 2 1 2 2 1 2 1 2 1 1 2 2 1 2 1 1 1 2 2 1 2 1 1 2 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 1 1\n",
      " 1 1 1 1 2 1 2 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 1 1 2 2 1 1 2 2 1 1 2 2 1\n",
      " 1 1 1 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 3 2 2 2 1 1 1 1 1 2 2 2 1 1 1 2 2 1\n",
      " 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 2 2 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 1 1 1 1 2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 1 1 1 2 2 2 2 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 2 1 1 1 2 1 1 2 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 1 2 1\n",
      " 1 2 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 2 1 2 2 1 2 1 2 1 1 1 1 2\n",
      " 2 2 1 1 1 1 1 2 0 2 1 2 1 1 2 1 2 2 2 2 1 2 1 1 2 1 2 2 1 1 1 1 2 1 1 2 1\n",
      " 1 2 1 1 1 1 1 1 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.5931\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=2.17, val_loss=0.0581, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=2.17, val_loss=0.898, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.111, val_loss=0.898, avg_\u001b[A\n",
      "Epoch 1:  62%|▋| 40/64 [00:01<00:00, 25.98it/s, loss=0.111, val_loss=0.898, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 37.38it/s, loss=0.111, val_loss=0.0948, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.0328, val_loss=0.0948, av\u001b[A\n",
      "Epoch 2:  62%|▋| 40/64 [00:01<00:00, 26.52it/s, loss=0.0328, val_loss=0.0948, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.03it/s, loss=0.0328, val_loss=0.0468, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.0242, val_loss=0.0468, av\u001b[A\n",
      "Epoch 3:  62%|▋| 40/64 [00:01<00:00, 25.58it/s, loss=0.0242, val_loss=0.0468, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.0242, val_loss=0.0356, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.0205, val_loss=0.0356, av\u001b[A\n",
      "Epoch 4:  62%|▋| 40/64 [00:01<00:00, 26.12it/s, loss=0.0205, val_loss=0.0356, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 37.49it/s, loss=0.0205, val_loss=0.0293, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0181, val_loss=0.0293, av\u001b[A\n",
      "Epoch 5:  62%|▋| 40/64 [00:01<00:00, 26.14it/s, loss=0.0181, val_loss=0.0293, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.0181, val_loss=0.025, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.0165, val_loss=0.025, avg\u001b[A\n",
      "Epoch 6:  62%|▋| 40/64 [00:01<00:00, 25.90it/s, loss=0.0165, val_loss=0.025, avg\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.0165, val_loss=0.0218, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.0153, val_loss=0.0218, av\u001b[A\n",
      "Epoch 7:  62%|▋| 40/64 [00:01<00:00, 25.66it/s, loss=0.0153, val_loss=0.0218, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.0153, val_loss=0.0195, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.0144, val_loss=0.0195, av\u001b[A\n",
      "Epoch 8:  62%|▋| 40/64 [00:01<00:00, 25.87it/s, loss=0.0144, val_loss=0.0195, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.0144, val_loss=0.0178, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.0136, val_loss=0.0178, av\u001b[A\n",
      "Epoch 9:  62%|▋| 40/64 [00:01<00:00, 26.02it/s, loss=0.0136, val_loss=0.0178, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.0136, val_loss=0.0164, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.0129, val_loss=0.0164, a\u001b[A\n",
      "Epoch 10:  62%|▋| 40/64 [00:01<00:00, 25.99it/s, loss=0.0129, val_loss=0.0164, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 37.18it/s, loss=0.0129, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0123, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  62%|▋| 40/64 [00:01<00:00, 26.30it/s, loss=0.0123, val_loss=0.0152, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.0123, val_loss=0.0142, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.0118, val_loss=0.0142, a\u001b[A\n",
      "Epoch 12:  62%|▋| 40/64 [00:01<00:00, 26.00it/s, loss=0.0118, val_loss=0.0142, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.35it/s, loss=0.0118, val_loss=0.0134, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.15it/s, loss=0.0112, val_loss=0.0134, a\u001b[A\n",
      "Epoch 13:  62%|▋| 40/64 [00:01<00:00, 25.91it/s, loss=0.0112, val_loss=0.0134, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.0112, val_loss=0.0126, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.0107, val_loss=0.0126, a\u001b[A\n",
      "Epoch 14:  62%|▋| 40/64 [00:01<00:00, 26.08it/s, loss=0.0107, val_loss=0.0126, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.0107, val_loss=0.012, av\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.0103, val_loss=0.012, av\u001b[A\n",
      "Epoch 15:  62%|▋| 40/64 [00:01<00:00, 26.65it/s, loss=0.0103, val_loss=0.012, av\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.0103, val_loss=0.0114, a\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.00988, val_loss=0.0114, \u001b[A\n",
      "Epoch 16:  62%|▋| 40/64 [00:01<00:00, 26.45it/s, loss=0.00988, val_loss=0.0114, \n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00988, val_loss=0.0108, \u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00949, val_loss=0.0108, \u001b[A\n",
      "Epoch 17:  62%|▋| 40/64 [00:01<00:00, 26.09it/s, loss=0.00949, val_loss=0.0108, \n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00949, val_loss=0.0103, \u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.00913, val_loss=0.0103, \u001b[A\n",
      "Epoch 18:  62%|▋| 40/64 [00:01<00:00, 25.46it/s, loss=0.00913, val_loss=0.0103, \n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.63it/s, loss=0.00913, val_loss=0.00989,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.0088, val_loss=0.00989, \u001b[A\n",
      "Epoch 19:  62%|▋| 40/64 [00:01<00:00, 26.34it/s, loss=0.0088, val_loss=0.00989, \n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.75it/s, loss=0.0088, val_loss=0.00949, \u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.0085, val_loss=0.00949, \u001b[A\n",
      "Epoch 20:  62%|▋| 40/64 [00:01<00:00, 25.85it/s, loss=0.0085, val_loss=0.00949, \n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.0085, val_loss=0.00911, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.00823, val_loss=0.00911,\u001b[A\n",
      "Epoch 21:  62%|▋| 40/64 [00:01<00:00, 26.41it/s, loss=0.00823, val_loss=0.00911,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.00823, val_loss=0.00878,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00798, val_loss=0.00878,\u001b[A\n",
      "Epoch 22:  62%|▋| 40/64 [00:01<00:00, 25.96it/s, loss=0.00798, val_loss=0.00878,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.27it/s, loss=0.00798, val_loss=0.00848,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00776, val_loss=0.00848,\u001b[A\n",
      "Epoch 23:  62%|▋| 40/64 [00:01<00:00, 25.91it/s, loss=0.00776, val_loss=0.00848,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00776, val_loss=0.00821,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.00755, val_loss=0.00821,\u001b[A\n",
      "Epoch 24:  62%|▋| 40/64 [00:01<00:00, 25.53it/s, loss=0.00755, val_loss=0.00821,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00755, val_loss=0.00794,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00737, val_loss=0.00794,\u001b[A\n",
      "Epoch 25:  62%|▋| 40/64 [00:01<00:00, 25.94it/s, loss=0.00737, val_loss=0.00794,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.27it/s, loss=0.00737, val_loss=0.0077, \u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 20.71it/s, loss=0.00721, val_loss=0.0077, \u001b[A\n",
      "Epoch 26:  62%|▋| 40/64 [00:01<00:00, 25.38it/s, loss=0.00721, val_loss=0.0077, \n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 36.53it/s, loss=0.00721, val_loss=0.00748,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00707, val_loss=0.00748,\u001b[A\n",
      "Epoch 27:  62%|▋| 40/64 [00:01<00:00, 26.57it/s, loss=0.00707, val_loss=0.00748,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00707, val_loss=0.00729,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.00695, val_loss=0.00729,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  62%|▋| 40/64 [00:01<00:00, 25.29it/s, loss=0.00695, val_loss=0.00729,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.00695, val_loss=0.00711,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00684, val_loss=0.00711,\u001b[A\n",
      "Epoch 29:  62%|▋| 40/64 [00:01<00:00, 25.56it/s, loss=0.00684, val_loss=0.00711,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.00684, val_loss=0.00695,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.69it/s, loss=0.00674, val_loss=0.00695,\u001b[A\n",
      "Epoch 30:  62%|▋| 40/64 [00:01<00:00, 25.36it/s, loss=0.00674, val_loss=0.00695,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 36.49it/s, loss=0.00674, val_loss=0.00681,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00666, val_loss=0.00681,\u001b[A\n",
      "Epoch 31:  62%|▋| 40/64 [00:01<00:00, 25.56it/s, loss=0.00666, val_loss=0.00681,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.00666, val_loss=0.00668,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00659, val_loss=0.00668,\u001b[A\n",
      "Epoch 32:  62%|▋| 40/64 [00:01<00:00, 26.01it/s, loss=0.00659, val_loss=0.00668,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.49it/s, loss=0.00659, val_loss=0.00656,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00652, val_loss=0.00656,\u001b[A\n",
      "Epoch 33:  62%|▋| 40/64 [00:01<00:00, 26.48it/s, loss=0.00652, val_loss=0.00656,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.00652, val_loss=0.00646,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00647, val_loss=0.00646,\u001b[A\n",
      "Epoch 34:  62%|▋| 40/64 [00:01<00:00, 25.64it/s, loss=0.00647, val_loss=0.00646,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 36.83it/s, loss=0.00647, val_loss=0.00637,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00642, val_loss=0.00637,\u001b[A\n",
      "Epoch 35:  62%|▋| 40/64 [00:01<00:00, 25.67it/s, loss=0.00642, val_loss=0.00637,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.00642, val_loss=0.00629,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00637, val_loss=0.00629,\u001b[A\n",
      "Epoch 36:  62%|▋| 40/64 [00:01<00:00, 25.75it/s, loss=0.00637, val_loss=0.00629,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.00637, val_loss=0.00621,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 20.53it/s, loss=0.00633, val_loss=0.00621,\u001b[A\n",
      "Epoch 37:  62%|▋| 40/64 [00:01<00:00, 25.17it/s, loss=0.00633, val_loss=0.00621,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 36.23it/s, loss=0.00633, val_loss=0.00615,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.0063, val_loss=0.00615, \u001b[A\n",
      "Epoch 38:  62%|▋| 40/64 [00:01<00:00, 25.58it/s, loss=0.0063, val_loss=0.00615, \n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 36.79it/s, loss=0.0063, val_loss=0.00608, \u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00627, val_loss=0.00608,\u001b[A\n",
      "Epoch 39:  62%|▋| 40/64 [00:01<00:00, 26.05it/s, loss=0.00627, val_loss=0.00608,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.28it/s, loss=0.00627, val_loss=0.00602,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.00624, val_loss=0.00602,\u001b[A\n",
      "Epoch 40:  62%|▋| 40/64 [00:01<00:00, 26.27it/s, loss=0.00624, val_loss=0.00602,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=0.00624, val_loss=0.00597,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00622, val_loss=0.00597,\u001b[A\n",
      "Epoch 41:  62%|▋| 40/64 [00:01<00:00, 26.27it/s, loss=0.00622, val_loss=0.00597,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 37.67it/s, loss=0.00622, val_loss=0.00591,\u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.0062, val_loss=0.00591, \u001b[A\n",
      "Epoch 42:  62%|▋| 40/64 [00:01<00:00, 26.03it/s, loss=0.0062, val_loss=0.00591, \n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.0062, val_loss=0.00586, \u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.00618, val_loss=0.00586,\u001b[A\n",
      "Epoch 43:  62%|▋| 40/64 [00:01<00:00, 25.58it/s, loss=0.00618, val_loss=0.00586,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 36.79it/s, loss=0.00618, val_loss=0.00582,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00616, val_loss=0.00582,\u001b[A\n",
      "Epoch 44:  62%|▋| 40/64 [00:01<00:00, 26.07it/s, loss=0.00616, val_loss=0.00582,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.49it/s, loss=0.00616, val_loss=0.00577,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00615, val_loss=0.00577,\u001b[A\n",
      "Epoch 45:  62%|▋| 40/64 [00:01<00:00, 25.61it/s, loss=0.00615, val_loss=0.00577,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 36.68it/s, loss=0.00615, val_loss=0.00573,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.00614, val_loss=0.00573,\u001b[A\n",
      "Epoch 46:  62%|▋| 40/64 [00:01<00:00, 25.55it/s, loss=0.00614, val_loss=0.00573,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.00614, val_loss=0.00569,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 20.77it/s, loss=0.00613, val_loss=0.00569,\u001b[A\n",
      "Epoch 47:  62%|▋| 40/64 [00:01<00:00, 25.45it/s, loss=0.00613, val_loss=0.00569,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 36.62it/s, loss=0.00613, val_loss=0.00564,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.68it/s, loss=0.00612, val_loss=0.00564,\u001b[A\n",
      "Epoch 48:  62%|▋| 40/64 [00:01<00:00, 25.21it/s, loss=0.00612, val_loss=0.00564,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 36.31it/s, loss=0.00612, val_loss=0.00561,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 21.01it/s, loss=0.00611, val_loss=0.00561,\u001b[A\n",
      "Epoch 49:  62%|▋| 40/64 [00:01<00:00, 25.64it/s, loss=0.00611, val_loss=0.00561,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 36.91it/s, loss=0.00611, val_loss=0.00558,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.0061, val_loss=0.00558, \u001b[A\n",
      "Epoch 50:  62%|▋| 40/64 [00:01<00:00, 26.01it/s, loss=0.0061, val_loss=0.00558, \n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.29it/s, loss=0.0061, val_loss=0.00555, \u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.0061, val_loss=0.00555, \u001b[A\n",
      "Epoch 51:  62%|▋| 40/64 [00:01<00:00, 25.39it/s, loss=0.0061, val_loss=0.00555, \n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.0061, val_loss=0.00552, \u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.00609, val_loss=0.00552,\u001b[A\n",
      "Epoch 52:  62%|▋| 40/64 [00:01<00:00, 26.21it/s, loss=0.00609, val_loss=0.00552,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.00609, val_loss=0.00549,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00609, val_loss=0.00549,\u001b[A\n",
      "Epoch 53:  62%|▋| 40/64 [00:01<00:00, 26.02it/s, loss=0.00609, val_loss=0.00549,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00609, val_loss=0.00546,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.07it/s, loss=0.00608, val_loss=0.00546,\u001b[A\n",
      "Epoch 54:  62%|▋| 40/64 [00:01<00:00, 25.82it/s, loss=0.00608, val_loss=0.00546,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.00608, val_loss=0.00544,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 20.87it/s, loss=0.00608, val_loss=0.00544,\u001b[A\n",
      "Epoch 55:  62%|▋| 40/64 [00:01<00:00, 25.53it/s, loss=0.00608, val_loss=0.00544,\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 36.66it/s, loss=0.00608, val_loss=0.00542,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 20.59it/s, loss=0.00608, val_loss=0.00542,\u001b[A\n",
      "Epoch 56:  62%|▋| 40/64 [00:01<00:00, 25.06it/s, loss=0.00608, val_loss=0.00542,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.35it/s, loss=0.00608, val_loss=0.0054, \u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00608, val_loss=0.0054, \u001b[A\n",
      "Epoch 57:  62%|▋| 40/64 [00:01<00:00, 25.80it/s, loss=0.00608, val_loss=0.0054, \n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.00608, val_loss=0.00538,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00607, val_loss=0.00538,\u001b[A\n",
      "Epoch 58:  62%|▋| 40/64 [00:01<00:00, 25.79it/s, loss=0.00607, val_loss=0.00538,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00607, val_loss=0.00537,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.00607, val_loss=0.00537,\u001b[A\n",
      "Epoch 59:  62%|▋| 40/64 [00:01<00:00, 25.69it/s, loss=0.00607, val_loss=0.00537,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 36.67it/s, loss=0.00607, val_loss=0.00535,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00607, val_loss=0.00535,\u001b[A\n",
      "Epoch 60:  62%|▋| 40/64 [00:01<00:00, 26.41it/s, loss=0.00607, val_loss=0.00535,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.00607, val_loss=0.00534,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00607, val_loss=0.00534,\u001b[A\n",
      "Epoch 61:  62%|▋| 40/64 [00:01<00:00, 26.28it/s, loss=0.00607, val_loss=0.00534,\n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.00607, val_loss=0.00533,\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 20.88it/s, loss=0.00607, val_loss=0.00533,\u001b[A\n",
      "Epoch 62:  62%|▋| 40/64 [00:01<00:00, 25.46it/s, loss=0.00607, val_loss=0.00533,\n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 36.63it/s, loss=0.00607, val_loss=0.00533,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00609, val_loss=0.00533,\u001b[A\n",
      "Epoch 63:  62%|▋| 40/64 [00:01<00:00, 25.85it/s, loss=0.00609, val_loss=0.00533,\n",
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00609, val_loss=0.00543,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 19.95it/s, loss=0.0143, val_loss=0.00543, \u001b[A\n",
      "Epoch 64:  62%|▋| 40/64 [00:01<00:00, 24.47it/s, loss=0.0143, val_loss=0.00543, \n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 35.34it/s, loss=0.0143, val_loss=0.0393, a\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.00741, val_loss=0.0393, \u001b[A\n",
      "Epoch 65:  62%|▋| 40/64 [00:01<00:00, 26.05it/s, loss=0.00741, val_loss=0.0393, \n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 37.39it/s, loss=0.00741, val_loss=0.00535,\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.00615, val_loss=0.00535,\u001b[A\n",
      "Epoch 66:  62%|▋| 40/64 [00:01<00:00, 25.66it/s, loss=0.00615, val_loss=0.00535,\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 36.89it/s, loss=0.00615, val_loss=0.00529,\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.0061, val_loss=0.00529, \u001b[A\n",
      "Epoch 67:  62%|▋| 40/64 [00:01<00:00, 25.74it/s, loss=0.0061, val_loss=0.00529, \n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.0061, val_loss=0.00556, \u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.0247, val_loss=0.00556, \u001b[A\n",
      "Epoch 68:  62%|▋| 40/64 [00:01<00:00, 26.43it/s, loss=0.0247, val_loss=0.00556, \n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.0247, val_loss=0.00922, \u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.00715, val_loss=0.00922,\u001b[A\n",
      "Epoch 69:  62%|▋| 40/64 [00:01<00:00, 25.82it/s, loss=0.00715, val_loss=0.00922,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 37.11it/s, loss=0.00715, val_loss=0.00554,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00612, val_loss=0.00554,\u001b[A\n",
      "Epoch 70:  62%|▋| 40/64 [00:01<00:00, 25.60it/s, loss=0.00612, val_loss=0.00554,\n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00612, val_loss=0.00527,\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00608, val_loss=0.00527,\u001b[A\n",
      "Epoch 71:  62%|▋| 40/64 [00:01<00:00, 25.46it/s, loss=0.00608, val_loss=0.00527,\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.64it/s, loss=0.00608, val_loss=0.0054, \u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.0437, val_loss=0.0054, a\u001b[A\n",
      "Epoch 72:  62%|▋| 40/64 [00:01<00:00, 26.34it/s, loss=0.0437, val_loss=0.0054, a\n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 37.76it/s, loss=0.0437, val_loss=0.0199, a\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.00864, val_loss=0.0199, \u001b[A\n",
      "Epoch 73:  62%|▋| 40/64 [00:01<00:00, 25.70it/s, loss=0.00864, val_loss=0.0199, \n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 37.07it/s, loss=0.00864, val_loss=0.00558,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.00616, val_loss=0.00558,\u001b[A\n",
      "Epoch 74:  62%|▋| 40/64 [00:01<00:00, 26.09it/s, loss=0.00616, val_loss=0.00558,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 37.45it/s, loss=0.00616, val_loss=0.00533,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00608, val_loss=0.00533,\u001b[A\n",
      "Epoch 75:  62%|▋| 40/64 [00:01<00:00, 26.31it/s, loss=0.00608, val_loss=0.00533,\n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 37.75it/s, loss=0.00608, val_loss=0.00545,\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 21.06it/s, loss=0.0591, val_loss=0.00545, \u001b[A\n",
      "Epoch 76:  62%|▋| 40/64 [00:01<00:00, 25.79it/s, loss=0.0591, val_loss=0.00545, \n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 37.08it/s, loss=0.0591, val_loss=0.0254, a\u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.00771, val_loss=0.0254, \u001b[A\n",
      "Epoch 77:  62%|▋| 40/64 [00:01<00:00, 26.12it/s, loss=0.00771, val_loss=0.0254, \n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.44it/s, loss=0.00771, val_loss=0.00573,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00615, val_loss=0.00573,\u001b[A\n",
      "Epoch 78:  62%|▋| 40/64 [00:01<00:00, 25.95it/s, loss=0.00615, val_loss=0.00573,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00615, val_loss=0.00533,\u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.0355, val_loss=0.00533, \u001b[A\n",
      "Epoch 79:  62%|▋| 40/64 [00:01<00:00, 26.19it/s, loss=0.0355, val_loss=0.00533, \n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 37.47it/s, loss=0.0355, val_loss=0.0411, a\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 20.41it/s, loss=0.00796, val_loss=0.0411, \u001b[A\n",
      "Epoch 80:  62%|▋| 40/64 [00:01<00:00, 25.01it/s, loss=0.00796, val_loss=0.0411, \n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 36.05it/s, loss=0.00796, val_loss=0.00547,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.00627, val_loss=0.00547,\u001b[A\n",
      "Epoch 81:  62%|▋| 40/64 [00:01<00:00, 26.10it/s, loss=0.00627, val_loss=0.00547,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00627, val_loss=0.00569,\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.0288, val_loss=0.00569, \u001b[A\n",
      "Epoch 82:  62%|▋| 40/64 [00:01<00:00, 25.39it/s, loss=0.0288, val_loss=0.00569, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 36.54it/s, loss=0.0288, val_loss=0.0349, a\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.00816, val_loss=0.0349, \u001b[A\n",
      "Epoch 83:  62%|▋| 40/64 [00:01<00:00, 25.35it/s, loss=0.00816, val_loss=0.0349, \n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 36.43it/s, loss=0.00816, val_loss=0.0057, \u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00614, val_loss=0.0057, \u001b[A\n",
      "Epoch 84:  62%|▋| 40/64 [00:01<00:00, 26.05it/s, loss=0.00614, val_loss=0.0057, \n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00614, val_loss=0.00532,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.95it/s, loss=0.0153, val_loss=0.00532, \u001b[A\n",
      "Epoch 85:  62%|▋| 40/64 [00:01<00:00, 25.67it/s, loss=0.0153, val_loss=0.00532, \n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.0153, val_loss=0.102, av\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.0205, val_loss=0.102, av\u001b[A\n",
      "Epoch 86:  62%|▋| 40/64 [00:01<00:00, 26.01it/s, loss=0.0205, val_loss=0.102, av\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 37.32it/s, loss=0.0205, val_loss=0.0109, a\u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00675, val_loss=0.0109, \u001b[A\n",
      "Epoch 87:  62%|▋| 40/64 [00:01<00:00, 26.15it/s, loss=0.00675, val_loss=0.0109, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.00675, val_loss=0.00626,\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.0241, val_loss=0.00626, \u001b[A\n",
      "Epoch 88:  62%|▋| 40/64 [00:01<00:00, 26.09it/s, loss=0.0241, val_loss=0.00626, \n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.0241, val_loss=0.0216, a\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.008, val_loss=0.0216, av\u001b[A\n",
      "Epoch 89:  62%|▋| 40/64 [00:01<00:00, 26.55it/s, loss=0.008, val_loss=0.0216, av\n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.008, val_loss=0.00703, a\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.0185, val_loss=0.00703, \u001b[A\n",
      "Epoch 90:  62%|▋| 40/64 [00:01<00:00, 26.32it/s, loss=0.0185, val_loss=0.00703, \n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.0185, val_loss=0.0627, a\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.0103, val_loss=0.0627, a\u001b[A\n",
      "Epoch 91:  62%|▋| 40/64 [00:01<00:00, 26.10it/s, loss=0.0103, val_loss=0.0627, a\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.0103, val_loss=0.00725, \u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.69it/s, loss=0.0437, val_loss=0.00725, \u001b[A\n",
      "Epoch 92:  62%|▋| 40/64 [00:01<00:00, 25.37it/s, loss=0.0437, val_loss=0.00725, \n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.50it/s, loss=0.0437, val_loss=0.0849, a\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.011, val_loss=0.0849, av\u001b[A\n",
      "Epoch 93:  62%|▋| 40/64 [00:01<00:00, 26.03it/s, loss=0.011, val_loss=0.0849, av\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 37.44it/s, loss=0.011, val_loss=0.00717, a\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00627, val_loss=0.00717,\u001b[A\n",
      "Epoch 94:  62%|▋| 40/64 [00:01<00:00, 26.51it/s, loss=0.00627, val_loss=0.00717,\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00627, val_loss=0.0054, \u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.00611, val_loss=0.0054, \u001b[A\n",
      "Epoch 95:  62%|▋| 40/64 [00:01<00:00, 26.20it/s, loss=0.00611, val_loss=0.0054, \n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00611, val_loss=0.00546,\u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.0782, val_loss=0.00546, \u001b[A\n",
      "Epoch 96:  62%|▋| 40/64 [00:01<00:00, 25.36it/s, loss=0.0782, val_loss=0.00546, \n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 36.54it/s, loss=0.0782, val_loss=0.0207, a\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.00899, val_loss=0.0207, \u001b[A\n",
      "Epoch 97:  62%|▋| 40/64 [00:01<00:00, 26.11it/s, loss=0.00899, val_loss=0.0207, \n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 37.47it/s, loss=0.00899, val_loss=0.00539,\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00622, val_loss=0.00539,\u001b[A\n",
      "Epoch 98:  62%|▋| 40/64 [00:01<00:00, 26.18it/s, loss=0.00622, val_loss=0.00539,\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 37.56it/s, loss=0.00622, val_loss=0.00573,\u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.13it/s, loss=0.0711, val_loss=0.00573, \u001b[A\n",
      "Epoch 99:  62%|▋| 40/64 [00:01<00:00, 25.88it/s, loss=0.0711, val_loss=0.00573, \n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.16it/s, loss=0.0711, val_loss=0.0384, a\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 36.95it/s, loss=0.0711, val_loss=0.0384, a\u001b[A\n",
      "Sizes of clusters: 514, 395, 304, 387\n",
      "\n",
      "preds: [0 0 2 2 0 0 2 2 0 2 0 0 0 0 2 0 0 2 2 0 0 2 2 2 0 0 2 2 2 2 0 2 0 2 2 0 0\n",
      " 0 2 2 0 0 0 2 0 2 0 0 0 2 0 0 0 0 0 2 0 0 2 2 0 2 2 2 2 0 0 0 0 0 2 2 0 2\n",
      " 2 2 0 0 2 0 2 2 2 2 2 2 2 2 0 2 0 2 0 0 2 0 2 2 2 0 2 0 0 0 0 0 0 2 0 0 2\n",
      " 2 2 0 2 2 0 0 2 2 2 2 0 0 2 0 2 0 0 2 2 0 0 2 2 0 2 0 2 2 0 2 0 2 0 0 0 2\n",
      " 0 2 0 2 2 2 2 2 0 0 2 0 0 2 2 2 0 0 0 2 0 0 0 2 0 0 0 2 2 2 2 2 0 0 2 2 2\n",
      " 0 0 2 0 0 2 0 2 0 2 2 0 2 0 2 1 0 2 2 0 2 2 0 0 0 2 2 2 2 2 0 2 0 0 2 0 0\n",
      " 0 2 0 2 2 0 0 0 0 2 2 2 2 2 0 0 0 2 0 2 2 0 0 2 2 2 0 0 1 2 2 2 2 2 0 2 2\n",
      " 2 0 2 0 0 2 0 2 2 0 2 2 0 2 0 0 2 0 0 0 2 2 2 0 0 2 2 2 0 0 2 0 0 0 2 2 0\n",
      " 2 0 0 0 0 2 0 2 2 2 2 2 2 0 2 0 2 0 2 2 2 2 0 0 2 2 2 2 0 2 0 0 0 2 0 2 2\n",
      " 2 1 0 0 2 0 0 0 0 0 2 0 0 2 0 0 2 0 0 2 2 2 0 0 0 0 2 0 2 2 2 2 2 2 0 2 0\n",
      " 2 2 0 0 2 0 2 0 0 0 2 2 0 2 2 0 2 0 2 0 0 0 2 0 2 2 0 2 2 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 0 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 0 3 3 3 0 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 0 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 0 3 3 3 3 3 0 3 3 0 0 2 0 0 0 2 0 2 2 0 0 0 2 0 0 0 0 1 0 0\n",
      " 2 0 0 0 0 2 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 2 0 0 2 2 0\n",
      " 0 2 2 0 0 0 0 0 0 0 2 0 2 2 2 2 0 0 0 0 0 0 0 0 0 2 0 2 0 0 2 2 0 2 2 0 0\n",
      " 0 0 0 2 0 0 2 0 0 2 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 0 0\n",
      " 2 0 0 2 0 0 1 2 0 0 0 2 0 2 0 2 2 0 0 2 0 2 0 0 0 0 0 0 2 2 2 0 0 0 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 2 0 2 0 0 0 2\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 2 2 0 0 0 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 2 2 0 0 0 0 0 0 0 2 0 2 2 0 1 1 0 0 0 0\n",
      " 2 0 0 0 0 1 2 0 0 0 2 2 0 0 0 2 2 0 0 2 0 0 0 0 0 2 0 0 1 0 2 1 0 0 0 2 2\n",
      " 0 0 2 0 0 0 0 1 2 0 2 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 2\n",
      " 0 2 0 0 0 0 0 2 1 0 0 0 0 2 0 0 0 0 2 0 0 2 0 0 2 0 2 2 0 0 0 0 0 0 0 2 0\n",
      " 0 2 0 0 0 0 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.7900\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.912, val_loss=0.0686, avg\n",
      "Epoch 0:  80%|▊| 51/64 [00:01<00:00, 32.00it/s, loss=0.912, val_loss=0.0686, avg\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.912, val_loss=1.4, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 20.81it/s, loss=0.0652, val_loss=1.4, avg_v\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.0652, val_loss=1.4, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.0652, val_loss=0.0559, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.0257, val_loss=0.0559, av\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.12it/s, loss=0.0257, val_loss=0.0559, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.0257, val_loss=0.0278, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.0203, val_loss=0.0278, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 24.18it/s, loss=0.0203, val_loss=0.0278, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 36.48it/s, loss=0.0203, val_loss=0.0225, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.05it/s, loss=0.0178, val_loss=0.0225, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 24.47it/s, loss=0.0178, val_loss=0.0225, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.0178, val_loss=0.0193, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.0162, val_loss=0.0193, av\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 24.59it/s, loss=0.0162, val_loss=0.0193, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 36.93it/s, loss=0.0162, val_loss=0.0171, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.0149, val_loss=0.0171, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.0149, val_loss=0.0171, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.0149, val_loss=0.0155, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.0138, val_loss=0.0155, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.0138, val_loss=0.0155, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.0138, val_loss=0.0143, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.0129, val_loss=0.0143, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 24.63it/s, loss=0.0129, val_loss=0.0143, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.02it/s, loss=0.0129, val_loss=0.0132, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.012, val_loss=0.0132, avg\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 24.83it/s, loss=0.012, val_loss=0.0132, avg\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.28it/s, loss=0.012, val_loss=0.0122, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.0113, val_loss=0.0122, a\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.0113, val_loss=0.0122, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 36.94it/s, loss=0.0113, val_loss=0.0113, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.0106, val_loss=0.0113, a\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 24.84it/s, loss=0.0106, val_loss=0.0113, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.34it/s, loss=0.0106, val_loss=0.0106, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00993, val_loss=0.0106, \u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00993, val_loss=0.0106, \n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.35it/s, loss=0.00993, val_loss=0.00987,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.00936, val_loss=0.00987,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00936, val_loss=0.00987,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.00936, val_loss=0.00925,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00885, val_loss=0.00925,\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.06it/s, loss=0.00885, val_loss=0.00925,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00885, val_loss=0.00872,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.0084, val_loss=0.00872, \u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 24.22it/s, loss=0.0084, val_loss=0.00872, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 36.41it/s, loss=0.0084, val_loss=0.00824, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00802, val_loss=0.00824,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00802, val_loss=0.00824,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.00802, val_loss=0.00782,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.08it/s, loss=0.00768, val_loss=0.00782,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 24.67it/s, loss=0.00768, val_loss=0.00782,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00768, val_loss=0.00746,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.0074, val_loss=0.00746, \u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 24.38it/s, loss=0.0074, val_loss=0.00746, \n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.0074, val_loss=0.00715, \u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 20.93it/s, loss=0.00716, val_loss=0.00715,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 24.53it/s, loss=0.00716, val_loss=0.00715,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.00716, val_loss=0.00689,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00696, val_loss=0.00689,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00696, val_loss=0.00689,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.11it/s, loss=0.00696, val_loss=0.00666,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.0068, val_loss=0.00666, \u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 24.44it/s, loss=0.0068, val_loss=0.00666, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.0068, val_loss=0.00646, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00666, val_loss=0.00646,\u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.27it/s, loss=0.00666, val_loss=0.00646,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.00666, val_loss=0.0063, \u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 20.90it/s, loss=0.00656, val_loss=0.0063, \u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 24.52it/s, loss=0.00656, val_loss=0.0063, \n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.00656, val_loss=0.00616,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00647, val_loss=0.00616,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 24.28it/s, loss=0.00647, val_loss=0.00616,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 36.49it/s, loss=0.00647, val_loss=0.00605,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.00641, val_loss=0.00605,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 25.72it/s, loss=0.00641, val_loss=0.00605,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.41it/s, loss=0.00641, val_loss=0.00597,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00636, val_loss=0.00597,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00636, val_loss=0.00597,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.00636, val_loss=0.00591,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00631, val_loss=0.00591,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.01it/s, loss=0.00631, val_loss=0.00591,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.00631, val_loss=0.00586,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00628, val_loss=0.00586,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 24.79it/s, loss=0.00628, val_loss=0.00586,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.00628, val_loss=0.00583,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00626, val_loss=0.00583,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00626, val_loss=0.00583,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00626, val_loss=0.00581,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.00624, val_loss=0.00581,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 24.51it/s, loss=0.00624, val_loss=0.00581,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 36.88it/s, loss=0.00624, val_loss=0.00579,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00622, val_loss=0.00579,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 24.46it/s, loss=0.00622, val_loss=0.00579,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 36.76it/s, loss=0.00622, val_loss=0.00578,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.14it/s, loss=0.00621, val_loss=0.00578,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 24.80it/s, loss=0.00621, val_loss=0.00578,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00621, val_loss=0.0058, \u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.30it/s, loss=0.0062, val_loss=0.0058, a\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.0062, val_loss=0.0058, a\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.0062, val_loss=0.00583, \u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00619, val_loss=0.00583,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 24.96it/s, loss=0.00619, val_loss=0.00583,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.00619, val_loss=0.00589,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.00618, val_loss=0.00589,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.00618, val_loss=0.00589,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=0.00618, val_loss=0.00593,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00617, val_loss=0.00593,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 24.95it/s, loss=0.00617, val_loss=0.00593,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.00617, val_loss=0.00595,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00616, val_loss=0.00595,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 24.64it/s, loss=0.00616, val_loss=0.00595,\n",
      "Epoch 37:  89%|▉| 57/64 [00:01<00:00, 34.40it/s, loss=0.00616, val_loss=0.00595,\u001b[A\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.00616, val_loss=0.00597,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 20.83it/s, loss=0.00615, val_loss=0.00597,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00615, val_loss=0.00597,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 36.71it/s, loss=0.00615, val_loss=0.00599,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 20.65it/s, loss=0.00615, val_loss=0.00599,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 24.12it/s, loss=0.00615, val_loss=0.00599,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 36.42it/s, loss=0.00615, val_loss=0.00602,\u001b[A\n",
      "Epoch 40:  50%|▌| 32/64 [00:01<00:01, 20.18it/s, loss=0.00615, val_loss=0.00602,\u001b[A\n",
      "Epoch 40:  59%|▌| 38/64 [00:01<00:01, 23.47it/s, loss=0.00615, val_loss=0.00602,\n",
      "Epoch 40: 100%|█| 64/64 [00:01<00:00, 35.68it/s, loss=0.00615, val_loss=0.00605,\u001b[A\n",
      "Epoch 41:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00615, val_loss=0.00605,\u001b[A\n",
      "Epoch 41:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00615, val_loss=0.00605,\n",
      "Epoch 41: 100%|█| 64/64 [00:01<00:00, 37.14it/s, loss=0.00615, val_loss=0.0061, \u001b[A\n",
      "Epoch 42:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00615, val_loss=0.0061, \u001b[A\n",
      "Epoch 42:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.00615, val_loss=0.0061, \n",
      "Epoch 42: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00615, val_loss=0.00615,\u001b[A\n",
      "Epoch 43:  50%|▌| 32/64 [00:01<00:01, 20.37it/s, loss=0.00615, val_loss=0.00615,\u001b[A\n",
      "Epoch 43:  59%|▌| 38/64 [00:01<00:01, 23.91it/s, loss=0.00615, val_loss=0.00615,\n",
      "Epoch 43: 100%|█| 64/64 [00:01<00:00, 35.94it/s, loss=0.00615, val_loss=0.00619,\u001b[A\n",
      "Epoch 44:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00615, val_loss=0.00619,\u001b[A\n",
      "Epoch 44:  59%|▌| 38/64 [00:01<00:01, 24.79it/s, loss=0.00615, val_loss=0.00619,\n",
      "Epoch 44: 100%|█| 64/64 [00:01<00:00, 37.14it/s, loss=0.00615, val_loss=0.00623,\u001b[A\n",
      "Epoch 45:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.00615, val_loss=0.00623,\u001b[A\n",
      "Epoch 45:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00615, val_loss=0.00623,\n",
      "Epoch 45: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00615, val_loss=0.00627,\u001b[A\n",
      "Epoch 46:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00615, val_loss=0.00627,\u001b[A\n",
      "Epoch 46:  59%|▌| 38/64 [00:01<00:01, 25.24it/s, loss=0.00615, val_loss=0.00627,\n",
      "Epoch 46: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.00615, val_loss=0.00632,\u001b[A\n",
      "Epoch 47:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00615, val_loss=0.00632,\u001b[A\n",
      "Epoch 47:  59%|▌| 38/64 [00:01<00:01, 25.50it/s, loss=0.00615, val_loss=0.00632,\n",
      "Epoch 47: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00615, val_loss=0.00637,\u001b[A\n",
      "Epoch 48:  50%|▌| 32/64 [00:01<00:01, 20.67it/s, loss=0.00615, val_loss=0.00637,\u001b[A\n",
      "Epoch 48:  59%|▌| 38/64 [00:01<00:01, 24.24it/s, loss=0.00615, val_loss=0.00637,\n",
      "Epoch 48: 100%|█| 64/64 [00:01<00:00, 36.45it/s, loss=0.00615, val_loss=0.00643,\u001b[A\n",
      "Epoch 49:  50%|▌| 32/64 [00:01<00:01, 20.73it/s, loss=0.00615, val_loss=0.00643,\u001b[A\n",
      "Epoch 49:  59%|▌| 38/64 [00:01<00:01, 24.25it/s, loss=0.00615, val_loss=0.00643,\n",
      "Epoch 49: 100%|█| 64/64 [00:01<00:00, 36.57it/s, loss=0.00615, val_loss=0.00648,\u001b[A\n",
      "Epoch 50:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00615, val_loss=0.00648,\u001b[A\n",
      "Epoch 50:  59%|▌| 38/64 [00:01<00:01, 25.19it/s, loss=0.00615, val_loss=0.00648,\n",
      "Epoch 50: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.00615, val_loss=0.00656,\u001b[A\n",
      "Epoch 51:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.00615, val_loss=0.00656,\u001b[A\n",
      "Epoch 51:  59%|▌| 38/64 [00:01<00:01, 24.41it/s, loss=0.00615, val_loss=0.00656,\n",
      "Epoch 51: 100%|█| 64/64 [00:01<00:00, 36.75it/s, loss=0.00615, val_loss=0.00663,\u001b[A\n",
      "Epoch 52:  50%|▌| 32/64 [00:01<00:01, 21.17it/s, loss=0.00615, val_loss=0.00663,\u001b[A\n",
      "Epoch 52:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00615, val_loss=0.00663,\n",
      "Epoch 52: 100%|█| 64/64 [00:01<00:00, 37.09it/s, loss=0.00615, val_loss=0.00669,\u001b[A\n",
      "Epoch 53:  50%|▌| 32/64 [00:01<00:01, 21.33it/s, loss=0.00616, val_loss=0.00669,\u001b[A\n",
      "Epoch 53:  59%|▌| 38/64 [00:01<00:01, 25.02it/s, loss=0.00616, val_loss=0.00669,\n",
      "Epoch 53: 100%|█| 64/64 [00:01<00:00, 37.48it/s, loss=0.00616, val_loss=0.00678,\u001b[A\n",
      "Epoch 54:  50%|▌| 32/64 [00:01<00:01, 21.09it/s, loss=0.00616, val_loss=0.00678,\u001b[A\n",
      "Epoch 54:  59%|▌| 38/64 [00:01<00:01, 24.74it/s, loss=0.00616, val_loss=0.00678,\n",
      "Epoch 54: 100%|█| 64/64 [00:01<00:00, 37.06it/s, loss=0.00616, val_loss=0.00686,\u001b[A\n",
      "Epoch 55:  50%|▌| 32/64 [00:01<00:01, 21.42it/s, loss=0.00616, val_loss=0.00686,\u001b[A\n",
      "Epoch 55:  59%|▌| 38/64 [00:01<00:01, 25.09it/s, loss=0.00616, val_loss=0.00686,\n",
      "Epoch 55: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.00616, val_loss=0.00694,\u001b[A\n",
      "Epoch 56:  50%|▌| 32/64 [00:01<00:01, 21.00it/s, loss=0.00616, val_loss=0.00694,\u001b[A\n",
      "Epoch 56:  59%|▌| 38/64 [00:01<00:01, 24.65it/s, loss=0.00616, val_loss=0.00694,\n",
      "Epoch 56: 100%|█| 64/64 [00:01<00:00, 36.98it/s, loss=0.00616, val_loss=0.00704,\u001b[A\n",
      "Epoch 57:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.00616, val_loss=0.00704,\u001b[A\n",
      "Epoch 57:  59%|▌| 38/64 [00:01<00:01, 24.90it/s, loss=0.00616, val_loss=0.00704,\n",
      "Epoch 57: 100%|█| 64/64 [00:01<00:00, 37.33it/s, loss=0.00616, val_loss=0.00714,\u001b[A\n",
      "Epoch 58:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00616, val_loss=0.00714,\u001b[A\n",
      "Epoch 58:  59%|▌| 38/64 [00:01<00:01, 24.77it/s, loss=0.00616, val_loss=0.00714,\n",
      "Epoch 58: 100%|█| 64/64 [00:01<00:00, 37.15it/s, loss=0.00616, val_loss=0.00724,\u001b[A\n",
      "Epoch 59:  50%|▌| 32/64 [00:01<00:01, 20.48it/s, loss=0.00617, val_loss=0.00724,\u001b[A\n",
      "Epoch 59:  59%|▌| 38/64 [00:01<00:01, 24.03it/s, loss=0.00617, val_loss=0.00724,\n",
      "Epoch 59: 100%|█| 64/64 [00:01<00:00, 36.13it/s, loss=0.00617, val_loss=0.00735,\u001b[A\n",
      "Epoch 60:  50%|▌| 32/64 [00:01<00:01, 20.56it/s, loss=0.00621, val_loss=0.00735,\u001b[A\n",
      "Epoch 60:  59%|▌| 38/64 [00:01<00:01, 24.08it/s, loss=0.00621, val_loss=0.00735,\n",
      "Epoch 60: 100%|█| 64/64 [00:01<00:00, 36.29it/s, loss=0.00621, val_loss=0.00781,\u001b[A\n",
      "Epoch 61:  50%|▌| 32/64 [00:01<00:01, 20.97it/s, loss=0.0157, val_loss=0.00781, \u001b[A\n",
      "Epoch 61:  59%|▌| 38/64 [00:01<00:01, 24.54it/s, loss=0.0157, val_loss=0.00781, \n",
      "Epoch 61: 100%|█| 64/64 [00:01<00:00, 36.90it/s, loss=0.0157, val_loss=0.0108, a\u001b[A\n",
      "Epoch 62:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00647, val_loss=0.0108, \u001b[A\n",
      "Epoch 62:  59%|▌| 38/64 [00:01<00:01, 25.00it/s, loss=0.00647, val_loss=0.0108, \n",
      "Epoch 62: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00647, val_loss=0.00757,\u001b[A\n",
      "Epoch 63:  50%|▌| 32/64 [00:01<00:01, 20.58it/s, loss=0.00618, val_loss=0.00757,\u001b[A\n",
      "Epoch 63:  59%|▌| 38/64 [00:01<00:01, 23.93it/s, loss=0.00618, val_loss=0.00757,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|█| 64/64 [00:01<00:00, 36.27it/s, loss=0.00618, val_loss=0.00776,\u001b[A\n",
      "Epoch 64:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00617, val_loss=0.00776,\u001b[A\n",
      "Epoch 64:  59%|▌| 38/64 [00:01<00:01, 24.63it/s, loss=0.00617, val_loss=0.00776,\n",
      "Epoch 64: 100%|█| 64/64 [00:01<00:00, 36.96it/s, loss=0.00617, val_loss=0.00788,\u001b[A\n",
      "Epoch 65:  50%|▌| 32/64 [00:01<00:01, 20.86it/s, loss=0.0068, val_loss=0.00788, \u001b[A\n",
      "Epoch 65:  59%|▌| 38/64 [00:01<00:01, 24.50it/s, loss=0.0068, val_loss=0.00788, \n",
      "Epoch 65: 100%|█| 64/64 [00:01<00:00, 36.77it/s, loss=0.0068, val_loss=0.0153, a\u001b[A\n",
      "Epoch 66:  50%|▌| 32/64 [00:01<00:01, 21.23it/s, loss=0.012, val_loss=0.0153, av\u001b[A\n",
      "Epoch 66:  59%|▌| 38/64 [00:01<00:01, 24.90it/s, loss=0.012, val_loss=0.0153, av\n",
      "Epoch 66: 100%|█| 64/64 [00:01<00:00, 37.17it/s, loss=0.012, val_loss=0.0101, av\u001b[A\n",
      "Epoch 67:  50%|▌| 32/64 [00:01<00:01, 20.32it/s, loss=0.00639, val_loss=0.0101, \u001b[A\n",
      "Epoch 67:  59%|▌| 38/64 [00:01<00:01, 23.84it/s, loss=0.00639, val_loss=0.0101, \n",
      "Epoch 67: 100%|█| 64/64 [00:01<00:00, 35.91it/s, loss=0.00639, val_loss=0.00836,\u001b[A\n",
      "Epoch 68:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.00618, val_loss=0.00836,\u001b[A\n",
      "Epoch 68:  59%|▌| 38/64 [00:01<00:01, 24.32it/s, loss=0.00618, val_loss=0.00836,\n",
      "Epoch 68: 100%|█| 64/64 [00:01<00:00, 36.81it/s, loss=0.00618, val_loss=0.00827,\u001b[A\n",
      "Epoch 69:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00618, val_loss=0.00827,\u001b[A\n",
      "Epoch 69:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00618, val_loss=0.00827,\n",
      "Epoch 69: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00618, val_loss=0.00847,\u001b[A\n",
      "Epoch 70:  50%|▌| 32/64 [00:01<00:01, 20.32it/s, loss=0.0423, val_loss=0.00847, \u001b[A\n",
      "Epoch 70:  59%|▌| 38/64 [00:01<00:01, 23.86it/s, loss=0.0423, val_loss=0.00847, \n",
      "Epoch 70: 100%|█| 64/64 [00:01<00:00, 35.93it/s, loss=0.0423, val_loss=0.0578, a\u001b[A\n",
      "Epoch 71:  50%|▌| 32/64 [00:01<00:01, 20.64it/s, loss=0.0108, val_loss=0.0578, a\u001b[A\n",
      "Epoch 71:  59%|▌| 38/64 [00:01<00:01, 24.06it/s, loss=0.0108, val_loss=0.0578, a\n",
      "Epoch 71: 100%|█| 64/64 [00:01<00:00, 36.22it/s, loss=0.0108, val_loss=0.0111, a\u001b[A\n",
      "Epoch 72:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00635, val_loss=0.0111, \u001b[A\n",
      "Epoch 72:  59%|▌| 38/64 [00:01<00:01, 24.73it/s, loss=0.00635, val_loss=0.0111, \n",
      "Epoch 72: 100%|█| 64/64 [00:01<00:00, 37.21it/s, loss=0.00635, val_loss=0.00868,\u001b[A\n",
      "Epoch 73:  50%|▌| 32/64 [00:01<00:01, 20.94it/s, loss=0.00619, val_loss=0.00868,\u001b[A\n",
      "Epoch 73:  59%|▌| 38/64 [00:01<00:01, 24.34it/s, loss=0.00619, val_loss=0.00868,\n",
      "Epoch 73: 100%|█| 64/64 [00:01<00:00, 36.82it/s, loss=0.00619, val_loss=0.00879,\u001b[A\n",
      "Epoch 74:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00619, val_loss=0.00879,\u001b[A\n",
      "Epoch 74:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.00619, val_loss=0.00879,\n",
      "Epoch 74: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00619, val_loss=0.00894,\u001b[A\n",
      "Epoch 75:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.0215, val_loss=0.00894, \u001b[A\n",
      "Epoch 75:  59%|▌| 38/64 [00:01<00:01, 24.53it/s, loss=0.0215, val_loss=0.00894, \n",
      "Epoch 75: 100%|█| 64/64 [00:01<00:00, 36.86it/s, loss=0.0215, val_loss=0.141, av\u001b[A\n",
      "Epoch 76:  50%|▌| 32/64 [00:01<00:01, 20.52it/s, loss=0.0148, val_loss=0.141, av\u001b[A\n",
      "Epoch 76:  59%|▌| 38/64 [00:01<00:01, 23.93it/s, loss=0.0148, val_loss=0.141, av\n",
      "Epoch 76: 100%|█| 64/64 [00:01<00:00, 36.19it/s, loss=0.0148, val_loss=0.00924, \u001b[A\n",
      "Epoch 77:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.00652, val_loss=0.00924,\u001b[A\n",
      "Epoch 77:  59%|▌| 38/64 [00:01<00:01, 24.89it/s, loss=0.00652, val_loss=0.00924,\n",
      "Epoch 77: 100%|█| 64/64 [00:01<00:00, 37.23it/s, loss=0.00652, val_loss=0.00941,\u001b[A\n",
      "Epoch 78:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00636, val_loss=0.00941,\u001b[A\n",
      "Epoch 78:  59%|▌| 38/64 [00:01<00:01, 24.82it/s, loss=0.00636, val_loss=0.00941,\n",
      "Epoch 78: 100%|█| 64/64 [00:01<00:00, 37.26it/s, loss=0.00636, val_loss=0.0109, \u001b[A\n",
      "Epoch 79:  50%|▌| 32/64 [00:01<00:01, 20.76it/s, loss=0.0851, val_loss=0.0109, a\u001b[A\n",
      "Epoch 79:  59%|▌| 38/64 [00:01<00:01, 24.25it/s, loss=0.0851, val_loss=0.0109, a\n",
      "Epoch 79: 100%|█| 64/64 [00:01<00:00, 36.51it/s, loss=0.0851, val_loss=0.0333, a\u001b[A\n",
      "Epoch 80:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00756, val_loss=0.0333, \u001b[A\n",
      "Epoch 80:  59%|▌| 38/64 [00:01<00:01, 24.93it/s, loss=0.00756, val_loss=0.0333, \n",
      "Epoch 80: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.00756, val_loss=0.00858,\u001b[A\n",
      "Epoch 81:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00621, val_loss=0.00858,\u001b[A\n",
      "Epoch 81:  59%|▌| 38/64 [00:01<00:01, 25.22it/s, loss=0.00621, val_loss=0.00858,\n",
      "Epoch 81: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00621, val_loss=0.00887,\u001b[A\n",
      "Epoch 82:  50%|▌| 32/64 [00:01<00:01, 21.38it/s, loss=0.0068, val_loss=0.00887, \u001b[A\n",
      "Epoch 82:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.0068, val_loss=0.00887, \n",
      "Epoch 82: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.0068, val_loss=0.0167, a\u001b[A\n",
      "Epoch 83:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.0622, val_loss=0.0167, a\u001b[A\n",
      "Epoch 83:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.0622, val_loss=0.0167, a\n",
      "Epoch 83: 100%|█| 64/64 [00:01<00:00, 37.58it/s, loss=0.0622, val_loss=0.0256, a\u001b[A\n",
      "Epoch 84:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00758, val_loss=0.0256, \u001b[A\n",
      "Epoch 84:  59%|▌| 38/64 [00:01<00:01, 24.51it/s, loss=0.00758, val_loss=0.0256, \n",
      "Epoch 84: 100%|█| 64/64 [00:01<00:00, 36.87it/s, loss=0.00758, val_loss=0.00923,\u001b[A\n",
      "Epoch 85:  50%|▌| 32/64 [00:01<00:01, 20.78it/s, loss=0.00621, val_loss=0.00923,\u001b[A\n",
      "Epoch 85:  59%|▌| 38/64 [00:01<00:01, 24.39it/s, loss=0.00621, val_loss=0.00923,\n",
      "Epoch 85: 100%|█| 64/64 [00:01<00:00, 36.63it/s, loss=0.00621, val_loss=0.00848,\u001b[A\n",
      "Epoch 86:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.00616, val_loss=0.00848,\u001b[A\n",
      "Epoch 86:  59%|▌| 38/64 [00:01<00:01, 25.06it/s, loss=0.00616, val_loss=0.00848,\n",
      "Epoch 86: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.00616, val_loss=0.0086, \u001b[A\n",
      "Epoch 87:  50%|▌| 32/64 [00:01<00:01, 20.63it/s, loss=0.00618, val_loss=0.0086, \u001b[A\n",
      "Epoch 87:  59%|▌| 38/64 [00:01<00:01, 24.07it/s, loss=0.00618, val_loss=0.0086, \n",
      "Epoch 87: 100%|█| 64/64 [00:01<00:00, 36.31it/s, loss=0.00618, val_loss=0.00888,\u001b[A\n",
      "Epoch 88:  50%|▌| 32/64 [00:01<00:01, 21.21it/s, loss=0.0923, val_loss=0.00888, \u001b[A\n",
      "Epoch 88:  59%|▌| 38/64 [00:01<00:01, 24.61it/s, loss=0.0923, val_loss=0.00888, \n",
      "Epoch 88: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.0923, val_loss=0.0395, a\u001b[A\n",
      "Epoch 89:  50%|▌| 32/64 [00:01<00:01, 20.82it/s, loss=0.00838, val_loss=0.0395, \u001b[A\n",
      "Epoch 89:  59%|▌| 38/64 [00:01<00:01, 24.36it/s, loss=0.00838, val_loss=0.0395, \n",
      "Epoch 89: 100%|█| 64/64 [00:01<00:00, 36.69it/s, loss=0.00838, val_loss=0.00862,\u001b[A\n",
      "Epoch 90:  50%|▌| 32/64 [00:01<00:01, 21.10it/s, loss=0.00624, val_loss=0.00862,\u001b[A\n",
      "Epoch 90:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00624, val_loss=0.00862,\n",
      "Epoch 90: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00624, val_loss=0.00844,\u001b[A\n",
      "Epoch 91:  50%|▌| 32/64 [00:01<00:01, 20.89it/s, loss=0.00615, val_loss=0.00844,\u001b[A\n",
      "Epoch 91:  59%|▌| 38/64 [00:01<00:01, 24.43it/s, loss=0.00615, val_loss=0.00844,\n",
      "Epoch 91: 100%|█| 64/64 [00:01<00:00, 36.74it/s, loss=0.00615, val_loss=0.00859,\u001b[A\n",
      "Epoch 92:  50%|▌| 32/64 [00:01<00:01, 20.92it/s, loss=0.0401, val_loss=0.00859, \u001b[A\n",
      "Epoch 92:  59%|▌| 38/64 [00:01<00:01, 24.53it/s, loss=0.0401, val_loss=0.00859, \n",
      "Epoch 92: 100%|█| 64/64 [00:01<00:00, 36.85it/s, loss=0.0401, val_loss=0.136, av\u001b[A\n",
      "Epoch 93:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.0146, val_loss=0.136, av\u001b[A\n",
      "Epoch 93:  59%|▌| 38/64 [00:01<00:01, 24.87it/s, loss=0.0146, val_loss=0.136, av\n",
      "Epoch 93: 100%|█| 64/64 [00:01<00:00, 37.27it/s, loss=0.0146, val_loss=0.0104, a\u001b[A\n",
      "Epoch 94:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.0274, val_loss=0.0104, a\u001b[A\n",
      "Epoch 94:  59%|▌| 38/64 [00:01<00:01, 25.87it/s, loss=0.0274, val_loss=0.0104, a\n",
      "Epoch 94: 100%|█| 64/64 [00:01<00:00, 38.64it/s, loss=0.0274, val_loss=0.105, av\u001b[A\n",
      "Epoch 95:  50%|▌| 32/64 [00:01<00:01, 21.25it/s, loss=0.0113, val_loss=0.105, av\u001b[A\n",
      "Epoch 95:  59%|▌| 38/64 [00:01<00:01, 24.91it/s, loss=0.0113, val_loss=0.105, av\n",
      "Epoch 95: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.0113, val_loss=0.00848, \u001b[A\n",
      "Epoch 96:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00649, val_loss=0.00848,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:  59%|▌| 38/64 [00:01<00:01, 24.86it/s, loss=0.00649, val_loss=0.00848,\n",
      "Epoch 96:  89%|▉| 57/64 [00:01<00:00, 34.66it/s, loss=0.00649, val_loss=0.00848,\u001b[A\n",
      "Epoch 96: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00649, val_loss=0.00929,\u001b[A\n",
      "Epoch 97:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.099, val_loss=0.00929, a\u001b[A\n",
      "Epoch 97:  59%|▌| 38/64 [00:01<00:01, 25.30it/s, loss=0.099, val_loss=0.00929, a\n",
      "Epoch 97: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.099, val_loss=0.0259, av\u001b[A\n",
      "Epoch 98:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.0092, val_loss=0.0259, a\u001b[A\n",
      "Epoch 98:  59%|▌| 38/64 [00:01<00:01, 24.85it/s, loss=0.0092, val_loss=0.0259, a\n",
      "Epoch 98: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.0092, val_loss=0.00966, \u001b[A\n",
      "Epoch 99:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00628, val_loss=0.00966,\u001b[A\n",
      "Epoch 99:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.00628, val_loss=0.00966,\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.00628, val_loss=0.00827,\u001b[A\n",
      "Epoch 99: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00628, val_loss=0.00827,\u001b[A\n",
      "Sizes of clusters: 582, 395, 190, 433\n",
      "\n",
      "preds: [0 3 1 1 0 3 1 1 0 0 3 0 0 0 1 3 3 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 3 1 1 0 0\n",
      " 3 1 1 0 0 2 1 3 1 0 0 0 1 0 0 0 2 3 1 0 0 1 1 2 1 1 1 1 0 0 0 3 0 1 1 0 1\n",
      " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 3 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 3 1 1 0 0 1 1 1 1 0 0 1 0 1 0 2 1 1 0 0 0 1 0 1 0 1 1 3 1 0 1 0 0 0 1\n",
      " 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 3 0 0 1 0 3 0 1 1 1 1 1 0 0 1 1 1\n",
      " 3 3 1 0 0 0 2 1 0 1 1 3 1 0 1 3 0 1 1 0 1 1 0 0 3 1 1 1 1 1 0 1 0 0 1 3 3\n",
      " 3 1 0 1 1 3 0 0 0 1 1 1 1 1 0 0 3 1 3 1 1 3 0 1 1 1 3 0 3 1 1 1 1 1 0 1 1\n",
      " 0 0 1 3 3 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 3 3 1 0 3 0 1 1 3\n",
      " 1 0 3 2 0 1 3 1 1 1 1 1 1 0 1 3 1 0 1 1 1 1 0 3 1 1 1 1 0 1 0 0 0 1 0 1 0\n",
      " 1 2 0 0 1 0 3 0 0 0 1 3 0 1 3 0 1 0 3 1 1 1 0 0 3 0 1 0 1 1 0 1 1 1 0 1 0\n",
      " 1 1 0 3 1 0 1 3 0 0 1 1 0 1 1 3 1 3 1 0 3 3 1 0 1 1 0 1 1 0 0 3 3 2 2 3 3\n",
      " 3 2 0 3 0 3 3 3 3 0 0 1 2 0 0 0 0 3 2 2 3 0 2 2 1 3 0 3 2 2 0 3 2 3 2 0 3\n",
      " 3 3 3 0 2 2 3 2 0 3 0 2 3 0 0 3 0 3 2 0 2 2 2 0 2 3 2 0 0 3 0 0 0 0 2 2 2\n",
      " 0 3 0 0 3 0 3 0 0 3 3 3 3 3 1 0 3 0 2 3 3 0 0 2 3 0 3 0 0 0 0 0 0 3 2 0 0\n",
      " 0 2 3 2 2 0 0 2 0 0 0 0 3 3 3 3 2 0 0 1 0 2 2 3 3 3 3 0 0 0 3 3 2 0 2 3 2\n",
      " 0 3 2 2 0 3 2 3 3 0 3 3 3 3 0 2 0 3 0 3 0 3 3 0 0 3 3 0 3 2 0 3 3 2 3 3 0\n",
      " 2 0 0 0 3 1 3 3 2 0 0 3 3 2 0 3 0 3 0 0 3 3 0 3 3 0 2 0 2 3 0 0 0 3 2 3 2\n",
      " 0 2 3 0 2 3 0 2 0 2 0 3 0 2 3 2 3 3 3 0 0 2 0 2 3 2 3 3 3 3 0 2 0 3 3 0 0\n",
      " 0 2 0 3 0 0 0 0 3 0 0 2 2 3 1 2 3 0 2 0 3 2 0 0 2 0 3 2 3 3 0 0 2 3 3 0 2\n",
      " 3 2 0 0 3 3 3 0 0 3 2 0 2 2 0 3 0 3 0 0 2 3 3 3 0 2 3 0 2 2 3 0 3 2 0 0 3\n",
      " 3 3 2 0 0 3 3 0 0 0 3 2 0 2 0 2 2 2 1 0 2 0 2 2 2 0 3 0 3 3 3 0 0 2 2 3 0\n",
      " 0 0 2 2 3 0 0 3 2 0 3 2 0 0 3 2 0 0 0 0 0 3 1 3 3 1 3 0 1 1 1 1 1 1 0 1 3\n",
      " 1 0 1 0 3 2 1 3 0 1 1 1 3 3 0 0 1 0 3 1 1 0 0 3 0 0 0 1 1 0 3 1 1 3 1 0 3\n",
      " 3 1 1 1 1 0 1 1 1 1 3 1 0 3 1 1 1 1 3 3 1 3 1 0 0 0 1 0 3 0 3 0 0 1 1 3 0\n",
      " 0 0 0 0 1 0 0 0 1 3 0 0 0 0 0 0 0 0 1 0 3 0 0 0 3 0 1 0 1 0 3 0 3 0 1 1 1\n",
      " 1 1 1 1 2 1 0 2 3 1 0 2 3 1 3 1 3 3 3 1 3 3 3 1 0 2 1 3 1 3 3 2 0 0 0 0 0\n",
      " 1 3 0 0 3 3 2 1 2 3 0 1 1 0 3 0 0 0 0 3 2 0 3 1 0 0 0 1 0 1 3 2 1 1 3 0 1\n",
      " 0 0 1 0 3 1 0 0 1 3 2 0 1 0 3 0 0 1 1 3 1 1 1 0 0 2 1 1 0 1 0 0 1 3 0 2 0\n",
      " 3 1 3 1 3 0 0 1 3 0 0 0 0 1 1 0 2 2 3 3 3 1 3 3 1 1 3 3 0 0 3 2 1 3 1 1 0\n",
      " 0 1 3 0 3 0 2 0 1 2 1 3 3 1 3 1 3 1 3 3 0 1 0 2 1 0 1 3 0 3 0 0 0 1 0 2 0\n",
      " 0 0 1 3 2 0 0 0 1 0 3 1 1 0 3 0 1 0 0 0 2 1 0 1 1 0 3 0 0 2 0 3 1 2 3 1 1\n",
      " 3 1 0 1 1 1 1 0 3 0 0 3 3 1 3 2 1 1 2 1 1 0 0 0 1 3 0 0 3 0 0 1 1 0 1 0 0\n",
      " 0 1 3 0 1 1 0 2 3 1 0 2 0 2 3 0 3 0 0 3 0 3 0 3 1 1 0 0 0 1 2 0 3 3 2 0 2\n",
      " 1 3 0 3 3 0 0 2 1 0 3 2 3 0 0 3 3 2 0 3 0 3 0 1 3 2 0 2 3 0 2 1 3 3 0 1 2\n",
      " 0 1 1 3 0 2 3 2 2 3 1 0 0 1 1 0 0 0 0 2 3 3 3 3 2 1 3 1 3 3 1 1 3 0 0 3 3\n",
      " 2 3 2 0 3 2 1 3 3 1 0 0 3 0 0 3 3 3 3 0 3 3 3 3 3 0 0 0 0 3 1 1 3 3 1 0 0\n",
      " 0 0 3 0 0 0 2 0 3 3 2 1 3 0 3 1 0 3 3 1 0 1 0 3 3 0 3 3 0 1 1 3 0 3 1 3 0\n",
      " 0 3 0 3 3 0 2 0 0 3 3 1 3 3 3 3 3 0 3 0 0 3 0 0 2 3 1 3 2 2 0 2 1 3 3 2 0\n",
      " 3 0 3 3 0 0 3 3 0 0 3 0 3 3 3 2 3 0 3 3 1 0 3 0 0 2 0 3 1 3 3 2 3 3 3 0 2\n",
      " 3 0 2 0 3 3 2 3 2 3 3 1 3 2 0 0 1 1 0 2 3 0 0 2 0 0 0 3 1 1 3 2 2 0 2 3 2\n",
      " 0 0 3 3 0 2 1 2 0 0 1 0 2 3 0 0 1 3 0 1 3 3 2 3 3 1 2 2 2 3 1 2 0 3 3 1 0\n",
      " 3 0 0 3 2 3 3 2 1 0 0 3 0 0 0 1 1 0 3 3 3 3 3 0 0 2 1 1 3 0 2 0 3 2 3 0 1\n",
      " 0 0 0 3 3 3 3 0 2 0 0 3 3 0 3 2 0 0 1 0 3 1 2 3 1 3 1 1 3 3 0 0 0 3 3 1 3\n",
      " 3 0 0 3 3 3 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consistency: 0.3742\n",
      "Purity: 0.544+-0.14125309731117405\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K4_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.714, val_loss=0.0699, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  74%|▋| 59/80 [00:02<00:00, 28.16it/s, loss=0.714, val_loss=0.0699, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.714, val_loss=1.49, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.40it/s, loss=0.0416, val_loss=1.49, avg_\u001b[A\n",
      "Epoch 1:  71%|▋| 57/80 [00:02<00:00, 27.73it/s, loss=0.0416, val_loss=1.49, avg_\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 169.07it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 35.96it/s, loss=0.0416, val_loss=0.0699, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.48it/s, loss=0.0204, val_loss=0.0699, av\u001b[A\n",
      "Epoch 2:  71%|▋| 57/80 [00:02<00:00, 27.93it/s, loss=0.0204, val_loss=0.0699, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.55it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.18it/s, loss=0.0204, val_loss=0.0464, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.62it/s, loss=0.015, val_loss=0.0464, avg\u001b[A\n",
      "Epoch 3:  71%|▋| 57/80 [00:02<00:00, 28.09it/s, loss=0.015, val_loss=0.0464, avg\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.48it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 36.39it/s, loss=0.015, val_loss=0.0352, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.0118, val_loss=0.0352, av\u001b[A\n",
      "Epoch 4:  71%|▋| 57/80 [00:02<00:00, 28.08it/s, loss=0.0118, val_loss=0.0352, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 173.28it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.52it/s, loss=0.0118, val_loss=0.028, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00979, val_loss=0.028, av\u001b[A\n",
      "Epoch 5:  71%|▋| 57/80 [00:02<00:00, 28.15it/s, loss=0.00979, val_loss=0.028, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.27it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00979, val_loss=0.023, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.00844, val_loss=0.023, av\u001b[A\n",
      "Epoch 6:  71%|▋| 57/80 [00:02<00:00, 28.31it/s, loss=0.00844, val_loss=0.023, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.63it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00844, val_loss=0.0195, a\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.0075, val_loss=0.0195, av\u001b[A\n",
      "Epoch 7:  71%|▋| 57/80 [00:01<00:00, 28.52it/s, loss=0.0075, val_loss=0.0195, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.74it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.02it/s, loss=0.0075, val_loss=0.017, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.00682, val_loss=0.017, av\u001b[A\n",
      "Epoch 8:  71%|▋| 57/80 [00:01<00:00, 29.17it/s, loss=0.00682, val_loss=0.017, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.50it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 37.57it/s, loss=0.00682, val_loss=0.0151, a\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00631, val_loss=0.0151, a\u001b[A\n",
      "Epoch 9:  71%|▋| 57/80 [00:02<00:00, 27.92it/s, loss=0.00631, val_loss=0.0151, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.52it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 36.24it/s, loss=0.00631, val_loss=0.0135, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00592, val_loss=0.0135, \u001b[A\n",
      "Epoch 10:  71%|▋| 57/80 [00:02<00:00, 28.16it/s, loss=0.00592, val_loss=0.0135, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 164.76it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.45it/s, loss=0.00592, val_loss=0.0123, \u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00561, val_loss=0.0123, \u001b[A\n",
      "Epoch 11:  71%|▋| 57/80 [00:02<00:00, 28.41it/s, loss=0.00561, val_loss=0.0123, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.07it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 36.78it/s, loss=0.00561, val_loss=0.0113, \u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.80it/s, loss=0.00536, val_loss=0.0113, \u001b[A\n",
      "Epoch 12:  71%|▋| 57/80 [00:02<00:00, 28.25it/s, loss=0.00536, val_loss=0.0113, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 170.60it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00536, val_loss=0.0104, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00515, val_loss=0.0104, \u001b[A\n",
      "Epoch 13:  71%|▋| 57/80 [00:02<00:00, 28.34it/s, loss=0.00515, val_loss=0.0104, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.25it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 36.69it/s, loss=0.00515, val_loss=0.00973,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.00498, val_loss=0.00973,\u001b[A\n",
      "Epoch 14:  71%|▋| 57/80 [00:01<00:00, 28.90it/s, loss=0.00498, val_loss=0.00973,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.93it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.35it/s, loss=0.00498, val_loss=0.00912,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.00484, val_loss=0.00912,\u001b[A\n",
      "Epoch 15:  71%|▋| 57/80 [00:01<00:00, 28.71it/s, loss=0.00484, val_loss=0.00912,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.75it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 37.01it/s, loss=0.00484, val_loss=0.00861,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 20.57it/s, loss=0.00472, val_loss=0.00861,\u001b[A\n",
      "Epoch 16:  71%|▋| 57/80 [00:02<00:00, 27.96it/s, loss=0.00472, val_loss=0.00861,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 169.54it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 36.23it/s, loss=0.00472, val_loss=0.00818,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 20.73it/s, loss=0.00462, val_loss=0.00818,\u001b[A\n",
      "Epoch 17:  71%|▋| 57/80 [00:02<00:00, 28.23it/s, loss=0.00462, val_loss=0.00818,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 165.02it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00462, val_loss=0.00778,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00454, val_loss=0.00778,\u001b[A\n",
      "Epoch 18:  71%|▋| 57/80 [00:02<00:00, 28.25it/s, loss=0.00454, val_loss=0.00778,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.11it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 36.67it/s, loss=0.00454, val_loss=0.00743,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.00446, val_loss=0.00743,\u001b[A\n",
      "Epoch 19:  71%|▋| 57/80 [00:01<00:00, 28.65it/s, loss=0.00446, val_loss=0.00743,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.07it/s, loss=0.00446, val_loss=0.0071, \u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.0044, val_loss=0.0071, a\u001b[A\n",
      "Epoch 20:  71%|▋| 57/80 [00:02<00:00, 28.10it/s, loss=0.0044, val_loss=0.0071, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 164.82it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 36.58it/s, loss=0.0044, val_loss=0.00681, \u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00434, val_loss=0.00681,\u001b[A\n",
      "Epoch 21:  71%|▋| 57/80 [00:02<00:00, 28.30it/s, loss=0.00434, val_loss=0.00681,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 169.76it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00434, val_loss=0.00659,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00429, val_loss=0.00659,\u001b[A\n",
      "Epoch 22:  71%|▋| 57/80 [00:02<00:00, 28.30it/s, loss=0.00429, val_loss=0.00659,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.90it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 36.65it/s, loss=0.00429, val_loss=0.00636,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00425, val_loss=0.00636,\u001b[A\n",
      "Epoch 23:  71%|▋| 57/80 [00:02<00:00, 27.97it/s, loss=0.00425, val_loss=0.00636,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.01it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.24it/s, loss=0.00425, val_loss=0.00616,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00421, val_loss=0.00616,\u001b[A\n",
      "Epoch 24:  71%|▋| 57/80 [00:02<00:00, 28.34it/s, loss=0.00421, val_loss=0.00616,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.07it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 36.68it/s, loss=0.00421, val_loss=0.00601,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00418, val_loss=0.00601,\u001b[A\n",
      "Epoch 25:  71%|▋| 57/80 [00:01<00:00, 28.71it/s, loss=0.00418, val_loss=0.00601,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.95it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00418, val_loss=0.00587,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00414, val_loss=0.00587,\u001b[A\n",
      "Epoch 26:  71%|▋| 57/80 [00:02<00:00, 28.33it/s, loss=0.00414, val_loss=0.00587,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.67it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 36.75it/s, loss=0.00414, val_loss=0.00573,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.00411, val_loss=0.00573,\u001b[A\n",
      "Epoch 27:  71%|▋| 57/80 [00:01<00:00, 28.62it/s, loss=0.00411, val_loss=0.00573,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.48it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 37.02it/s, loss=0.00411, val_loss=0.00561,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.94it/s, loss=0.00409, val_loss=0.00561,\u001b[A\n",
      "Epoch 28:  71%|▋| 57/80 [00:01<00:00, 28.52it/s, loss=0.00409, val_loss=0.00561,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.71it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 36.90it/s, loss=0.00409, val_loss=0.00549,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00407, val_loss=0.00549,\u001b[A\n",
      "Epoch 29:  71%|▋| 57/80 [00:01<00:00, 28.62it/s, loss=0.00407, val_loss=0.00549,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.42it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00407, val_loss=0.00541,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00405, val_loss=0.00541,\u001b[A\n",
      "Epoch 30:  71%|▋| 57/80 [00:01<00:00, 28.57it/s, loss=0.00405, val_loss=0.00541,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.18it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.00405, val_loss=0.00533,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00403, val_loss=0.00533,\u001b[A\n",
      "Epoch 31:  71%|▋| 57/80 [00:02<00:00, 28.23it/s, loss=0.00403, val_loss=0.00533,\n",
      "Epoch 31:  95%|▉| 76/80 [00:02<00:00, 35.61it/s, loss=0.00403, val_loss=0.00533,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00403, val_loss=0.00525,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 20.98it/s, loss=0.00401, val_loss=0.00525,\u001b[A\n",
      "Epoch 32:  71%|▋| 57/80 [00:01<00:00, 28.50it/s, loss=0.00401, val_loss=0.00525,\n",
      "Epoch 32:  95%|▉| 76/80 [00:02<00:00, 35.90it/s, loss=0.00401, val_loss=0.00525,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 36.79it/s, loss=0.00401, val_loss=0.00519,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.004, val_loss=0.00519, a\u001b[A\n",
      "Epoch 33:  71%|▋| 57/80 [00:02<00:00, 28.28it/s, loss=0.004, val_loss=0.00519, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.35it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 36.71it/s, loss=0.004, val_loss=0.00511, a\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.00399, val_loss=0.00511,\u001b[A\n",
      "Epoch 34:  71%|▋| 57/80 [00:02<00:00, 28.36it/s, loss=0.00399, val_loss=0.00511,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 164.82it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.71it/s, loss=0.00399, val_loss=0.00502,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.00397, val_loss=0.00502,\u001b[A\n",
      "Epoch 35:  71%|▋| 57/80 [00:01<00:00, 28.55it/s, loss=0.00397, val_loss=0.00502,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.06it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.00397, val_loss=0.00496,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00396, val_loss=0.00496,\u001b[A\n",
      "Epoch 36:  71%|▋| 57/80 [00:02<00:00, 28.14it/s, loss=0.00396, val_loss=0.00496,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.89it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 36.46it/s, loss=0.00396, val_loss=0.00492,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.00395, val_loss=0.00492,\u001b[A\n",
      "Epoch 37:  71%|▋| 57/80 [00:01<00:00, 28.86it/s, loss=0.00395, val_loss=0.00492,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.41it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.31it/s, loss=0.00395, val_loss=0.00486,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.00394, val_loss=0.00486,\u001b[A\n",
      "Epoch 38:  71%|▋| 57/80 [00:02<00:00, 28.00it/s, loss=0.00394, val_loss=0.00486,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.36it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 36.13it/s, loss=0.00394, val_loss=0.00482,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 20.82it/s, loss=0.00393, val_loss=0.00482,\u001b[A\n",
      "Epoch 39:  71%|▋| 57/80 [00:02<00:00, 28.35it/s, loss=0.00393, val_loss=0.00482,\n",
      "Epoch 39:  95%|▉| 76/80 [00:02<00:00, 35.70it/s, loss=0.00393, val_loss=0.00482,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 36.73it/s, loss=0.00393, val_loss=0.00477,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:02<00:02, 17.84it/s, loss=0.00393, val_loss=0.00477,\u001b[A\n",
      "Epoch 40:  71%|▋| 57/80 [00:02<00:00, 24.42it/s, loss=0.00393, val_loss=0.00477,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 182.73it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 31.95it/s, loss=0.00393, val_loss=0.00473,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.00392, val_loss=0.00473,\u001b[A\n",
      "Epoch 41:  71%|▋| 57/80 [00:01<00:00, 29.08it/s, loss=0.00392, val_loss=0.00473,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 182.22it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 37.63it/s, loss=0.00392, val_loss=0.0047, \u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00391, val_loss=0.0047, \u001b[A\n",
      "Epoch 42:  71%|▋| 57/80 [00:01<00:00, 28.73it/s, loss=0.00391, val_loss=0.0047, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.64it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 37.09it/s, loss=0.00391, val_loss=0.00467,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 21.02it/s, loss=0.00391, val_loss=0.00467,\u001b[A\n",
      "Epoch 43:  71%|▋| 57/80 [00:01<00:00, 28.63it/s, loss=0.00391, val_loss=0.00467,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 168.49it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 36.92it/s, loss=0.00391, val_loss=0.00464,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.41it/s, loss=0.0039, val_loss=0.00464, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44:  71%|▋| 57/80 [00:02<00:00, 27.84it/s, loss=0.0039, val_loss=0.00464, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.69it/s]\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.0039, val_loss=0.0046, a\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.0039, val_loss=0.0046, a\u001b[A\n",
      "Epoch 45:  71%|▋| 57/80 [00:01<00:00, 28.89it/s, loss=0.0039, val_loss=0.0046, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.66it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 37.34it/s, loss=0.0039, val_loss=0.0046, a\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00389, val_loss=0.0046, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46:  71%|▋| 57/80 [00:02<00:00, 28.29it/s, loss=0.00389, val_loss=0.0046, \u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 36.80it/s, loss=0.00389, val_loss=0.00458,\u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 20.80it/s, loss=0.00389, val_loss=0.00458,\u001b[A\n",
      "Epoch 47:  71%|▋| 57/80 [00:02<00:00, 28.30it/s, loss=0.00389, val_loss=0.00458,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.08it/s]\u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 48:  71%|▋| 57/80 [00:02<00:00, 28.47it/s, loss=0.00389, val_loss=0.00455,\n",
      "Epoch 48:  95%|▉| 76/80 [00:02<00:00, 35.84it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 36.88it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 49:  71%|▋| 57/80 [00:01<00:00, 28.82it/s, loss=0.00389, val_loss=0.00455,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.82it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 37.26it/s, loss=0.00389, val_loss=0.00454,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 20.83it/s, loss=0.00388, val_loss=0.00454,\u001b[A\n",
      "Epoch 50:  71%|▋| 57/80 [00:02<00:00, 28.38it/s, loss=0.00388, val_loss=0.00454,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.78it/s]\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 36.74it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 20.61it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 51:  71%|▋| 57/80 [00:02<00:00, 28.06it/s, loss=0.00388, val_loss=0.00452,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.24it/s]\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 36.34it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 52:  71%|▋| 57/80 [00:02<00:00, 28.25it/s, loss=0.00388, val_loss=0.00452,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.14it/s]\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00388, val_loss=0.00453,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.00388, val_loss=0.00453,\u001b[A\n",
      "Epoch 53:  71%|▋| 57/80 [00:02<00:00, 28.18it/s, loss=0.00388, val_loss=0.00453,\n",
      "Epoch 53:  95%|▉| 76/80 [00:02<00:00, 35.46it/s, loss=0.00388, val_loss=0.00453,\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 21.07it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 54:  71%|▋| 57/80 [00:01<00:00, 28.55it/s, loss=0.00388, val_loss=0.00452,\n",
      "Epoch 54:  95%|▉| 76/80 [00:02<00:00, 36.07it/s, loss=0.00388, val_loss=0.00452,\u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 37.10it/s, loss=0.00388, val_loss=0.00453,\u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 20.53it/s, loss=0.00388, val_loss=0.00453,\u001b[A\n",
      "Epoch 55:  71%|▋| 57/80 [00:02<00:00, 27.79it/s, loss=0.00388, val_loss=0.00453,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 160.73it/s]\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 36.09it/s, loss=0.00388, val_loss=0.00455,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 20.73it/s, loss=0.00389, val_loss=0.00455,\u001b[A\n",
      "Epoch 56:  71%|▋| 57/80 [00:02<00:00, 28.09it/s, loss=0.00389, val_loss=0.00455,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 170.97it/s]\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 36.39it/s, loss=0.00389, val_loss=0.00461,\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.178, val_loss=0.00461, a\u001b[A\n",
      "Epoch 57:  71%|▋| 57/80 [00:02<00:00, 28.12it/s, loss=0.178, val_loss=0.00461, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 168.78it/s]\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 36.61it/s, loss=0.178, val_loss=0.0548, av\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 21.14it/s, loss=0.0055, val_loss=0.0548, a\u001b[A\n",
      "Epoch 58:  71%|▋| 57/80 [00:01<00:00, 28.74it/s, loss=0.0055, val_loss=0.0548, a\n",
      "Epoch 58:  95%|▉| 76/80 [00:02<00:00, 36.13it/s, loss=0.0055, val_loss=0.0548, a\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 37.24it/s, loss=0.0055, val_loss=0.00584, \u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.09it/s, loss=0.00387, val_loss=0.00584,\u001b[A\n",
      "Epoch 59:  71%|▋| 57/80 [00:01<00:00, 28.74it/s, loss=0.00387, val_loss=0.00584,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.28it/s]\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00387, val_loss=0.00443,\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.07it/s, loss=0.00384, val_loss=0.00443,\u001b[A\n",
      "Epoch 60:  71%|▋| 57/80 [00:01<00:00, 28.69it/s, loss=0.00384, val_loss=0.00443,\n",
      "Epoch 60:  95%|▉| 76/80 [00:02<00:00, 36.11it/s, loss=0.00384, val_loss=0.00443,\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00384, val_loss=0.00445,\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.00384, val_loss=0.00445,\u001b[A\n",
      "Epoch 61:  71%|▋| 57/80 [00:02<00:00, 28.08it/s, loss=0.00384, val_loss=0.00445,\n",
      "Epoch 61:  95%|▉| 76/80 [00:02<00:00, 35.41it/s, loss=0.00384, val_loss=0.00445,\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00384, val_loss=0.00444,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00385, val_loss=0.00444,\u001b[A\n",
      "Epoch 62:  71%|▋| 57/80 [00:02<00:00, 28.19it/s, loss=0.00385, val_loss=0.00444,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.61it/s]\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 36.48it/s, loss=0.00385, val_loss=0.00447,\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.00387, val_loss=0.00447,\u001b[A\n",
      "Epoch 63:  71%|▋| 57/80 [00:01<00:00, 28.76it/s, loss=0.00387, val_loss=0.00447,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.38it/s]\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 37.19it/s, loss=0.00387, val_loss=0.00468,\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.20it/s, loss=0.0865, val_loss=0.00468, \u001b[A\n",
      "Epoch 64:  71%|▋| 57/80 [00:01<00:00, 28.75it/s, loss=0.0865, val_loss=0.00468, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.15it/s]\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 37.33it/s, loss=0.0865, val_loss=0.0437, a\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 20.73it/s, loss=0.00468, val_loss=0.0437, \u001b[A\n",
      "Epoch 65:  71%|▋| 57/80 [00:02<00:00, 28.17it/s, loss=0.00468, val_loss=0.0437, \n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 158.91it/s]\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 36.48it/s, loss=0.00468, val_loss=0.00454,\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.00384, val_loss=0.00454,\u001b[A\n",
      "Epoch 66:  71%|▋| 57/80 [00:02<00:00, 28.42it/s, loss=0.00384, val_loss=0.00454,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 165.76it/s]\u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 36.91it/s, loss=0.00384, val_loss=0.00445,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 21.19it/s, loss=0.00383, val_loss=0.00445,\u001b[A\n",
      "Epoch 67:  71%|▋| 57/80 [00:01<00:00, 28.80it/s, loss=0.00383, val_loss=0.00445,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.13it/s]\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 37.23it/s, loss=0.00383, val_loss=0.00445,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.00383, val_loss=0.00445,\u001b[A\n",
      "Epoch 68:  71%|▋| 57/80 [00:01<00:00, 28.82it/s, loss=0.00383, val_loss=0.00445,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 37.28it/s, loss=0.00383, val_loss=0.00448,\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 20.39it/s, loss=0.151, val_loss=0.00448, a\u001b[A\n",
      "Epoch 69:  71%|▋| 57/80 [00:02<00:00, 27.83it/s, loss=0.151, val_loss=0.00448, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.82it/s]\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 36.08it/s, loss=0.151, val_loss=0.0158, av\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.35it/s, loss=0.00506, val_loss=0.0158, \u001b[A\n",
      "Epoch 70:  71%|▋| 57/80 [00:01<00:00, 29.01it/s, loss=0.00506, val_loss=0.0158, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.86it/s]\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 37.45it/s, loss=0.00506, val_loss=0.00439,\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 20.56it/s, loss=0.00382, val_loss=0.00439,\u001b[A\n",
      "Epoch 71:  71%|▋| 57/80 [00:02<00:00, 28.01it/s, loss=0.00382, val_loss=0.00439,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 173.01it/s]\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 36.32it/s, loss=0.00382, val_loss=0.00441,\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00381, val_loss=0.00441,\u001b[A\n",
      "Epoch 72:  71%|▋| 57/80 [00:02<00:00, 27.97it/s, loss=0.00381, val_loss=0.00441,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.77it/s]\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 36.28it/s, loss=0.00381, val_loss=0.00443,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.127, val_loss=0.00443, a\u001b[A\n",
      "Epoch 73:  71%|▋| 57/80 [00:02<00:00, 27.87it/s, loss=0.127, val_loss=0.00443, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.48it/s]\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 36.11it/s, loss=0.127, val_loss=0.113, avg\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.52it/s, loss=0.00829, val_loss=0.113, a\u001b[A\n",
      "Epoch 74:  71%|▋| 57/80 [00:02<00:00, 27.97it/s, loss=0.00829, val_loss=0.113, a\n",
      "Epoch 74:  95%|▉| 76/80 [00:02<00:00, 35.22it/s, loss=0.00829, val_loss=0.113, a\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 36.26it/s, loss=0.00829, val_loss=0.00447,\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 21.09it/s, loss=0.00387, val_loss=0.00447,\u001b[A\n",
      "Epoch 75:  71%|▋| 57/80 [00:01<00:00, 28.66it/s, loss=0.00387, val_loss=0.00447,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.35it/s]\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 37.15it/s, loss=0.00387, val_loss=0.00438,\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.55it/s, loss=0.0038, val_loss=0.00438, \u001b[A\n",
      "Epoch 76:  71%|▋| 57/80 [00:02<00:00, 28.00it/s, loss=0.0038, val_loss=0.00438, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 170.98it/s]\u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.29it/s, loss=0.0038, val_loss=0.00441, \u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.131, val_loss=0.00441, a\u001b[A\n",
      "Epoch 77:  71%|▋| 57/80 [00:02<00:00, 28.46it/s, loss=0.131, val_loss=0.00441, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 170.03it/s]\u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.131, val_loss=0.134, avg\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.59it/s, loss=0.00629, val_loss=0.134, a\u001b[A\n",
      "Epoch 78:  71%|▋| 57/80 [00:02<00:00, 27.90it/s, loss=0.00629, val_loss=0.134, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 166.19it/s]\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 36.35it/s, loss=0.00629, val_loss=0.00489,\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00382, val_loss=0.00489,\u001b[A\n",
      "Epoch 79:  71%|▋| 57/80 [00:02<00:00, 27.52it/s, loss=0.00382, val_loss=0.00489,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.37it/s]\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 35.78it/s, loss=0.00382, val_loss=0.00428,\u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.0038, val_loss=0.00428, \u001b[A\n",
      "Epoch 80:  71%|▋| 57/80 [00:02<00:00, 28.46it/s, loss=0.0038, val_loss=0.00428, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.60it/s]\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.0038, val_loss=0.00425, \u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 20.44it/s, loss=0.123, val_loss=0.00425, a\u001b[A\n",
      "Epoch 81:  71%|▋| 57/80 [00:02<00:00, 27.77it/s, loss=0.123, val_loss=0.00425, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 157.25it/s]\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.123, val_loss=0.176, avg\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.57it/s, loss=0.00826, val_loss=0.176, a\u001b[A\n",
      "Epoch 82:  71%|▋| 57/80 [00:02<00:00, 28.05it/s, loss=0.00826, val_loss=0.176, a\n",
      "Epoch 82:  95%|▉| 76/80 [00:02<00:00, 35.27it/s, loss=0.00826, val_loss=0.176, a\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.30it/s, loss=0.00826, val_loss=0.0057, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.40it/s, loss=0.00384, val_loss=0.0057, \u001b[A\n",
      "Epoch 83:  71%|▋| 57/80 [00:02<00:00, 27.76it/s, loss=0.00384, val_loss=0.0057, \n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 163.08it/s]\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 35.86it/s, loss=0.00384, val_loss=0.0042, \u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00377, val_loss=0.0042, \u001b[A\n",
      "Epoch 84:  71%|▋| 57/80 [00:02<00:00, 27.94it/s, loss=0.00377, val_loss=0.0042, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.16it/s]\u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 36.30it/s, loss=0.00377, val_loss=0.00423,\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 21.28it/s, loss=0.00381, val_loss=0.00423,\u001b[A\n",
      "Epoch 85:  71%|▋| 57/80 [00:01<00:00, 28.98it/s, loss=0.00381, val_loss=0.00423,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.37it/s]\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 37.34it/s, loss=0.00381, val_loss=0.0044, \u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.116, val_loss=0.0044, av\u001b[A\n",
      "Epoch 86:  71%|▋| 57/80 [00:02<00:00, 28.42it/s, loss=0.116, val_loss=0.0044, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 157.63it/s]\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.116, val_loss=0.0336, av\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00478, val_loss=0.0336, \u001b[A\n",
      "Epoch 87:  71%|▋| 57/80 [00:01<00:00, 28.50it/s, loss=0.00478, val_loss=0.0336, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.14it/s]\u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 36.88it/s, loss=0.00478, val_loss=0.00426,\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00378, val_loss=0.00426,\u001b[A\n",
      "Epoch 88:  71%|▋| 57/80 [00:01<00:00, 29.36it/s, loss=0.00378, val_loss=0.00426,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 174.71it/s]\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00378, val_loss=0.00418,\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.027, val_loss=0.00418, a\u001b[A\n",
      "Epoch 89:  71%|▋| 57/80 [00:01<00:00, 28.50it/s, loss=0.027, val_loss=0.00418, a\n",
      "Epoch 89:  95%|▉| 76/80 [00:02<00:00, 35.82it/s, loss=0.027, val_loss=0.00418, a\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 36.87it/s, loss=0.027, val_loss=0.288, avg\u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 21.32it/s, loss=0.0144, val_loss=0.288, av\u001b[A\n",
      "Epoch 90:  71%|▋| 57/80 [00:01<00:00, 28.94it/s, loss=0.0144, val_loss=0.288, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 172.17it/s]\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 37.40it/s, loss=0.0144, val_loss=0.0061, a\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 21.16it/s, loss=0.00392, val_loss=0.0061, \u001b[A\n",
      "Epoch 91:  71%|▋| 57/80 [00:01<00:00, 28.81it/s, loss=0.00392, val_loss=0.0061, \n",
      "Epoch 91:  95%|▉| 76/80 [00:02<00:00, 36.22it/s, loss=0.00392, val_loss=0.0061, \u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 37.25it/s, loss=0.00392, val_loss=0.0042, \u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00741, val_loss=0.0042, \u001b[A\n",
      "Epoch 92:  71%|▋| 57/80 [00:01<00:00, 29.27it/s, loss=0.00741, val_loss=0.0042, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.86it/s]\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 37.79it/s, loss=0.00741, val_loss=0.0539, \u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.0171, val_loss=0.0539, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93:  71%|▋| 57/80 [00:01<00:00, 28.68it/s, loss=0.0171, val_loss=0.0539, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 182.37it/s]\u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 37.21it/s, loss=0.0171, val_loss=0.00936, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 21.25it/s, loss=0.00394, val_loss=0.00936,\u001b[A\n",
      "Epoch 94:  71%|▋| 57/80 [00:01<00:00, 28.87it/s, loss=0.00394, val_loss=0.00936,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.25it/s]\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 37.41it/s, loss=0.00394, val_loss=0.00409,\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.00374, val_loss=0.00409,\u001b[A\n",
      "Epoch 95:  71%|▋| 57/80 [00:01<00:00, 29.27it/s, loss=0.00374, val_loss=0.00409,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.91it/s]\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 37.81it/s, loss=0.00374, val_loss=0.00404,\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.0168, val_loss=0.00404, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  71%|▋| 57/80 [00:02<00:00, 28.48it/s, loss=0.0168, val_loss=0.00404, \u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 37.02it/s, loss=0.0168, val_loss=0.188, av\u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 21.09it/s, loss=0.0195, val_loss=0.188, av\u001b[A\n",
      "Epoch 97:  71%|▋| 57/80 [00:01<00:00, 28.66it/s, loss=0.0195, val_loss=0.188, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 181.04it/s]\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 37.15it/s, loss=0.0195, val_loss=0.0115, a\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00394, val_loss=0.0115, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  71%|▋| 57/80 [00:02<00:00, 28.26it/s, loss=0.00394, val_loss=0.0115, \u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 36.76it/s, loss=0.00394, val_loss=0.0039, \u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00372, val_loss=0.0039, \u001b[A\n",
      "Epoch 99:  71%|▋| 57/80 [00:02<00:00, 28.25it/s, loss=0.00372, val_loss=0.0039, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 176.53it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00372, val_loss=0.00386,\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00372, val_loss=0.00386,\u001b[A\n",
      "Sizes of clusters: 307, 636, 267, 265, 525\n",
      "\n",
      "preds: [2 2 2 2 2 0 2 4 2 0 2 2 2 2 0 2 0 2 2 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2\n",
      " 2 0 2 2 2 4 2 0 0 2 2 2 0 2 4 2 2 2 1 2 2 2 4 0 2 2 2 2 2 2 2 2 0 1 0 4 2\n",
      " 0 0 0 2 2 0 0 2 0 0 0 2 2 2 2 2 0 2 2 2 0 4 0 0 2 0 0 4 2 0 0 2 2 2 2 0 2\n",
      " 0 2 4 2 2 2 2 2 2 2 0 2 0 2 2 2 4 2 0 0 0 0 2 4 0 0 2 0 2 0 4 0 0 2 4 2 0\n",
      " 2 2 0 2 0 0 2 2 2 2 2 2 2 2 2 2 2 0 0 4 2 4 2 0 2 0 2 4 0 2 2 2 2 2 2 2 2\n",
      " 2 0 2 0 2 2 0 4 2 2 0 2 2 2 2 2 0 2 0 0 2 2 0 2 2 0 4 0 2 2 0 0 2 2 4 2 2\n",
      " 2 0 4 2 2 2 2 0 2 0 4 0 2 1 2 2 2 2 0 0 2 4 0 2 2 2 4 0 0 0 0 2 0 2 0 0 2\n",
      " 0 2 0 2 0 0 0 0 2 2 0 2 0 2 0 2 2 2 0 2 0 2 2 4 2 0 2 0 2 0 2 2 0 2 0 2 2\n",
      " 2 2 0 2 0 2 0 2 2 2 1 0 2 2 2 0 0 0 2 2 2 4 2 2 2 4 2 2 2 4 2 2 2 4 2 2 4\n",
      " 2 0 0 2 2 2 0 0 2 0 2 4 2 0 2 0 2 2 2 2 0 0 0 0 0 0 2 2 0 2 0 2 2 4 0 0 2\n",
      " 0 2 2 2 2 2 2 0 2 2 2 0 2 2 1 0 2 2 4 0 2 4 0 0 2 2 0 4 2 0 4 0 1 4 1 3 4\n",
      " 3 1 1 4 4 4 4 0 3 1 4 1 3 3 3 1 1 4 0 1 1 4 1 2 3 4 4 4 4 1 1 1 3 1 1 4 4\n",
      " 1 1 1 4 1 4 1 1 1 4 1 4 1 4 3 0 1 0 1 4 1 4 1 1 4 4 4 4 3 4 0 1 4 1 0 4 1\n",
      " 1 4 1 3 4 1 0 1 1 0 4 1 1 4 1 1 1 4 4 1 1 1 0 4 0 0 4 1 0 0 4 1 1 3 1 4 3\n",
      " 3 1 4 4 4 4 1 1 0 0 1 1 1 1 4 1 1 1 3 4 1 4 0 1 4 4 1 0 1 4 1 4 0 4 1 4 4\n",
      " 4 1 0 1 1 0 4 0 4 3 1 4 0 4 0 4 1 1 4 0 3 3 3 1 1 4 0 1 1 2 0 4 4 3 4 4 0\n",
      " 4 1 1 4 3 0 2 1 4 0 4 1 1 4 1 3 0 1 1 3 3 1 1 1 4 1 4 0 4 2 0 0 0 1 1 3 1\n",
      " 1 1 0 2 1 0 1 1 4 2 4 3 1 0 1 1 4 4 4 0 3 0 4 1 3 3 1 1 1 1 4 4 3 0 4 3 0\n",
      " 2 1 0 4 1 4 1 3 1 4 4 4 0 1 1 4 0 0 1 0 1 1 1 3 4 4 1 4 3 0 4 3 3 0 4 1 4\n",
      " 4 0 1 3 1 0 4 1 1 1 3 4 4 1 0 4 3 0 1 0 3 1 1 1 1 1 1 1 3 3 4 1 3 1 3 0 1\n",
      " 4 0 1 0 3 4 0 1 1 4 4 4 4 1 0 1 4 1 0 4 1 4 4 2 3 1 1 3 1 1 4 1 1 1 1 1 1\n",
      " 4 1 3 3 4 4 3 1 1 3 1 0 4 3 3 1 3 3 0 4 4 4 1 4 0 4 4 3 4 3 1 4 4 1 4 0 1\n",
      " 3 4 4 4 4 4 4 4 4 1 4 3 1 4 1 1 4 4 4 4 1 1 4 2 0 0 4 3 1 1 1 3 4 4 1 4 1\n",
      " 4 3 1 0 1 4 4 3 4 4 4 3 3 2 1 1 4 4 4 4 3 1 1 1 1 3 1 1 4 1 4 3 3 3 3 1 1\n",
      " 4 4 1 4 4 4 0 4 4 3 1 4 1 1 1 3 4 1 4 4 1 4 1 3 1 4 3 3 2 4 1 1 4 4 3 1 4\n",
      " 1 0 4 3 1 0 4 0 1 4 1 4 0 4 1 4 1 4 1 4 1 4 4 1 1 0 4 0 4 4 4 4 0 4 3 1 4\n",
      " 1 1 0 4 1 0 4 4 4 4 4 1 1 1 4 1 4 3 3 3 0 4 1 1 4 3 4 4 4 1 1 4 4 1 4 4 3\n",
      " 1 3 4 4 1 0 1 4 4 4 0 4 1 4 4 1 4 3 3 1 4 1 4 0 4 1 1 4 3 4 4 1 4 4 4 1 1\n",
      " 0 1 1 0 0 1 4 1 4 1 3 1 0 4 4 4 3 4 4 4 3 0 3 1 1 0 1 1 0 4 1 4 1 3 3 1 1\n",
      " 1 4 0 1 1 3 4 4 4 3 0 4 4 3 4 4 3 4 4 3 4 1 4 3 1 3 3 0 4 3 3 1 1 1 3 1 1\n",
      " 4 1 1 0 4 4 1 4 4 4 4 0 4 4 4 1 4 1 0 0 3 4 1 1 0 0 4 0 3 1 4 1 3 1 3 4 4\n",
      " 3 1 1 4 1 2 4 3 1 4 4 1 4 1 1 3 1 3 4 3 1 3 0 1 1 4 3 4 4 0 3 1 1 1 4 4 4\n",
      " 1 4 1 1 1 4 1 4 1 4 1 1 4 1 4 1 1 1 1 4 4 0 1 4 0 1 4 1 4 4 1 1 0 0 3 4 1\n",
      " 4 3 1 4 4 4 4 1 0 0 3 1 1 2 4 1 4 3 1 4 4 4 0 4 4 4 1 1 1 0 2 4 1 1 1 0 4\n",
      " 0 4 1 0 4 4 1 1 1 1 4 4 1 1 4 4 4 3 1 4 0 4 4 4 4 1 1 1 3 1 0 1 4 1 3 2 1\n",
      " 4 1 1 4 4 1 1 1 4 1 0 3 4 4 4 4 0 0 1 4 1 1 4 4 1 1 4 4 0 4 4 3 0 3 4 2 1\n",
      " 4 3 0 4 4 0 0 1 1 4 4 3 1 0 1 4 3 1 4 1 4 1 2 0 0 0 0 4 1 4 1 1 1 2 2 1 4\n",
      " 1 4 4 1 1 0 4 0 4 4 4 0 1 1 0 4 4 1 1 4 4 4 1 1 4 4 4 4 0 4 1 1 4 1 4 1 1\n",
      " 1 1 2 1 4 1 1 0 4 0 4 4 4 4 4 0 3 1 1 3 1 4 3 3 3 4 0 4 1 1 4 4 0 2 0 0 1\n",
      " 1 4 4 2 4 1 0 3 3 0 1 1 0 4 0 1 4 1 4 1 0 4 1 3 4 4 3 4 0 1 4 0 1 0 4 4 2\n",
      " 4 1 1 4 4 1 1 2 0 4 1 3 4 1 1 0 1 0 0 1 2 4 4 0 3 1 1 1 1 1 1 0 1 0 4 4 4\n",
      " 4 0 2 1 0 3 0 0 1 1 1 4 4 0 1 0 4 1 4 1 3 0 1 4 4 4 4 4 2 1 1 4 1 1 0 1 4\n",
      " 4 0 1 1 4 0 4 0 0 4 4 3 1 4 4 1 2 1 0 2 1 2 4 1 1 4 0 1 1 4 4 0 4 4 0 2 3\n",
      " 4 4 4 4 0 4 1 4 4 1 1 3 3 1 1 3 1 1 1 1 3 1 1 3 1 4 1 1 3 4 3 4 3 3 1 1 1\n",
      " 1 1 3 1 1 1 1 1 1 4 1 4 1 3 1 3 1 1 4 3 3 3 1 3 0 3 1 1 3 1 4 1 4 1 1 1 3\n",
      " 3 4 1 1 1 0 1 1 1 3 3 1 2 1 0 0 3 1 4 4 3 3 1 1 3 4 3 1 3 3 4 1 3 1 1 1 1\n",
      " 3 1 3 1 1 3 3 3 1 1 1 1 1 3 4 1 3 4 3 1 3 1 1 1 1 3 1 4 1 3 1 3 1 4 1 3 1\n",
      " 1 1 1 1 3 3 3 4 3 1 3 0 1 3 3 3 3 1 1 3 1 1 1 1 1 1 1 4 4 3 1 0 1 1 1 1 3\n",
      " 3 3 3 1 1 1 1 1 1 1 4 1 3 4 3 3 1 3 3 1 1 1 3 0 1 1 1 3 3 1 1 4 4 1 3 3 1\n",
      " 1 3 4 4 1 1 3 1 3 1 1 4 1 4 4 1 4 1 1 1 1 4 1 1 1 1 3 3 1 1 3 1 1 1 4 3 1\n",
      " 4 4 1 1 3 4 4 3 3 3 3 4 4 1 1 1 1 3 3 4 3 3 1 1 3 1 1 0 1 4 1 1 3 4 1 3 1\n",
      " 1 1 1 3 1 1 4 4 1 1 3 1 3 1 4 0 1 1 1 3 3 1 1 3 1 3 3 4 1 4 3 3 1 1 1 4 1\n",
      " 4 1 3 1 1 0 0 1 4 1 1 1 4 3 1 3 4 1 3 1 3 3 0 1 3 4 1 1 3 3 3 4 1 1 1 1 3\n",
      " 1 3 2 3 4 3 1 1 1 1 3 3 4 1 3 1 1 1 3 4 1 3 1 1 1 1 3 3 4 4 1 3 1 3 1 1 1\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.4255\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.886, val_loss=0.062, avg_\n",
      "Epoch 0:  60%|▌| 48/80 [00:01<00:01, 24.29it/s, loss=0.886, val_loss=0.062, avg_\n",
      "Epoch 0:  81%|▊| 65/80 [00:02<00:00, 31.21it/s, loss=0.886, val_loss=0.062, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 36.49it/s, loss=0.886, val_loss=1.13, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 20.41it/s, loss=0.0425, val_loss=1.13, avg_\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:02<00:01, 25.32it/s, loss=0.0425, val_loss=1.13, avg_\n",
      "Epoch 1:  85%|▊| 68/80 [00:02<00:00, 32.11it/s, loss=0.0425, val_loss=1.13, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 36.09it/s, loss=0.0425, val_loss=0.0382, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.0209, val_loss=0.0382, av\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 26.03it/s, loss=0.0209, val_loss=0.0382, av\n",
      "Epoch 2:  85%|▊| 68/80 [00:02<00:00, 32.77it/s, loss=0.0209, val_loss=0.0382, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.96it/s, loss=0.0209, val_loss=0.0267, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.87it/s, loss=0.016, val_loss=0.0267, avg\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 25.94it/s, loss=0.016, val_loss=0.0267, avg\n",
      "Epoch 3:  85%|▊| 68/80 [00:02<00:00, 32.80it/s, loss=0.016, val_loss=0.0267, avg\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.016, val_loss=0.0214, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.0132, val_loss=0.0214, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 25.91it/s, loss=0.0132, val_loss=0.0214, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:02<00:00, 32.76it/s, loss=0.0132, val_loss=0.0214, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.76it/s, loss=0.0132, val_loss=0.0172, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.04it/s, loss=0.0112, val_loss=0.0172, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 26.14it/s, loss=0.0112, val_loss=0.0172, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:02<00:00, 33.04it/s, loss=0.0112, val_loss=0.0172, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 36.98it/s, loss=0.0112, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.0097, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 26.02it/s, loss=0.0097, val_loss=0.0141, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:02<00:00, 32.89it/s, loss=0.0097, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.92it/s, loss=0.0097, val_loss=0.0119, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.0085, val_loss=0.0119, av\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 26.05it/s, loss=0.0085, val_loss=0.0119, av\n",
      "Epoch 7:  85%|▊| 68/80 [00:02<00:00, 32.77it/s, loss=0.0085, val_loss=0.0119, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 36.96it/s, loss=0.0085, val_loss=0.0102, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00754, val_loss=0.0102, a\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 25.66it/s, loss=0.00754, val_loss=0.0102, a\n",
      "Epoch 8:  85%|▊| 68/80 [00:02<00:00, 32.45it/s, loss=0.00754, val_loss=0.0102, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 36.44it/s, loss=0.00754, val_loss=0.00909, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.57it/s, loss=0.00676, val_loss=0.00909, \u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:02<00:01, 25.40it/s, loss=0.00676, val_loss=0.00909, \n",
      "Epoch 9:  85%|▊| 68/80 [00:02<00:00, 32.18it/s, loss=0.00676, val_loss=0.00909, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 36.19it/s, loss=0.00676, val_loss=0.00815, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.94it/s, loss=0.00614, val_loss=0.00815,\u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 25.94it/s, loss=0.00614, val_loss=0.00815,\n",
      "Epoch 10:  85%|▊| 68/80 [00:02<00:00, 32.72it/s, loss=0.00614, val_loss=0.00815,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.00614, val_loss=0.00742,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.00565, val_loss=0.00742,\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 25.94it/s, loss=0.00565, val_loss=0.00742,\n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 32.80it/s, loss=0.00565, val_loss=0.00742,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 36.89it/s, loss=0.00565, val_loss=0.00691,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00527, val_loss=0.00691,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 25.87it/s, loss=0.00527, val_loss=0.00691,\n",
      "Epoch 12:  85%|▊| 68/80 [00:02<00:00, 32.80it/s, loss=0.00527, val_loss=0.00691,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.00527, val_loss=0.00651,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.38it/s, loss=0.00497, val_loss=0.00651,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 26.40it/s, loss=0.00497, val_loss=0.00651,\n",
      "Epoch 13:  86%|▊| 69/80 [00:02<00:00, 33.92it/s, loss=0.00497, val_loss=0.00651,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.61it/s, loss=0.00497, val_loss=0.00619,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00475, val_loss=0.00619,\u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 27.01it/s, loss=0.00475, val_loss=0.00619,\n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 34.03it/s, loss=0.00475, val_loss=0.00619,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00475, val_loss=0.00596,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00458, val_loss=0.00596,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:01<00:00, 27.50it/s, loss=0.00458, val_loss=0.00596,\n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 34.67it/s, loss=0.00458, val_loss=0.00596,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00458, val_loss=0.00585,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00445, val_loss=0.00585,\u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.00445, val_loss=0.00585,\n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 34.02it/s, loss=0.00445, val_loss=0.00585,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 36.61it/s, loss=0.00445, val_loss=0.00582,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.00435, val_loss=0.00582,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:02<00:00, 26.73it/s, loss=0.00435, val_loss=0.00582,\n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 33.75it/s, loss=0.00435, val_loss=0.00582,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 36.23it/s, loss=0.00435, val_loss=0.00597,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.25it/s, loss=0.00428, val_loss=0.00597,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:01<00:00, 27.46it/s, loss=0.00428, val_loss=0.00597,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 34.64it/s, loss=0.00428, val_loss=0.00597,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 37.20it/s, loss=0.00428, val_loss=0.00604,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.00422, val_loss=0.00604,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:02<00:00, 26.87it/s, loss=0.00422, val_loss=0.00604,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 33.97it/s, loss=0.00422, val_loss=0.00604,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 36.47it/s, loss=0.00422, val_loss=0.00627,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00418, val_loss=0.00627,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:01<00:00, 27.18it/s, loss=0.00418, val_loss=0.00627,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.00418, val_loss=0.00627,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.00418, val_loss=0.00644,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.42it/s, loss=0.00414, val_loss=0.00644,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:02<00:00, 26.55it/s, loss=0.00414, val_loss=0.00644,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 33.57it/s, loss=0.00414, val_loss=0.00644,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 36.04it/s, loss=0.00414, val_loss=0.00641,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.0041, val_loss=0.00641, \u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 27.24it/s, loss=0.0041, val_loss=0.00641, \n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 34.42it/s, loss=0.0041, val_loss=0.00641, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 36.96it/s, loss=0.0041, val_loss=0.00656, \u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00407, val_loss=0.00656,\u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:02<00:00, 26.51it/s, loss=0.00407, val_loss=0.00656,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 33.41it/s, loss=0.00407, val_loss=0.00656,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.04it/s, loss=0.00407, val_loss=0.00675,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.19it/s, loss=0.00405, val_loss=0.00675,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 27.40it/s, loss=0.00405, val_loss=0.00675,\n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 34.49it/s, loss=0.00405, val_loss=0.00675,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00405, val_loss=0.00682,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00403, val_loss=0.00682,\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 27.04it/s, loss=0.00403, val_loss=0.00682,\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 34.01it/s, loss=0.00403, val_loss=0.00682,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 36.61it/s, loss=0.00403, val_loss=0.00701,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00401, val_loss=0.00701,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:02<00:00, 26.98it/s, loss=0.00401, val_loss=0.00701,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 34.04it/s, loss=0.00401, val_loss=0.00701,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00401, val_loss=0.00723,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.95it/s, loss=0.00399, val_loss=0.00723,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.00399, val_loss=0.00723,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 34.42it/s, loss=0.00399, val_loss=0.00723,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.00399, val_loss=0.00746,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.62it/s, loss=0.00397, val_loss=0.00746,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:02<00:00, 26.85it/s, loss=0.00397, val_loss=0.00746,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 33.90it/s, loss=0.00397, val_loss=0.00746,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 36.36it/s, loss=0.00397, val_loss=0.00769,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00396, val_loss=0.00769,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 27.01it/s, loss=0.00396, val_loss=0.00769,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 34.08it/s, loss=0.00396, val_loss=0.00769,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 36.50it/s, loss=0.00396, val_loss=0.00788,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.21it/s, loss=0.00394, val_loss=0.00788,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 27.57it/s, loss=0.00394, val_loss=0.00788,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 34.71it/s, loss=0.00394, val_loss=0.00788,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 37.29it/s, loss=0.00394, val_loss=0.00816,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00393, val_loss=0.00816,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.00393, val_loss=0.00816,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 34.26it/s, loss=0.00393, val_loss=0.00816,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 36.68it/s, loss=0.00393, val_loss=0.00842,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.00392, val_loss=0.00842,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:02<00:00, 26.59it/s, loss=0.00392, val_loss=0.00842,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 33.56it/s, loss=0.00392, val_loss=0.00842,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 36.05it/s, loss=0.00392, val_loss=0.00871,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 20.55it/s, loss=0.00391, val_loss=0.00871,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:02<00:00, 26.71it/s, loss=0.00391, val_loss=0.00871,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 33.76it/s, loss=0.00391, val_loss=0.00871,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 36.26it/s, loss=0.00391, val_loss=0.00891,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00391, val_loss=0.00891,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 27.12it/s, loss=0.00391, val_loss=0.00891,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 34.29it/s, loss=0.00391, val_loss=0.00891,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.78it/s, loss=0.00391, val_loss=0.00913,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.0039, val_loss=0.00913, \u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 27.66it/s, loss=0.0039, val_loss=0.00913, \n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 34.97it/s, loss=0.0039, val_loss=0.00913, \u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 37.50it/s, loss=0.0039, val_loss=0.0094, a\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.00389, val_loss=0.0094, \u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.00389, val_loss=0.0094, \n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 33.93it/s, loss=0.00389, val_loss=0.0094, \u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 36.54it/s, loss=0.00389, val_loss=0.0096, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00389, val_loss=0.0096, \u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 27.28it/s, loss=0.00389, val_loss=0.0096, \n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 34.40it/s, loss=0.00389, val_loss=0.0096, \u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 36.92it/s, loss=0.00389, val_loss=0.00992,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 20.52it/s, loss=0.00388, val_loss=0.00992,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:02<00:00, 26.71it/s, loss=0.00388, val_loss=0.00992,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 33.63it/s, loss=0.00388, val_loss=0.00992,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 36.21it/s, loss=0.00388, val_loss=0.0102, \u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00388, val_loss=0.0102, \u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 27.12it/s, loss=0.00388, val_loss=0.0102, \n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 34.34it/s, loss=0.00388, val_loss=0.0102, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 36.84it/s, loss=0.00388, val_loss=0.0105, \u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.00387, val_loss=0.0105, \u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00387, val_loss=0.0105, \n",
      "Epoch 40:  90%|▉| 72/80 [00:02<00:00, 34.28it/s, loss=0.00387, val_loss=0.0105, \u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.00387, val_loss=0.0107, \u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 20.82it/s, loss=0.00387, val_loss=0.0107, \u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:02<00:00, 26.97it/s, loss=0.00387, val_loss=0.0107, \n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 33.98it/s, loss=0.00387, val_loss=0.0107, \u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 36.65it/s, loss=0.00387, val_loss=0.0111, \u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00386, val_loss=0.0111, \u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:02<00:00, 26.96it/s, loss=0.00386, val_loss=0.0111, \n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 33.98it/s, loss=0.00386, val_loss=0.0111, \u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 36.51it/s, loss=0.00386, val_loss=0.0113, \u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 20.69it/s, loss=0.00386, val_loss=0.0113, \u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:02<00:00, 26.94it/s, loss=0.00386, val_loss=0.0113, \n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.00386, val_loss=0.0113, \u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00386, val_loss=0.0116, \u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.87it/s, loss=0.00386, val_loss=0.0116, \u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00386, val_loss=0.0116, \n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 34.23it/s, loss=0.00386, val_loss=0.0116, \u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 36.79it/s, loss=0.00386, val_loss=0.0119, \u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.00386, val_loss=0.0119, \u001b[A\n",
      "Epoch 45:  68%|▋| 54/80 [00:02<00:00, 26.95it/s, loss=0.00386, val_loss=0.0119, \n",
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 34.02it/s, loss=0.00386, val_loss=0.0119, \u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 36.60it/s, loss=0.00386, val_loss=0.0122, \u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00386, val_loss=0.0122, \u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:02<00:00, 26.91it/s, loss=0.00386, val_loss=0.0122, \n",
      "Epoch 46:  90%|▉| 72/80 [00:02<00:00, 34.06it/s, loss=0.00386, val_loss=0.0122, \u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00386, val_loss=0.0125, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 21.29it/s, loss=0.00385, val_loss=0.0125, \u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:01<00:00, 27.68it/s, loss=0.00385, val_loss=0.0125, \n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 34.89it/s, loss=0.00385, val_loss=0.0125, \u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 37.42it/s, loss=0.00385, val_loss=0.0128, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00385, val_loss=0.0128, \u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:02<00:00, 26.42it/s, loss=0.00385, val_loss=0.0128, \n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 33.44it/s, loss=0.00385, val_loss=0.0128, \u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 35.91it/s, loss=0.00385, val_loss=0.0132, \u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00385, val_loss=0.0132, \u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:01<00:00, 27.39it/s, loss=0.00385, val_loss=0.0132, \n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 34.54it/s, loss=0.00385, val_loss=0.0132, \u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 37.05it/s, loss=0.00385, val_loss=0.0136, \u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00385, val_loss=0.0136, \u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.00385, val_loss=0.0136, \n",
      "Epoch 50:  90%|▉| 72/80 [00:02<00:00, 34.33it/s, loss=0.00385, val_loss=0.0136, \u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 36.90it/s, loss=0.00385, val_loss=0.0138, \u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.00385, val_loss=0.0138, \u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.00385, val_loss=0.0138, \n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 34.42it/s, loss=0.00385, val_loss=0.0138, \u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.00385, val_loss=0.0141, \u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.86it/s, loss=0.00385, val_loss=0.0141, \u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:01<00:00, 27.11it/s, loss=0.00385, val_loss=0.0141, \n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 34.18it/s, loss=0.00385, val_loss=0.0141, \u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 36.69it/s, loss=0.00385, val_loss=0.0143, \u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00385, val_loss=0.0143, \u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:01<00:00, 27.07it/s, loss=0.00385, val_loss=0.0143, \n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 34.15it/s, loss=0.00385, val_loss=0.0143, \u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 36.56it/s, loss=0.00385, val_loss=0.0147, \u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00385, val_loss=0.0147, \u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:01<00:00, 27.16it/s, loss=0.00385, val_loss=0.0147, \n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 34.25it/s, loss=0.00385, val_loss=0.0147, \u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 36.68it/s, loss=0.00385, val_loss=0.0151, \u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.00385, val_loss=0.0151, \u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:02<00:00, 26.99it/s, loss=0.00385, val_loss=0.0151, \n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 34.00it/s, loss=0.00385, val_loss=0.0151, \u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 36.58it/s, loss=0.00385, val_loss=0.0155, \u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 20.44it/s, loss=0.00385, val_loss=0.0155, \u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:02<00:00, 26.53it/s, loss=0.00385, val_loss=0.0155, \n",
      "Epoch 56:  90%|▉| 72/80 [00:02<00:00, 33.46it/s, loss=0.00385, val_loss=0.0155, \u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 35.99it/s, loss=0.00385, val_loss=0.0158, \u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.00385, val_loss=0.0158, \u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:02<00:00, 26.83it/s, loss=0.00385, val_loss=0.0158, \n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 34.00it/s, loss=0.00385, val_loss=0.0158, \u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 36.33it/s, loss=0.00385, val_loss=0.0161, \u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00385, val_loss=0.0161, \u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:01<00:00, 27.48it/s, loss=0.00385, val_loss=0.0161, \n",
      "Epoch 58:  90%|▉| 72/80 [00:02<00:00, 34.61it/s, loss=0.00385, val_loss=0.0161, \u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 37.16it/s, loss=0.00385, val_loss=0.0165, \u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00385, val_loss=0.0165, \u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:01<00:00, 27.19it/s, loss=0.00385, val_loss=0.0165, \n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 34.29it/s, loss=0.00385, val_loss=0.0165, \u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 36.80it/s, loss=0.00385, val_loss=0.0168, \u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.00385, val_loss=0.0168, \u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:01<00:00, 27.37it/s, loss=0.00385, val_loss=0.0168, \n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 34.53it/s, loss=0.00385, val_loss=0.0168, \u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 37.04it/s, loss=0.00385, val_loss=0.0172, \u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.33it/s, loss=0.00386, val_loss=0.0172, \u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:02<00:00, 26.52it/s, loss=0.00386, val_loss=0.0172, \n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 33.41it/s, loss=0.00386, val_loss=0.0172, \u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 35.91it/s, loss=0.00386, val_loss=0.0174, \u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.00386, val_loss=0.0174, \u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:01<00:00, 27.16it/s, loss=0.00386, val_loss=0.0174, \n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 34.10it/s, loss=0.00386, val_loss=0.0174, \u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 36.75it/s, loss=0.00386, val_loss=0.018, a\u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.106, val_loss=0.018, avg\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:02<00:00, 26.59it/s, loss=0.106, val_loss=0.018, avg\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 33.66it/s, loss=0.106, val_loss=0.018, avg\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.106, val_loss=0.128, avg\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.00604, val_loss=0.128, a\u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:01<00:00, 27.10it/s, loss=0.00604, val_loss=0.128, a\n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 34.18it/s, loss=0.00604, val_loss=0.128, a\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 36.60it/s, loss=0.00604, val_loss=0.0192, \u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00388, val_loss=0.0192, \u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:01<00:00, 27.07it/s, loss=0.00388, val_loss=0.0192, \n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 34.16it/s, loss=0.00388, val_loss=0.0192, \u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00388, val_loss=0.0175, \u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 20.61it/s, loss=0.00385, val_loss=0.0175, \u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:02<00:00, 26.75it/s, loss=0.00385, val_loss=0.0175, \n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 33.81it/s, loss=0.00385, val_loss=0.0175, \u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 36.29it/s, loss=0.00385, val_loss=0.018, a\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 20.41it/s, loss=0.00385, val_loss=0.018, a\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:02<00:00, 26.55it/s, loss=0.00385, val_loss=0.018, a\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 33.61it/s, loss=0.00385, val_loss=0.018, a\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 36.09it/s, loss=0.00385, val_loss=0.0185, \u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.00385, val_loss=0.0185, \u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:01<00:00, 27.31it/s, loss=0.00385, val_loss=0.0185, \n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 34.44it/s, loss=0.00385, val_loss=0.0185, \u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 36.94it/s, loss=0.00385, val_loss=0.0188, \u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.139, val_loss=0.0188, av\u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:01<00:00, 27.45it/s, loss=0.139, val_loss=0.0188, av\n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 34.61it/s, loss=0.139, val_loss=0.0188, av\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 37.13it/s, loss=0.139, val_loss=0.224, avg\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.16it/s, loss=0.00818, val_loss=0.224, a\u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:01<00:00, 27.45it/s, loss=0.00818, val_loss=0.224, a\n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 34.55it/s, loss=0.00818, val_loss=0.224, a\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 37.26it/s, loss=0.00818, val_loss=0.0212, \u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 20.96it/s, loss=0.0039, val_loss=0.0212, a\u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:01<00:00, 27.25it/s, loss=0.0039, val_loss=0.0212, a\n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 34.37it/s, loss=0.0039, val_loss=0.0212, a\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 36.89it/s, loss=0.0039, val_loss=0.0176, a\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 20.87it/s, loss=0.00384, val_loss=0.0176, \u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:01<00:00, 27.01it/s, loss=0.00384, val_loss=0.0176, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 33.98it/s, loss=0.00384, val_loss=0.0176, \u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 36.71it/s, loss=0.00384, val_loss=0.018, a\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 20.87it/s, loss=0.00384, val_loss=0.018, a\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00384, val_loss=0.018, a\n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 34.04it/s, loss=0.00384, val_loss=0.018, a\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 36.73it/s, loss=0.00384, val_loss=0.0184, \u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.76it/s, loss=0.00385, val_loss=0.0184, \u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:02<00:00, 26.79it/s, loss=0.00385, val_loss=0.0184, \n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 33.94it/s, loss=0.00385, val_loss=0.0184, \u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00385, val_loss=0.0189, \u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 20.69it/s, loss=0.116, val_loss=0.0189, av\u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.116, val_loss=0.0189, av\n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 33.84it/s, loss=0.116, val_loss=0.0189, av\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 36.38it/s, loss=0.116, val_loss=0.0376, av\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.0049, val_loss=0.0376, a\u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.0049, val_loss=0.0376, a\n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 33.87it/s, loss=0.0049, val_loss=0.0376, a\u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.24it/s, loss=0.0049, val_loss=0.0187, a\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.00385, val_loss=0.0187, \u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:01<00:00, 27.40it/s, loss=0.00385, val_loss=0.0187, \n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 34.40it/s, loss=0.00385, val_loss=0.0187, \u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 36.97it/s, loss=0.00385, val_loss=0.018, a\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.133, val_loss=0.018, avg\u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:01<00:00, 27.21it/s, loss=0.133, val_loss=0.018, avg\n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 34.28it/s, loss=0.133, val_loss=0.018, avg\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 36.89it/s, loss=0.133, val_loss=0.106, avg\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 20.83it/s, loss=0.00821, val_loss=0.106, a\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00821, val_loss=0.106, a\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.00821, val_loss=0.106, a\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 36.74it/s, loss=0.00821, val_loss=0.0189, \u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00388, val_loss=0.0189, \u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:01<00:00, 27.37it/s, loss=0.00388, val_loss=0.0189, \n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 34.42it/s, loss=0.00388, val_loss=0.0189, \u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 37.02it/s, loss=0.00388, val_loss=0.0171, \u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00382, val_loss=0.0171, \u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:01<00:00, 27.12it/s, loss=0.00382, val_loss=0.0171, \n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 34.17it/s, loss=0.00382, val_loss=0.0171, \u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.00382, val_loss=0.0175, \u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00383, val_loss=0.0175, \u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.00383, val_loss=0.0175, \n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 33.92it/s, loss=0.00383, val_loss=0.0175, \u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.54it/s, loss=0.00383, val_loss=0.0179, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.48it/s, loss=0.113, val_loss=0.0179, av\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:02<00:00, 26.70it/s, loss=0.113, val_loss=0.0179, av\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 33.71it/s, loss=0.113, val_loss=0.0179, av\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 36.19it/s, loss=0.113, val_loss=0.0532, av\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.96it/s, loss=0.00547, val_loss=0.0532, \u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:01<00:00, 27.16it/s, loss=0.00547, val_loss=0.0532, \n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 34.25it/s, loss=0.00547, val_loss=0.0532, \u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 36.76it/s, loss=0.00547, val_loss=0.0184, \u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.00384, val_loss=0.0184, \u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:01<00:00, 27.63it/s, loss=0.00384, val_loss=0.0184, \n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 34.76it/s, loss=0.00384, val_loss=0.0184, \u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 37.23it/s, loss=0.00384, val_loss=0.0175, \u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.67it/s, loss=0.00382, val_loss=0.0175, \u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:02<00:00, 26.86it/s, loss=0.00382, val_loss=0.0175, \n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 33.99it/s, loss=0.00382, val_loss=0.0175, \u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 36.49it/s, loss=0.00382, val_loss=0.0178, \u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.95it/s, loss=0.109, val_loss=0.0178, av\u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:01<00:00, 27.02it/s, loss=0.109, val_loss=0.0178, av\n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 34.30it/s, loss=0.109, val_loss=0.0178, av\u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.109, val_loss=0.14, avg_\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:01<00:01, 21.09it/s, loss=0.00757, val_loss=0.14, av\u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:01<00:00, 27.49it/s, loss=0.00757, val_loss=0.14, av\n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 34.48it/s, loss=0.00757, val_loss=0.14, av\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 37.15it/s, loss=0.00757, val_loss=0.019, a\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 21.44it/s, loss=0.00386, val_loss=0.019, a\u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:01<00:00, 27.79it/s, loss=0.00386, val_loss=0.019, a\n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 35.11it/s, loss=0.00386, val_loss=0.019, a\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 37.64it/s, loss=0.00386, val_loss=0.0172, \u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 21.02it/s, loss=0.0038, val_loss=0.0172, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:01<00:00, 27.40it/s, loss=0.0038, val_loss=0.0172, a\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 34.54it/s, loss=0.0038, val_loss=0.0172, a\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 36.91it/s, loss=0.0038, val_loss=0.0177, a\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.128, val_loss=0.0177, av\u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.128, val_loss=0.0177, av\n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 34.24it/s, loss=0.128, val_loss=0.0177, av\u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 36.87it/s, loss=0.128, val_loss=0.157, avg\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 20.48it/s, loss=0.00916, val_loss=0.157, a\u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:02<00:00, 26.71it/s, loss=0.00916, val_loss=0.157, a\n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 33.72it/s, loss=0.00916, val_loss=0.157, a\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.00916, val_loss=0.0203, \u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 20.69it/s, loss=0.00388, val_loss=0.0203, \u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:02<00:00, 26.96it/s, loss=0.00388, val_loss=0.0203, \n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 34.02it/s, loss=0.00388, val_loss=0.0203, \u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 36.51it/s, loss=0.00388, val_loss=0.0162, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.0038, val_loss=0.0162, a\u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:02<00:00, 26.93it/s, loss=0.0038, val_loss=0.0162, a\n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 33.95it/s, loss=0.0038, val_loss=0.0162, a\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 36.56it/s, loss=0.0038, val_loss=0.0169, a\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 21.08it/s, loss=0.17, val_loss=0.0169, avg\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:01<00:00, 27.43it/s, loss=0.17, val_loss=0.0169, avg\n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 34.52it/s, loss=0.17, val_loss=0.0169, avg\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 37.05it/s, loss=0.17, val_loss=0.267, avg_\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.97it/s, loss=0.00816, val_loss=0.267, a\u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:01<00:00, 27.21it/s, loss=0.00816, val_loss=0.267, a\n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 34.21it/s, loss=0.00816, val_loss=0.267, a\u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 36.82it/s, loss=0.00816, val_loss=0.0172, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 20.55it/s, loss=0.00385, val_loss=0.0172, \u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:02<00:00, 26.69it/s, loss=0.00385, val_loss=0.0172, \n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 33.80it/s, loss=0.00385, val_loss=0.0172, \u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 36.25it/s, loss=0.00385, val_loss=0.0155, \u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.81it/s, loss=0.00379, val_loss=0.0155, \u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:01<00:00, 27.08it/s, loss=0.00379, val_loss=0.0155, \n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 34.03it/s, loss=0.00379, val_loss=0.0155, \u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 36.62it/s, loss=0.00379, val_loss=0.016, a\u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 20.74it/s, loss=0.00379, val_loss=0.016, a\u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:01<00:00, 27.04it/s, loss=0.00379, val_loss=0.016, a\n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 34.12it/s, loss=0.00379, val_loss=0.016, a\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.56it/s, loss=0.00379, val_loss=0.0162, \u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 36.28it/s, loss=0.00379, val_loss=0.0162, \u001b[A\n",
      "Sizes of clusters: 765, 605, 152, 133, 345\n",
      "\n",
      "preds: [2 2 2 2 4 4 2 4 2 4 2 4 2 2 4 2 0 4 2 0 4 4 4 4 2 2 2 4 4 2 4 2 0 2 4 2 2\n",
      " 2 0 2 2 2 4 4 4 4 2 2 2 4 2 0 2 4 2 0 2 4 2 0 4 2 4 2 2 2 2 4 2 4 0 0 0 4\n",
      " 4 4 0 4 4 4 0 2 4 0 2 4 4 4 2 4 4 2 4 2 0 0 4 0 4 0 4 0 2 4 4 4 2 2 2 4 2\n",
      " 4 4 0 4 2 2 2 4 4 4 4 2 0 2 2 4 0 2 0 4 4 0 2 0 4 4 2 4 2 0 4 4 4 2 4 2 4\n",
      " 2 4 4 4 0 4 4 4 2 2 4 2 2 2 2 2 2 4 0 0 4 4 2 4 4 4 4 0 4 4 4 4 2 2 2 2 2\n",
      " 2 4 4 0 2 2 0 0 2 4 0 4 2 4 2 4 0 2 2 4 2 2 0 4 4 4 1 4 4 2 0 0 4 2 0 2 4\n",
      " 2 4 0 2 2 4 2 4 2 4 0 0 4 1 4 2 4 2 4 4 2 0 4 2 4 4 0 4 4 4 4 2 4 2 4 0 2\n",
      " 4 2 2 2 4 4 4 4 2 2 4 2 4 4 0 4 4 4 4 4 4 2 2 0 2 0 4 4 4 4 4 2 4 4 4 2 2\n",
      " 2 2 4 2 0 4 4 4 2 2 1 4 2 2 2 0 4 0 4 2 2 0 2 2 2 0 2 2 2 0 4 4 4 0 2 4 0\n",
      " 4 4 4 4 4 2 0 4 2 0 2 0 2 2 4 4 4 4 2 4 0 4 4 4 4 0 4 4 4 4 4 4 2 0 4 4 4\n",
      " 0 2 2 4 2 2 4 4 2 2 2 0 4 4 1 4 2 2 4 4 4 0 4 4 4 2 4 0 2 4 1 0 1 0 1 1 0\n",
      " 3 0 0 0 1 0 0 0 1 0 0 0 3 1 3 1 1 4 4 1 3 0 1 4 1 0 0 4 0 0 1 1 3 1 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 1 1 1 0 3 0 1 4 1 0 0 0 0 1 0 0 0 4 3 0 4 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 4 1 0 4 0 0 0 0 0 0 1 0 0 1 1 1 4 0 0 4 0 1 4 4 1 1 1 1 1 4 3\n",
      " 1 1 0 4 0 0 1 0 0 4 1 1 1 3 0 1 1 1 3 4 0 4 0 1 0 4 1 0 1 0 1 0 4 0 1 0 4\n",
      " 0 1 0 0 1 4 0 4 0 1 1 0 0 0 0 0 1 0 0 4 3 3 1 1 1 0 0 0 1 4 0 1 0 1 4 0 4\n",
      " 0 0 1 0 3 4 4 0 0 4 4 0 0 0 1 1 4 0 1 1 1 1 1 0 0 1 1 4 1 4 4 4 4 0 0 1 0\n",
      " 0 1 4 4 1 2 1 0 4 4 1 1 1 4 1 1 1 0 1 4 3 0 0 0 1 3 0 1 0 0 0 1 1 0 0 3 4\n",
      " 4 1 4 0 1 0 1 1 1 0 0 0 0 1 1 1 0 4 1 0 1 1 1 1 0 0 0 0 1 4 0 1 1 4 1 1 0\n",
      " 0 4 0 1 1 4 0 0 1 0 1 0 0 0 4 0 1 4 0 4 3 0 0 0 1 1 1 0 1 1 0 1 0 0 1 4 1\n",
      " 4 4 1 4 3 0 4 1 1 4 0 0 0 1 0 1 0 0 0 0 1 0 0 4 1 0 0 1 0 1 1 1 1 1 0 1 0\n",
      " 0 0 3 1 1 0 1 1 1 1 1 0 4 3 3 0 1 3 0 0 0 0 0 0 4 0 1 3 0 1 1 0 0 1 0 0 1\n",
      " 1 0 0 4 0 0 0 0 0 0 0 1 1 4 0 1 1 0 0 0 0 1 0 4 0 4 0 1 0 1 1 1 0 0 1 0 0\n",
      " 1 1 0 4 0 0 0 3 0 0 0 1 1 4 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 3 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 3 1 4 0 1 0 0 0 3 1 0\n",
      " 0 0 1 1 1 4 0 4 0 0 1 4 4 0 1 0 1 0 1 0 0 0 0 0 1 4 0 0 0 1 0 0 4 1 3 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 3 0 1 3 1 4 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 3\n",
      " 1 1 0 0 1 4 0 0 0 0 4 0 1 0 4 0 0 1 1 0 0 0 0 4 1 0 1 0 1 0 4 0 0 0 0 0 1\n",
      " 4 1 1 0 4 1 0 1 0 0 3 1 4 0 0 0 3 0 0 4 3 0 1 1 0 0 1 1 4 0 1 0 0 3 1 1 1\n",
      " 1 0 0 1 0 3 0 0 0 1 4 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 3 4 0 1 1 0 1 1 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 4 0 0 0 1 1 0 4 4 1 0 1 1 0 4 0 0 1 1 0 0 1 0 3 0 0\n",
      " 1 0 0 0 0 4 0 3 1 0 0 0 0 1 0 3 1 1 1 1 0 1 4 0 1 0 3 1 4 0 1 1 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 0 0 3 1 1\n",
      " 1 3 1 0 0 0 0 1 4 0 3 1 1 4 0 3 0 3 1 0 0 0 0 0 0 0 1 3 1 0 4 1 1 3 3 0 0\n",
      " 4 0 1 0 0 0 1 3 1 1 0 1 1 1 0 0 0 3 1 1 0 0 0 1 0 3 1 1 3 3 4 1 0 1 3 2 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 3 0 0 0 0 0 0 1 0 1 3 0 1 1 1 0 0 0 1 0 3 0 3 1 4 3\n",
      " 1 3 0 0 1 4 0 1 1 0 0 3 1 4 1 1 3 3 0 1 1 1 4 0 0 0 0 0 1 0 1 3 1 4 4 1 0\n",
      " 3 0 1 1 1 4 0 0 0 0 0 4 3 1 0 0 0 1 3 0 0 1 1 1 0 0 1 0 0 1 1 1 0 3 0 1 1\n",
      " 1 3 0 1 1 1 1 0 1 0 0 1 0 1 1 0 3 1 1 3 3 0 3 3 3 0 0 0 1 1 0 1 4 4 0 0 1\n",
      " 1 0 0 4 0 1 0 3 3 0 3 1 4 1 4 1 1 3 0 1 0 0 1 3 1 0 3 1 4 1 1 0 3 0 0 1 4\n",
      " 0 1 1 1 1 1 1 2 0 0 1 3 0 1 1 0 1 0 4 3 0 0 0 0 3 1 1 1 1 1 1 0 1 4 1 0 0\n",
      " 1 4 4 1 0 3 0 4 1 1 1 0 1 0 1 0 0 1 0 1 3 0 1 0 0 0 0 0 4 1 1 0 3 1 4 1 0\n",
      " 1 0 1 1 0 0 0 4 0 0 0 3 1 0 0 1 2 1 0 4 1 4 0 3 1 1 0 1 1 0 0 0 0 0 4 4 3\n",
      " 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 4 1 4 1 0 1 3 0 0 0\n",
      " 1 1 3 1 0 0 1 0 0 4 0 0 0 1 0 3 1 0 0 3 3 1 0 1 4 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 3 0 0 1 4 4 1 1 0 1 1 0 2 1 4 4 3 0 0 0 3 1 0 0 1 0 3 0 1 1 0 1 1 0 1 1 0\n",
      " 3 1 3 0 1 1 1 3 1 1 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 4 0 1 0 3 1 0 1 1 0\n",
      " 0 1 1 0 3 3 3 0 3 1 1 4 0 1 1 1 3 0 0 0 0 1 0 0 1 0 1 4 4 1 0 4 1 1 1 0 3\n",
      " 1 1 1 0 0 0 1 1 0 1 0 1 1 0 3 1 0 3 1 1 0 1 1 4 1 1 0 1 3 1 0 4 0 1 1 1 0\n",
      " 0 3 0 4 0 0 1 1 1 0 1 4 1 0 0 0 0 0 0 0 1 4 0 0 0 0 3 3 1 1 1 0 0 1 0 3 0\n",
      " 0 4 0 1 1 0 4 3 1 1 3 0 4 1 1 1 1 1 3 0 1 1 0 1 3 1 1 4 1 4 1 0 3 0 1 1 1\n",
      " 1 0 1 1 1 1 0 0 0 0 3 1 1 0 0 4 1 1 1 0 1 0 0 1 0 0 1 0 0 0 3 3 0 1 0 0 0\n",
      " 0 1 1 0 1 4 4 0 4 1 0 1 0 3 0 3 4 0 1 1 1 1 4 1 1 0 1 1 1 3 1 4 0 0 1 0 1\n",
      " 1 3 2 1 4 3 1 0 1 0 1 1 0 0 1 1 0 1 3 0 1 1 0 1 1 1 1 1 0 4 0 1 1 3 1 1 1\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3870\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.41it/s, loss=0.745, val_loss=0.0625, avg\n",
      "Epoch 0:  64%|▋| 51/80 [00:01<00:01, 26.54it/s, loss=0.745, val_loss=0.0625, avg\n",
      "Epoch 0:  84%|▊| 67/80 [00:02<00:00, 33.01it/s, loss=0.745, val_loss=0.0625, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.56it/s, loss=0.745, val_loss=0.568, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.07it/s, loss=0.0347, val_loss=0.568, avg\u001b[A\n",
      "Epoch 1:  60%|▌| 48/80 [00:01<00:01, 24.86it/s, loss=0.0347, val_loss=0.568, avg\n",
      "Epoch 1:  80%|▊| 64/80 [00:02<00:00, 31.49it/s, loss=0.0347, val_loss=0.568, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.07it/s, loss=0.0347, val_loss=0.0419, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.0178, val_loss=0.0419, av\u001b[A\n",
      "Epoch 2:  60%|▌| 48/80 [00:01<00:01, 25.81it/s, loss=0.0178, val_loss=0.0419, av\n",
      "Epoch 2:  80%|▊| 64/80 [00:01<00:00, 32.52it/s, loss=0.0178, val_loss=0.0419, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.0178, val_loss=0.032, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.0139, val_loss=0.032, avg\u001b[A\n",
      "Epoch 3:  60%|▌| 48/80 [00:01<00:01, 24.94it/s, loss=0.0139, val_loss=0.032, avg\n",
      "Epoch 3:  80%|▊| 64/80 [00:02<00:00, 31.50it/s, loss=0.0139, val_loss=0.032, avg\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 37.19it/s, loss=0.0139, val_loss=0.0255, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.0113, val_loss=0.0255, av\u001b[A\n",
      "Epoch 4:  60%|▌| 48/80 [00:01<00:01, 24.83it/s, loss=0.0113, val_loss=0.0255, av\n",
      "Epoch 4:  81%|▊| 65/80 [00:02<00:00, 31.89it/s, loss=0.0113, val_loss=0.0255, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 37.10it/s, loss=0.0113, val_loss=0.0218, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.19it/s, loss=0.00946, val_loss=0.0218, a\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 26.31it/s, loss=0.00946, val_loss=0.0218, a\n",
      "Epoch 5:  85%|▊| 68/80 [00:02<00:00, 33.23it/s, loss=0.00946, val_loss=0.0218, a\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 37.26it/s, loss=0.00946, val_loss=0.0174, a\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.0081, val_loss=0.0174, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 26.17it/s, loss=0.0081, val_loss=0.0174, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:02<00:00, 33.07it/s, loss=0.0081, val_loss=0.0174, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.0081, val_loss=0.0145, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:02<00:02, 19.72it/s, loss=0.00709, val_loss=0.0145, a\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:02<00:01, 24.54it/s, loss=0.00709, val_loss=0.0145, a\n",
      "Epoch 7:  85%|▊| 68/80 [00:02<00:00, 31.08it/s, loss=0.00709, val_loss=0.0145, a\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 34.98it/s, loss=0.00709, val_loss=0.0135, a\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.00634, val_loss=0.0135, a\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:02<00:01, 24.97it/s, loss=0.00634, val_loss=0.0135, a\n",
      "Epoch 8:  85%|▊| 68/80 [00:02<00:00, 31.61it/s, loss=0.00634, val_loss=0.0135, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 35.56it/s, loss=0.00634, val_loss=0.011, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:02<00:02, 19.79it/s, loss=0.00578, val_loss=0.011, av\u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:02<00:01, 24.53it/s, loss=0.00578, val_loss=0.011, av\n",
      "Epoch 9:  85%|▊| 68/80 [00:02<00:00, 31.12it/s, loss=0.00578, val_loss=0.011, av\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 35.04it/s, loss=0.00578, val_loss=0.01, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.13it/s, loss=0.00537, val_loss=0.01, av\u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:02<00:01, 24.99it/s, loss=0.00537, val_loss=0.01, av\n",
      "Epoch 10:  85%|▊| 68/80 [00:02<00:00, 31.67it/s, loss=0.00537, val_loss=0.01, av\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.00537, val_loss=0.00916,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:02<00:02, 19.90it/s, loss=0.00506, val_loss=0.00916,\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:02<00:01, 24.69it/s, loss=0.00506, val_loss=0.00916,\n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 31.29it/s, loss=0.00506, val_loss=0.00916,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 35.26it/s, loss=0.00506, val_loss=0.00838,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00483, val_loss=0.00838,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 25.66it/s, loss=0.00483, val_loss=0.00838,\n",
      "Epoch 12:  85%|▊| 68/80 [00:02<00:00, 32.44it/s, loss=0.00483, val_loss=0.00838,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00483, val_loss=0.00781,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00466, val_loss=0.00781,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 26.49it/s, loss=0.00466, val_loss=0.00781,\n",
      "Epoch 13:  85%|▊| 68/80 [00:02<00:00, 33.49it/s, loss=0.00466, val_loss=0.00781,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.53it/s, loss=0.00466, val_loss=0.00744,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.20it/s, loss=0.00453, val_loss=0.00744,\u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 26.23it/s, loss=0.00453, val_loss=0.00744,\n",
      "Epoch 14:  85%|▊| 68/80 [00:02<00:00, 33.24it/s, loss=0.00453, val_loss=0.00744,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.23it/s, loss=0.00453, val_loss=0.00707,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00443, val_loss=0.00707,\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 25.91it/s, loss=0.00443, val_loss=0.00707,\n",
      "Epoch 15:  85%|▊| 68/80 [00:02<00:00, 32.74it/s, loss=0.00443, val_loss=0.00707,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 36.79it/s, loss=0.00443, val_loss=0.00676,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:02<00:02, 19.58it/s, loss=0.00435, val_loss=0.00676,\u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:02<00:01, 24.33it/s, loss=0.00435, val_loss=0.00676,\n",
      "Epoch 16:  85%|▊| 68/80 [00:02<00:00, 30.85it/s, loss=0.00435, val_loss=0.00676,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 34.66it/s, loss=0.00435, val_loss=0.00658,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:02<00:02, 19.96it/s, loss=0.00429, val_loss=0.00658,\u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:02<00:01, 24.71it/s, loss=0.00429, val_loss=0.00658,\n",
      "Epoch 17:  85%|▊| 68/80 [00:02<00:00, 31.30it/s, loss=0.00429, val_loss=0.00658,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 35.28it/s, loss=0.00429, val_loss=0.00644,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:02<00:02, 19.66it/s, loss=0.00424, val_loss=0.00644,\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:02<00:01, 24.33it/s, loss=0.00424, val_loss=0.00644,\n",
      "Epoch 18:  86%|▊| 69/80 [00:02<00:00, 31.38it/s, loss=0.00424, val_loss=0.00644,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 34.89it/s, loss=0.00424, val_loss=0.00629,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00419, val_loss=0.00629,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:02<00:00, 26.52it/s, loss=0.00419, val_loss=0.00629,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 33.38it/s, loss=0.00419, val_loss=0.00629,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 35.94it/s, loss=0.00419, val_loss=0.00616,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:02<00:02, 19.88it/s, loss=0.00415, val_loss=0.00616,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:02<00:01, 25.60it/s, loss=0.00415, val_loss=0.00616,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 32.50it/s, loss=0.00415, val_loss=0.00616,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 34.95it/s, loss=0.00415, val_loss=0.00603,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.58it/s, loss=0.00412, val_loss=0.00603,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.00412, val_loss=0.00603,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 33.84it/s, loss=0.00412, val_loss=0.00603,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 36.31it/s, loss=0.00412, val_loss=0.00593,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00409, val_loss=0.00593,\u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 28.37it/s, loss=0.00409, val_loss=0.00593,\n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 35.67it/s, loss=0.00409, val_loss=0.00593,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00409, val_loss=0.00581,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00406, val_loss=0.00581,\u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 27.14it/s, loss=0.00406, val_loss=0.00581,\n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 34.33it/s, loss=0.00406, val_loss=0.00581,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.74it/s, loss=0.00406, val_loss=0.00573,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.00404, val_loss=0.00573,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 27.33it/s, loss=0.00404, val_loss=0.00573,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 34.49it/s, loss=0.00404, val_loss=0.00573,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00404, val_loss=0.0057, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.41it/s, loss=0.00402, val_loss=0.0057, \u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 27.87it/s, loss=0.00402, val_loss=0.0057, \n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 35.11it/s, loss=0.00402, val_loss=0.0057, \u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 37.64it/s, loss=0.00402, val_loss=0.00567,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.17it/s, loss=0.004, val_loss=0.00567, a\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:01<00:00, 27.50it/s, loss=0.004, val_loss=0.00567, a\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 34.60it/s, loss=0.004, val_loss=0.00567, a\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 37.19it/s, loss=0.004, val_loss=0.00568, a\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.33it/s, loss=0.00398, val_loss=0.00568,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:02<00:00, 26.51it/s, loss=0.00398, val_loss=0.00568,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 33.44it/s, loss=0.00398, val_loss=0.00568,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 35.95it/s, loss=0.00398, val_loss=0.00567,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.29it/s, loss=0.00396, val_loss=0.00567,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:02<00:00, 26.45it/s, loss=0.00396, val_loss=0.00567,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 33.43it/s, loss=0.00396, val_loss=0.00567,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 35.90it/s, loss=0.00396, val_loss=0.00568,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.57it/s, loss=0.00395, val_loss=0.00568,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 28.08it/s, loss=0.00395, val_loss=0.00568,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 35.32it/s, loss=0.00395, val_loss=0.00568,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.80it/s, loss=0.00395, val_loss=0.00567,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.24it/s, loss=0.00394, val_loss=0.00567,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 27.64it/s, loss=0.00394, val_loss=0.00567,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 34.79it/s, loss=0.00394, val_loss=0.00567,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 37.30it/s, loss=0.00394, val_loss=0.00566,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 20.42it/s, loss=0.00393, val_loss=0.00566,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:02<00:00, 26.57it/s, loss=0.00393, val_loss=0.00566,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 33.59it/s, loss=0.00393, val_loss=0.00566,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 35.97it/s, loss=0.00393, val_loss=0.00564,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:02<00:02, 19.58it/s, loss=0.00392, val_loss=0.00564,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:02<00:01, 25.57it/s, loss=0.00392, val_loss=0.00564,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 32.24it/s, loss=0.00392, val_loss=0.00564,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 34.76it/s, loss=0.00392, val_loss=0.00558,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 20.18it/s, loss=0.00391, val_loss=0.00558,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:02<00:00, 26.18it/s, loss=0.00391, val_loss=0.00558,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 33.12it/s, loss=0.00391, val_loss=0.00558,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 35.61it/s, loss=0.00391, val_loss=0.00552,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00391, val_loss=0.00552,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:02<00:00, 26.22it/s, loss=0.00391, val_loss=0.00552,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 33.16it/s, loss=0.00391, val_loss=0.00552,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 35.64it/s, loss=0.00391, val_loss=0.00545,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.04it/s, loss=0.0039, val_loss=0.00545, \u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:02<00:00, 26.14it/s, loss=0.0039, val_loss=0.00545, \n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 32.93it/s, loss=0.0039, val_loss=0.00545, \u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 35.43it/s, loss=0.0039, val_loss=0.00543, \u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:02<00:02, 19.19it/s, loss=0.00389, val_loss=0.00543,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:02<00:01, 25.06it/s, loss=0.00389, val_loss=0.00543,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 31.70it/s, loss=0.00389, val_loss=0.00543,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 34.13it/s, loss=0.00389, val_loss=0.00546,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00389, val_loss=0.00546,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 27.57it/s, loss=0.00389, val_loss=0.00546,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 34.72it/s, loss=0.00389, val_loss=0.00546,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.22it/s, loss=0.00389, val_loss=0.00549,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00388, val_loss=0.00549,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:01<00:00, 28.12it/s, loss=0.00388, val_loss=0.00549,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 35.35it/s, loss=0.00388, val_loss=0.00549,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.88it/s, loss=0.00388, val_loss=0.0055, \u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.00388, val_loss=0.0055, \u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 27.51it/s, loss=0.00388, val_loss=0.0055, \n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 34.64it/s, loss=0.00388, val_loss=0.0055, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00388, val_loss=0.00552,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 20.60it/s, loss=0.00387, val_loss=0.00552,\u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.00387, val_loss=0.00552,\n",
      "Epoch 40:  90%|▉| 72/80 [00:02<00:00, 33.83it/s, loss=0.00387, val_loss=0.00552,\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 36.34it/s, loss=0.00387, val_loss=0.00555,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 20.49it/s, loss=0.00387, val_loss=0.00555,\u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:02<00:00, 26.61it/s, loss=0.00387, val_loss=0.00555,\n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 33.63it/s, loss=0.00387, val_loss=0.00555,\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 36.07it/s, loss=0.00387, val_loss=0.0056, \u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 20.23it/s, loss=0.00386, val_loss=0.0056, \u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:02<00:00, 26.22it/s, loss=0.00386, val_loss=0.0056, \n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 33.20it/s, loss=0.00386, val_loss=0.0056, \u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 35.66it/s, loss=0.00386, val_loss=0.00565,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:02<00:02, 19.63it/s, loss=0.00386, val_loss=0.00565,\u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:02<00:01, 25.56it/s, loss=0.00386, val_loss=0.00565,\n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 32.27it/s, loss=0.00386, val_loss=0.00565,\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 34.76it/s, loss=0.00386, val_loss=0.0057, \u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:02<00:02, 19.82it/s, loss=0.00385, val_loss=0.0057, \u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:02<00:01, 25.74it/s, loss=0.00385, val_loss=0.0057, \n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 32.65it/s, loss=0.00385, val_loss=0.0057, \u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 35.11it/s, loss=0.00385, val_loss=0.00575,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:02<00:02, 19.92it/s, loss=0.00385, val_loss=0.00575,\u001b[A\n",
      "Epoch 45:  68%|▋| 54/80 [00:02<00:01, 25.88it/s, loss=0.00385, val_loss=0.00575,\n",
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 32.72it/s, loss=0.00385, val_loss=0.00575,\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 35.13it/s, loss=0.00385, val_loss=0.00581,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 20.96it/s, loss=0.00385, val_loss=0.00581,\u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:01<00:00, 27.30it/s, loss=0.00385, val_loss=0.00581,\n",
      "Epoch 46:  90%|▉| 72/80 [00:02<00:00, 34.41it/s, loss=0.00385, val_loss=0.00581,\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 36.91it/s, loss=0.00385, val_loss=0.00589,\u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.00384, val_loss=0.00589,\u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:01<00:00, 28.05it/s, loss=0.00384, val_loss=0.00589,\n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 35.31it/s, loss=0.00384, val_loss=0.00589,\u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 37.83it/s, loss=0.00384, val_loss=0.00595,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00384, val_loss=0.00595,\u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:01<00:00, 27.01it/s, loss=0.00384, val_loss=0.00595,\n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 34.06it/s, loss=0.00384, val_loss=0.00595,\u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 36.50it/s, loss=0.00384, val_loss=0.00601,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 20.34it/s, loss=0.00384, val_loss=0.00601,\u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:02<00:00, 26.44it/s, loss=0.00384, val_loss=0.00601,\n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 33.30it/s, loss=0.00384, val_loss=0.00601,\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 35.84it/s, loss=0.00384, val_loss=0.00607,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 20.29it/s, loss=0.00384, val_loss=0.00607,\u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:02<00:00, 26.34it/s, loss=0.00384, val_loss=0.00607,\n",
      "Epoch 50:  90%|▉| 72/80 [00:02<00:00, 33.23it/s, loss=0.00384, val_loss=0.00607,\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 35.78it/s, loss=0.00384, val_loss=0.00614,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:02<00:02, 19.77it/s, loss=0.00384, val_loss=0.00614,\u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:02<00:01, 25.76it/s, loss=0.00384, val_loss=0.00614,\n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 32.61it/s, loss=0.00384, val_loss=0.00614,\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 34.99it/s, loss=0.00384, val_loss=0.00621,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.05it/s, loss=0.00383, val_loss=0.00621,\u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:02<00:00, 26.07it/s, loss=0.00383, val_loss=0.00621,\n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 32.81it/s, loss=0.00383, val_loss=0.00621,\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 35.42it/s, loss=0.00383, val_loss=0.00626,\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.17it/s, loss=0.00383, val_loss=0.00626,\u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:02<00:00, 26.06it/s, loss=0.00383, val_loss=0.00626,\n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 33.14it/s, loss=0.00383, val_loss=0.00626,\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.00383, val_loss=0.00632,\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 20.18it/s, loss=0.00383, val_loss=0.00632,\u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:02<00:00, 26.25it/s, loss=0.00383, val_loss=0.00632,\n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 33.24it/s, loss=0.00383, val_loss=0.00632,\u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 35.63it/s, loss=0.00383, val_loss=0.00638,\u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 20.91it/s, loss=0.00383, val_loss=0.00638,\u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:01<00:00, 27.24it/s, loss=0.00383, val_loss=0.00638,\n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 34.33it/s, loss=0.00383, val_loss=0.00638,\u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 36.82it/s, loss=0.00383, val_loss=0.00644,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00383, val_loss=0.00644,\u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:01<00:00, 28.26it/s, loss=0.00383, val_loss=0.00644,\n",
      "Epoch 56:  90%|▉| 72/80 [00:02<00:00, 35.55it/s, loss=0.00383, val_loss=0.00644,\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00383, val_loss=0.00649,\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00724, val_loss=0.00649,\u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:01<00:00, 27.54it/s, loss=0.00724, val_loss=0.00649,\n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 34.77it/s, loss=0.00724, val_loss=0.00649,\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 37.25it/s, loss=0.00724, val_loss=0.0581, \u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 20.25it/s, loss=0.00628, val_loss=0.0581, \u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:02<00:01, 25.91it/s, loss=0.00628, val_loss=0.0581, \u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 35.43it/s, loss=0.00628, val_loss=0.00668,\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 21.08it/s, loss=0.00386, val_loss=0.00668,\u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:01<00:00, 27.47it/s, loss=0.00386, val_loss=0.00668,\n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 34.62it/s, loss=0.00386, val_loss=0.00668,\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 37.13it/s, loss=0.00386, val_loss=0.00658,\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.23it/s, loss=0.00382, val_loss=0.00658,\u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:01<00:00, 27.51it/s, loss=0.00382, val_loss=0.00658,\n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 34.60it/s, loss=0.00382, val_loss=0.00658,\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 37.12it/s, loss=0.00382, val_loss=0.00663,\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.18it/s, loss=0.00382, val_loss=0.00663,\u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:02<00:00, 26.30it/s, loss=0.00382, val_loss=0.00663,\n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 33.26it/s, loss=0.00382, val_loss=0.00663,\u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 35.72it/s, loss=0.00382, val_loss=0.00668,\u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 20.51it/s, loss=0.00394, val_loss=0.00668,\u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00394, val_loss=0.00668,\n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 33.45it/s, loss=0.00394, val_loss=0.00668,\u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 35.93it/s, loss=0.00394, val_loss=0.0088, \u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 21.56it/s, loss=0.0276, val_loss=0.0088, a\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:01<00:00, 28.05it/s, loss=0.0276, val_loss=0.0088, a\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 35.31it/s, loss=0.0276, val_loss=0.0088, a\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 37.74it/s, loss=0.0276, val_loss=0.0183, a\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:01<00:01, 21.04it/s, loss=0.0041, val_loss=0.0183, a\u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:01<00:00, 27.41it/s, loss=0.0041, val_loss=0.0183, a\n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 34.53it/s, loss=0.0041, val_loss=0.0183, a\u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 37.02it/s, loss=0.0041, val_loss=0.00682, \u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:02<00:02, 19.97it/s, loss=0.00381, val_loss=0.00682,\u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:02<00:01, 25.92it/s, loss=0.00381, val_loss=0.00682,\n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 32.82it/s, loss=0.00381, val_loss=0.00682,\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 35.25it/s, loss=0.00381, val_loss=0.00665,\u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:02<00:02, 19.82it/s, loss=0.0038, val_loss=0.00665, \u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:02<00:01, 25.76it/s, loss=0.0038, val_loss=0.00665, \n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 32.68it/s, loss=0.0038, val_loss=0.00665, \u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 35.15it/s, loss=0.0038, val_loss=0.00665, \u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 20.04it/s, loss=0.00385, val_loss=0.00665,\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:02<00:01, 25.95it/s, loss=0.00385, val_loss=0.00665,\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 32.81it/s, loss=0.00385, val_loss=0.00665,\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 35.28it/s, loss=0.00385, val_loss=0.00733,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:02<00:02, 19.78it/s, loss=0.0176, val_loss=0.00733, \u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:02<00:01, 25.78it/s, loss=0.0176, val_loss=0.00733, \n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 32.47it/s, loss=0.0176, val_loss=0.00733, \u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 34.96it/s, loss=0.0176, val_loss=0.00838, \u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:02<00:02, 19.85it/s, loss=0.00399, val_loss=0.00838,\u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:02<00:01, 25.87it/s, loss=0.00399, val_loss=0.00838,\n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 32.72it/s, loss=0.00399, val_loss=0.00838,\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 35.09it/s, loss=0.00399, val_loss=0.00672,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 20.02it/s, loss=0.00514, val_loss=0.00672,\u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:02<00:00, 26.04it/s, loss=0.00514, val_loss=0.00672,\n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 32.85it/s, loss=0.00514, val_loss=0.00672,\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 35.36it/s, loss=0.00514, val_loss=0.0298, \u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.0305, val_loss=0.0298, a\u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:01<00:00, 27.89it/s, loss=0.0305, val_loss=0.0298, a\n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 35.11it/s, loss=0.0305, val_loss=0.0298, a\u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 37.63it/s, loss=0.0305, val_loss=0.0206, a\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00413, val_loss=0.0206, \u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:01<00:00, 28.01it/s, loss=0.00413, val_loss=0.0206, \n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 35.25it/s, loss=0.00413, val_loss=0.0206, \u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 37.78it/s, loss=0.00413, val_loss=0.00626,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 21.27it/s, loss=0.00379, val_loss=0.00626,\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:01<00:00, 27.68it/s, loss=0.00379, val_loss=0.00626,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 34.87it/s, loss=0.00379, val_loss=0.00626,\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.00379, val_loss=0.00611,\u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.15it/s, loss=0.00379, val_loss=0.00611,\u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:02<00:00, 26.21it/s, loss=0.00379, val_loss=0.00611,\n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 33.04it/s, loss=0.00379, val_loss=0.00611,\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 35.55it/s, loss=0.00379, val_loss=0.00615,\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 20.75it/s, loss=0.00379, val_loss=0.00615,\u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:02<00:00, 26.94it/s, loss=0.00379, val_loss=0.00615,\n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 34.05it/s, loss=0.00379, val_loss=0.00615,\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 36.49it/s, loss=0.00379, val_loss=0.00616,\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:02<00:02, 19.62it/s, loss=0.0105, val_loss=0.00616, \u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:02<00:01, 25.57it/s, loss=0.0105, val_loss=0.00616, \n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 32.31it/s, loss=0.0105, val_loss=0.00616, \u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 34.79it/s, loss=0.0105, val_loss=0.112, av\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 20.04it/s, loss=0.0149, val_loss=0.112, av\u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:02<00:01, 25.99it/s, loss=0.0149, val_loss=0.112, av\n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 32.88it/s, loss=0.0149, val_loss=0.112, av\u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 35.39it/s, loss=0.0149, val_loss=0.0108, a\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.32it/s, loss=0.00394, val_loss=0.0108, \u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:02<00:00, 26.47it/s, loss=0.00394, val_loss=0.0108, \n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 33.27it/s, loss=0.00394, val_loss=0.0108, \u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 35.83it/s, loss=0.00394, val_loss=0.00604,\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:02<00:02, 19.96it/s, loss=0.00378, val_loss=0.00604,\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:02<00:01, 25.97it/s, loss=0.00378, val_loss=0.00604,\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 32.78it/s, loss=0.00378, val_loss=0.00604,\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 35.29it/s, loss=0.00378, val_loss=0.00597,\u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00378, val_loss=0.00597,\u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:01<00:00, 27.27it/s, loss=0.00378, val_loss=0.00597,\n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 34.38it/s, loss=0.00378, val_loss=0.00597,\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 36.88it/s, loss=0.00378, val_loss=0.00597,\u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.0241, val_loss=0.00597, \u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.0241, val_loss=0.00597, \n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 35.61it/s, loss=0.0241, val_loss=0.00597, \u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.0241, val_loss=0.279, av\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 21.11it/s, loss=0.0115, val_loss=0.279, av\u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:01<00:00, 27.50it/s, loss=0.0115, val_loss=0.279, av\n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 34.66it/s, loss=0.0115, val_loss=0.279, av\u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 37.08it/s, loss=0.0115, val_loss=0.00847, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.40it/s, loss=0.00391, val_loss=0.00847,\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:02<00:00, 26.57it/s, loss=0.00391, val_loss=0.00847,\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 33.48it/s, loss=0.00391, val_loss=0.00847,\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.00391, val_loss=0.00599,\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:02<00:02, 19.66it/s, loss=0.0556, val_loss=0.00599, \u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:02<00:01, 25.61it/s, loss=0.0556, val_loss=0.00599, \n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 32.41it/s, loss=0.0556, val_loss=0.00599, \u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 34.84it/s, loss=0.0556, val_loss=0.0467, a\u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:02<00:02, 19.88it/s, loss=0.0194, val_loss=0.0467, a\u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:02<00:01, 25.74it/s, loss=0.0194, val_loss=0.0467, a\n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 32.67it/s, loss=0.0194, val_loss=0.0467, a\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 35.11it/s, loss=0.0194, val_loss=0.0551, a\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:02<00:02, 19.65it/s, loss=0.00465, val_loss=0.0551, \u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:02<00:01, 25.46it/s, loss=0.00465, val_loss=0.0551, \n",
      "Validating:  40%|████████████                  | 16/40 [00:00<00:00, 158.28it/s]\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 34.54it/s, loss=0.00465, val_loss=0.00592,\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:02<00:02, 19.70it/s, loss=0.00399, val_loss=0.00592,\u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:02<00:01, 25.48it/s, loss=0.00399, val_loss=0.00592,\n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 32.32it/s, loss=0.00399, val_loss=0.00592,\u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 34.79it/s, loss=0.00399, val_loss=0.00739,\u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:02<00:02, 19.80it/s, loss=0.037, val_loss=0.00739, a\u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:02<00:01, 25.79it/s, loss=0.037, val_loss=0.00739, a\n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 32.57it/s, loss=0.037, val_loss=0.00739, a\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 35.04it/s, loss=0.037, val_loss=0.0122, av\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00421, val_loss=0.0122, \u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:02<00:00, 27.00it/s, loss=0.00421, val_loss=0.0122, \n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 34.04it/s, loss=0.00421, val_loss=0.0122, \u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00421, val_loss=0.00551,\u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00378, val_loss=0.00551,\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:01<00:00, 28.22it/s, loss=0.00378, val_loss=0.00551,\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00378, val_loss=0.00551,\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00378, val_loss=0.00544,\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.0282, val_loss=0.00544, \u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:01<00:00, 27.39it/s, loss=0.0282, val_loss=0.00544, \n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 34.52it/s, loss=0.0282, val_loss=0.00544, \u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.0282, val_loss=0.354, av\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 20.49it/s, loss=0.0165, val_loss=0.354, av\u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:02<00:00, 26.70it/s, loss=0.0165, val_loss=0.354, av\n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 33.68it/s, loss=0.0165, val_loss=0.354, av\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 36.09it/s, loss=0.0165, val_loss=0.0088, a\u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:02<00:02, 19.40it/s, loss=0.00395, val_loss=0.0088, \u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:02<00:01, 25.30it/s, loss=0.00395, val_loss=0.0088, \n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 31.98it/s, loss=0.00395, val_loss=0.0088, \u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 34.40it/s, loss=0.00395, val_loss=0.00522,\u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:02<00:02, 19.64it/s, loss=0.00377, val_loss=0.00522,\u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:02<00:01, 25.41it/s, loss=0.00377, val_loss=0.00522,\n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 32.34it/s, loss=0.00377, val_loss=0.00522,\u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 34.74it/s, loss=0.00377, val_loss=0.00517,\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:02<00:02, 19.67it/s, loss=0.107, val_loss=0.00517, a\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:02<00:01, 25.14it/s, loss=0.107, val_loss=0.00517, a\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 34.35it/s, loss=0.107, val_loss=0.0356, av\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.07it/s, loss=0.00508, val_loss=0.0356, \u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:02<00:00, 26.15it/s, loss=0.00508, val_loss=0.0356, \n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 33.07it/s, loss=0.00508, val_loss=0.0356, \u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 35.51it/s, loss=0.00508, val_loss=0.00558,\u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:02<00:02, 19.93it/s, loss=0.0763, val_loss=0.00558, \u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:02<00:01, 25.88it/s, loss=0.0763, val_loss=0.00558, \n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 32.68it/s, loss=0.0763, val_loss=0.00558, \u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 35.17it/s, loss=0.0763, val_loss=0.0151, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 21.06it/s, loss=0.00494, val_loss=0.0151, \u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:01<00:00, 27.42it/s, loss=0.00494, val_loss=0.0151, \n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 34.56it/s, loss=0.00494, val_loss=0.0151, \u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 37.06it/s, loss=0.00494, val_loss=0.0051, \u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00378, val_loss=0.0051, \u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:01<00:00, 28.39it/s, loss=0.00378, val_loss=0.0051, \n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 35.71it/s, loss=0.00378, val_loss=0.0051, \u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 38.25it/s, loss=0.00378, val_loss=0.00488,\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 38.06it/s, loss=0.00378, val_loss=0.00488,\u001b[A\n",
      "Sizes of clusters: 358, 604, 588, 213, 237\n",
      "\n",
      "preds: [4 4 4 4 4 0 4 0 4 0 4 4 4 4 0 4 0 4 4 2 0 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4\n",
      " 4 0 4 4 4 0 4 0 0 4 4 4 0 4 2 4 4 4 2 4 4 4 0 0 4 0 4 4 4 4 4 4 0 2 0 0 4\n",
      " 0 0 0 4 4 4 0 4 0 0 0 4 4 4 4 0 0 4 4 4 0 2 0 0 4 0 0 2 4 0 0 4 4 4 4 0 4\n",
      " 0 4 0 4 4 4 4 4 0 4 0 4 0 4 4 4 0 4 0 0 0 0 4 0 0 0 4 0 4 0 0 0 0 4 0 4 0\n",
      " 4 4 0 4 0 0 4 4 4 4 4 4 4 4 4 4 4 0 0 0 4 0 4 0 0 0 4 0 0 4 4 4 4 4 4 4 4\n",
      " 4 0 4 0 4 4 0 0 4 4 0 4 4 4 4 4 0 4 0 0 4 4 0 4 4 0 2 0 4 4 0 0 4 4 2 4 4\n",
      " 4 0 0 4 4 4 4 0 4 0 0 0 4 2 4 4 4 4 0 0 4 2 0 4 4 4 2 0 4 0 0 4 0 4 0 0 4\n",
      " 0 4 0 4 0 0 0 0 4 4 0 4 0 0 0 4 4 4 0 4 0 4 4 0 4 0 4 4 4 0 4 4 0 4 0 4 4\n",
      " 4 4 0 4 0 4 0 4 4 4 2 0 4 4 4 0 4 0 4 4 4 0 4 4 4 2 4 4 4 0 4 4 4 0 4 4 2\n",
      " 4 0 0 4 4 4 0 0 4 0 4 2 4 0 4 0 4 4 4 4 0 0 0 0 0 0 4 0 0 4 0 4 4 2 0 0 4\n",
      " 0 4 4 0 4 4 4 0 4 4 4 0 0 4 2 0 4 4 0 0 4 0 0 0 4 4 0 0 4 0 2 0 1 2 1 3 2\n",
      " 3 1 2 2 2 2 1 0 3 1 1 1 3 3 3 1 1 2 0 1 3 2 1 0 3 1 2 2 2 1 1 1 3 1 1 2 2\n",
      " 1 1 1 1 1 2 2 1 1 2 1 2 1 2 3 0 1 2 1 2 1 2 1 1 2 2 1 2 3 2 0 1 2 1 0 2 1\n",
      " 1 2 1 3 2 1 0 1 1 0 2 1 1 1 1 1 1 2 2 1 1 1 0 2 0 0 2 1 0 2 2 1 1 3 1 2 3\n",
      " 3 1 2 2 2 2 1 1 0 0 1 1 1 1 2 1 1 1 3 2 1 2 0 3 2 2 1 0 1 2 1 1 0 2 1 2 2\n",
      " 2 1 0 1 1 2 2 2 2 3 1 2 0 2 0 2 1 1 2 0 3 3 3 1 1 2 0 2 1 0 0 2 2 3 2 2 2\n",
      " 2 2 1 2 3 2 0 1 2 0 2 1 1 2 1 3 0 1 1 3 3 1 1 1 2 1 2 0 2 0 0 0 0 1 1 3 1\n",
      " 2 1 2 0 1 0 1 1 2 0 2 1 1 2 1 1 2 2 2 0 3 0 1 1 3 3 1 1 1 2 2 2 3 0 2 3 2\n",
      " 0 1 0 2 1 1 1 3 3 2 1 2 0 1 1 2 0 0 1 0 1 1 1 3 2 2 1 2 3 0 2 3 3 2 2 1 2\n",
      " 2 0 1 3 1 0 1 1 1 2 3 2 2 1 0 2 3 2 1 2 3 1 1 1 1 1 1 1 1 1 2 1 1 1 1 0 1\n",
      " 2 0 1 0 3 2 2 1 1 2 2 2 2 1 0 1 1 1 0 1 1 2 2 0 3 1 1 3 1 1 2 1 1 1 1 1 1\n",
      " 2 1 3 3 2 2 3 1 1 3 1 0 2 3 3 2 3 3 0 2 2 2 2 2 0 2 2 1 2 1 1 2 2 1 2 0 1\n",
      " 3 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 0 1 1 2 4 0 0 2 1 2 1 1 1 2 2 1 2 2\n",
      " 2 1 2 2 2 2 2 3 2 2 2 1 3 4 2 1 0 2 2 2 1 2 2 2 2 3 2 2 2 2 2 3 1 3 1 2 2\n",
      " 2 2 1 2 0 2 0 2 2 1 2 2 1 1 1 1 2 2 2 2 2 2 2 1 1 2 3 1 4 2 2 1 2 2 1 1 2\n",
      " 2 0 2 3 1 0 2 0 2 2 2 2 0 2 2 2 2 0 1 0 2 2 2 2 1 0 2 0 2 2 2 2 0 2 3 2 2\n",
      " 1 2 0 2 1 0 2 2 2 2 2 2 1 1 2 1 2 1 3 1 0 2 2 2 0 1 2 2 2 1 2 2 2 2 2 2 1\n",
      " 1 1 2 2 2 0 1 2 2 2 0 2 1 2 2 2 2 1 3 1 2 2 2 0 2 1 1 2 1 2 2 2 2 2 2 1 2\n",
      " 0 1 1 0 0 2 2 2 0 2 3 1 0 2 0 2 3 2 2 2 3 0 1 1 1 0 1 1 0 2 1 2 2 1 3 1 2\n",
      " 2 2 0 2 1 3 2 2 2 1 0 2 2 1 2 2 1 2 2 1 2 1 2 1 1 1 1 0 2 1 1 2 2 1 3 1 2\n",
      " 2 1 2 0 2 2 1 2 2 2 2 0 2 2 2 2 2 2 0 0 1 2 2 1 0 0 2 0 1 1 2 2 1 2 1 0 2\n",
      " 1 2 2 2 2 4 2 1 1 2 2 2 2 1 2 1 2 3 2 1 1 1 0 2 1 2 1 2 2 0 1 1 1 1 2 2 2\n",
      " 2 2 2 2 1 2 1 2 2 2 1 1 2 1 2 2 1 1 1 2 2 0 1 2 0 2 2 1 2 2 1 2 0 0 3 2 1\n",
      " 2 3 3 2 2 2 2 1 0 0 1 1 1 0 2 1 2 1 1 2 2 2 0 2 2 2 1 1 2 0 0 2 1 1 1 0 2\n",
      " 0 2 1 0 2 2 1 1 1 1 2 2 1 2 2 2 2 3 2 2 0 2 2 2 2 1 1 1 3 1 0 1 2 1 3 4 1\n",
      " 2 1 1 2 2 1 1 1 2 1 0 3 2 2 2 2 0 0 1 2 3 1 2 2 1 1 2 2 0 2 2 3 0 1 2 4 1\n",
      " 2 3 0 2 2 0 0 1 1 2 2 3 1 0 2 2 3 1 2 2 2 1 0 0 0 0 0 2 3 2 1 1 1 0 0 1 2\n",
      " 1 2 2 1 1 0 2 0 2 2 2 0 1 1 0 2 2 1 1 2 2 2 1 1 0 2 2 2 0 2 1 1 2 1 2 1 1\n",
      " 1 1 0 1 2 1 1 0 2 0 2 2 2 2 2 0 3 1 1 1 1 2 1 1 3 2 0 2 2 1 2 2 0 0 0 0 1\n",
      " 1 2 2 0 2 1 0 1 1 0 1 1 0 2 0 1 2 1 1 1 0 2 2 3 1 2 1 2 0 1 2 0 1 0 2 2 0\n",
      " 2 1 1 2 2 1 1 0 0 2 2 3 0 1 1 0 3 0 0 1 0 2 2 0 3 1 1 1 1 1 1 0 1 0 2 2 2\n",
      " 2 0 0 1 0 3 0 0 1 3 1 2 2 0 1 0 2 1 2 1 3 0 1 2 2 2 2 2 0 1 2 2 1 1 0 1 2\n",
      " 2 0 1 3 2 0 2 0 0 2 2 3 1 2 2 1 4 1 0 0 1 0 2 1 1 2 0 2 2 2 2 0 2 2 0 0 3\n",
      " 2 2 2 2 0 2 1 0 2 1 1 3 3 1 1 3 1 1 1 1 3 1 1 3 1 2 1 1 3 2 3 2 3 3 3 1 1\n",
      " 1 1 3 1 1 1 1 1 1 2 1 2 1 3 1 3 1 1 2 3 3 3 1 1 0 3 1 1 3 1 2 1 2 1 1 1 3\n",
      " 3 2 1 1 1 0 1 1 1 3 3 1 0 1 0 0 3 1 2 2 3 1 1 1 3 2 3 1 3 3 2 3 1 1 1 1 1\n",
      " 3 1 3 1 1 1 1 3 2 1 1 1 1 3 2 1 1 2 3 1 3 1 3 3 1 3 1 2 1 3 1 3 1 2 2 1 1\n",
      " 1 1 1 1 3 3 3 2 3 1 3 0 1 1 3 1 3 1 1 3 1 3 1 1 1 1 1 2 2 3 3 0 1 1 1 1 3\n",
      " 3 3 1 1 1 1 1 1 1 1 1 1 3 2 3 1 1 3 3 1 1 1 1 0 1 1 1 3 3 1 1 2 2 1 3 3 1\n",
      " 1 3 2 2 1 1 3 1 3 1 1 2 1 2 2 1 2 3 1 1 1 2 1 1 1 1 3 3 1 2 3 1 1 1 2 3 1\n",
      " 2 2 1 1 3 2 2 3 3 3 3 2 2 3 1 1 1 3 3 2 1 3 1 1 3 1 1 0 2 2 1 1 3 2 1 1 1\n",
      " 1 1 1 3 1 1 2 2 1 1 3 1 3 1 2 0 3 1 3 3 3 1 1 3 1 3 3 2 1 2 3 3 1 1 1 2 1\n",
      " 2 1 3 1 3 0 0 1 2 3 1 1 2 3 1 3 2 1 3 1 3 3 0 1 3 2 1 1 3 3 3 2 1 1 1 1 3\n",
      " 1 3 0 3 2 3 1 1 1 1 3 3 2 1 3 1 1 1 3 2 1 1 1 1 1 1 3 3 2 2 1 3 1 3 1 1 1\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.4660\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=1.11, val_loss=0.0987, avg_\n",
      "Epoch 0:  64%|▋| 51/80 [00:02<00:01, 25.40it/s, loss=1.11, val_loss=0.0987, avg_\n",
      "Epoch 0:  84%|▊| 67/80 [00:02<00:00, 31.77it/s, loss=1.11, val_loss=0.0987, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 36.12it/s, loss=1.11, val_loss=2.84, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.0589, val_loss=2.84, avg_\u001b[A\n",
      "Epoch 1:  60%|▌| 48/80 [00:01<00:01, 25.52it/s, loss=0.0589, val_loss=2.84, avg_\n",
      "Epoch 1:  80%|▊| 64/80 [00:01<00:00, 32.29it/s, loss=0.0589, val_loss=2.84, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.0589, val_loss=0.0806, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.83it/s, loss=0.0263, val_loss=0.0806, av\u001b[A\n",
      "Epoch 2:  60%|▌| 48/80 [00:01<00:01, 24.52it/s, loss=0.0263, val_loss=0.0806, av\n",
      "Epoch 2:  81%|▊| 65/80 [00:02<00:00, 31.47it/s, loss=0.0263, val_loss=0.0806, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.61it/s, loss=0.0263, val_loss=0.0432, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.0189, val_loss=0.0432, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:02<00:01, 24.92it/s, loss=0.0189, val_loss=0.0432, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:02<00:00, 31.63it/s, loss=0.0189, val_loss=0.0432, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 35.59it/s, loss=0.0189, val_loss=0.0282, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.0148, val_loss=0.0282, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 25.91it/s, loss=0.0148, val_loss=0.0282, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:02<00:00, 32.79it/s, loss=0.0148, val_loss=0.0282, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.82it/s, loss=0.0148, val_loss=0.0219, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.0123, val_loss=0.0219, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 25.93it/s, loss=0.0123, val_loss=0.0219, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:02<00:00, 32.68it/s, loss=0.0123, val_loss=0.0219, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 36.73it/s, loss=0.0123, val_loss=0.0176, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.0107, val_loss=0.0176, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 25.65it/s, loss=0.0107, val_loss=0.0176, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:02<00:00, 32.50it/s, loss=0.0107, val_loss=0.0176, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 36.58it/s, loss=0.0107, val_loss=0.0152, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:02<00:02, 19.89it/s, loss=0.00961, val_loss=0.0152, a\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:02<00:01, 24.64it/s, loss=0.00961, val_loss=0.0152, a\n",
      "Epoch 7:  85%|▊| 68/80 [00:02<00:00, 31.23it/s, loss=0.00961, val_loss=0.0152, a\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 35.04it/s, loss=0.00961, val_loss=0.0128, a\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:02<00:02, 19.79it/s, loss=0.00872, val_loss=0.0128, a\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:02<00:01, 24.49it/s, loss=0.00872, val_loss=0.0128, a\n",
      "Epoch 8:  85%|▊| 68/80 [00:02<00:00, 30.97it/s, loss=0.00872, val_loss=0.0128, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 34.96it/s, loss=0.00872, val_loss=0.012, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 20.26it/s, loss=0.00796, val_loss=0.012, av\u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:02<00:01, 25.17it/s, loss=0.00796, val_loss=0.012, av\n",
      "Epoch 9:  85%|▊| 68/80 [00:02<00:00, 31.64it/s, loss=0.00796, val_loss=0.012, av\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 35.68it/s, loss=0.00796, val_loss=0.0118, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00735, val_loss=0.0118, \u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:02<00:01, 25.37it/s, loss=0.00735, val_loss=0.0118, \n",
      "Epoch 10:  85%|▊| 68/80 [00:02<00:00, 32.16it/s, loss=0.00735, val_loss=0.0118, \u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 36.16it/s, loss=0.00735, val_loss=0.0143, \u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:02<00:02, 19.88it/s, loss=0.00688, val_loss=0.0143, \u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:02<00:01, 24.73it/s, loss=0.00688, val_loss=0.0143, \n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 31.35it/s, loss=0.00688, val_loss=0.0143, \u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 35.25it/s, loss=0.00688, val_loss=0.00984,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 20.41it/s, loss=0.00648, val_loss=0.00984,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:02<00:01, 25.37it/s, loss=0.00648, val_loss=0.00984,\n",
      "Epoch 12:  85%|▊| 68/80 [00:02<00:00, 32.09it/s, loss=0.00648, val_loss=0.00984,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 36.04it/s, loss=0.00648, val_loss=0.00917,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00612, val_loss=0.00917,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 26.87it/s, loss=0.00612, val_loss=0.00917,\n",
      "Epoch 13:  85%|▊| 68/80 [00:02<00:00, 33.90it/s, loss=0.00612, val_loss=0.00917,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00612, val_loss=0.00829,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.24it/s, loss=0.0058, val_loss=0.00829, \u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 26.37it/s, loss=0.0058, val_loss=0.00829, \n",
      "Epoch 14:  85%|▊| 68/80 [00:02<00:00, 33.32it/s, loss=0.0058, val_loss=0.00829, \u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.36it/s, loss=0.0058, val_loss=0.00753, \u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.10it/s, loss=0.00553, val_loss=0.00753,\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 26.12it/s, loss=0.00553, val_loss=0.00753,\n",
      "Epoch 15:  85%|▊| 68/80 [00:02<00:00, 33.08it/s, loss=0.00553, val_loss=0.00753,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00553, val_loss=0.00707,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:02<00:02, 19.98it/s, loss=0.00528, val_loss=0.00707,\u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:02<00:01, 24.81it/s, loss=0.00528, val_loss=0.00707,\n",
      "Epoch 16:  85%|▊| 68/80 [00:02<00:00, 31.30it/s, loss=0.00528, val_loss=0.00707,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 35.29it/s, loss=0.00528, val_loss=0.00735,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:02<00:02, 19.45it/s, loss=0.00507, val_loss=0.00735,\u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:02<00:01, 24.07it/s, loss=0.00507, val_loss=0.00735,\n",
      "Epoch 17:  85%|▊| 68/80 [00:02<00:00, 30.55it/s, loss=0.00507, val_loss=0.00735,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 34.45it/s, loss=0.00507, val_loss=0.0065, \u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:02<00:02, 19.78it/s, loss=0.0049, val_loss=0.0065, a\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:02<00:01, 24.47it/s, loss=0.0049, val_loss=0.0065, a\n",
      "Epoch 18:  85%|▊| 68/80 [00:02<00:00, 30.94it/s, loss=0.0049, val_loss=0.0065, a\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 34.99it/s, loss=0.0049, val_loss=0.00627, \u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:02<00:02, 19.76it/s, loss=0.00478, val_loss=0.00627,\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:02<00:01, 24.48it/s, loss=0.00478, val_loss=0.00627,\n",
      "Epoch 19:  85%|▊| 68/80 [00:02<00:00, 30.95it/s, loss=0.00478, val_loss=0.00627,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 34.96it/s, loss=0.00478, val_loss=0.006, a\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00468, val_loss=0.006, a\u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:02<00:01, 25.45it/s, loss=0.00468, val_loss=0.006, a\n",
      "Epoch 20:  85%|▊| 68/80 [00:02<00:00, 32.18it/s, loss=0.00468, val_loss=0.006, a\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 36.18it/s, loss=0.00468, val_loss=0.00584,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:02<00:02, 20.00it/s, loss=0.0046, val_loss=0.00584, \u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:02<00:01, 24.88it/s, loss=0.0046, val_loss=0.00584, \n",
      "Epoch 21:  85%|▊| 68/80 [00:02<00:00, 31.52it/s, loss=0.0046, val_loss=0.00584, \u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 35.42it/s, loss=0.0046, val_loss=0.0058, a\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00452, val_loss=0.0058, \u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:01<00:01, 26.94it/s, loss=0.00452, val_loss=0.0058, \n",
      "Epoch 22:  85%|▊| 68/80 [00:02<00:00, 33.98it/s, loss=0.00452, val_loss=0.0058, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00452, val_loss=0.00571,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.00445, val_loss=0.00571,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 26.19it/s, loss=0.00445, val_loss=0.00571,\n",
      "Epoch 23:  85%|▊| 68/80 [00:02<00:00, 33.11it/s, loss=0.00445, val_loss=0.00571,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.13it/s, loss=0.00445, val_loss=0.00559,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.05it/s, loss=0.00439, val_loss=0.00559,\u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 26.10it/s, loss=0.00439, val_loss=0.00559,\n",
      "Epoch 24:  85%|▊| 68/80 [00:02<00:00, 32.97it/s, loss=0.00439, val_loss=0.00559,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 36.93it/s, loss=0.00439, val_loss=0.00532,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 20.53it/s, loss=0.00433, val_loss=0.00532,\u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:02<00:01, 25.41it/s, loss=0.00433, val_loss=0.00532,\n",
      "Epoch 25:  85%|▊| 68/80 [00:02<00:00, 32.20it/s, loss=0.00433, val_loss=0.00532,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 36.22it/s, loss=0.00433, val_loss=0.00504,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.23it/s, loss=0.00429, val_loss=0.00504,\u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:02<00:01, 24.99it/s, loss=0.00429, val_loss=0.00504,\n",
      "Epoch 26:  85%|▊| 68/80 [00:02<00:00, 31.72it/s, loss=0.00429, val_loss=0.00504,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 35.54it/s, loss=0.00429, val_loss=0.00498,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:02<00:02, 19.54it/s, loss=0.00425, val_loss=0.00498,\u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:02<00:01, 24.28it/s, loss=0.00425, val_loss=0.00498,\n",
      "Epoch 27:  85%|▊| 68/80 [00:02<00:00, 30.78it/s, loss=0.00425, val_loss=0.00498,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 34.68it/s, loss=0.00425, val_loss=0.00494,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:02<00:02, 19.50it/s, loss=0.00422, val_loss=0.00494,\u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:02<00:01, 24.22it/s, loss=0.00422, val_loss=0.00494,\n",
      "Epoch 28:  85%|▊| 68/80 [00:02<00:00, 30.58it/s, loss=0.00422, val_loss=0.00494,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 34.33it/s, loss=0.00422, val_loss=0.00482,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:02<00:02, 19.51it/s, loss=0.0042, val_loss=0.00482, \u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:02<00:01, 24.27it/s, loss=0.0042, val_loss=0.00482, \n",
      "Epoch 29:  85%|▊| 68/80 [00:02<00:00, 30.64it/s, loss=0.0042, val_loss=0.00482, \u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 34.39it/s, loss=0.0042, val_loss=0.00474, \u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 20.32it/s, loss=0.00418, val_loss=0.00474,\u001b[A\n",
      "Epoch 30:  64%|▋| 51/80 [00:02<00:01, 25.27it/s, loss=0.00418, val_loss=0.00474,\n",
      "Epoch 30:  85%|▊| 68/80 [00:02<00:00, 31.98it/s, loss=0.00418, val_loss=0.00474,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 35.94it/s, loss=0.00418, val_loss=0.00525,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00417, val_loss=0.00525,\u001b[A\n",
      "Epoch 31:  64%|▋| 51/80 [00:01<00:01, 26.91it/s, loss=0.00417, val_loss=0.00525,\n",
      "Epoch 31:  85%|▊| 68/80 [00:02<00:00, 33.95it/s, loss=0.00417, val_loss=0.00525,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.03it/s, loss=0.00417, val_loss=0.00536,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.40it/s, loss=0.00416, val_loss=0.00536,\u001b[A\n",
      "Epoch 32:  64%|▋| 51/80 [00:01<00:01, 26.57it/s, loss=0.00416, val_loss=0.00536,\n",
      "Epoch 32:  85%|▊| 68/80 [00:02<00:00, 33.53it/s, loss=0.00416, val_loss=0.00536,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 37.57it/s, loss=0.00416, val_loss=0.00455,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.08it/s, loss=0.00413, val_loss=0.00455,\u001b[A\n",
      "Epoch 33:  64%|▋| 51/80 [00:01<00:01, 26.17it/s, loss=0.00413, val_loss=0.00455,\n",
      "Epoch 33:  85%|▊| 68/80 [00:02<00:00, 32.95it/s, loss=0.00413, val_loss=0.00455,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 37.00it/s, loss=0.00413, val_loss=0.00527,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:02<00:02, 19.51it/s, loss=0.00411, val_loss=0.00527,\u001b[A\n",
      "Epoch 34:  64%|▋| 51/80 [00:02<00:01, 24.25it/s, loss=0.00411, val_loss=0.00527,\n",
      "Epoch 34:  85%|▊| 68/80 [00:02<00:00, 30.68it/s, loss=0.00411, val_loss=0.00527,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 34.66it/s, loss=0.00411, val_loss=0.00428,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.31it/s, loss=0.00408, val_loss=0.00428,\u001b[A\n",
      "Epoch 35:  64%|▋| 51/80 [00:02<00:01, 25.24it/s, loss=0.00408, val_loss=0.00428,\n",
      "Epoch 35:  85%|▊| 68/80 [00:02<00:00, 31.92it/s, loss=0.00408, val_loss=0.00428,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 35.84it/s, loss=0.00408, val_loss=0.00559,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.13it/s, loss=0.00406, val_loss=0.00559,\u001b[A\n",
      "Epoch 36:  64%|▋| 51/80 [00:02<00:01, 24.98it/s, loss=0.00406, val_loss=0.00559,\n",
      "Epoch 36:  85%|▊| 68/80 [00:02<00:00, 31.65it/s, loss=0.00406, val_loss=0.00559,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 35.53it/s, loss=0.00406, val_loss=0.0045, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:02<00:02, 19.72it/s, loss=0.00404, val_loss=0.0045, \u001b[A\n",
      "Epoch 37:  64%|▋| 51/80 [00:02<00:01, 24.52it/s, loss=0.00404, val_loss=0.0045, \n",
      "Epoch 37:  85%|▊| 68/80 [00:02<00:00, 31.08it/s, loss=0.00404, val_loss=0.0045, \u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 34.89it/s, loss=0.00404, val_loss=0.00442,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 20.15it/s, loss=0.00402, val_loss=0.00442,\u001b[A\n",
      "Epoch 38:  64%|▋| 51/80 [00:02<00:01, 25.06it/s, loss=0.00402, val_loss=0.00442,\n",
      "Epoch 38:  85%|▊| 68/80 [00:02<00:00, 31.68it/s, loss=0.00402, val_loss=0.00442,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 35.67it/s, loss=0.00402, val_loss=0.00432,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 20.22it/s, loss=0.00401, val_loss=0.00432,\u001b[A\n",
      "Epoch 39:  64%|▋| 51/80 [00:02<00:01, 25.14it/s, loss=0.00401, val_loss=0.00432,\n",
      "Epoch 39:  85%|▊| 68/80 [00:02<00:00, 31.82it/s, loss=0.00401, val_loss=0.00432,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 35.76it/s, loss=0.00401, val_loss=0.00467,\u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00403, val_loss=0.00467,\u001b[A\n",
      "Epoch 40:  64%|▋| 51/80 [00:01<00:01, 26.66it/s, loss=0.00403, val_loss=0.00467,\n",
      "Epoch 40:  85%|▊| 68/80 [00:02<00:00, 33.66it/s, loss=0.00403, val_loss=0.00467,\u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 37.73it/s, loss=0.00403, val_loss=0.00414,\u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 21.43it/s, loss=0.00406, val_loss=0.00414,\u001b[A\n",
      "Epoch 41:  64%|▋| 51/80 [00:01<00:01, 26.60it/s, loss=0.00406, val_loss=0.00414,\n",
      "Epoch 41:  85%|▊| 68/80 [00:02<00:00, 33.57it/s, loss=0.00406, val_loss=0.00414,\u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 37.62it/s, loss=0.00406, val_loss=0.00405,\u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 20.93it/s, loss=0.00412, val_loss=0.00405,\u001b[A\n",
      "Epoch 42:  64%|▋| 51/80 [00:01<00:01, 26.00it/s, loss=0.00412, val_loss=0.00405,\n",
      "Epoch 42:  85%|▊| 68/80 [00:02<00:00, 32.86it/s, loss=0.00412, val_loss=0.00405,\u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 36.85it/s, loss=0.00412, val_loss=0.00459,\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 20.52it/s, loss=0.00416, val_loss=0.00459,\u001b[A\n",
      "Epoch 43:  64%|▋| 51/80 [00:02<00:01, 25.45it/s, loss=0.00416, val_loss=0.00459,\n",
      "Epoch 43:  85%|▊| 68/80 [00:02<00:00, 32.14it/s, loss=0.00416, val_loss=0.00459,\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 36.16it/s, loss=0.00416, val_loss=0.00455,\u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.22it/s, loss=0.00426, val_loss=0.00455,\u001b[A\n",
      "Epoch 44:  64%|▋| 51/80 [00:02<00:01, 25.04it/s, loss=0.00426, val_loss=0.00455,\n",
      "Epoch 44:  85%|▊| 68/80 [00:02<00:00, 31.67it/s, loss=0.00426, val_loss=0.00455,\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 35.65it/s, loss=0.00426, val_loss=0.00545,\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:02<00:02, 19.85it/s, loss=0.00416, val_loss=0.00545,\u001b[A\n",
      "Epoch 45:  64%|▋| 51/80 [00:02<00:01, 24.44it/s, loss=0.00416, val_loss=0.00545,\n",
      "Epoch 45:  85%|▊| 68/80 [00:02<00:00, 31.01it/s, loss=0.00416, val_loss=0.00545,\u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 34.98it/s, loss=0.00416, val_loss=0.00505,\u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:01<00:01, 20.26it/s, loss=0.00428, val_loss=0.00505,\u001b[A\n",
      "Epoch 46:  64%|▋| 51/80 [00:02<00:01, 25.15it/s, loss=0.00428, val_loss=0.00505,\n",
      "Epoch 46:  85%|▊| 68/80 [00:02<00:00, 31.86it/s, loss=0.00428, val_loss=0.00505,\u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 35.77it/s, loss=0.00428, val_loss=0.00476,\u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:01<00:01, 20.26it/s, loss=0.00446, val_loss=0.00476,\u001b[A\n",
      "Epoch 47:  64%|▋| 51/80 [00:02<00:01, 25.08it/s, loss=0.00446, val_loss=0.00476,\n",
      "Epoch 47:  85%|▊| 68/80 [00:02<00:00, 31.71it/s, loss=0.00446, val_loss=0.00476,\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 35.74it/s, loss=0.00446, val_loss=0.00496,\u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.20it/s, loss=0.0048, val_loss=0.00496, \u001b[A\n",
      "Epoch 48:  64%|▋| 51/80 [00:02<00:01, 25.01it/s, loss=0.0048, val_loss=0.00496, \n",
      "Epoch 48:  85%|▊| 68/80 [00:02<00:00, 31.70it/s, loss=0.0048, val_loss=0.00496, \u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 35.60it/s, loss=0.0048, val_loss=0.00552, \u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00486, val_loss=0.00552,\u001b[A\n",
      "Epoch 49:  64%|▋| 51/80 [00:01<00:01, 27.00it/s, loss=0.00486, val_loss=0.00552,\n",
      "Epoch 49:  85%|▊| 68/80 [00:01<00:00, 34.07it/s, loss=0.00486, val_loss=0.00552,\u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00486, val_loss=0.00743,\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00674, val_loss=0.00743,\u001b[A\n",
      "Epoch 50:  64%|▋| 51/80 [00:01<00:01, 26.83it/s, loss=0.00674, val_loss=0.00743,\n",
      "Epoch 50:  85%|▊| 68/80 [00:02<00:00, 33.86it/s, loss=0.00674, val_loss=0.00743,\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.00674, val_loss=0.00629,\u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.00493, val_loss=0.00629,\u001b[A\n",
      "Epoch 51:  64%|▋| 51/80 [00:01<00:01, 25.72it/s, loss=0.00493, val_loss=0.00629,\n",
      "Epoch 51:  85%|▊| 68/80 [00:02<00:00, 32.46it/s, loss=0.00493, val_loss=0.00629,\u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 36.53it/s, loss=0.00493, val_loss=0.00506,\u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 20.18it/s, loss=0.00513, val_loss=0.00506,\u001b[A\n",
      "Epoch 52:  64%|▋| 51/80 [00:02<00:01, 25.09it/s, loss=0.00513, val_loss=0.00506,\n",
      "Epoch 52:  85%|▊| 68/80 [00:02<00:00, 31.79it/s, loss=0.00513, val_loss=0.00506,\u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 35.72it/s, loss=0.00513, val_loss=0.0127, \u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.0061, val_loss=0.0127, a\u001b[A\n",
      "Epoch 53:  64%|▋| 51/80 [00:01<00:01, 26.63it/s, loss=0.0061, val_loss=0.0127, a\n",
      "Epoch 53:  85%|▊| 68/80 [00:02<00:00, 33.63it/s, loss=0.0061, val_loss=0.0127, a\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 37.71it/s, loss=0.0061, val_loss=0.0057, a\u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:01<00:01, 20.83it/s, loss=0.00575, val_loss=0.0057, \u001b[A\n",
      "Epoch 54:  64%|▋| 51/80 [00:01<00:01, 25.87it/s, loss=0.00575, val_loss=0.0057, \n",
      "Epoch 54:  85%|▊| 68/80 [00:02<00:00, 32.74it/s, loss=0.00575, val_loss=0.0057, \u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 36.75it/s, loss=0.00575, val_loss=0.0052, \u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.00744, val_loss=0.0052, \u001b[A\n",
      "Epoch 55:  64%|▋| 51/80 [00:01<00:01, 25.88it/s, loss=0.00744, val_loss=0.0052, \n",
      "Epoch 55:  85%|▊| 68/80 [00:02<00:00, 32.74it/s, loss=0.00744, val_loss=0.0052, \u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 36.77it/s, loss=0.00744, val_loss=0.00761,\u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00847, val_loss=0.00761,\u001b[A\n",
      "Epoch 56:  64%|▋| 51/80 [00:01<00:01, 25.82it/s, loss=0.00847, val_loss=0.00761,\n",
      "Epoch 56:  85%|▊| 68/80 [00:02<00:00, 32.64it/s, loss=0.00847, val_loss=0.00761,\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.00847, val_loss=0.021, a\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 21.14it/s, loss=0.00817, val_loss=0.021, a\u001b[A\n",
      "Epoch 57:  64%|▋| 51/80 [00:01<00:01, 26.26it/s, loss=0.00817, val_loss=0.021, a\n",
      "Epoch 57:  85%|▊| 68/80 [00:02<00:00, 33.16it/s, loss=0.00817, val_loss=0.021, a\u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 37.18it/s, loss=0.00817, val_loss=0.00808,\u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:01<00:01, 20.65it/s, loss=0.00917, val_loss=0.00808,\u001b[A\n",
      "Epoch 58:  64%|▋| 51/80 [00:01<00:01, 25.66it/s, loss=0.00917, val_loss=0.00808,\n",
      "Epoch 58:  85%|▊| 68/80 [00:02<00:00, 32.40it/s, loss=0.00917, val_loss=0.00808,\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 36.31it/s, loss=0.00917, val_loss=0.0116, \u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 20.47it/s, loss=0.00894, val_loss=0.0116, \u001b[A\n",
      "Epoch 59:  64%|▋| 51/80 [00:02<00:01, 25.41it/s, loss=0.00894, val_loss=0.0116, \n",
      "Epoch 59:  85%|▊| 68/80 [00:02<00:00, 32.19it/s, loss=0.00894, val_loss=0.0116, \u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 36.10it/s, loss=0.00894, val_loss=0.0106, \u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 20.35it/s, loss=0.00879, val_loss=0.0106, \u001b[A\n",
      "Epoch 60:  64%|▋| 51/80 [00:02<00:01, 25.22it/s, loss=0.00879, val_loss=0.0106, \n",
      "Epoch 60:  85%|▊| 68/80 [00:02<00:00, 31.96it/s, loss=0.00879, val_loss=0.0106, \u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 35.88it/s, loss=0.00879, val_loss=0.0105, \u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00832, val_loss=0.0105, \u001b[A\n",
      "Epoch 61:  64%|▋| 51/80 [00:02<00:01, 24.96it/s, loss=0.00832, val_loss=0.0105, \n",
      "Epoch 61:  86%|▊| 69/80 [00:02<00:00, 32.13it/s, loss=0.00832, val_loss=0.0105, \u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 35.67it/s, loss=0.00832, val_loss=0.0108, \u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:02<00:02, 19.99it/s, loss=0.00709, val_loss=0.0108, \u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:02<00:00, 26.06it/s, loss=0.00709, val_loss=0.0108, \n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 32.83it/s, loss=0.00709, val_loss=0.0108, \u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 35.43it/s, loss=0.00709, val_loss=0.0103, \u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:02<00:02, 19.86it/s, loss=0.0078, val_loss=0.0103, a\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:02<00:01, 25.89it/s, loss=0.0078, val_loss=0.0103, a\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 32.68it/s, loss=0.0078, val_loss=0.0103, a\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 35.11it/s, loss=0.0078, val_loss=0.0301, a\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:02<00:02, 19.87it/s, loss=0.00793, val_loss=0.0301, \u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:02<00:01, 25.83it/s, loss=0.00793, val_loss=0.0301, \n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 32.62it/s, loss=0.00793, val_loss=0.0301, \u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 35.20it/s, loss=0.00793, val_loss=0.00717,\u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00812, val_loss=0.00717,\u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:01<00:00, 28.40it/s, loss=0.00812, val_loss=0.00717,\n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 35.71it/s, loss=0.00812, val_loss=0.00717,\u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 38.25it/s, loss=0.00812, val_loss=0.0063, \u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:01<00:01, 21.01it/s, loss=0.00805, val_loss=0.0063, \u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:01<00:00, 27.34it/s, loss=0.00805, val_loss=0.0063, \n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 34.36it/s, loss=0.00805, val_loss=0.0063, \u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 36.97it/s, loss=0.00805, val_loss=0.00726,\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.00829, val_loss=0.00726,\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:01<00:00, 27.15it/s, loss=0.00829, val_loss=0.00726,\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 34.20it/s, loss=0.00829, val_loss=0.00726,\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 36.74it/s, loss=0.00829, val_loss=0.00925,\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:02<00:02, 19.90it/s, loss=0.0153, val_loss=0.00925, \u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:02<00:01, 25.91it/s, loss=0.0153, val_loss=0.00925, \n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 32.75it/s, loss=0.0153, val_loss=0.00925, \u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 35.20it/s, loss=0.0153, val_loss=0.0509, a\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:02<00:02, 19.90it/s, loss=0.00789, val_loss=0.0509, \u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:02<00:01, 25.87it/s, loss=0.00789, val_loss=0.0509, \n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 32.73it/s, loss=0.00789, val_loss=0.0509, \u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 35.19it/s, loss=0.00789, val_loss=0.00864,\u001b[A\n",
      "Epoch 70:  50%|▌| 40/80 [00:02<00:02, 19.72it/s, loss=0.00696, val_loss=0.00864,\u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:02<00:01, 25.64it/s, loss=0.00696, val_loss=0.00864,\n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 32.48it/s, loss=0.00696, val_loss=0.00864,\u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 34.92it/s, loss=0.00696, val_loss=0.00881,\u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:02<00:02, 19.69it/s, loss=0.0121, val_loss=0.00881, \u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:02<00:01, 25.63it/s, loss=0.0121, val_loss=0.00881, \n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 32.33it/s, loss=0.0121, val_loss=0.00881, \u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 34.87it/s, loss=0.0121, val_loss=0.0165, a\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:01<00:01, 20.36it/s, loss=0.00851, val_loss=0.0165, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00851, val_loss=0.0165, \n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 33.46it/s, loss=0.00851, val_loss=0.0165, \u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.00851, val_loss=0.00927,\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.00939, val_loss=0.00927,\u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:02<00:00, 26.06it/s, loss=0.00939, val_loss=0.00927,\n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 32.96it/s, loss=0.00939, val_loss=0.00927,\u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 35.45it/s, loss=0.00939, val_loss=0.0153, \u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00861, val_loss=0.0153, \u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00861, val_loss=0.0153, \n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 35.57it/s, loss=0.00861, val_loss=0.0153, \u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.00861, val_loss=0.0105, \u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.0168, val_loss=0.0105, a\u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:01<00:00, 27.99it/s, loss=0.0168, val_loss=0.0105, a\n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 35.18it/s, loss=0.0168, val_loss=0.0105, a\u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 37.67it/s, loss=0.0168, val_loss=0.0106, a\u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.92it/s, loss=0.00913, val_loss=0.0106, \u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:01<00:00, 27.13it/s, loss=0.00913, val_loss=0.0106, \n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 34.24it/s, loss=0.00913, val_loss=0.0106, \u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 36.83it/s, loss=0.00913, val_loss=0.0154, \u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:02<00:02, 19.98it/s, loss=0.0155, val_loss=0.0154, a\u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:02<00:01, 25.97it/s, loss=0.0155, val_loss=0.0154, a\n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 32.83it/s, loss=0.0155, val_loss=0.0154, a\u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 35.29it/s, loss=0.0155, val_loss=0.0816, a\u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 20.08it/s, loss=0.00903, val_loss=0.0816, \u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:02<00:00, 26.15it/s, loss=0.00903, val_loss=0.0816, \n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 32.92it/s, loss=0.00903, val_loss=0.0816, \u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 35.53it/s, loss=0.00903, val_loss=0.0129, \u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:02<00:02, 19.80it/s, loss=0.0133, val_loss=0.0129, a\u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:02<00:01, 25.68it/s, loss=0.0133, val_loss=0.0129, a\n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 32.53it/s, loss=0.0133, val_loss=0.0129, a\u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 35.04it/s, loss=0.0133, val_loss=0.0164, a\u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:02<00:02, 19.91it/s, loss=0.0106, val_loss=0.0164, a\u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:02<00:01, 25.77it/s, loss=0.0106, val_loss=0.0164, a\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 169.83it/s]\u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 35.02it/s, loss=0.0106, val_loss=0.0121, a\u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:02<00:02, 19.93it/s, loss=0.0284, val_loss=0.0121, a\u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:02<00:01, 25.91it/s, loss=0.0284, val_loss=0.0121, a\n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 32.68it/s, loss=0.0284, val_loss=0.0121, a\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 35.12it/s, loss=0.0284, val_loss=0.0429, a\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:02<00:02, 19.74it/s, loss=0.00991, val_loss=0.0429, \u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:02<00:01, 25.77it/s, loss=0.00991, val_loss=0.0429, \n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 32.58it/s, loss=0.00991, val_loss=0.0429, \u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 35.03it/s, loss=0.00991, val_loss=0.00818,\u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00868, val_loss=0.00818,\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:01<00:00, 28.34it/s, loss=0.00868, val_loss=0.00818,\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 35.66it/s, loss=0.00868, val_loss=0.00818,\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 38.20it/s, loss=0.00868, val_loss=0.0195, \u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.00884, val_loss=0.0195, \u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:01<00:00, 27.53it/s, loss=0.00884, val_loss=0.0195, \n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 34.69it/s, loss=0.00884, val_loss=0.0195, \u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 37.19it/s, loss=0.00884, val_loss=0.0113, \u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.0429, val_loss=0.0113, a\u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:01<00:00, 27.33it/s, loss=0.0429, val_loss=0.0113, a\n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 34.47it/s, loss=0.0429, val_loss=0.0113, a\u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 37.01it/s, loss=0.0429, val_loss=0.13, avg\u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:02<00:02, 19.75it/s, loss=0.0102, val_loss=0.13, avg\u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:02<00:01, 25.70it/s, loss=0.0102, val_loss=0.13, avg\n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 32.54it/s, loss=0.0102, val_loss=0.13, avg\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 35.01it/s, loss=0.0102, val_loss=0.0194, a\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.08it/s, loss=0.00875, val_loss=0.0194, \u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:02<00:00, 26.13it/s, loss=0.00875, val_loss=0.0194, \n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 33.03it/s, loss=0.00875, val_loss=0.0194, \u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 35.54it/s, loss=0.00875, val_loss=0.0303, \u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:02<00:02, 19.89it/s, loss=0.0154, val_loss=0.0303, a\u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:02<00:01, 25.80it/s, loss=0.0154, val_loss=0.0303, a\n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 32.71it/s, loss=0.0154, val_loss=0.0303, a\u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 35.12it/s, loss=0.0154, val_loss=0.0259, a\u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:01<00:01, 20.30it/s, loss=0.00951, val_loss=0.0259, \u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:02<00:00, 26.47it/s, loss=0.00951, val_loss=0.0259, \n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 33.41it/s, loss=0.00951, val_loss=0.0259, \u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 35.86it/s, loss=0.00951, val_loss=0.0438, \u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:02<00:02, 19.54it/s, loss=0.0108, val_loss=0.0438, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:02<00:01, 25.42it/s, loss=0.0108, val_loss=0.0438, a\n",
      "Epoch 90:  90%|▉| 72/80 [00:02<00:00, 32.14it/s, loss=0.0108, val_loss=0.0438, a\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 34.54it/s, loss=0.0108, val_loss=0.041, av\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 20.38it/s, loss=0.0273, val_loss=0.041, av\u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:02<00:00, 26.55it/s, loss=0.0273, val_loss=0.041, av\n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 33.52it/s, loss=0.0273, val_loss=0.041, av\u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 35.97it/s, loss=0.0273, val_loss=0.147, av\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.0144, val_loss=0.147, av\u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:01<00:00, 28.27it/s, loss=0.0144, val_loss=0.147, av\n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 35.55it/s, loss=0.0144, val_loss=0.147, av\u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.0144, val_loss=0.0725, a\u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.03it/s, loss=0.0188, val_loss=0.0725, a\u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:01<00:00, 27.38it/s, loss=0.0188, val_loss=0.0725, a\n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 34.51it/s, loss=0.0188, val_loss=0.0725, a\u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 37.01it/s, loss=0.0188, val_loss=0.0865, a\u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00922, val_loss=0.0865, \u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:02<00:00, 26.95it/s, loss=0.00922, val_loss=0.0865, \n",
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 34.02it/s, loss=0.00922, val_loss=0.0865, \u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 36.50it/s, loss=0.00922, val_loss=0.769, a\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 20.37it/s, loss=0.0112, val_loss=0.769, av\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:02<00:00, 26.57it/s, loss=0.0112, val_loss=0.769, av\n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 33.48it/s, loss=0.0112, val_loss=0.769, av\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.0112, val_loss=0.154, av\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.14it/s, loss=0.0235, val_loss=0.154, av\u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:02<00:00, 26.25it/s, loss=0.0235, val_loss=0.154, av\n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 33.16it/s, loss=0.0235, val_loss=0.154, av\u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 35.53it/s, loss=0.0235, val_loss=0.0533, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:  50%|▌| 40/80 [00:02<00:02, 19.82it/s, loss=0.0135, val_loss=0.0533, a\u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:02<00:01, 25.72it/s, loss=0.0135, val_loss=0.0533, a\n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 32.63it/s, loss=0.0135, val_loss=0.0533, a\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 35.14it/s, loss=0.0135, val_loss=0.0299, a\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:02<00:02, 19.98it/s, loss=0.0249, val_loss=0.0299, a\u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:02<00:00, 26.02it/s, loss=0.0249, val_loss=0.0299, a\n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 32.82it/s, loss=0.0249, val_loss=0.0299, a\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 35.34it/s, loss=0.0249, val_loss=1.44, avg\u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:02<00:02, 19.73it/s, loss=0.0112, val_loss=1.44, avg\u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:02<00:01, 25.56it/s, loss=0.0112, val_loss=1.44, avg\n",
      "Validating:  40%|████████████                  | 16/40 [00:00<00:00, 158.93it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 34.82it/s, loss=0.0112, val_loss=67.5, avg\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 34.44it/s, loss=0.0112, val_loss=67.5, avg\u001b[A\n",
      "Sizes of clusters: 349, 435, 328, 459, 429\n",
      "\n",
      "preds: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 0 0 0 2 2\n",
      " 2 2 2 2 2 2 2 2 0 0 2 0 2 2 2 0 0 2 2 2 2 0 2 4 2 2 0 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 0 2 0 2 2 2 2 0\n",
      " 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 0 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 0 2 2 2 0 2 2 2 0 2 2 2 2 0 2\n",
      " 0 2 2 2 0 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2\n",
      " 2 2 0 2 2 2 2 2 2 2 0 0 0 2 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 0\n",
      " 2 2 0 2 2 2 4 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 0 0 2 0 2 2 0 0 0 2\n",
      " 2 2 2 0 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 0 2 2 0 2 2 2 2 2 2 2 4 4 3 0 4 4 0\n",
      " 0 4 0 0 4 0 3 4 3 0 3 4 3 0 3 0 4 0 4 4 4 0 4 0 4 3 0 0 0 4 3 4 4 4 3 0 0\n",
      " 0 4 4 3 4 0 0 4 4 0 4 4 3 0 1 4 0 4 4 0 4 4 4 4 4 0 3 0 3 0 3 4 0 4 4 3 4\n",
      " 4 4 4 1 0 4 4 4 4 0 0 4 4 3 0 4 3 0 4 4 3 4 0 0 4 0 3 4 3 4 4 3 4 3 4 0 1\n",
      " 4 2 0 0 0 0 4 4 4 0 3 4 4 0 0 3 4 0 3 0 4 0 4 3 0 0 4 0 4 4 4 3 4 0 0 0 0\n",
      " 0 4 4 0 4 4 0 4 0 3 4 0 4 0 4 0 4 0 0 0 3 4 3 4 0 0 4 0 4 0 4 4 0 3 0 0 4\n",
      " 4 0 4 0 4 4 0 4 0 0 0 0 0 0 4 3 0 4 3 3 3 3 0 4 0 4 4 0 4 0 0 4 0 4 4 3 4\n",
      " 0 4 4 0 4 0 4 4 0 0 4 4 4 4 4 4 4 0 4 0 4 4 3 4 3 4 4 4 4 0 0 4 3 4 3 3 4\n",
      " 0 4 0 0 4 3 0 3 3 0 3 0 4 4 4 4 4 0 4 4 3 4 3 3 0 0 4 3 3 0 0 4 4 4 4 4 0\n",
      " 0 4 4 3 4 0 3 4 4 0 4 4 0 4 0 0 0 4 0 4 3 4 4 0 4 4 4 4 4 4 0 4 2 3 4 0 4\n",
      " 0 0 3 0 4 0 4 4 0 0 0 0 4 4 4 3 3 0 4 3 4 0 0 0 3 4 4 3 4 4 4 4 4 4 4 4 4\n",
      " 0 0 3 4 4 0 3 3 4 3 3 0 0 3 0 0 4 4 4 0 0 0 0 4 0 4 3 4 0 4 3 4 4 4 0 0 4\n",
      " 3 0 4 0 4 4 0 4 0 0 0 4 4 0 3 0 0 0 0 4 4 4 4 4 0 0 0 0 0 4 4 4 4 0 4 4 3\n",
      " 3 3 0 4 3 4 3 4 4 4 0 4 3 4 3 4 4 0 4 4 3 0 0 3 4 3 3 3 4 0 0 3 4 1 4 0 0\n",
      " 4 0 4 0 4 0 0 4 0 4 0 4 4 4 4 4 4 3 4 0 0 4 0 4 4 4 1 4 2 0 3 4 4 4 3 4 4\n",
      " 0 0 3 0 4 0 4 0 3 4 3 4 0 4 3 0 3 4 4 4 0 4 4 0 4 0 4 0 4 3 3 4 0 0 0 3 4\n",
      " 4 0 0 4 4 4 0 4 0 0 0 0 4 4 4 3 4 4 3 4 3 4 1 0 4 4 0 0 0 4 0 0 4 3 3 4 4\n",
      " 4 0 0 0 3 0 0 4 4 4 0 4 4 0 4 0 4 4 3 4 4 3 4 0 0 0 4 0 4 4 0 0 4 4 0 4 3\n",
      " 0 4 4 0 0 3 4 3 4 0 0 4 0 4 4 4 0 4 4 0 4 0 3 4 4 0 4 4 0 4 4 0 0 4 1 3 3\n",
      " 3 0 0 3 4 3 4 4 4 3 0 4 4 4 4 0 4 0 0 3 4 4 3 4 4 4 4 4 4 3 4 0 3 4 3 4 0\n",
      " 4 4 0 0 4 4 4 4 4 4 3 4 4 0 4 3 3 3 4 0 4 4 3 4 0 0 4 0 4 4 0 3 0 2 3 0 4\n",
      " 4 0 3 0 0 4 0 0 4 4 0 0 4 4 0 3 3 3 0 4 4 4 0 3 4 0 4 3 0 0 4 4 4 4 4 4 4\n",
      " 0 0 0 3 4 4 4 4 3 4 3 4 0 4 4 3 3 1 1 1 1 3 1 1 3 3 3 3 1 3 3 3 3 3 1 4 1\n",
      " 1 1 1 1 3 3 3 3 3 3 1 3 1 3 3 1 3 1 3 3 3 3 3 3 3 1 1 1 3 3 3 1 3 1 3 3 3\n",
      " 4 3 1 4 3 3 3 1 1 3 1 4 3 4 3 4 3 1 3 1 3 1 3 4 3 1 1 1 1 3 4 1 1 1 1 4 1\n",
      " 1 3 3 4 1 3 1 1 1 3 3 1 3 3 3 3 3 3 1 1 1 3 3 1 3 3 1 1 3 1 3 3 3 1 1 0 1\n",
      " 1 1 3 1 1 4 3 1 3 1 1 1 1 3 3 1 3 3 3 3 1 1 3 4 3 3 3 3 1 3 1 3 3 3 3 1 1\n",
      " 1 3 1 1 3 3 3 3 3 3 1 3 3 1 3 3 3 3 1 3 3 4 1 1 4 3 1 3 3 1 3 3 1 3 1 3 1\n",
      " 1 1 3 3 1 3 1 3 1 3 3 1 3 1 1 3 1 3 1 1 1 3 1 1 3 1 3 1 3 3 3 1 4 3 3 3 1\n",
      " 1 3 3 3 1 3 3 1 1 3 1 1 3 1 3 3 1 1 3 1 3 3 3 1 3 3 1 1 4 3 1 3 3 3 4 1 3\n",
      " 1 1 1 1 1 3 1 3 3 1 3 1 4 3 3 4 1 3 4 3 3 3 1 3 1 3 1 1 1 1 3 4 1 4 1 1 3\n",
      " 4 4 3 3 3 1 3 4 1 1 3 3 4 3 3 3 1 1 3 1 1 3 3 1 3 3 3 3 3 3 3 1 1 1 4 1 1\n",
      " 1 3 1 1 1 3 3 4 3 3 3 3 1 3 1 3 0 1 3 3 1 3 1 1 3 1 3 3 3 3 3 3 1 1 4 3 1\n",
      " 1 1 1 4 3 1 1 4 1 3 3 1 1 1 1 1 3 1 3 3 1 3 3 1 3 1 1 1 1 4 1 1 1 1 1 1 3\n",
      " 1 1 1 1 3 3 1 3 3 3 3 1 3 1 3 1 3 3 4 1 1 1 3 1 3 1 1 3 1 3 1 1 1 3 1 1 1\n",
      " 1 1 3 1 1 4 1 1 3 3 1 1 3 1 3 3 1 3 1 3 1 4 1 3 1 1 1 1 1 1 1 1 1 3 1 1 3\n",
      " 1 1 1 3 1 1 1 3 3 1 3 1 3 1 1 3 1 1 1 3 1 1 1 1 1 1 1 3 3 1 3 1 1 1 3 1 3\n",
      " 3 1 1 3 1 1 1 4 1 3 1 3 3 1 1 1 1 1 1 1 1 1 3 3 1 3 1 4 3 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 3 1 1 3 1 3 1 1 3 3 1 1 1 1 1 1 1 1 4 1 3 1 1 1 1 1 3 1 3 3 1 3\n",
      " 3 1 1 1 3 1 1 1 1 3 1 3 1 1 1 3 1 1 1 3 1 3 3 1 3 3 1 1 1 3 1 3 3 1 1 1 1\n",
      " 1 4 3 1 1 3 3 1 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 3 1 3 1 3 3 3 1 3 1 1 1 1 1\n",
      " 1 1 1 1 1 3 1 4 1 1 1 3 1 3 1 3 1 1 1 1 1 3 3 3 1 1 1 1 3 3 1 1 3 1 3 3 1\n",
      " 4 3 1 3 1 3 3 1 3 1 3 1 1 1 3 1 4 3 1 3 1 1 3 1 1 3 1 1 1 1 1 3 3 1 1 3 1\n",
      " 1 1 3 1 4 1 1 3 1 1 1 1 4 3 1 1 3 1 1 3 1 1 1 3 1 1 1 1 4 3 3 1 1 1 1 1 1\n",
      " 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5615\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 533 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.862, val_loss=0.0648, avg\n",
      "Epoch 0:  64%|▋| 51/80 [00:01<00:01, 26.92it/s, loss=0.862, val_loss=0.0648, avg\n",
      "Epoch 0:  85%|▊| 68/80 [00:01<00:00, 34.00it/s, loss=0.862, val_loss=0.0648, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.862, val_loss=0.671, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.0479, val_loss=0.671, avg\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:01<00:01, 26.23it/s, loss=0.0479, val_loss=0.671, avg\n",
      "Epoch 1:  85%|▊| 68/80 [00:02<00:00, 33.18it/s, loss=0.0479, val_loss=0.671, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.18it/s, loss=0.0479, val_loss=0.0703, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 20.45it/s, loss=0.0224, val_loss=0.0703, av\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:02<00:01, 25.42it/s, loss=0.0224, val_loss=0.0703, av\n",
      "Epoch 2:  85%|▊| 68/80 [00:02<00:00, 32.07it/s, loss=0.0224, val_loss=0.0703, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 36.07it/s, loss=0.0224, val_loss=0.0383, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:02<00:02, 19.92it/s, loss=0.0173, val_loss=0.0383, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:02<00:01, 24.76it/s, loss=0.0173, val_loss=0.0383, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:02<00:00, 31.31it/s, loss=0.0173, val_loss=0.0383, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 35.29it/s, loss=0.0173, val_loss=0.0306, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 20.40it/s, loss=0.0146, val_loss=0.0306, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:02<00:01, 25.34it/s, loss=0.0146, val_loss=0.0306, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:02<00:00, 31.99it/s, loss=0.0146, val_loss=0.0306, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 35.99it/s, loss=0.0146, val_loss=0.0264, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:02<00:02, 19.62it/s, loss=0.0127, val_loss=0.0264, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:02<00:01, 24.30it/s, loss=0.0127, val_loss=0.0264, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:02<00:00, 30.92it/s, loss=0.0127, val_loss=0.0264, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 34.79it/s, loss=0.0127, val_loss=0.0224, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:02<00:02, 19.99it/s, loss=0.0113, val_loss=0.0224, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:02<00:01, 24.81it/s, loss=0.0113, val_loss=0.0224, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:02<00:00, 31.39it/s, loss=0.0113, val_loss=0.0224, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 35.34it/s, loss=0.0113, val_loss=0.0203, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:02<00:02, 19.76it/s, loss=0.0101, val_loss=0.0203, av\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:02<00:01, 24.59it/s, loss=0.0101, val_loss=0.0203, av\n",
      "Epoch 7:  85%|▊| 68/80 [00:02<00:00, 31.11it/s, loss=0.0101, val_loss=0.0203, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 35.04it/s, loss=0.0101, val_loss=0.0191, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.60it/s, loss=0.00894, val_loss=0.0191, a\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 26.81it/s, loss=0.00894, val_loss=0.0191, a\n",
      "Epoch 8:  85%|▊| 68/80 [00:02<00:00, 33.81it/s, loss=0.00894, val_loss=0.0191, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 37.89it/s, loss=0.00894, val_loss=0.0183, a\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.00809, val_loss=0.0183, a\u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:01<00:01, 26.60it/s, loss=0.00809, val_loss=0.0183, a\n",
      "Epoch 9:  85%|▊| 68/80 [00:02<00:00, 33.58it/s, loss=0.00809, val_loss=0.0183, a\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 37.65it/s, loss=0.00809, val_loss=0.0165, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.00it/s, loss=0.00743, val_loss=0.0165, \u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 26.10it/s, loss=0.00743, val_loss=0.0165, \n",
      "Epoch 10:  85%|▊| 68/80 [00:02<00:00, 32.97it/s, loss=0.00743, val_loss=0.0165, \u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 37.01it/s, loss=0.00743, val_loss=0.0163, \u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 20.72it/s, loss=0.0069, val_loss=0.0163, a\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 25.65it/s, loss=0.0069, val_loss=0.0163, a\n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 32.47it/s, loss=0.0069, val_loss=0.0163, a\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 36.51it/s, loss=0.0069, val_loss=0.0158, a\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00641, val_loss=0.0158, \u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 26.93it/s, loss=0.00641, val_loss=0.0158, \n",
      "Epoch 12:  85%|▊| 68/80 [00:02<00:00, 33.97it/s, loss=0.00641, val_loss=0.0158, \u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00641, val_loss=0.0146, \u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.00596, val_loss=0.0146, \u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 25.77it/s, loss=0.00596, val_loss=0.0146, \n",
      "Epoch 13:  85%|▊| 68/80 [00:02<00:00, 32.59it/s, loss=0.00596, val_loss=0.0146, \u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 36.59it/s, loss=0.00596, val_loss=0.0141, \u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00564, val_loss=0.0141, \u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:02<00:01, 25.13it/s, loss=0.00564, val_loss=0.0141, \n",
      "Epoch 14:  85%|▊| 68/80 [00:02<00:00, 31.74it/s, loss=0.00564, val_loss=0.0141, \u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 35.67it/s, loss=0.00564, val_loss=0.0128, \u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 20.79it/s, loss=0.0054, val_loss=0.0128, a\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 25.84it/s, loss=0.0054, val_loss=0.0128, a\n",
      "Epoch 15:  85%|▊| 68/80 [00:02<00:00, 32.67it/s, loss=0.0054, val_loss=0.0128, a\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 36.64it/s, loss=0.0054, val_loss=0.0128, a\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.08it/s, loss=0.00518, val_loss=0.0128, \u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:01<00:01, 26.18it/s, loss=0.00518, val_loss=0.0128, \n",
      "Epoch 16:  85%|▊| 68/80 [00:02<00:00, 33.06it/s, loss=0.00518, val_loss=0.0128, \u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.07it/s, loss=0.00518, val_loss=0.0126, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00496, val_loss=0.0126, \u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:01<00:01, 25.70it/s, loss=0.00496, val_loss=0.0126, \n",
      "Epoch 17:  85%|▊| 68/80 [00:02<00:00, 32.51it/s, loss=0.00496, val_loss=0.0126, \u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 36.39it/s, loss=0.00496, val_loss=0.0125, \u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 20.01it/s, loss=0.00483, val_loss=0.0125, \u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:02<00:01, 24.86it/s, loss=0.00483, val_loss=0.0125, \n",
      "Epoch 18:  85%|▊| 68/80 [00:02<00:00, 31.48it/s, loss=0.00483, val_loss=0.0125, \u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 35.38it/s, loss=0.00483, val_loss=0.012, a\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:02<00:02, 19.93it/s, loss=0.00478, val_loss=0.012, a\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:02<00:01, 24.70it/s, loss=0.00478, val_loss=0.012, a\n",
      "Epoch 19:  85%|▊| 68/80 [00:02<00:00, 31.25it/s, loss=0.00478, val_loss=0.012, a\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 35.22it/s, loss=0.00478, val_loss=0.0126, \u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.00477, val_loss=0.0126, \u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:02<00:01, 24.83it/s, loss=0.00477, val_loss=0.0126, \n",
      "Epoch 20:  85%|▊| 68/80 [00:02<00:00, 31.29it/s, loss=0.00477, val_loss=0.0126, \u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 35.32it/s, loss=0.00477, val_loss=0.0128, \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 20.13it/s, loss=0.00477, val_loss=0.0128, \u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:02<00:01, 24.88it/s, loss=0.00477, val_loss=0.0128, \n",
      "Epoch 21:  85%|▊| 68/80 [00:02<00:00, 31.51it/s, loss=0.00477, val_loss=0.0128, \u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 35.46it/s, loss=0.00477, val_loss=0.0129, \u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 20.30it/s, loss=0.00467, val_loss=0.0129, \u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:02<00:01, 25.17it/s, loss=0.00467, val_loss=0.0129, \n",
      "Epoch 22:  85%|▊| 68/80 [00:02<00:00, 31.91it/s, loss=0.00467, val_loss=0.0129, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.00467, val_loss=0.0143, \u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 20.53it/s, loss=0.00449, val_loss=0.0143, \u001b[A\n",
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 25.51it/s, loss=0.00449, val_loss=0.0143, \n",
      "Epoch 23:  85%|▊| 68/80 [00:02<00:00, 32.27it/s, loss=0.00449, val_loss=0.0143, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 36.24it/s, loss=0.00449, val_loss=0.0149, \u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.60it/s, loss=0.00439, val_loss=0.0149, \u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 26.83it/s, loss=0.00439, val_loss=0.0149, \n",
      "Epoch 24:  85%|▊| 68/80 [00:02<00:00, 33.84it/s, loss=0.00439, val_loss=0.0149, \u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.00439, val_loss=0.0151, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.35it/s, loss=0.00434, val_loss=0.0151, \u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:01<00:01, 26.50it/s, loss=0.00434, val_loss=0.0151, \n",
      "Epoch 25:  85%|▊| 68/80 [00:02<00:00, 33.44it/s, loss=0.00434, val_loss=0.0151, \u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 37.47it/s, loss=0.00434, val_loss=0.0152, \u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.00431, val_loss=0.0152, \u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:02<00:01, 25.35it/s, loss=0.00431, val_loss=0.0152, \n",
      "Epoch 26:  85%|▊| 68/80 [00:02<00:00, 32.17it/s, loss=0.00431, val_loss=0.0152, \u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 36.13it/s, loss=0.00431, val_loss=0.0159, \u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 20.35it/s, loss=0.00431, val_loss=0.0159, \u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:02<00:01, 25.22it/s, loss=0.00431, val_loss=0.0159, \n",
      "Epoch 27:  85%|▊| 68/80 [00:02<00:00, 31.90it/s, loss=0.00431, val_loss=0.0159, \u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 35.86it/s, loss=0.00431, val_loss=0.0162, \u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 20.30it/s, loss=0.00428, val_loss=0.0162, \u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:02<00:01, 25.19it/s, loss=0.00428, val_loss=0.0162, \n",
      "Epoch 28:  85%|▊| 68/80 [00:02<00:00, 31.89it/s, loss=0.00428, val_loss=0.0162, \u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.00428, val_loss=0.0163, \u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00427, val_loss=0.0163, \u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:01<00:01, 25.55it/s, loss=0.00427, val_loss=0.0163, \n",
      "Epoch 29:  86%|▊| 69/80 [00:02<00:00, 32.82it/s, loss=0.00427, val_loss=0.0163, \u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 36.43it/s, loss=0.00427, val_loss=0.0163, \u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 20.08it/s, loss=0.00429, val_loss=0.0163, \u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:02<00:00, 26.13it/s, loss=0.00429, val_loss=0.0163, \n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 32.95it/s, loss=0.00429, val_loss=0.0163, \u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 35.45it/s, loss=0.00429, val_loss=0.0167, \u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:02<00:02, 19.79it/s, loss=0.00433, val_loss=0.0167, \u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:02<00:01, 25.75it/s, loss=0.00433, val_loss=0.0167, \n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 32.52it/s, loss=0.00433, val_loss=0.0167, \u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 35.02it/s, loss=0.00433, val_loss=0.0169, \u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.00434, val_loss=0.0169, \u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:02<00:00, 26.22it/s, loss=0.00434, val_loss=0.0169, \n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 33.11it/s, loss=0.00434, val_loss=0.0169, \u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 35.55it/s, loss=0.00434, val_loss=0.017, a\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.00428, val_loss=0.017, a\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:01<00:00, 28.08it/s, loss=0.00428, val_loss=0.017, a\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 35.32it/s, loss=0.00428, val_loss=0.017, a\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 37.85it/s, loss=0.00428, val_loss=0.0178, \u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.12it/s, loss=0.00422, val_loss=0.0178, \u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 27.50it/s, loss=0.00422, val_loss=0.0178, \n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 34.61it/s, loss=0.00422, val_loss=0.0178, \u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00422, val_loss=0.0182, \u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 20.84it/s, loss=0.00424, val_loss=0.0182, \u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 27.08it/s, loss=0.00424, val_loss=0.0182, \n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 34.08it/s, loss=0.00424, val_loss=0.0182, \u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 36.63it/s, loss=0.00424, val_loss=0.0189, \u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.00434, val_loss=0.0189, \u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:02<00:00, 26.16it/s, loss=0.00434, val_loss=0.0189, \n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 33.13it/s, loss=0.00434, val_loss=0.0189, \u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 35.49it/s, loss=0.00434, val_loss=0.0193, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:02<00:02, 19.58it/s, loss=0.0043, val_loss=0.0193, a\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:02<00:01, 25.48it/s, loss=0.0043, val_loss=0.0193, a\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 32.26it/s, loss=0.0043, val_loss=0.0193, a\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 34.74it/s, loss=0.0043, val_loss=0.0199, a\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:02<00:02, 19.52it/s, loss=0.00429, val_loss=0.0199, \u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:02<00:01, 25.43it/s, loss=0.00429, val_loss=0.0199, \n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 32.13it/s, loss=0.00429, val_loss=0.0199, \u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 34.63it/s, loss=0.00429, val_loss=0.0205, \u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:02<00:02, 19.85it/s, loss=0.00434, val_loss=0.0205, \u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:02<00:01, 25.84it/s, loss=0.00434, val_loss=0.0205, \n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 32.62it/s, loss=0.00434, val_loss=0.0205, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 35.19it/s, loss=0.00434, val_loss=0.0205, \u001b[A\n",
      "Epoch 40:  50%|▌| 40/80 [00:01<00:01, 20.21it/s, loss=0.00424, val_loss=0.0205, \u001b[A\n",
      "Epoch 40:  68%|▋| 54/80 [00:02<00:00, 26.23it/s, loss=0.00424, val_loss=0.0205, \n",
      "Epoch 40:  90%|▉| 72/80 [00:02<00:00, 33.19it/s, loss=0.00424, val_loss=0.0205, \u001b[A\n",
      "Epoch 40: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.00424, val_loss=0.0215, \u001b[A\n",
      "Epoch 41:  50%|▌| 40/80 [00:01<00:01, 20.29it/s, loss=0.00425, val_loss=0.0215, \u001b[A\n",
      "Epoch 41:  68%|▋| 54/80 [00:02<00:00, 26.46it/s, loss=0.00425, val_loss=0.0215, \n",
      "Epoch 41:  90%|▉| 72/80 [00:02<00:00, 33.39it/s, loss=0.00425, val_loss=0.0215, \u001b[A\n",
      "Epoch 41: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.00425, val_loss=0.0216, \u001b[A\n",
      "Epoch 42:  50%|▌| 40/80 [00:01<00:01, 21.48it/s, loss=0.00437, val_loss=0.0216, \u001b[A\n",
      "Epoch 42:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.00437, val_loss=0.0216, \n",
      "Epoch 42:  90%|▉| 72/80 [00:02<00:00, 35.18it/s, loss=0.00437, val_loss=0.0216, \u001b[A\n",
      "Epoch 42: 100%|█| 80/80 [00:02<00:00, 37.71it/s, loss=0.00437, val_loss=0.023, a\u001b[A\n",
      "Epoch 43:  50%|▌| 40/80 [00:01<00:01, 21.13it/s, loss=0.00474, val_loss=0.023, a\u001b[A\n",
      "Epoch 43:  68%|▋| 54/80 [00:01<00:00, 27.51it/s, loss=0.00474, val_loss=0.023, a\n",
      "Epoch 43:  90%|▉| 72/80 [00:02<00:00, 34.64it/s, loss=0.00474, val_loss=0.023, a\u001b[A\n",
      "Epoch 43: 100%|█| 80/80 [00:02<00:00, 37.13it/s, loss=0.00474, val_loss=0.0263, \u001b[A\n",
      "Epoch 44:  50%|▌| 40/80 [00:01<00:01, 20.54it/s, loss=0.0047, val_loss=0.0263, a\u001b[A\n",
      "Epoch 44:  68%|▋| 54/80 [00:02<00:00, 26.77it/s, loss=0.0047, val_loss=0.0263, a\n",
      "Epoch 44:  90%|▉| 72/80 [00:02<00:00, 33.76it/s, loss=0.0047, val_loss=0.0263, a\u001b[A\n",
      "Epoch 44: 100%|█| 80/80 [00:02<00:00, 36.20it/s, loss=0.0047, val_loss=0.0251, a\u001b[A\n",
      "Epoch 45:  50%|▌| 40/80 [00:01<00:01, 20.12it/s, loss=0.00447, val_loss=0.0251, \u001b[A\n",
      "Epoch 45:  68%|▋| 54/80 [00:02<00:00, 26.24it/s, loss=0.00447, val_loss=0.0251, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  90%|▉| 72/80 [00:02<00:00, 33.16it/s, loss=0.00447, val_loss=0.0251, \u001b[A\n",
      "Epoch 45: 100%|█| 80/80 [00:02<00:00, 35.60it/s, loss=0.00447, val_loss=0.0252, \u001b[A\n",
      "Epoch 46:  50%|▌| 40/80 [00:02<00:02, 19.90it/s, loss=0.00498, val_loss=0.0252, \u001b[A\n",
      "Epoch 46:  68%|▋| 54/80 [00:02<00:01, 25.90it/s, loss=0.00498, val_loss=0.0252, \n",
      "Epoch 46:  90%|▉| 72/80 [00:02<00:00, 32.82it/s, loss=0.00498, val_loss=0.0252, \u001b[A\n",
      "Epoch 46: 100%|█| 80/80 [00:02<00:00, 35.16it/s, loss=0.00498, val_loss=0.0272, \u001b[A\n",
      "Epoch 47:  50%|▌| 40/80 [00:02<00:02, 19.86it/s, loss=0.00518, val_loss=0.0272, \u001b[A\n",
      "Epoch 47:  68%|▋| 54/80 [00:02<00:01, 25.93it/s, loss=0.00518, val_loss=0.0272, \n",
      "Epoch 47:  90%|▉| 72/80 [00:02<00:00, 32.77it/s, loss=0.00518, val_loss=0.0272, \u001b[A\n",
      "Epoch 47: 100%|█| 80/80 [00:02<00:00, 35.20it/s, loss=0.00518, val_loss=0.0285, \u001b[A\n",
      "Epoch 48:  50%|▌| 40/80 [00:01<00:01, 20.05it/s, loss=0.00491, val_loss=0.0285, \u001b[A\n",
      "Epoch 48:  68%|▋| 54/80 [00:02<00:00, 26.16it/s, loss=0.00491, val_loss=0.0285, \n",
      "Epoch 48:  90%|▉| 72/80 [00:02<00:00, 33.06it/s, loss=0.00491, val_loss=0.0285, \u001b[A\n",
      "Epoch 48: 100%|█| 80/80 [00:02<00:00, 35.44it/s, loss=0.00491, val_loss=0.0283, \u001b[A\n",
      "Epoch 49:  50%|▌| 40/80 [00:02<00:02, 19.94it/s, loss=0.00504, val_loss=0.0283, \u001b[A\n",
      "Epoch 49:  68%|▋| 54/80 [00:02<00:01, 25.99it/s, loss=0.00504, val_loss=0.0283, \n",
      "Epoch 49:  90%|▉| 72/80 [00:02<00:00, 32.89it/s, loss=0.00504, val_loss=0.0283, \u001b[A\n",
      "Epoch 49: 100%|█| 80/80 [00:02<00:00, 35.26it/s, loss=0.00504, val_loss=0.027, a\u001b[A\n",
      "Epoch 50:  50%|▌| 40/80 [00:01<00:01, 20.20it/s, loss=0.00522, val_loss=0.027, a\u001b[A\n",
      "Epoch 50:  68%|▋| 54/80 [00:02<00:00, 26.31it/s, loss=0.00522, val_loss=0.027, a\n",
      "Epoch 50:  90%|▉| 72/80 [00:02<00:00, 33.23it/s, loss=0.00522, val_loss=0.027, a\u001b[A\n",
      "Epoch 50: 100%|█| 80/80 [00:02<00:00, 35.69it/s, loss=0.00522, val_loss=0.0255, \u001b[A\n",
      "Epoch 51:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00528, val_loss=0.0255, \u001b[A\n",
      "Epoch 51:  68%|▋| 54/80 [00:01<00:00, 28.24it/s, loss=0.00528, val_loss=0.0255, \n",
      "Epoch 51:  90%|▉| 72/80 [00:02<00:00, 35.53it/s, loss=0.00528, val_loss=0.0255, \u001b[A\n",
      "Epoch 51: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00528, val_loss=0.0258, \u001b[A\n",
      "Epoch 52:  50%|▌| 40/80 [00:01<00:01, 21.27it/s, loss=0.00556, val_loss=0.0258, \u001b[A\n",
      "Epoch 52:  68%|▋| 54/80 [00:01<00:00, 27.68it/s, loss=0.00556, val_loss=0.0258, \n",
      "Epoch 52:  90%|▉| 72/80 [00:02<00:00, 34.87it/s, loss=0.00556, val_loss=0.0258, \u001b[A\n",
      "Epoch 52: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.00556, val_loss=0.026, a\u001b[A\n",
      "Epoch 53:  50%|▌| 40/80 [00:01<00:01, 20.70it/s, loss=0.00588, val_loss=0.026, a\u001b[A\n",
      "Epoch 53:  68%|▋| 54/80 [00:02<00:00, 26.98it/s, loss=0.00588, val_loss=0.026, a\n",
      "Epoch 53:  90%|▉| 72/80 [00:02<00:00, 34.02it/s, loss=0.00588, val_loss=0.026, a\u001b[A\n",
      "Epoch 53: 100%|█| 80/80 [00:02<00:00, 36.48it/s, loss=0.00588, val_loss=0.0275, \u001b[A\n",
      "Epoch 54:  50%|▌| 40/80 [00:02<00:02, 19.96it/s, loss=0.00648, val_loss=0.0275, \u001b[A\n",
      "Epoch 54:  68%|▋| 54/80 [00:02<00:01, 26.00it/s, loss=0.00648, val_loss=0.0275, \n",
      "Epoch 54:  90%|▉| 72/80 [00:02<00:00, 32.81it/s, loss=0.00648, val_loss=0.0275, \u001b[A\n",
      "Epoch 54: 100%|█| 80/80 [00:02<00:00, 35.26it/s, loss=0.00648, val_loss=0.0304, \u001b[A\n",
      "Epoch 55:  50%|▌| 40/80 [00:02<00:02, 19.87it/s, loss=0.00764, val_loss=0.0304, \u001b[A\n",
      "Epoch 55:  68%|▋| 54/80 [00:02<00:01, 25.90it/s, loss=0.00764, val_loss=0.0304, \n",
      "Epoch 55:  90%|▉| 72/80 [00:02<00:00, 32.71it/s, loss=0.00764, val_loss=0.0304, \u001b[A\n",
      "Epoch 55: 100%|█| 80/80 [00:02<00:00, 35.17it/s, loss=0.00764, val_loss=0.0387, \u001b[A\n",
      "Epoch 56:  50%|▌| 40/80 [00:02<00:02, 20.00it/s, loss=0.0077, val_loss=0.0387, a\u001b[A\n",
      "Epoch 56:  68%|▋| 54/80 [00:02<00:01, 25.96it/s, loss=0.0077, val_loss=0.0387, a\n",
      "Epoch 56:  90%|▉| 72/80 [00:02<00:00, 32.84it/s, loss=0.0077, val_loss=0.0387, a\u001b[A\n",
      "Epoch 56: 100%|█| 80/80 [00:02<00:00, 35.32it/s, loss=0.0077, val_loss=0.0353, a\u001b[A\n",
      "Epoch 57:  50%|▌| 40/80 [00:01<00:01, 20.43it/s, loss=0.00747, val_loss=0.0353, \u001b[A\n",
      "Epoch 57:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.00747, val_loss=0.0353, \n",
      "Epoch 57:  90%|▉| 72/80 [00:02<00:00, 33.61it/s, loss=0.00747, val_loss=0.0353, \u001b[A\n",
      "Epoch 57: 100%|█| 80/80 [00:02<00:00, 36.03it/s, loss=0.00747, val_loss=0.0361, \u001b[A\n",
      "Epoch 58:  50%|▌| 40/80 [00:02<00:02, 19.72it/s, loss=0.0075, val_loss=0.0361, a\u001b[A\n",
      "Epoch 58:  68%|▋| 54/80 [00:02<00:01, 25.49it/s, loss=0.0075, val_loss=0.0361, a\n",
      "Validating:  40%|████████████                  | 16/40 [00:00<00:00, 150.03it/s]\u001b[A\n",
      "Epoch 58: 100%|█| 80/80 [00:02<00:00, 34.67it/s, loss=0.0075, val_loss=0.0373, a\u001b[A\n",
      "Epoch 59:  50%|▌| 40/80 [00:01<00:01, 20.46it/s, loss=0.0082, val_loss=0.0373, a\u001b[A\n",
      "Epoch 59:  68%|▋| 54/80 [00:02<00:00, 26.67it/s, loss=0.0082, val_loss=0.0373, a\n",
      "Epoch 59:  90%|▉| 72/80 [00:02<00:00, 33.59it/s, loss=0.0082, val_loss=0.0373, a\u001b[A\n",
      "Epoch 59: 100%|█| 80/80 [00:02<00:00, 36.14it/s, loss=0.0082, val_loss=0.0348, a\u001b[A\n",
      "Epoch 60:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.0154, val_loss=0.0348, a\u001b[A\n",
      "Epoch 60:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.0154, val_loss=0.0348, a\n",
      "Epoch 60:  90%|▉| 72/80 [00:02<00:00, 35.74it/s, loss=0.0154, val_loss=0.0348, a\u001b[A\n",
      "Epoch 60: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.0154, val_loss=0.0381, a\u001b[A\n",
      "Epoch 61:  50%|▌| 40/80 [00:01<00:01, 21.22it/s, loss=0.00655, val_loss=0.0381, \u001b[A\n",
      "Epoch 61:  68%|▋| 54/80 [00:01<00:00, 27.53it/s, loss=0.00655, val_loss=0.0381, \n",
      "Epoch 61:  90%|▉| 72/80 [00:02<00:00, 34.60it/s, loss=0.00655, val_loss=0.0381, \u001b[A\n",
      "Epoch 61: 100%|█| 80/80 [00:02<00:00, 37.16it/s, loss=0.00655, val_loss=0.0351, \u001b[A\n",
      "Epoch 62:  50%|▌| 40/80 [00:01<00:01, 20.64it/s, loss=0.00892, val_loss=0.0351, \u001b[A\n",
      "Epoch 62:  68%|▋| 54/80 [00:02<00:00, 26.81it/s, loss=0.00892, val_loss=0.0351, \n",
      "Epoch 62:  90%|▉| 72/80 [00:02<00:00, 33.80it/s, loss=0.00892, val_loss=0.0351, \u001b[A\n",
      "Epoch 62: 100%|█| 80/80 [00:02<00:00, 36.33it/s, loss=0.00892, val_loss=0.0458, \u001b[A\n",
      "Epoch 63:  50%|▌| 40/80 [00:01<00:01, 20.42it/s, loss=0.0106, val_loss=0.0458, a\u001b[A\n",
      "Epoch 63:  68%|▋| 54/80 [00:02<00:00, 26.56it/s, loss=0.0106, val_loss=0.0458, a\n",
      "Epoch 63:  90%|▉| 72/80 [00:02<00:00, 33.59it/s, loss=0.0106, val_loss=0.0458, a\u001b[A\n",
      "Epoch 63: 100%|█| 80/80 [00:02<00:00, 36.02it/s, loss=0.0106, val_loss=0.0422, a\u001b[A\n",
      "Epoch 64:  50%|▌| 40/80 [00:02<00:02, 19.70it/s, loss=0.00536, val_loss=0.0422, \u001b[A\n",
      "Epoch 64:  68%|▋| 54/80 [00:02<00:01, 25.69it/s, loss=0.00536, val_loss=0.0422, \n",
      "Epoch 64:  90%|▉| 72/80 [00:02<00:00, 32.39it/s, loss=0.00536, val_loss=0.0422, \u001b[A\n",
      "Epoch 64: 100%|█| 80/80 [00:02<00:00, 34.86it/s, loss=0.00536, val_loss=0.0277, \u001b[A\n",
      "Epoch 65:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.00653, val_loss=0.0277, \u001b[A\n",
      "Epoch 65:  68%|▋| 54/80 [00:02<00:00, 26.24it/s, loss=0.00653, val_loss=0.0277, \n",
      "Epoch 65:  90%|▉| 72/80 [00:02<00:00, 33.27it/s, loss=0.00653, val_loss=0.0277, \u001b[A\n",
      "Epoch 65: 100%|█| 80/80 [00:02<00:00, 35.72it/s, loss=0.00653, val_loss=0.0363, \u001b[A\n",
      "Epoch 66:  50%|▌| 40/80 [00:02<00:02, 19.70it/s, loss=0.0563, val_loss=0.0363, a\u001b[A\n",
      "Epoch 66:  68%|▋| 54/80 [00:02<00:01, 25.69it/s, loss=0.0563, val_loss=0.0363, a\n",
      "Epoch 66:  90%|▉| 72/80 [00:02<00:00, 32.40it/s, loss=0.0563, val_loss=0.0363, a\u001b[A\n",
      "Epoch 66: 100%|█| 80/80 [00:02<00:00, 34.92it/s, loss=0.0563, val_loss=0.27, avg\u001b[A\n",
      "Epoch 67:  50%|▌| 40/80 [00:02<00:02, 19.52it/s, loss=0.00758, val_loss=0.27, av\u001b[A\n",
      "Epoch 67:  68%|▋| 54/80 [00:02<00:01, 25.41it/s, loss=0.00758, val_loss=0.27, av\n",
      "Epoch 67:  90%|▉| 72/80 [00:02<00:00, 32.18it/s, loss=0.00758, val_loss=0.27, av\u001b[A\n",
      "Epoch 67: 100%|█| 80/80 [00:02<00:00, 34.66it/s, loss=0.00758, val_loss=0.026, a\u001b[A\n",
      "Epoch 68:  50%|▌| 40/80 [00:01<00:01, 20.89it/s, loss=0.0047, val_loss=0.026, av\u001b[A\n",
      "Epoch 68:  68%|▋| 54/80 [00:01<00:00, 27.22it/s, loss=0.0047, val_loss=0.026, av\n",
      "Epoch 68:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.0047, val_loss=0.026, av\u001b[A\n",
      "Epoch 68: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.0047, val_loss=0.0289, a\u001b[A\n",
      "Epoch 69:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.0101, val_loss=0.0289, a\u001b[A\n",
      "Epoch 69:  68%|▋| 54/80 [00:01<00:00, 28.15it/s, loss=0.0101, val_loss=0.0289, a\n",
      "Epoch 69:  90%|▉| 72/80 [00:02<00:00, 35.49it/s, loss=0.0101, val_loss=0.0289, a\u001b[A\n",
      "Epoch 69: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.0101, val_loss=0.0294, a\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00478, val_loss=0.0294, \u001b[A\n",
      "Epoch 70:  68%|▋| 54/80 [00:01<00:00, 27.58it/s, loss=0.00478, val_loss=0.0294, \n",
      "Epoch 70:  90%|▉| 72/80 [00:02<00:00, 34.72it/s, loss=0.00478, val_loss=0.0294, \u001b[A\n",
      "Epoch 70: 100%|█| 80/80 [00:02<00:00, 37.22it/s, loss=0.00478, val_loss=0.0315, \u001b[A\n",
      "Epoch 71:  50%|▌| 40/80 [00:01<00:01, 20.87it/s, loss=0.00683, val_loss=0.0315, \u001b[A\n",
      "Epoch 71:  68%|▋| 54/80 [00:01<00:00, 27.05it/s, loss=0.00683, val_loss=0.0315, \n",
      "Epoch 71:  90%|▉| 72/80 [00:02<00:00, 34.04it/s, loss=0.00683, val_loss=0.0315, \u001b[A\n",
      "Epoch 71: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00683, val_loss=0.033, a\u001b[A\n",
      "Epoch 72:  50%|▌| 40/80 [00:02<00:02, 19.73it/s, loss=0.0241, val_loss=0.033, av\u001b[A\n",
      "Epoch 72:  68%|▋| 54/80 [00:02<00:01, 25.74it/s, loss=0.0241, val_loss=0.033, av\n",
      "Epoch 72:  90%|▉| 72/80 [00:02<00:00, 32.55it/s, loss=0.0241, val_loss=0.033, av\u001b[A\n",
      "Epoch 72: 100%|█| 80/80 [00:02<00:00, 34.94it/s, loss=0.0241, val_loss=0.0371, a\u001b[A\n",
      "Epoch 73:  50%|▌| 40/80 [00:02<00:02, 19.63it/s, loss=0.00575, val_loss=0.0371, \u001b[A\n",
      "Epoch 73:  68%|▋| 54/80 [00:02<00:01, 25.51it/s, loss=0.00575, val_loss=0.0371, \n",
      "Epoch 73:  90%|▉| 72/80 [00:02<00:00, 32.26it/s, loss=0.00575, val_loss=0.0371, \u001b[A\n",
      "Epoch 73: 100%|█| 80/80 [00:02<00:00, 34.79it/s, loss=0.00575, val_loss=0.0309, \u001b[A\n",
      "Epoch 74:  50%|▌| 40/80 [00:01<00:01, 20.09it/s, loss=0.0158, val_loss=0.0309, a\u001b[A\n",
      "Epoch 74:  68%|▋| 54/80 [00:02<00:01, 25.97it/s, loss=0.0158, val_loss=0.0309, a\n",
      "Epoch 74:  90%|▉| 72/80 [00:02<00:00, 32.89it/s, loss=0.0158, val_loss=0.0309, a\u001b[A\n",
      "Epoch 74: 100%|█| 80/80 [00:02<00:00, 35.41it/s, loss=0.0158, val_loss=0.0378, a\u001b[A\n",
      "Epoch 75:  50%|▌| 40/80 [00:02<00:02, 19.65it/s, loss=0.00561, val_loss=0.0378, \u001b[A\n",
      "Epoch 75:  68%|▋| 54/80 [00:02<00:01, 25.51it/s, loss=0.00561, val_loss=0.0378, \n",
      "Epoch 75:  90%|▉| 72/80 [00:02<00:00, 32.35it/s, loss=0.00561, val_loss=0.0378, \u001b[A\n",
      "Epoch 75: 100%|█| 80/80 [00:02<00:00, 34.72it/s, loss=0.00561, val_loss=0.0295, \u001b[A\n",
      "Epoch 76:  50%|▌| 40/80 [00:01<00:01, 20.10it/s, loss=0.0183, val_loss=0.0295, a\u001b[A\n",
      "Epoch 76:  68%|▋| 54/80 [00:02<00:00, 26.17it/s, loss=0.0183, val_loss=0.0295, a\n",
      "Epoch 76:  90%|▉| 72/80 [00:02<00:00, 33.07it/s, loss=0.0183, val_loss=0.0295, a\u001b[A\n",
      "Epoch 76: 100%|█| 80/80 [00:02<00:00, 35.47it/s, loss=0.0183, val_loss=0.0368, a\u001b[A\n",
      "Epoch 77:  50%|▌| 40/80 [00:01<00:01, 20.90it/s, loss=0.00532, val_loss=0.0368, \u001b[A\n",
      "Epoch 77:  68%|▋| 54/80 [00:01<00:00, 27.22it/s, loss=0.00532, val_loss=0.0368, \n",
      "Epoch 77:  90%|▉| 72/80 [00:02<00:00, 34.31it/s, loss=0.00532, val_loss=0.0368, \u001b[A\n",
      "Epoch 77: 100%|█| 80/80 [00:02<00:00, 36.81it/s, loss=0.00532, val_loss=0.0282, \u001b[A\n",
      "Epoch 78:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.0555, val_loss=0.0282, a\u001b[A\n",
      "Epoch 78:  68%|▋| 54/80 [00:01<00:00, 28.37it/s, loss=0.0555, val_loss=0.0282, a\n",
      "Epoch 78:  90%|▉| 72/80 [00:02<00:00, 35.69it/s, loss=0.0555, val_loss=0.0282, a\u001b[A\n",
      "Epoch 78: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.0555, val_loss=0.0675, a\u001b[A\n",
      "Epoch 79:  50%|▌| 40/80 [00:01<00:01, 20.63it/s, loss=0.00532, val_loss=0.0675, \u001b[A\n",
      "Epoch 79:  68%|▋| 54/80 [00:02<00:00, 26.84it/s, loss=0.00532, val_loss=0.0675, \n",
      "Epoch 79:  90%|▉| 72/80 [00:02<00:00, 33.89it/s, loss=0.00532, val_loss=0.0675, \u001b[A\n",
      "Epoch 79: 100%|█| 80/80 [00:02<00:00, 36.42it/s, loss=0.00532, val_loss=0.0325, \u001b[A\n",
      "Epoch 80:  50%|▌| 40/80 [00:01<00:01, 20.78it/s, loss=0.00543, val_loss=0.0325, \u001b[A\n",
      "Epoch 80:  68%|▋| 54/80 [00:01<00:00, 27.07it/s, loss=0.00543, val_loss=0.0325, \n",
      "Epoch 80:  90%|▉| 72/80 [00:02<00:00, 34.17it/s, loss=0.00543, val_loss=0.0325, \u001b[A\n",
      "Epoch 80: 100%|█| 80/80 [00:02<00:00, 36.67it/s, loss=0.00543, val_loss=0.0315, \u001b[A\n",
      "Epoch 81:  50%|▌| 40/80 [00:01<00:01, 21.36it/s, loss=0.0269, val_loss=0.0315, a\u001b[A\n",
      "Epoch 81:  68%|▋| 54/80 [00:01<00:00, 27.81it/s, loss=0.0269, val_loss=0.0315, a\n",
      "Epoch 81:  90%|▉| 72/80 [00:02<00:00, 35.01it/s, loss=0.0269, val_loss=0.0315, a\u001b[A\n",
      "Epoch 81: 100%|█| 80/80 [00:02<00:00, 37.54it/s, loss=0.0269, val_loss=0.0404, a\u001b[A\n",
      "Epoch 82:  50%|▌| 40/80 [00:01<00:01, 20.66it/s, loss=0.00548, val_loss=0.0404, \u001b[A\n",
      "Epoch 82:  68%|▋| 54/80 [00:02<00:00, 26.79it/s, loss=0.00548, val_loss=0.0404, \n",
      "Epoch 82:  90%|▉| 72/80 [00:02<00:00, 33.71it/s, loss=0.00548, val_loss=0.0404, \u001b[A\n",
      "Epoch 82: 100%|█| 80/80 [00:02<00:00, 36.37it/s, loss=0.00548, val_loss=0.0327, \u001b[A\n",
      "Epoch 83:  50%|▌| 40/80 [00:01<00:01, 20.45it/s, loss=0.0693, val_loss=0.0327, a\u001b[A\n",
      "Epoch 83:  68%|▋| 54/80 [00:02<00:00, 26.65it/s, loss=0.0693, val_loss=0.0327, a\n",
      "Epoch 83:  90%|▉| 72/80 [00:02<00:00, 33.64it/s, loss=0.0693, val_loss=0.0327, a\u001b[A\n",
      "Epoch 83: 100%|█| 80/80 [00:02<00:00, 36.03it/s, loss=0.0693, val_loss=0.0534, a\u001b[A\n",
      "Epoch 84:  50%|▌| 40/80 [00:01<00:01, 20.88it/s, loss=0.00502, val_loss=0.0534, \u001b[A\n",
      "Epoch 84:  68%|▋| 54/80 [00:01<00:00, 27.20it/s, loss=0.00502, val_loss=0.0534, \n",
      "Epoch 84:  90%|▉| 72/80 [00:02<00:00, 34.29it/s, loss=0.00502, val_loss=0.0534, \u001b[A\n",
      "Epoch 84: 100%|█| 80/80 [00:02<00:00, 36.78it/s, loss=0.00502, val_loss=0.0316, \u001b[A\n",
      "Epoch 85:  50%|▌| 40/80 [00:01<00:01, 20.85it/s, loss=0.00501, val_loss=0.0316, \u001b[A\n",
      "Epoch 85:  68%|▋| 54/80 [00:01<00:00, 27.03it/s, loss=0.00501, val_loss=0.0316, \n",
      "Epoch 85:  90%|▉| 72/80 [00:02<00:00, 34.10it/s, loss=0.00501, val_loss=0.0316, \u001b[A\n",
      "Epoch 85: 100%|█| 80/80 [00:02<00:00, 36.57it/s, loss=0.00501, val_loss=0.0331, \u001b[A\n",
      "Epoch 86:  50%|▌| 40/80 [00:01<00:01, 20.68it/s, loss=0.0326, val_loss=0.0331, a\u001b[A\n",
      "Epoch 86:  68%|▋| 54/80 [00:02<00:00, 26.82it/s, loss=0.0326, val_loss=0.0331, a\n",
      "Epoch 86:  90%|▉| 72/80 [00:02<00:00, 33.74it/s, loss=0.0326, val_loss=0.0331, a\u001b[A\n",
      "Epoch 86: 100%|█| 80/80 [00:02<00:00, 36.35it/s, loss=0.0326, val_loss=0.0482, a\u001b[A\n",
      "Epoch 87:  50%|▌| 40/80 [00:01<00:01, 20.27it/s, loss=0.00439, val_loss=0.0482, \u001b[A\n",
      "Epoch 87:  68%|▋| 54/80 [00:02<00:00, 26.31it/s, loss=0.00439, val_loss=0.0482, \n",
      "Epoch 87:  90%|▉| 72/80 [00:02<00:00, 33.26it/s, loss=0.00439, val_loss=0.0482, \u001b[A\n",
      "Epoch 87: 100%|█| 80/80 [00:02<00:00, 35.71it/s, loss=0.00439, val_loss=0.0281, \u001b[A\n",
      "Epoch 88:  50%|▌| 40/80 [00:02<00:02, 19.79it/s, loss=0.00582, val_loss=0.0281, \u001b[A\n",
      "Epoch 88:  68%|▋| 54/80 [00:02<00:01, 25.75it/s, loss=0.00582, val_loss=0.0281, \n",
      "Epoch 88:  90%|▉| 72/80 [00:02<00:00, 32.47it/s, loss=0.00582, val_loss=0.0281, \u001b[A\n",
      "Epoch 88: 100%|█| 80/80 [00:02<00:00, 35.00it/s, loss=0.00582, val_loss=0.0336, \u001b[A\n",
      "Epoch 89:  50%|▌| 40/80 [00:02<00:02, 19.74it/s, loss=0.0106, val_loss=0.0336, a\u001b[A\n",
      "Epoch 89:  68%|▋| 54/80 [00:02<00:01, 25.62it/s, loss=0.0106, val_loss=0.0336, a\n",
      "Epoch 89:  90%|▉| 72/80 [00:02<00:00, 32.49it/s, loss=0.0106, val_loss=0.0336, a\u001b[A\n",
      "Epoch 89: 100%|█| 80/80 [00:02<00:00, 34.83it/s, loss=0.0106, val_loss=0.0323, a\u001b[A\n",
      "Epoch 90:  50%|▌| 40/80 [00:01<00:01, 20.24it/s, loss=0.0104, val_loss=0.0323, a\u001b[A\n",
      "Epoch 90:  68%|▋| 54/80 [00:02<00:00, 26.07it/s, loss=0.0104, val_loss=0.0323, a\n",
      "Validating:  38%|███████████▎                  | 15/40 [00:00<00:00, 148.26it/s]\u001b[A\n",
      "Epoch 90: 100%|█| 80/80 [00:02<00:00, 35.50it/s, loss=0.0104, val_loss=0.0859, a\u001b[A\n",
      "Epoch 91:  50%|▌| 40/80 [00:01<00:01, 20.34it/s, loss=0.0179, val_loss=0.0859, a\u001b[A\n",
      "Epoch 91:  68%|▋| 54/80 [00:02<00:00, 26.48it/s, loss=0.0179, val_loss=0.0859, a\n",
      "Epoch 91:  90%|▉| 72/80 [00:02<00:00, 33.34it/s, loss=0.0179, val_loss=0.0859, a\u001b[A\n",
      "Epoch 91: 100%|█| 80/80 [00:02<00:00, 35.88it/s, loss=0.0179, val_loss=0.0414, a\u001b[A\n",
      "Epoch 92:  50%|▌| 40/80 [00:01<00:01, 20.71it/s, loss=0.00518, val_loss=0.0414, \u001b[A\n",
      "Epoch 92:  68%|▋| 54/80 [00:02<00:00, 26.98it/s, loss=0.00518, val_loss=0.0414, \n",
      "Epoch 92:  90%|▉| 72/80 [00:02<00:00, 34.00it/s, loss=0.00518, val_loss=0.0414, \u001b[A\n",
      "Epoch 92: 100%|█| 80/80 [00:02<00:00, 36.50it/s, loss=0.00518, val_loss=0.0321, \u001b[A\n",
      "Epoch 93:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.00908, val_loss=0.0321, \u001b[A\n",
      "Epoch 93:  68%|▋| 54/80 [00:01<00:00, 27.92it/s, loss=0.00908, val_loss=0.0321, \n",
      "Epoch 93:  90%|▉| 72/80 [00:02<00:00, 35.13it/s, loss=0.00908, val_loss=0.0321, \u001b[A\n",
      "Epoch 93: 100%|█| 80/80 [00:02<00:00, 37.65it/s, loss=0.00908, val_loss=0.0357, \u001b[A\n",
      "Epoch 94:  50%|▌| 40/80 [00:01<00:01, 20.77it/s, loss=0.00652, val_loss=0.0357, \u001b[A\n",
      "Epoch 94:  68%|▋| 54/80 [00:01<00:00, 27.06it/s, loss=0.00652, val_loss=0.0357, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:  90%|▉| 72/80 [00:02<00:00, 34.12it/s, loss=0.00652, val_loss=0.0357, \u001b[A\n",
      "Epoch 94: 100%|█| 80/80 [00:02<00:00, 36.55it/s, loss=0.00652, val_loss=0.041, a\u001b[A\n",
      "Epoch 95:  50%|▌| 40/80 [00:01<00:01, 20.33it/s, loss=0.0341, val_loss=0.041, av\u001b[A\n",
      "Epoch 95:  68%|▋| 54/80 [00:02<00:00, 26.47it/s, loss=0.0341, val_loss=0.041, av\n",
      "Epoch 95:  90%|▉| 72/80 [00:02<00:00, 33.42it/s, loss=0.0341, val_loss=0.041, av\u001b[A\n",
      "Epoch 95: 100%|█| 80/80 [00:02<00:00, 35.87it/s, loss=0.0341, val_loss=0.0447, a\u001b[A\n",
      "Epoch 96:  50%|▌| 40/80 [00:01<00:01, 20.03it/s, loss=0.00506, val_loss=0.0447, \u001b[A\n",
      "Epoch 96:  68%|▋| 54/80 [00:02<00:00, 26.04it/s, loss=0.00506, val_loss=0.0447, \n",
      "Epoch 96:  90%|▉| 72/80 [00:02<00:00, 33.00it/s, loss=0.00506, val_loss=0.0447, \u001b[A\n",
      "Epoch 96: 100%|█| 80/80 [00:02<00:00, 35.36it/s, loss=0.00506, val_loss=0.0318, \u001b[A\n",
      "Epoch 97:  50%|▌| 40/80 [00:01<00:01, 20.17it/s, loss=0.0111, val_loss=0.0318, a\u001b[A\n",
      "Epoch 97:  68%|▋| 54/80 [00:02<00:00, 26.20it/s, loss=0.0111, val_loss=0.0318, a\n",
      "Epoch 97:  90%|▉| 72/80 [00:02<00:00, 33.11it/s, loss=0.0111, val_loss=0.0318, a\u001b[A\n",
      "Epoch 97: 100%|█| 80/80 [00:02<00:00, 35.64it/s, loss=0.0111, val_loss=0.066, av\u001b[A\n",
      "Epoch 98:  50%|▌| 40/80 [00:01<00:01, 20.11it/s, loss=0.00885, val_loss=0.066, a\u001b[A\n",
      "Epoch 98:  68%|▋| 54/80 [00:02<00:00, 26.14it/s, loss=0.00885, val_loss=0.066, a\n",
      "Epoch 98:  90%|▉| 72/80 [00:02<00:00, 33.13it/s, loss=0.00885, val_loss=0.066, a\u001b[A\n",
      "Epoch 98: 100%|█| 80/80 [00:02<00:00, 35.58it/s, loss=0.00885, val_loss=0.0459, \u001b[A\n",
      "Epoch 99:  50%|▌| 40/80 [00:02<00:02, 19.44it/s, loss=0.0366, val_loss=0.0459, a\u001b[A\n",
      "Epoch 99:  68%|▋| 54/80 [00:02<00:01, 25.28it/s, loss=0.0366, val_loss=0.0459, a\n",
      "Epoch 99:  90%|▉| 72/80 [00:02<00:00, 32.09it/s, loss=0.0366, val_loss=0.0459, a\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 34.46it/s, loss=0.0366, val_loss=0.0437, a\u001b[A\n",
      "Epoch 99: 100%|█| 80/80 [00:02<00:00, 34.21it/s, loss=0.0366, val_loss=0.0437, a\u001b[A\n",
      "Sizes of clusters: 524, 436, 465, 385, 190\n",
      "\n",
      "preds: [3 3 3 3 3 1 3 1 3 1 3 1 3 3 2 3 1 3 3 1 1 3 1 3 3 3 3 3 1 1 1 3 1 3 3 3 3\n",
      " 3 1 3 3 3 3 3 3 1 3 3 1 3 3 1 3 3 1 1 1 3 3 1 3 3 3 3 3 3 3 3 1 2 1 1 1 3\n",
      " 3 3 1 1 3 1 1 3 1 1 3 2 1 3 3 3 1 1 1 3 1 1 3 1 3 1 1 1 3 3 3 1 3 3 1 3 3\n",
      " 3 3 1 1 1 3 3 3 3 3 1 1 1 3 3 3 1 3 1 3 3 1 3 1 3 2 3 3 3 1 3 1 1 3 1 3 1\n",
      " 3 3 2 1 1 1 1 3 3 3 3 3 3 3 3 1 1 3 1 1 3 3 3 3 3 1 1 1 1 1 1 1 3 3 3 3 3\n",
      " 3 3 1 1 3 3 1 1 3 3 1 3 3 3 3 3 1 3 3 1 3 3 1 1 3 3 1 1 1 3 1 1 3 3 1 3 3\n",
      " 3 3 1 3 1 1 3 1 3 3 1 1 1 1 1 1 3 3 3 1 3 1 1 3 1 3 3 3 1 3 1 3 1 3 3 1 3\n",
      " 1 3 3 3 2 3 2 3 3 3 3 3 3 3 1 3 1 3 3 1 1 3 1 1 3 1 3 1 3 1 3 3 3 1 1 3 3\n",
      " 3 3 1 3 1 1 1 3 1 3 2 2 1 3 1 1 3 1 3 3 3 1 3 3 3 1 3 1 3 1 3 3 3 1 3 3 1\n",
      " 3 3 2 3 3 3 1 3 1 1 3 1 3 3 3 3 3 3 3 3 1 3 2 2 1 1 3 3 1 1 2 3 3 3 2 1 1\n",
      " 1 3 3 3 3 3 3 2 3 3 3 1 3 1 1 1 1 3 3 3 3 1 1 3 1 3 3 1 3 3 1 3 1 3 1 3 1\n",
      " 3 1 3 1 1 1 1 3 1 3 1 1 2 3 3 1 1 3 1 3 3 3 1 3 3 1 3 3 1 1 2 1 1 1 2 1 1\n",
      " 3 1 1 1 1 3 1 1 3 1 3 1 1 1 3 3 1 1 1 3 1 3 1 1 1 3 1 3 2 1 3 3 1 1 3 1 1\n",
      " 1 3 1 1 1 1 3 1 1 3 3 3 1 1 3 3 1 1 1 3 1 1 3 1 1 3 1 3 3 3 1 1 2 1 1 3 1\n",
      " 3 3 1 3 1 3 1 1 1 3 1 3 3 3 3 1 1 1 2 3 3 3 3 3 1 3 1 1 1 3 1 1 1 3 1 1 3\n",
      " 3 1 3 3 1 3 1 3 3 1 3 1 1 3 1 1 1 3 3 3 3 2 1 1 3 1 1 3 1 3 1 1 3 1 3 1 3\n",
      " 1 1 1 1 1 3 3 1 3 3 3 3 3 1 1 1 3 1 1 1 1 1 1 3 3 1 1 3 1 3 3 3 3 3 3 1 3\n",
      " 1 1 1 3 2 1 1 1 3 3 1 1 1 3 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 2 1\n",
      " 3 3 3 1 3 1 1 2 3 3 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 3 1 3 3 3 1 1 3\n",
      " 1 1 1 1 1 3 1 1 1 1 3 1 3 1 3 1 3 1 3 3 2 3 3 3 1 1 1 3 1 2 3 1 3 1 1 3 1\n",
      " 3 3 3 3 2 1 3 1 1 3 3 1 3 1 1 1 1 3 1 1 1 1 3 3 1 1 1 1 1 1 1 1 1 2 3 1 3\n",
      " 1 3 2 3 1 1 1 1 1 1 1 1 3 2 3 1 3 1 1 1 3 1 1 2 2 2 2 4 2 0 0 2 2 0 2 2 0\n",
      " 2 2 2 1 2 2 2 2 2 2 2 0 2 1 2 1 0 2 2 0 2 1 2 2 2 1 2 1 2 0 0 0 2 2 0 2 2\n",
      " 2 0 2 1 2 2 0 0 2 2 2 0 2 2 2 0 0 0 2 2 0 2 2 0 0 2 2 0 2 1 2 2 0 4 2 2 2\n",
      " 2 0 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 1 2 0 0 1 1 0 2 2 2 4 2 2\n",
      " 2 2 2 1 0 1 2 1 2 2 0 1 2 2 0 2 0 0 0 0 2 2 2 2 1 1 2 2 2 2 4 2 1 0 2 4 2\n",
      " 2 2 2 2 0 0 2 2 2 2 2 2 0 1 2 0 2 0 2 0 2 2 4 2 0 2 2 2 2 0 2 2 2 2 2 2 0\n",
      " 0 1 2 2 0 2 3 2 2 2 2 2 0 2 1 2 2 2 1 2 2 2 2 2 2 1 0 2 0 2 1 2 2 2 2 2 0\n",
      " 1 0 0 2 1 0 2 0 0 2 1 0 2 2 0 2 2 2 2 1 2 2 0 0 2 2 0 0 1 2 0 2 2 0 0 2 0\n",
      " 0 2 2 0 2 2 2 2 2 0 1 2 2 0 2 2 1 2 2 0 2 2 4 0 2 1 0 0 2 0 0 2 0 0 0 1 2\n",
      " 2 2 0 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 0 1 0 2 0 0 2 2 2 2 1 1 2 2 1 1 4 2 2\n",
      " 0 2 2 2 2 2 2 4 0 2 2 2 2 0 2 4 0 0 0 2 2 0 2 2 0 2 0 2 1 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 1 2 0 2 0 2 0 0 2 2 2 0 2 4 2 4 2 0 4 4 0 4 0 4 0 1 2 4 0 0 4 2 2\n",
      " 4 2 0 0 0 2 2 2 0 0 0 0 4 0 2 4 2 0 0 0 1 0 0 0 2 0 4 4 4 0 2 2 0 4 0 0 2\n",
      " 1 2 4 1 4 2 2 4 2 0 0 2 0 4 2 0 2 0 4 4 4 0 0 2 0 4 2 4 4 0 0 0 0 4 4 2 4\n",
      " 0 0 2 2 4 2 2 0 4 0 0 0 0 2 0 2 0 0 2 0 0 0 0 4 0 0 4 2 0 2 0 2 0 0 4 2 0\n",
      " 4 4 0 0 2 2 0 4 0 0 0 4 4 2 4 4 0 2 0 4 4 2 2 1 0 0 0 2 2 4 0 0 2 0 0 4 0\n",
      " 4 0 4 2 0 2 1 0 4 2 0 2 0 2 0 2 2 0 4 0 2 2 0 0 0 2 4 0 0 4 0 0 0 0 4 0 4\n",
      " 4 4 0 2 4 0 2 4 4 0 0 4 2 4 4 0 4 0 4 0 4 2 0 4 4 4 0 0 4 0 0 4 2 0 0 0 2\n",
      " 2 2 4 2 0 2 0 0 4 0 4 4 2 4 0 2 4 0 1 2 0 2 4 4 2 0 4 4 0 0 4 0 0 0 0 4 0\n",
      " 0 2 4 4 4 0 2 2 0 0 4 4 0 2 2 2 2 0 1 0 0 2 0 0 4 2 2 4 2 2 2 2 4 1 4 0 2\n",
      " 2 1 2 2 0 4 0 1 2 2 2 2 2 0 0 0 0 2 2 2 4 0 2 0 2 0 2 2 0 0 4 0 4 2 0 0 0\n",
      " 4 0 2 2 0 0 2 0 0 0 2 0 2 2 0 0 2 2 0 2 2 0 0 0 0 4 0 4 4 0 2 0 0 0 0 0 4\n",
      " 0 0 0 2 0 4 2 0 0 0 0 0 0 4 0 0 0 0 2 0 2 2 0 0 0 4 0 2 0 2 0 0 4 4 2 0 0\n",
      " 2 0 4 4 0 0 0 0 0 2 0 0 0 0 0 4 4 0 0 4 0 0 0 4 2 0 4 0 0 0 0 0 0 2 0 0 0\n",
      " 4 0 0 0 2 2 0 0 0 2 2 0 2 4 2 2 4 2 0 0 4 0 0 0 0 4 4 0 2 0 0 2 4 0 0 0 0\n",
      " 4 0 4 0 0 4 4 0 4 0 0 2 0 2 0 0 4 0 0 0 2 0 0 0 0 0 0 2 0 4 0 4 0 0 4 4 0\n",
      " 0 4 0 0 4 0 4 0 0 0 4 0 2 4 0 4 4 0 0 0 2 0 0 0 0 2 0 2 2 4 2 2 0 0 0 0 4\n",
      " 0 0 4 0 0 0 0 0 0 0 2 0 2 0 2 4 2 4 4 0 0 2 4 2 0 4 0 0 4 0 0 2 0 0 0 2 0\n",
      " 0 4 0 2 0 0 2 0 2 0 4 2 0 0 0 0 0 2 0 2 0 2 0 0 0 0 4 4 0 4 0 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 2 4 2 4 4 0 2 0 0 0 0 0 0 0 4 4 0 2 4 0 4 2 4 2 0 0 4 0 0 4 4\n",
      " 0 2 0 4 4 0 0 0 2 0 4 4 2 0 4 2 0 0 0 0 2 2 0 0 0 0 4 0 0 0 4 4 0 0 0 0 0\n",
      " 0 0 4 0 0 0 2 0 2 0 0 0 0 0 0 4 2 0 2 4 0 0 0 0 0 0 0 0 2 4 0 2 0 0 0 0 2\n",
      " 0 4 2 0 2 4 0 0 0 0 4 0 0 2 0 0 2 4 4 0 0 4 0 2 0 0 0 0 0 2 0 4 0 4 4 0 0\n",
      " 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.5275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3324\r\n",
      "Purity: 0.4734999999999999+-0.06403514659934807\r\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K5_C5_0' \\\n",
    "    --verbose \\\n",
    "    --epochs 100 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 20.95it/s, loss=162, val_loss=0.084, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 36.72it/s, loss=162, val_loss=0.284, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=2.51, val_loss=0.284, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=2.51, val_loss=0.292, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.476, val_loss=0.292, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.476, val_loss=0.158, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.131, val_loss=0.158, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.60it/s, loss=0.131, val_loss=0.0845, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0607, val_loss=0.0845, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.0607, val_loss=0.0583, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.0404, val_loss=0.0583, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.72it/s, loss=0.0404, val_loss=0.0501, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.0322, val_loss=0.0501, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.53it/s, loss=0.0322, val_loss=0.0404, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0274, val_loss=0.0404, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.0274, val_loss=0.0338, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.46it/s, loss=0.0239, val_loss=0.0338, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.0239, val_loss=0.0288, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 20.10it/s, loss=0.0212, val_loss=0.0288, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 35.42it/s, loss=0.0212, val_loss=0.0248, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.019, val_loss=0.0248, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.57it/s, loss=0.019, val_loss=0.0217, av\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 20.49it/s, loss=0.0171, val_loss=0.0217, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 35.67it/s, loss=0.0171, val_loss=0.0194, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 20.32it/s, loss=0.0156, val_loss=0.0194, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 35.37it/s, loss=0.0156, val_loss=0.0172, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 20.85it/s, loss=0.0143, val_loss=0.0172, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 36.14it/s, loss=0.0143, val_loss=0.0155, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 16.47it/s, loss=0.0132, val_loss=0.0155, a\n",
      "Epoch 14:  81%|▊| 26/32 [00:01<00:00, 24.47it/s, loss=0.0132, val_loss=0.0155, a\n",
      "Epoch 14: 100%|█| 32/32 [00:01<00:00, 26.55it/s, loss=0.0132, val_loss=0.014, av\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:01<00:01,  9.90it/s, loss=0.0122, val_loss=0.014, av\u001b[A\n",
      "Epoch 15:  81%|▊| 26/32 [00:01<00:00, 15.23it/s, loss=0.0122, val_loss=0.014, av\n",
      "Epoch 15: 100%|█| 32/32 [00:01<00:00, 17.31it/s, loss=0.0122, val_loss=0.0129, a\u001b[A\n",
      "Epoch 16:  50%|▌| 16/32 [00:01<00:01, 10.33it/s, loss=0.0114, val_loss=0.0129, a\u001b[A\n",
      "Epoch 16:  81%|▊| 26/32 [00:01<00:00, 15.85it/s, loss=0.0114, val_loss=0.0129, a\n",
      "Epoch 16: 100%|█| 32/32 [00:01<00:00, 17.91it/s, loss=0.0114, val_loss=0.012, av\u001b[A\n",
      "Epoch 17:  50%|▌| 16/32 [00:01<00:01, 10.30it/s, loss=0.0107, val_loss=0.012, av\u001b[A\n",
      "Epoch 17:  81%|▊| 26/32 [00:01<00:00, 15.81it/s, loss=0.0107, val_loss=0.012, av\n",
      "Epoch 17: 100%|█| 32/32 [00:01<00:00, 17.89it/s, loss=0.0107, val_loss=0.0111, a\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:01<00:01,  9.93it/s, loss=0.01, val_loss=0.0111, avg\u001b[A\n",
      "Epoch 18:  81%|▊| 26/32 [00:01<00:00, 15.30it/s, loss=0.01, val_loss=0.0111, avg\n",
      "Epoch 18: 100%|█| 32/32 [00:01<00:00, 17.35it/s, loss=0.01, val_loss=0.0104, avg\u001b[A\n",
      "Epoch 19:  50%|▌| 16/32 [00:01<00:01, 10.35it/s, loss=0.00947, val_loss=0.0104, \u001b[A\n",
      "Epoch 19:  81%|▊| 26/32 [00:01<00:00, 15.86it/s, loss=0.00947, val_loss=0.0104, \n",
      "Epoch 19: 100%|█| 32/32 [00:01<00:00, 17.96it/s, loss=0.00947, val_loss=0.00976,\u001b[A\n",
      "Epoch 20:  50%|▌| 16/32 [00:01<00:01, 10.54it/s, loss=0.00897, val_loss=0.00976,\u001b[A\n",
      "Epoch 20:  81%|▊| 26/32 [00:01<00:00, 16.16it/s, loss=0.00897, val_loss=0.00976,\n",
      "Epoch 20: 100%|█| 32/32 [00:01<00:00, 18.25it/s, loss=0.00897, val_loss=0.00918,\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:01<00:01,  9.95it/s, loss=0.00851, val_loss=0.00918,\u001b[A\n",
      "Epoch 21:  81%|▊| 26/32 [00:01<00:00, 15.31it/s, loss=0.00851, val_loss=0.00918,\n",
      "Epoch 21: 100%|█| 32/32 [00:01<00:00, 17.34it/s, loss=0.00851, val_loss=0.00868,\u001b[A\n",
      "Epoch 22:  50%|▌| 16/32 [00:01<00:01, 14.32it/s, loss=0.00809, val_loss=0.00868,\u001b[A\n",
      "Epoch 22: 100%|█| 32/32 [00:01<00:00, 26.15it/s, loss=0.00809, val_loss=0.00823,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.00771, val_loss=0.00823,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.00771, val_loss=0.00782,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00736, val_loss=0.00782,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.00736, val_loss=0.00746,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00703, val_loss=0.00746,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.00703, val_loss=0.00713,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.00673, val_loss=0.00713,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00673, val_loss=0.00682,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00645, val_loss=0.00682,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00645, val_loss=0.00653,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.31it/s, loss=0.00619, val_loss=0.00653,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.31it/s, loss=0.00619, val_loss=0.00627,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00595, val_loss=0.00627,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.00595, val_loss=0.00604,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00572, val_loss=0.00604,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.91it/s, loss=0.00572, val_loss=0.00581,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.35it/s, loss=0.00551, val_loss=0.00581,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.35it/s, loss=0.00551, val_loss=0.0056, \n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.53it/s, loss=0.00531, val_loss=0.0056, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.64it/s, loss=0.00531, val_loss=0.00538,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00513, val_loss=0.00538,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00513, val_loss=0.00518,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.00496, val_loss=0.00518,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.45it/s, loss=0.00496, val_loss=0.005, a\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0048, val_loss=0.005, av\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.0048, val_loss=0.00484, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.00465, val_loss=0.00484,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.00465, val_loss=0.00469,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.00451, val_loss=0.00469,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.30it/s, loss=0.00451, val_loss=0.00454,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00438, val_loss=0.00454,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.00438, val_loss=0.00441,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00426, val_loss=0.00441,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.69it/s, loss=0.00426, val_loss=0.0043, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.43it/s, loss=0.00426, val_loss=0.0043, \n",
      "Sizes of clusters: 377, 423\n",
      "\n",
      "preds: [0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0\n",
      " 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0\n",
      " 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.6262\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=137, val_loss=0.08, avg_val\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=137, val_loss=0.119, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=2.31, val_loss=0.119, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=2.31, val_loss=0.154, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.51it/s, loss=0.436, val_loss=0.154, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.65it/s, loss=0.436, val_loss=0.0766, avg\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.108, val_loss=0.0766, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.58it/s, loss=0.108, val_loss=0.0452, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.80it/s, loss=0.0456, val_loss=0.0452, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.0456, val_loss=0.0329, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.0296, val_loss=0.0329, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.43it/s, loss=0.0296, val_loss=0.0266, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.0238, val_loss=0.0266, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.0238, val_loss=0.024, avg\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.0206, val_loss=0.024, avg\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.07it/s, loss=0.0206, val_loss=0.0215, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.34it/s, loss=0.0183, val_loss=0.0215, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.31it/s, loss=0.0183, val_loss=0.0194, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0165, val_loss=0.0194, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.72it/s, loss=0.0165, val_loss=0.0176, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.015, val_loss=0.0176, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.015, val_loss=0.016, avg\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0136, val_loss=0.016, av\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.94it/s, loss=0.0136, val_loss=0.0146, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.54it/s, loss=0.0125, val_loss=0.0146, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.70it/s, loss=0.0125, val_loss=0.0134, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0115, val_loss=0.0134, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=0.0115, val_loss=0.0123, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0106, val_loss=0.0123, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0106, val_loss=0.0113, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00977, val_loss=0.0113, \n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00977, val_loss=0.0105, \n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00907, val_loss=0.0105, \n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=0.00907, val_loss=0.00971,\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.45it/s, loss=0.00845, val_loss=0.00971,\n",
      "Epoch 17:  81%|▊| 26/32 [00:00<00:00, 32.88it/s, loss=0.00845, val_loss=0.00971,\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 36.80it/s, loss=0.00845, val_loss=0.00902,\u001b[A\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 20.91it/s, loss=0.00789, val_loss=0.00902,\u001b[A\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 36.64it/s, loss=0.00789, val_loss=0.0084, \n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00739, val_loss=0.0084, \n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.33it/s, loss=0.00739, val_loss=0.00785,\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.27it/s, loss=0.00694, val_loss=0.00785,\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.17it/s, loss=0.00694, val_loss=0.00736,\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.14it/s, loss=0.00653, val_loss=0.00736,\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 36.28it/s, loss=0.00653, val_loss=0.00691,\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.00616, val_loss=0.00691,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.28it/s, loss=0.00616, val_loss=0.00651,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.00583, val_loss=0.00651,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.68it/s, loss=0.00583, val_loss=0.00615,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.00553, val_loss=0.00615,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.39it/s, loss=0.00553, val_loss=0.00582,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.00526, val_loss=0.00582,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 36.84it/s, loss=0.00526, val_loss=0.00552,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.00501, val_loss=0.00552,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.40it/s, loss=0.00501, val_loss=0.00525,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00479, val_loss=0.00525,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.00479, val_loss=0.00501,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.00458, val_loss=0.00501,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.00458, val_loss=0.00479,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.0044, val_loss=0.00479, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.0044, val_loss=0.00458, \n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00423, val_loss=0.00458,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.00423, val_loss=0.0044, \n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.05it/s, loss=0.00407, val_loss=0.0044, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 36.89it/s, loss=0.00407, val_loss=0.00423,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.53it/s, loss=0.00393, val_loss=0.00423,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.62it/s, loss=0.00393, val_loss=0.00407,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.54it/s, loss=0.0038, val_loss=0.00407, \n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.62it/s, loss=0.0038, val_loss=0.00393, \n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.30it/s, loss=0.00368, val_loss=0.00393,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.26it/s, loss=0.00368, val_loss=0.00381,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.53it/s, loss=0.00356, val_loss=0.00381,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.55it/s, loss=0.00356, val_loss=0.00369,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00346, val_loss=0.00369,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.00346, val_loss=0.00358,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.18it/s, loss=0.00336, val_loss=0.00358,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.08it/s, loss=0.00336, val_loss=0.00348,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.00327, val_loss=0.00348,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.45it/s, loss=0.00327, val_loss=0.00338,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.42it/s, loss=0.00319, val_loss=0.00338,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.00319, val_loss=0.0033, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.20it/s, loss=0.00319, val_loss=0.0033, \n",
      "Sizes of clusters: 415, 385\n",
      "\n",
      "preds: [0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0\n",
      " 1 1 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n",
      " 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 0 1\n",
      " 1 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0\n",
      " 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0\n",
      " 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5613\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=140, val_loss=0.064, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=140, val_loss=0.27, avg_val\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.89it/s, loss=2.19, val_loss=0.27, avg_va\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=2.19, val_loss=0.114, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.395, val_loss=0.114, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.15it/s, loss=0.395, val_loss=0.0958, avg\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.112, val_loss=0.0958, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.112, val_loss=0.0628, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.0521, val_loss=0.0628, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.0521, val_loss=0.0441, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.86it/s, loss=0.0365, val_loss=0.0441, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.17it/s, loss=0.0365, val_loss=0.0385, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.03, val_loss=0.0385, avg_\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.24it/s, loss=0.03, val_loss=0.0337, avg_\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.0263, val_loss=0.0337, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.0263, val_loss=0.0298, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.0236, val_loss=0.0298, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=0.0236, val_loss=0.0266, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.0215, val_loss=0.0266, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.0215, val_loss=0.0239, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.0197, val_loss=0.0239, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 38.11it/s, loss=0.0197, val_loss=0.0217, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=0.0182, val_loss=0.0217, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.25it/s, loss=0.0182, val_loss=0.0198, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.017, val_loss=0.0198, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.017, val_loss=0.0183, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0159, val_loss=0.0183, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0159, val_loss=0.0169, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0149, val_loss=0.0169, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.0149, val_loss=0.0158, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.34it/s, loss=0.0141, val_loss=0.0158, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.32it/s, loss=0.0141, val_loss=0.0148, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.0133, val_loss=0.0148, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.0133, val_loss=0.0139, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.0126, val_loss=0.0139, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.97it/s, loss=0.0126, val_loss=0.0131, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.27it/s, loss=0.0119, val_loss=0.0131, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.16it/s, loss=0.0119, val_loss=0.0124, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0113, val_loss=0.0124, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.0113, val_loss=0.0117, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0107, val_loss=0.0117, a\n",
      "Epoch 20:  81%|▊| 26/32 [00:00<00:00, 33.29it/s, loss=0.0107, val_loss=0.0117, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.58it/s, loss=0.0107, val_loss=0.0111, a\u001b[A\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.18it/s, loss=0.0102, val_loss=0.0111, a\u001b[A\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.09it/s, loss=0.0102, val_loss=0.0105, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.00968, val_loss=0.0105, \n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.00968, val_loss=0.01, av\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00922, val_loss=0.01, av\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00922, val_loss=0.00952,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.29it/s, loss=0.00879, val_loss=0.00952,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.19it/s, loss=0.00879, val_loss=0.00907,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00839, val_loss=0.00907,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.75it/s, loss=0.00839, val_loss=0.00865,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.00802, val_loss=0.00865,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.70it/s, loss=0.00802, val_loss=0.00825,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00767, val_loss=0.00825,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00767, val_loss=0.00789,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.44it/s, loss=0.00734, val_loss=0.00789,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.51it/s, loss=0.00734, val_loss=0.00756,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00704, val_loss=0.00756,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.00704, val_loss=0.00724,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00675, val_loss=0.00724,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00675, val_loss=0.00693,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00649, val_loss=0.00693,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.00649, val_loss=0.00664,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.00624, val_loss=0.00664,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00624, val_loss=0.00637,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.00601, val_loss=0.00637,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00601, val_loss=0.00612,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.0058, val_loss=0.00612, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.07it/s, loss=0.0058, val_loss=0.00589, \n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00559, val_loss=0.00589,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.94it/s, loss=0.00559, val_loss=0.00568,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00541, val_loss=0.00568,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00541, val_loss=0.00548,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.01it/s, loss=0.00523, val_loss=0.00548,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 36.85it/s, loss=0.00523, val_loss=0.0053, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.00507, val_loss=0.0053, \n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.00507, val_loss=0.00513,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.50it/s, loss=0.00492, val_loss=0.00513,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.60it/s, loss=0.00492, val_loss=0.00498,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.32it/s, loss=0.00492, val_loss=0.00498,\n",
      "Sizes of clusters: 429, 371\n",
      "\n",
      "preds: [0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1\n",
      " 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 1\n",
      " 1 0 0 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0\n",
      " 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1\n",
      " 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 1\n",
      " 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1\n",
      " 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
      " 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0\n",
      " 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
      " 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 0\n",
      " 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5062\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=146, val_loss=0.0921, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.10it/s, loss=146, val_loss=0.268, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=2.32, val_loss=0.268, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.15it/s, loss=2.32, val_loss=0.238, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.455, val_loss=0.238, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.24it/s, loss=0.455, val_loss=0.113, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.128, val_loss=0.113, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.128, val_loss=0.0594, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.82it/s, loss=0.0568, val_loss=0.0594, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.0568, val_loss=0.0439, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.0366, val_loss=0.0439, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=0.0366, val_loss=0.0372, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.52it/s, loss=0.0285, val_loss=0.0372, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.35it/s, loss=0.0285, val_loss=0.0317, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.53it/s, loss=0.0237, val_loss=0.0317, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 37.66it/s, loss=0.0237, val_loss=0.0273, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0204, val_loss=0.0273, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.0204, val_loss=0.0237, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.48it/s, loss=0.0178, val_loss=0.0237, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.56it/s, loss=0.0178, val_loss=0.0208, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.0158, val_loss=0.0208, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.49it/s, loss=0.0158, val_loss=0.0184, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.30it/s, loss=0.0142, val_loss=0.0184, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.22it/s, loss=0.0142, val_loss=0.0163, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.0129, val_loss=0.0163, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.40it/s, loss=0.0129, val_loss=0.0146, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0117, val_loss=0.0146, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0117, val_loss=0.0131, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0108, val_loss=0.0131, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.0108, val_loss=0.0119, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.26it/s, loss=0.00996, val_loss=0.0119, \n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.22it/s, loss=0.00996, val_loss=0.0108, \n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00926, val_loss=0.0108, \n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00926, val_loss=0.00992,\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00864, val_loss=0.00992,\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.00864, val_loss=0.00917,\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.23it/s, loss=0.0081, val_loss=0.00917, \n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.17it/s, loss=0.0081, val_loss=0.00852, \n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00762, val_loss=0.00852,\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00762, val_loss=0.00795,\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.03it/s, loss=0.00719, val_loss=0.00795,\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 36.87it/s, loss=0.00719, val_loss=0.00746,\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.21it/s, loss=0.00681, val_loss=0.00746,\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.13it/s, loss=0.00681, val_loss=0.00703,\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00646, val_loss=0.00703,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00646, val_loss=0.00665,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00615, val_loss=0.00665,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.71it/s, loss=0.00615, val_loss=0.00631,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.35it/s, loss=0.00587, val_loss=0.00631,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.35it/s, loss=0.00587, val_loss=0.00601,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00561, val_loss=0.00601,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00561, val_loss=0.00573,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00538, val_loss=0.00573,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.00538, val_loss=0.00549,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.54it/s, loss=0.00516, val_loss=0.00549,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.65it/s, loss=0.00516, val_loss=0.00526,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00497, val_loss=0.00526,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.37it/s, loss=0.00497, val_loss=0.00506,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.00479, val_loss=0.00506,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.67it/s, loss=0.00479, val_loss=0.00487,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00463, val_loss=0.00487,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00463, val_loss=0.0047, \n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00448, val_loss=0.0047, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.40it/s, loss=0.00448, val_loss=0.00455,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00435, val_loss=0.00455,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00435, val_loss=0.00441,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00422, val_loss=0.00441,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.00422, val_loss=0.00428,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.00411, val_loss=0.00428,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.37it/s, loss=0.00411, val_loss=0.00416,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00401, val_loss=0.00416,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.00401, val_loss=0.00405,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.00391, val_loss=0.00405,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.00391, val_loss=0.00396,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00382, val_loss=0.00396,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.40it/s, loss=0.00382, val_loss=0.00387,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.00374, val_loss=0.00387,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.00374, val_loss=0.00379,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.00366, val_loss=0.00379,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.00366, val_loss=0.0037, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.54it/s, loss=0.00366, val_loss=0.0037, \n",
      "Sizes of clusters: 380, 420\n",
      "\n",
      "preds: [1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0\n",
      " 0 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0\n",
      " 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1\n",
      " 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0\n",
      " 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1\n",
      " 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1\n",
      " 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0\n",
      " 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 0 1\n",
      " 0 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1\n",
      " 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0\n",
      " 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5025\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=160, val_loss=0.0664, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.09it/s, loss=160, val_loss=0.144, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=2.05, val_loss=0.144, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.24it/s, loss=2.05, val_loss=0.129, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=0.412, val_loss=0.129, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.18it/s, loss=0.412, val_loss=0.0868, avg\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.124, val_loss=0.0868, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.53it/s, loss=0.124, val_loss=0.0552, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.92it/s, loss=0.0625, val_loss=0.0552, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.24it/s, loss=0.0625, val_loss=0.0453, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.84it/s, loss=0.0456, val_loss=0.0453, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.13it/s, loss=0.0456, val_loss=0.0405, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0381, val_loss=0.0405, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.71it/s, loss=0.0381, val_loss=0.0359, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.0336, val_loss=0.0359, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.26it/s, loss=0.0336, val_loss=0.0323, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0302, val_loss=0.0323, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.00it/s, loss=0.0302, val_loss=0.0294, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.0275, val_loss=0.0294, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.67it/s, loss=0.0275, val_loss=0.0271, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0254, val_loss=0.0271, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0254, val_loss=0.0252, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0235, val_loss=0.0252, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.68it/s, loss=0.0235, val_loss=0.0235, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.022, val_loss=0.0235, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.022, val_loss=0.0221, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0207, val_loss=0.0221, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0207, val_loss=0.0208, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.08it/s, loss=0.0195, val_loss=0.0208, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 36.92it/s, loss=0.0195, val_loss=0.0197, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.0184, val_loss=0.0197, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.34it/s, loss=0.0184, val_loss=0.0186, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.0175, val_loss=0.0186, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.66it/s, loss=0.0175, val_loss=0.0177, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.0166, val_loss=0.0177, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.0166, val_loss=0.0168, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.16it/s, loss=0.0158, val_loss=0.0168, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.07it/s, loss=0.0158, val_loss=0.016, av\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.015, val_loss=0.016, avg\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.015, val_loss=0.0152, av\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0144, val_loss=0.0152, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.0144, val_loss=0.0145, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.42it/s, loss=0.0137, val_loss=0.0145, a\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.49it/s, loss=0.0137, val_loss=0.0139, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0131, val_loss=0.0139, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.0131, val_loss=0.0133, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0126, val_loss=0.0133, a\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.0126, val_loss=0.0127, a\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 20.94it/s, loss=0.012, val_loss=0.0127, av\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 36.72it/s, loss=0.012, val_loss=0.0121, av\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.0115, val_loss=0.0121, a\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.82it/s, loss=0.0115, val_loss=0.0116, a\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.0111, val_loss=0.0116, a\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=0.0111, val_loss=0.0111, a\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.0106, val_loss=0.0111, a\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.0106, val_loss=0.0106, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.0102, val_loss=0.0106, a\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.41it/s, loss=0.0102, val_loss=0.0102, a\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.52it/s, loss=0.00984, val_loss=0.0102, \n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.62it/s, loss=0.00984, val_loss=0.00979,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.00947, val_loss=0.00979,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.55it/s, loss=0.00947, val_loss=0.0094, \n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.00912, val_loss=0.0094, \n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.42it/s, loss=0.00912, val_loss=0.00902,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00879, val_loss=0.00902,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00879, val_loss=0.00866,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.46it/s, loss=0.00847, val_loss=0.00866,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.53it/s, loss=0.00847, val_loss=0.00832,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.00816, val_loss=0.00832,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.14it/s, loss=0.00816, val_loss=0.008, a\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.00787, val_loss=0.008, a\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.00787, val_loss=0.0077, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00759, val_loss=0.0077, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.00759, val_loss=0.00742,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.02it/s, loss=0.00732, val_loss=0.00742,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 36.83it/s, loss=0.00732, val_loss=0.00716,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00706, val_loss=0.00716,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.00706, val_loss=0.0069, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00681, val_loss=0.0069, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00681, val_loss=0.00665,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.55it/s, loss=0.00681, val_loss=0.00665,\n",
      "Sizes of clusters: 415, 385\n",
      "\n",
      "preds: [1 0 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0\n",
      " 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0\n",
      " 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 0\n",
      " 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.6338\n",
      "\n",
      "Consistency: 0.5106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.5660000000000001+-0.0562938717801503\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K2_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=10.2, val_loss=0.065, avg_v\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 30.90it/s, loss=10.2, val_loss=0.065, avg_v\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=10.2, val_loss=0.412, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.15it/s, loss=0.487, val_loss=0.412, avg_\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.89it/s, loss=0.487, val_loss=0.412, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.63it/s, loss=0.487, val_loss=0.125, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.0866, val_loss=0.125, avg\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 31.25it/s, loss=0.0866, val_loss=0.125, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.0866, val_loss=0.0531, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.0406, val_loss=0.0531, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.0406, val_loss=0.0531, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.55it/s, loss=0.0406, val_loss=0.0426, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.0296, val_loss=0.0426, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 31.28it/s, loss=0.0296, val_loss=0.0426, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.0296, val_loss=0.0342, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.0238, val_loss=0.0342, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.37it/s, loss=0.0238, val_loss=0.0342, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.0238, val_loss=0.0276, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.02, val_loss=0.0276, avg_\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 31.20it/s, loss=0.02, val_loss=0.0276, avg_\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.02, val_loss=0.0229, avg_\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.0173, val_loss=0.0229, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 31.43it/s, loss=0.0173, val_loss=0.0229, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.46it/s, loss=0.0173, val_loss=0.0194, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.0152, val_loss=0.0194, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 31.24it/s, loss=0.0152, val_loss=0.0194, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.27it/s, loss=0.0152, val_loss=0.0168, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.0137, val_loss=0.0168, av\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 31.50it/s, loss=0.0137, val_loss=0.0168, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.54it/s, loss=0.0137, val_loss=0.0148, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.0126, val_loss=0.0148, a\u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 31.24it/s, loss=0.0126, val_loss=0.0148, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.25it/s, loss=0.0126, val_loss=0.0132, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.02it/s, loss=0.0116, val_loss=0.0132, a\u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 31.40it/s, loss=0.0116, val_loss=0.0132, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.45it/s, loss=0.0116, val_loss=0.012, av\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.0108, val_loss=0.012, av\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 31.21it/s, loss=0.0108, val_loss=0.012, av\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.0108, val_loss=0.011, av\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.0102, val_loss=0.011, av\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 31.51it/s, loss=0.0102, val_loss=0.011, av\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.56it/s, loss=0.0102, val_loss=0.0103, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.00958, val_loss=0.0103, \u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 31.31it/s, loss=0.00958, val_loss=0.0103, \n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.00958, val_loss=0.00963,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.00906, val_loss=0.00963,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 31.32it/s, loss=0.00906, val_loss=0.00963,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.00906, val_loss=0.00907,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.0086, val_loss=0.00907, \u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 31.28it/s, loss=0.0086, val_loss=0.00907, \n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.0086, val_loss=0.00859, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 22.07it/s, loss=0.00818, val_loss=0.00859,\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 31.48it/s, loss=0.00818, val_loss=0.00859,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.53it/s, loss=0.00818, val_loss=0.00815,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00779, val_loss=0.00815,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 31.16it/s, loss=0.00779, val_loss=0.00815,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.18it/s, loss=0.00779, val_loss=0.00776,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 22.09it/s, loss=0.00744, val_loss=0.00776,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 31.47it/s, loss=0.00744, val_loss=0.00776,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.52it/s, loss=0.00744, val_loss=0.00739,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00711, val_loss=0.00739,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 31.27it/s, loss=0.00711, val_loss=0.00739,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00711, val_loss=0.00706,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.00681, val_loss=0.00706,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 31.47it/s, loss=0.00681, val_loss=0.00706,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.54it/s, loss=0.00681, val_loss=0.00676,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00653, val_loss=0.00676,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 31.26it/s, loss=0.00653, val_loss=0.00676,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.29it/s, loss=0.00653, val_loss=0.00648,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.00627, val_loss=0.00648,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 31.56it/s, loss=0.00627, val_loss=0.00648,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.62it/s, loss=0.00627, val_loss=0.00623,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00603, val_loss=0.00623,\u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 30.90it/s, loss=0.00603, val_loss=0.00623,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.00603, val_loss=0.00599,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0058, val_loss=0.00599, \u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 30.99it/s, loss=0.0058, val_loss=0.00599, \n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.0058, val_loss=0.00576, \u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00559, val_loss=0.00576,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 31.05it/s, loss=0.00559, val_loss=0.00576,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.08it/s, loss=0.00559, val_loss=0.00555,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00539, val_loss=0.00555,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 30.86it/s, loss=0.00539, val_loss=0.00555,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00539, val_loss=0.00536,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00521, val_loss=0.00536,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 31.10it/s, loss=0.00521, val_loss=0.00536,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.00521, val_loss=0.00518,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00504, val_loss=0.00518,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 30.77it/s, loss=0.00504, val_loss=0.00518,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.77it/s, loss=0.00504, val_loss=0.00501,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00488, val_loss=0.00501,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 31.09it/s, loss=0.00488, val_loss=0.00501,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.00488, val_loss=0.00486,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00474, val_loss=0.00486,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 30.76it/s, loss=0.00474, val_loss=0.00486,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00474, val_loss=0.00472,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0046, val_loss=0.00472, \u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 30.90it/s, loss=0.0046, val_loss=0.00472, \n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=0.0046, val_loss=0.00459, \u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.52it/s, loss=0.00447, val_loss=0.00459,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 30.68it/s, loss=0.00447, val_loss=0.00459,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.00447, val_loss=0.00447,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00435, val_loss=0.00447,\u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 31.06it/s, loss=0.00435, val_loss=0.00447,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.00435, val_loss=0.00436,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00424, val_loss=0.00436,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 30.84it/s, loss=0.00424, val_loss=0.00436,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.84it/s, loss=0.00424, val_loss=0.00425,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00414, val_loss=0.00425,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 30.99it/s, loss=0.00414, val_loss=0.00425,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.00414, val_loss=0.00415,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00404, val_loss=0.00415,\u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 30.78it/s, loss=0.00404, val_loss=0.00415,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00404, val_loss=0.00406,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00395, val_loss=0.00406,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 31.12it/s, loss=0.00395, val_loss=0.00406,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=0.00395, val_loss=0.00397,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00387, val_loss=0.00397,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 30.78it/s, loss=0.00387, val_loss=0.00397,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00387, val_loss=0.00389,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.50it/s, loss=0.00387, val_loss=0.00389,\u001b[A\n",
      "Sizes of clusters: 412, 395, 393\n",
      "\n",
      "preds: [1 1 1 2 0 2 2 0 1 0 1 0 2 2 2 1 2 0 1 2 2 2 2 2 2 1 0 1 2 2 2 0 0 1 2 1 2\n",
      " 1 1 1 2 0 2 0 2 2 1 2 1 2 0 2 0 2 2 2 2 2 2 1 0 2 2 1 2 0 2 2 0 1 2 1 2 2\n",
      " 0 2 2 1 1 2 2 2 2 1 2 1 0 1 2 2 2 2 2 2 0 2 1 0 1 2 2 1 0 0 2 2 1 2 1 2 2\n",
      " 1 2 2 2 2 2 1 0 2 1 2 1 2 2 2 1 2 1 2 1 2 2 2 2 1 2 1 2 1 2 2 1 1 1 0 0 1\n",
      " 2 2 1 2 2 2 0 1 2 1 1 2 1 2 1 2 0 0 2 1 1 2 0 1 2 1 1 2 2 2 2 2 2 1 1 0 0\n",
      " 1 0 2 2 0 2 1 2 2 2 2 0 1 2 1 2 2 2 2 2 2 0 1 1 0 2 0 2 2 1 2 1 2 2 2 2 2\n",
      " 2 2 0 1 1 2 1 2 1 0 2 2 2 0 0 2 1 2 0 0 1 2 0 0 1 1 2 1 0 1 1 0 1 1 2 2 1\n",
      " 1 1 2 2 2 0 0 2 2 2 2 1 2 2 1 1 0 2 0 2 0 1 2 2 2 1 2 2 0 0 0 2 1 2 0 1 0\n",
      " 1 1 1 2 2 2 2 2 2 2 2 2 0 2 0 0 2 2 1 0 2 2 0 1 2 1 2 1 2 2 2 2 0 1 1 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 1 2 2 1 2 1 1 2 2 0 2 2 1 2 2 0 2 2 1 2 2 2 1 0 1 2 2\n",
      " 2 2 1 2 2 1 2 2 0 1 2 1 2 0 2 2 1 0 2 1 0 1 1 0 1 0 2 2 2 1 2 2 2 1 1 2 0\n",
      " 2 1 1 2 1 0 0 0 2 0 0 0 0 1 0 1 2 1 2 1 1 1 0 0 1 1 0 1 0 2 1 2 1 2 2 0 1\n",
      " 0 1 1 0 0 1 2 1 2 1 1 2 2 0 1 0 1 0 2 1 0 0 1 1 0 0 2 1 1 2 2 2 1 1 1 2 2\n",
      " 2 1 1 0 1 1 2 1 1 1 0 1 1 0 0 1 1 1 1 2 1 1 0 2 1 1 2 0 1 1 1 2 0 0 2 1 0\n",
      " 2 0 2 2 1 1 2 1 2 2 1 0 0 2 1 0 2 2 2 0 2 0 2 0 0 2 0 1 1 0 1 2 0 2 1 0 1\n",
      " 2 1 1 2 1 1 0 2 1 1 2 1 1 0 1 0 2 2 2 0 2 2 0 0 1 1 1 1 2 0 1 1 0 1 1 2 2\n",
      " 2 2 0 1 1 2 0 0 1 2 0 2 1 2 1 0 1 0 0 2 1 2 2 0 2 1 2 1 2 0 2 2 0 1 0 1 2\n",
      " 0 0 0 2 0 2 1 2 1 0 1 1 2 2 1 1 2 1 1 2 0 2 1 1 0 0 2 0 1 0 2 0 2 2 1 2 2\n",
      " 2 1 2 0 1 1 1 0 0 1 2 2 1 1 0 2 2 2 0 2 0 1 2 2 1 2 0 1 2 2 0 2 1 2 1 2 0\n",
      " 1 0 1 1 1 0 1 1 1 0 2 1 1 1 2 2 1 1 2 1 0 1 2 1 1 0 1 1 2 2 0 2 0 2 2 1 1\n",
      " 1 0 2 1 1 1 2 1 1 2 1 2 0 2 2 1 1 2 0 2 2 0 1 1 0 1 1 0 1 1 0 1 2 0 0 0 2\n",
      " 2 0 2 2 0 2 0 1 2 2 1 2 2 1 2 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 0 1 1 2 0 0 0 0 0 1 2 1 0 0 2 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 2 2 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 2 0 0 0 0 0 0 2 2 2 0 0 2 0 1 0 0 0 0 1 0 1 2 0 1 0 0 0 1\n",
      " 1 1 1 2 2 1 0 1 0 0 2 1 0 0 1 0 2 1 0 0 1 0 0 1 2 1 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 2 2 2 0 0 1 0 2 1 0 0 1 0 0 0 1 1 2 0 0 2 1 1 0 1 0 1\n",
      " 0 0 0 1 2 0 1 1 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 2 1 0 1 0 0 1 0 2 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 2 0 1 0 0 2 2 0 2\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 2 0 0 0 0 0 1 1 1 0 0 0 0 0 0 2 1 0 1 0 1 0 1\n",
      " 0 1 1 2 1 0 0 0 0 2 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 2 1 0\n",
      " 1 0 0 0 1 0 1 2 0 0 0 1 0 1 2 0 0 1 0 0 1 2 1 1 1 0 1 2 0 0 2 0 0 1 0 0 0\n",
      " 1 0 2 0 1 1 0 0 0 1 0 0 0 1 0 2 0 1 1 0 0 0 0 0 2 0 0 1 0 0 2 1 1 0 2 0 0\n",
      " 1 1 0 0 0 1 0 1 2 2 1 1 1 0 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5100\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=11.3, val_loss=0.0506, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=11.3, val_loss=0.0932, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.399, val_loss=0.0932, avg\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.73it/s, loss=0.399, val_loss=0.0932, avg\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.399, val_loss=0.0652, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.0711, val_loss=0.0652, av\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.55it/s, loss=0.0711, val_loss=0.0652, av\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.20it/s, loss=0.0711, val_loss=0.0464, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0337, val_loss=0.0464, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.0337, val_loss=0.0464, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.0337, val_loss=0.0337, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.0251, val_loss=0.0337, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 32.48it/s, loss=0.0251, val_loss=0.0337, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.0251, val_loss=0.0267, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.08it/s, loss=0.0213, val_loss=0.0267, av\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.88it/s, loss=0.0213, val_loss=0.0267, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.57it/s, loss=0.0213, val_loss=0.0226, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.0189, val_loss=0.0226, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 32.10it/s, loss=0.0189, val_loss=0.0226, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.0189, val_loss=0.0198, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 22.04it/s, loss=0.0173, val_loss=0.0198, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.75it/s, loss=0.0173, val_loss=0.0198, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.49it/s, loss=0.0173, val_loss=0.018, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0161, val_loss=0.018, avg\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 32.36it/s, loss=0.0161, val_loss=0.018, avg\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.0161, val_loss=0.0166, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.0152, val_loss=0.0166, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.0152, val_loss=0.0166, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.0152, val_loss=0.0156, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.52it/s, loss=0.0143, val_loss=0.0156, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 32.06it/s, loss=0.0143, val_loss=0.0156, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.68it/s, loss=0.0143, val_loss=0.0147, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.0136, val_loss=0.0147, a\u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 31.92it/s, loss=0.0136, val_loss=0.0147, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.54it/s, loss=0.0136, val_loss=0.0139, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.0129, val_loss=0.0139, a\u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.0129, val_loss=0.0139, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.0129, val_loss=0.0132, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0123, val_loss=0.0132, a\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.0123, val_loss=0.0132, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.0123, val_loss=0.0125, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.18it/s, loss=0.0117, val_loss=0.0125, a\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 31.57it/s, loss=0.0117, val_loss=0.0125, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.16it/s, loss=0.0117, val_loss=0.0119, a\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.86it/s, loss=0.0112, val_loss=0.0119, a\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.54it/s, loss=0.0112, val_loss=0.0119, a\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.21it/s, loss=0.0112, val_loss=0.0114, a\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.0107, val_loss=0.0114, a\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 32.27it/s, loss=0.0107, val_loss=0.0114, a\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.0107, val_loss=0.0108, a\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.0102, val_loss=0.0108, a\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.49it/s, loss=0.0102, val_loss=0.0108, a\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.0102, val_loss=0.0104, a\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.00979, val_loss=0.0104, \u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 32.00it/s, loss=0.00979, val_loss=0.0104, \n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.58it/s, loss=0.00979, val_loss=0.00993,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.00938, val_loss=0.00993,\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.39it/s, loss=0.00938, val_loss=0.00993,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00938, val_loss=0.00947,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.00899, val_loss=0.00947,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 32.01it/s, loss=0.00899, val_loss=0.00947,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.62it/s, loss=0.00899, val_loss=0.00906,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00862, val_loss=0.00906,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.00862, val_loss=0.00906,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.04it/s, loss=0.00862, val_loss=0.00866,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.00828, val_loss=0.00866,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 32.17it/s, loss=0.00828, val_loss=0.00866,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00828, val_loss=0.0083, \u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00795, val_loss=0.0083, \u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.47it/s, loss=0.00795, val_loss=0.0083, \n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=0.00795, val_loss=0.00796,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00763, val_loss=0.00796,\u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.00763, val_loss=0.00796,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00763, val_loss=0.00764,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00734, val_loss=0.00764,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.53it/s, loss=0.00734, val_loss=0.00764,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.00734, val_loss=0.00735,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00705, val_loss=0.00735,\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.36it/s, loss=0.00705, val_loss=0.00735,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.00705, val_loss=0.00709,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.54it/s, loss=0.00679, val_loss=0.00709,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.09it/s, loss=0.00679, val_loss=0.00709,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00679, val_loss=0.00684,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00653, val_loss=0.00684,\u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 32.52it/s, loss=0.00653, val_loss=0.00684,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.19it/s, loss=0.00653, val_loss=0.00658,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00629, val_loss=0.00658,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.00629, val_loss=0.00658,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.91it/s, loss=0.00629, val_loss=0.00634,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.87it/s, loss=0.00606, val_loss=0.00634,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.00606, val_loss=0.00634,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.00606, val_loss=0.00612,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00584, val_loss=0.00612,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.16it/s, loss=0.00584, val_loss=0.00612,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00584, val_loss=0.00591,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=0.00564, val_loss=0.00591,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.57it/s, loss=0.00564, val_loss=0.00591,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 38.27it/s, loss=0.00564, val_loss=0.00571,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00544, val_loss=0.00571,\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 32.13it/s, loss=0.00544, val_loss=0.00571,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00544, val_loss=0.00552,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.00526, val_loss=0.00552,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.56it/s, loss=0.00526, val_loss=0.00552,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00526, val_loss=0.00534,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.27it/s, loss=0.00509, val_loss=0.00534,\u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 31.27it/s, loss=0.00509, val_loss=0.00534,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.01it/s, loss=0.00509, val_loss=0.00518,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00493, val_loss=0.00518,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.44it/s, loss=0.00493, val_loss=0.00518,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.00493, val_loss=0.00504,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00479, val_loss=0.00504,\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 32.24it/s, loss=0.00479, val_loss=0.00504,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.00479, val_loss=0.0049, \u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00465, val_loss=0.0049, \u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.32it/s, loss=0.00465, val_loss=0.0049, \n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00465, val_loss=0.00476,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.49it/s, loss=0.00452, val_loss=0.00476,\u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.00452, val_loss=0.00476,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.00452, val_loss=0.00464,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.37it/s, loss=0.00452, val_loss=0.00464,\u001b[A\n",
      "Sizes of clusters: 330, 312, 558\n",
      "\n",
      "preds: [0 2 1 1 2 2 2 2 0 0 1 2 2 1 2 1 1 2 0 0 2 1 1 1 1 1 2 1 2 2 2 0 2 2 2 2 0\n",
      " 2 2 1 1 0 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 1 2 2 2 1 2 0 0 2 2 0 1 1 0 1 1\n",
      " 0 1 2 0 1 1 1 1 1 1 1 0 0 2 2 1 2 1 1 1 0 1 1 0 0 1 2 1 2 2 1 1 2 0 2 1 2\n",
      " 2 2 1 2 1 1 2 0 1 2 2 2 2 2 1 1 1 2 1 2 1 1 1 2 2 0 1 1 1 1 2 2 1 0 0 2 0\n",
      " 2 2 0 1 2 1 0 1 1 2 1 1 2 1 0 2 2 2 2 1 0 2 0 1 2 1 2 1 1 1 1 1 2 0 1 2 0\n",
      " 0 0 2 1 2 1 2 1 1 1 2 2 0 1 2 2 1 1 2 1 2 2 2 2 0 2 2 0 2 1 1 1 2 1 2 2 1\n",
      " 2 1 2 0 2 2 1 0 1 2 1 1 1 0 0 2 1 1 0 2 2 2 0 0 2 1 0 1 0 1 2 2 2 1 2 2 0\n",
      " 0 2 2 2 1 0 0 1 2 1 2 1 2 2 1 2 2 1 0 1 2 2 2 2 2 0 2 1 0 2 2 2 1 2 0 1 0\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 0 1 0 0 1 2 1 0 2 1 0 2 2 1 1 1 1 1 1 1 0 2 2 0 1\n",
      " 2 0 2 1 2 2 2 1 0 1 1 2 2 0 0 2 2 1 1 0 2 2 2 0 1 2 1 2 1 1 1 2 2 2 0 1 2\n",
      " 0 1 2 2 2 2 1 1 0 1 2 1 1 0 1 2 1 0 2 2 0 1 2 2 2 2 2 1 2 0 2 2 2 2 2 2 2\n",
      " 1 2 1 1 2 2 0 0 2 2 2 0 0 0 2 0 2 2 1 2 2 2 0 0 0 2 2 2 2 1 2 1 1 1 1 2 2\n",
      " 0 1 2 0 2 1 2 1 2 1 1 2 1 2 0 2 0 2 1 2 1 2 1 2 0 2 2 2 1 1 1 1 1 1 2 1 1\n",
      " 2 2 0 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 1 2 2 2 2 2\n",
      " 1 2 1 1 1 2 2 0 2 2 2 0 0 2 1 2 2 1 1 2 1 0 1 2 2 2 0 1 1 2 2 1 2 2 2 2 2\n",
      " 2 2 2 1 0 2 2 2 2 0 1 1 2 2 2 0 2 1 1 0 1 1 2 2 2 2 1 1 1 2 2 2 1 2 1 2 1\n",
      " 1 1 0 1 1 1 2 2 2 2 0 0 1 2 2 2 2 0 2 1 0 1 1 2 1 2 1 1 1 0 1 1 0 2 0 1 1\n",
      " 2 2 2 1 2 1 2 2 2 2 1 2 1 1 2 1 2 1 2 2 2 1 2 2 0 2 2 0 1 0 1 0 2 1 2 1 2\n",
      " 1 2 2 2 2 1 1 0 2 2 2 0 2 0 2 1 1 1 0 1 0 0 1 1 2 1 2 2 2 2 2 1 2 2 2 1 2\n",
      " 2 0 2 2 2 2 1 1 2 2 1 1 2 1 1 2 1 2 1 2 2 1 2 2 1 2 2 2 1 1 2 1 1 2 0 2 2\n",
      " 2 0 1 2 0 1 1 2 2 2 2 1 2 1 2 2 2 2 0 1 2 2 1 2 0 1 1 0 2 2 2 1 2 2 2 0 1\n",
      " 2 0 1 2 0 1 2 0 1 1 2 2 1 2 1 0 1 0 1 1 1 0 2 2 2 2 0 0 2 0 2 2 0 0 2 0 2\n",
      " 0 1 0 1 0 0 0 2 0 0 1 0 0 2 2 0 0 0 0 2 2 2 0 2 2 2 2 2 0 0 1 0 2 0 0 0 0\n",
      " 2 0 2 2 0 2 0 0 2 2 0 0 0 0 0 0 2 2 2 2 2 0 2 0 0 0 0 2 2 2 2 0 2 2 0 2 2\n",
      " 2 1 0 1 2 0 0 2 0 0 2 0 0 0 2 2 2 1 2 2 2 0 0 0 2 0 2 0 0 0 0 2 2 0 0 0 0\n",
      " 2 0 0 0 0 0 2 2 0 0 2 2 2 0 0 2 0 1 0 0 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2\n",
      " 2 2 0 2 2 0 2 2 0 0 2 2 0 0 0 0 2 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0 1 0 1 0 2\n",
      " 2 2 0 1 2 0 1 0 2 0 0 0 2 0 0 0 2 2 0 2 2 2 2 0 0 2 0 0 2 0 2 0 0 2 1 0 1\n",
      " 0 0 0 2 2 0 0 2 2 0 0 2 0 2 2 0 0 0 0 2 1 2 1 0 2 0 0 0 2 1 0 0 0 0 0 0 2\n",
      " 2 0 2 2 2 2 0 0 0 1 0 2 2 0 2 2 0 2 2 0 2 2 0 0 2 0 2 0 2 2 2 0 0 0 0 2 2\n",
      " 0 0 0 2 0 0 1 0 0 2 2 2 0 0 2 0 1 1 0 0 2 2 2 1 0 0 1 2 2 0 2 2 0 2 0 0 0\n",
      " 0 2 2 2 2 0 2 2 0 2 0 2 2 1 0 0 2 2 2 0 0 0 0 0 1 0 0 0 0 0 2 0 2 0 2 0 0\n",
      " 1 2 2 2 2 2 2 0 2 0 2 2 2 0 0 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4608\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=9.02, val_loss=0.0614, avg_\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 31.06it/s, loss=9.02, val_loss=0.0614, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.06it/s, loss=9.02, val_loss=0.385, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.00it/s, loss=0.432, val_loss=0.385, avg_\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.73it/s, loss=0.432, val_loss=0.385, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=0.432, val_loss=0.101, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.0658, val_loss=0.101, avg\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 31.10it/s, loss=0.0658, val_loss=0.101, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.0658, val_loss=0.0427, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.64it/s, loss=0.027, val_loss=0.0427, avg\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 30.88it/s, loss=0.027, val_loss=0.0427, avg\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 37.84it/s, loss=0.027, val_loss=0.0292, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.0182, val_loss=0.0292, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 31.31it/s, loss=0.0182, val_loss=0.0292, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.0182, val_loss=0.0228, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 22.05it/s, loss=0.0143, val_loss=0.0228, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.44it/s, loss=0.0143, val_loss=0.0228, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.49it/s, loss=0.0143, val_loss=0.0183, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.012, val_loss=0.0183, avg\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 30.81it/s, loss=0.012, val_loss=0.0183, avg\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.75it/s, loss=0.012, val_loss=0.0148, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.0105, val_loss=0.0148, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 31.01it/s, loss=0.0105, val_loss=0.0148, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.0105, val_loss=0.0121, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00935, val_loss=0.0121, a\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 30.95it/s, loss=0.00935, val_loss=0.0121, a\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00935, val_loss=0.0102, a\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00847, val_loss=0.0102, a\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 30.68it/s, loss=0.00847, val_loss=0.0102, a\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 37.67it/s, loss=0.00847, val_loss=0.00893, \u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00775, val_loss=0.00893,\u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 30.75it/s, loss=0.00775, val_loss=0.00893,\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.00775, val_loss=0.00802,\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.10it/s, loss=0.00715, val_loss=0.00802,\u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 30.07it/s, loss=0.00715, val_loss=0.00802,\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.02it/s, loss=0.00715, val_loss=0.00735,\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00663, val_loss=0.00735,\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 30.80it/s, loss=0.00663, val_loss=0.00735,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00663, val_loss=0.00682,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00619, val_loss=0.00682,\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 30.92it/s, loss=0.00619, val_loss=0.00682,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.91it/s, loss=0.00619, val_loss=0.00638,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00579, val_loss=0.00638,\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 30.70it/s, loss=0.00579, val_loss=0.00638,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.68it/s, loss=0.00579, val_loss=0.00602,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.00545, val_loss=0.00602,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 30.77it/s, loss=0.00545, val_loss=0.00602,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00545, val_loss=0.00569,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.00514, val_loss=0.00569,\u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 30.52it/s, loss=0.00514, val_loss=0.00569,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.47it/s, loss=0.00514, val_loss=0.0054, \u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.37it/s, loss=0.00487, val_loss=0.0054, \u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 30.47it/s, loss=0.00487, val_loss=0.0054, \n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.39it/s, loss=0.00487, val_loss=0.00514,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00462, val_loss=0.00514,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 30.66it/s, loss=0.00462, val_loss=0.00514,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00462, val_loss=0.00492,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00441, val_loss=0.00492,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 31.02it/s, loss=0.00441, val_loss=0.00492,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.00441, val_loss=0.00472,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.31it/s, loss=0.00422, val_loss=0.00472,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 30.39it/s, loss=0.00422, val_loss=0.00472,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.35it/s, loss=0.00422, val_loss=0.00454,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00404, val_loss=0.00454,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 31.10it/s, loss=0.00404, val_loss=0.00454,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=0.00404, val_loss=0.00438,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00389, val_loss=0.00438,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.00389, val_loss=0.00438,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.00389, val_loss=0.00422,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00374, val_loss=0.00422,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 30.74it/s, loss=0.00374, val_loss=0.00422,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00374, val_loss=0.00406,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.00359, val_loss=0.00406,\u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 30.60it/s, loss=0.00359, val_loss=0.00406,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00359, val_loss=0.0039, \u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00347, val_loss=0.0039, \u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.00347, val_loss=0.0039, \n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00347, val_loss=0.00375,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00335, val_loss=0.00375,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 31.01it/s, loss=0.00335, val_loss=0.00375,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.00335, val_loss=0.00362,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00325, val_loss=0.00362,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 30.83it/s, loss=0.00325, val_loss=0.00362,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.70it/s, loss=0.00325, val_loss=0.00349,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00316, val_loss=0.00349,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 31.04it/s, loss=0.00316, val_loss=0.00349,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.07it/s, loss=0.00316, val_loss=0.00337,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00307, val_loss=0.00337,\u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 30.95it/s, loss=0.00307, val_loss=0.00337,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.96it/s, loss=0.00307, val_loss=0.00328,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.00298, val_loss=0.00328,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 31.08it/s, loss=0.00298, val_loss=0.00328,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.13it/s, loss=0.00298, val_loss=0.00319,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.23it/s, loss=0.00294, val_loss=0.00319,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 30.27it/s, loss=0.00294, val_loss=0.00319,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.21it/s, loss=0.00294, val_loss=0.0031, \u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00283, val_loss=0.0031, \u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 30.84it/s, loss=0.00283, val_loss=0.0031, \n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00283, val_loss=0.00301,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 20.88it/s, loss=0.00276, val_loss=0.00301,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 29.83it/s, loss=0.00276, val_loss=0.00301,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 36.69it/s, loss=0.00276, val_loss=0.00292,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.72it/s, loss=0.0027, val_loss=0.00292, \u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 30.96it/s, loss=0.0027, val_loss=0.00292, \n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.0027, val_loss=0.00283, \u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00265, val_loss=0.00283,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 30.66it/s, loss=0.00265, val_loss=0.00283,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.00265, val_loss=0.00275,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00262, val_loss=0.00275,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 30.96it/s, loss=0.00262, val_loss=0.00275,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.97it/s, loss=0.00262, val_loss=0.00268,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00255, val_loss=0.00268,\u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 30.80it/s, loss=0.00255, val_loss=0.00268,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00255, val_loss=0.00266,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0025, val_loss=0.00266, \u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 31.03it/s, loss=0.0025, val_loss=0.00266, \n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.0025, val_loss=0.00258, \u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00247, val_loss=0.00258,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 30.89it/s, loss=0.00247, val_loss=0.00258,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00247, val_loss=0.00252,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.00247, val_loss=0.00252,\u001b[A\n",
      "Sizes of clusters: 296, 339, 565\n",
      "\n",
      "preds: [1 1 2 0 2 2 2 2 1 0 1 0 2 0 1 1 2 0 1 1 2 2 2 1 2 1 2 2 2 2 1 0 0 1 2 1 1\n",
      " 1 1 1 1 2 1 0 2 2 2 1 1 1 2 2 2 0 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 1 2 2\n",
      " 2 2 2 1 1 0 2 1 2 2 0 1 2 1 2 2 1 1 1 2 1 2 1 1 1 2 2 1 2 2 2 1 1 1 1 2 2\n",
      " 2 2 0 2 0 2 1 2 2 1 2 2 2 2 2 1 2 2 2 1 0 2 1 1 1 1 2 1 1 2 2 1 1 1 0 0 1\n",
      " 2 2 1 2 2 1 2 1 2 2 2 1 1 2 0 2 0 0 2 2 1 2 2 1 2 1 2 2 1 2 2 1 1 1 1 0 1\n",
      " 2 2 1 1 2 2 1 1 2 0 2 0 1 2 1 1 2 2 2 2 2 2 2 1 1 2 0 1 1 2 2 2 2 1 2 2 2\n",
      " 1 1 0 1 1 2 2 1 1 0 1 2 2 2 0 2 1 2 2 2 1 2 2 2 1 1 1 2 1 2 1 2 1 1 1 2 1\n",
      " 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 1 2 2 0 1 2 2 1 2 1 1 2 2 0 2 2 2 0 2 2\n",
      " 2 1 2 2 1 1 2 2 2 2 2 0 2 0 0 2 2 2 1 2 1 1 2 1 1 2 2 1 2 2 0 2 1 1 1 1 2\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 1 1 2 1 2 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 2 1 2 2\n",
      " 1 2 1 1 2 1 1 0 2 1 1 1 2 0 2 2 1 1 2 1 0 1 0 2 1 2 2 1 1 1 2 2 1 2 2 2 0\n",
      " 2 0 2 2 1 2 2 0 2 0 0 2 2 2 0 2 2 2 0 1 2 2 0 0 0 2 0 2 0 0 2 0 2 0 2 0 1\n",
      " 0 1 2 0 0 1 0 2 0 2 0 2 0 0 1 0 2 0 1 2 0 0 1 0 1 0 0 2 2 2 0 0 1 2 2 1 0\n",
      " 2 2 1 0 1 2 0 1 1 2 0 2 2 0 0 1 1 2 2 2 2 2 0 2 1 2 2 0 1 2 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 2 2 1 0 2 2 2 2 0 2 0 2 0 0 0 0 0 0 0 0 2 0 1 2 0 1 0 0 0 2 0 0\n",
      " 2 2 0 0 1 2 0 2 2 1 0 2 2 0 1 0 2 0 0 0 2 0 0 0 1 2 0 2 1 0 2 2 0 1 1 2 2\n",
      " 0 0 1 1 0 2 0 0 1 0 0 0 2 2 2 0 1 0 0 0 2 1 2 0 2 1 2 1 1 0 0 0 2 2 2 2 0\n",
      " 0 0 2 2 0 0 1 2 2 0 1 1 0 0 0 2 2 1 2 0 0 2 1 2 2 0 2 2 1 2 0 2 0 1 2 0 2\n",
      " 0 0 0 0 2 0 1 2 0 1 2 1 2 0 0 2 0 2 0 0 0 1 2 0 2 2 0 1 2 2 0 2 2 0 2 0 0\n",
      " 1 2 2 2 2 0 1 2 0 0 0 2 1 0 0 2 2 0 2 2 0 1 0 2 2 0 0 1 2 0 0 0 0 2 0 2 2\n",
      " 2 0 0 2 1 1 2 2 1 2 1 0 0 0 0 2 2 2 0 0 2 0 0 0 2 1 2 2 2 2 0 0 0 0 0 2 0\n",
      " 2 0 2 2 2 0 0 0 2 0 1 2 0 2 0 2 0 0 0 1 1 1 1 0 2 0 2 2 2 2 0 2 2 2 0 2 2\n",
      " 1 1 1 2 1 2 0 2 2 2 2 2 2 2 1 2 0 1 2 1 0 2 1 1 2 2 1 1 2 2 1 1 0 0 1 2 2\n",
      " 0 2 1 0 2 1 2 1 2 0 2 0 2 2 0 1 2 2 0 2 2 2 2 2 2 0 2 1 0 2 1 1 1 2 2 0 2\n",
      " 2 1 1 2 2 1 2 1 2 2 1 1 0 0 1 2 2 1 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 2 1 2\n",
      " 0 0 2 2 2 2 2 2 1 2 1 2 0 0 2 2 0 0 1 1 2 2 0 0 0 2 2 2 2 0 2 1 1 0 2 2 0\n",
      " 2 0 2 1 1 0 2 1 2 0 2 0 2 1 1 2 0 0 0 0 0 2 0 2 2 2 2 1 1 1 2 1 1 0 1 2 0\n",
      " 1 1 0 1 2 2 2 2 2 2 2 0 1 2 1 1 2 2 1 1 0 2 1 1 2 0 1 1 1 2 2 0 0 2 2 0 2\n",
      " 0 2 2 2 2 0 2 1 2 0 0 2 2 0 2 2 2 2 2 2 1 2 1 2 2 2 2 2 0 2 1 2 1 2 2 2 2\n",
      " 0 1 1 2 1 2 2 0 2 1 1 2 2 2 1 1 2 0 0 0 0 2 0 0 2 2 1 0 1 0 0 2 2 1 1 1 2\n",
      " 1 2 2 2 2 2 2 1 2 0 2 2 0 1 2 2 0 1 2 0 1 2 1 1 2 0 2 2 2 2 2 2 2 1 1 2 1\n",
      " 2 2 2 2 1 2 0 2 2 1 2 0 2 1 2 1 2 1 2 0 2 0 2 2 2 0 1 2 2 2 1 1 1 2 2 2 0\n",
      " 1 2 0 0 2 1 0 1 2 1 2 1 2 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4617\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=13.2, val_loss=0.0567, avg_\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 31.02it/s, loss=13.2, val_loss=0.0567, avg_\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=13.2, val_loss=0.356, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.89it/s, loss=0.407, val_loss=0.356, avg_\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.56it/s, loss=0.407, val_loss=0.356, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.407, val_loss=0.101, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.0732, val_loss=0.101, avg\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 30.64it/s, loss=0.0732, val_loss=0.101, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.0732, val_loss=0.0522, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.0362, val_loss=0.0522, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.0362, val_loss=0.0522, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.0362, val_loss=0.0357, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.0274, val_loss=0.0357, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 30.77it/s, loss=0.0274, val_loss=0.0357, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.0274, val_loss=0.0293, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.0226, val_loss=0.0293, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 31.05it/s, loss=0.0226, val_loss=0.0293, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.08it/s, loss=0.0226, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.18it/s, loss=0.0193, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 30.23it/s, loss=0.0193, val_loss=0.0246, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.16it/s, loss=0.0193, val_loss=0.0211, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.0168, val_loss=0.0211, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 31.00it/s, loss=0.0168, val_loss=0.0211, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.0168, val_loss=0.0183, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.52it/s, loss=0.0148, val_loss=0.0183, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 30.66it/s, loss=0.0148, val_loss=0.0183, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.0148, val_loss=0.0161, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.0131, val_loss=0.0161, av\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 31.09it/s, loss=0.0131, val_loss=0.0161, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.13it/s, loss=0.0131, val_loss=0.0142, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.0118, val_loss=0.0142, a\u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 30.82it/s, loss=0.0118, val_loss=0.0142, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.0118, val_loss=0.0127, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.36it/s, loss=0.0106, val_loss=0.0127, a\u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 30.47it/s, loss=0.0106, val_loss=0.0127, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.41it/s, loss=0.0106, val_loss=0.0113, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00961, val_loss=0.0113, \u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 30.94it/s, loss=0.00961, val_loss=0.0113, \n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00961, val_loss=0.0102, \u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00875, val_loss=0.0102, \u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 31.09it/s, loss=0.00875, val_loss=0.0102, \n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.12it/s, loss=0.00875, val_loss=0.00919,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.00801, val_loss=0.00919,\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 30.83it/s, loss=0.00801, val_loss=0.00919,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00801, val_loss=0.00834,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.00738, val_loss=0.00834,\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 30.54it/s, loss=0.00738, val_loss=0.00834,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.33it/s, loss=0.00738, val_loss=0.00761,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00682, val_loss=0.00761,\u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 30.75it/s, loss=0.00682, val_loss=0.00761,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00682, val_loss=0.00699,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00634, val_loss=0.00699,\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 30.99it/s, loss=0.00634, val_loss=0.00699,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00634, val_loss=0.00646,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00592, val_loss=0.00646,\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 30.96it/s, loss=0.00592, val_loss=0.00646,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.00592, val_loss=0.00602,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00556, val_loss=0.00602,\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 31.07it/s, loss=0.00556, val_loss=0.00602,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.00556, val_loss=0.00564,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00525, val_loss=0.00564,\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 30.84it/s, loss=0.00525, val_loss=0.00564,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.85it/s, loss=0.00525, val_loss=0.00532,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00497, val_loss=0.00532,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 31.14it/s, loss=0.00497, val_loss=0.00532,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.18it/s, loss=0.00497, val_loss=0.00505,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00474, val_loss=0.00505,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 30.75it/s, loss=0.00474, val_loss=0.00505,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00474, val_loss=0.00481,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00453, val_loss=0.00481,\u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 31.04it/s, loss=0.00453, val_loss=0.00481,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00453, val_loss=0.00461,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00435, val_loss=0.00461,\u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 30.95it/s, loss=0.00435, val_loss=0.00461,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.00435, val_loss=0.00443,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.54it/s, loss=0.0042, val_loss=0.00443, \u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 30.70it/s, loss=0.0042, val_loss=0.00443, \n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.0042, val_loss=0.00428, \u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00406, val_loss=0.00428,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 31.15it/s, loss=0.00406, val_loss=0.00428,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.19it/s, loss=0.00406, val_loss=0.00414,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00394, val_loss=0.00414,\u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 30.88it/s, loss=0.00394, val_loss=0.00414,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.00394, val_loss=0.00401,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00383, val_loss=0.00401,\u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 31.12it/s, loss=0.00383, val_loss=0.00401,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.00383, val_loss=0.0039, \u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.52it/s, loss=0.00374, val_loss=0.0039, \u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 30.71it/s, loss=0.00374, val_loss=0.0039, \n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00374, val_loss=0.00381,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.00365, val_loss=0.00381,\u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 31.10it/s, loss=0.00365, val_loss=0.00381,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.15it/s, loss=0.00365, val_loss=0.00372,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.00357, val_loss=0.00372,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 30.79it/s, loss=0.00357, val_loss=0.00372,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00357, val_loss=0.00364,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.0035, val_loss=0.00364, \u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 30.78it/s, loss=0.0035, val_loss=0.00364, \n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.72it/s, loss=0.0035, val_loss=0.00357, \u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.00343, val_loss=0.00357,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 30.80it/s, loss=0.00343, val_loss=0.00357,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.79it/s, loss=0.00343, val_loss=0.0035, \u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00337, val_loss=0.0035, \u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 31.08it/s, loss=0.00337, val_loss=0.0035, \n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.12it/s, loss=0.00337, val_loss=0.00344,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00331, val_loss=0.00344,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 30.86it/s, loss=0.00331, val_loss=0.00344,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.86it/s, loss=0.00331, val_loss=0.00338,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00325, val_loss=0.00338,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 31.14it/s, loss=0.00325, val_loss=0.00338,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.00325, val_loss=0.00332,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.0032, val_loss=0.00332, \u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 30.82it/s, loss=0.0032, val_loss=0.00332, \n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.0032, val_loss=0.00327, \u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.00315, val_loss=0.00327,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 31.21it/s, loss=0.00315, val_loss=0.00327,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.25it/s, loss=0.00315, val_loss=0.00322,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00311, val_loss=0.00322,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 30.76it/s, loss=0.00311, val_loss=0.00322,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00311, val_loss=0.00317,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.53it/s, loss=0.00311, val_loss=0.00317,\u001b[A\n",
      "Sizes of clusters: 316, 315, 569\n",
      "\n",
      "preds: [1 1 0 0 2 2 2 2 1 2 1 0 2 0 2 2 0 0 1 1 2 0 0 2 2 2 2 2 2 2 1 2 0 1 2 1 1\n",
      " 1 1 1 0 2 1 0 2 2 2 2 1 1 2 2 2 0 2 2 2 2 0 2 2 2 0 1 1 1 2 2 2 2 0 1 2 0\n",
      " 2 0 2 1 2 0 0 2 2 2 0 1 2 1 2 2 2 2 0 0 1 2 1 1 1 2 2 2 2 2 0 2 1 1 1 2 2\n",
      " 2 2 0 2 0 0 1 2 2 1 2 2 2 0 0 1 2 2 0 1 0 0 2 1 1 1 2 2 1 2 2 1 2 1 2 0 1\n",
      " 2 2 1 2 2 2 1 1 0 2 2 0 1 0 2 2 0 0 2 2 1 2 1 1 2 1 2 2 0 2 0 2 1 1 2 0 1\n",
      " 1 2 2 2 2 0 1 0 0 0 2 0 1 0 1 2 0 2 2 2 2 2 2 1 1 2 0 1 1 2 2 2 2 2 2 2 0\n",
      " 1 0 0 1 1 2 2 1 1 0 2 2 0 2 0 2 1 2 1 2 1 2 2 2 1 1 1 2 1 2 1 2 1 2 2 2 1\n",
      " 1 1 2 2 2 2 1 0 2 0 2 1 1 2 1 1 0 2 1 0 0 1 2 2 1 1 1 2 2 2 0 2 2 2 2 2 1\n",
      " 2 1 2 2 0 2 2 2 2 2 2 0 2 0 2 2 2 2 1 2 2 2 2 1 1 2 2 1 0 2 0 0 1 1 1 1 2\n",
      " 1 1 1 2 2 2 2 1 1 0 2 2 2 1 1 2 1 2 2 1 1 1 1 1 2 2 2 1 2 0 2 1 1 2 1 2 2\n",
      " 1 2 1 1 2 1 0 0 1 2 1 1 2 2 2 2 1 1 2 1 2 2 2 2 1 2 2 0 1 1 2 2 1 2 2 2 0\n",
      " 0 0 2 0 1 2 2 0 2 0 0 2 2 1 0 1 2 2 0 1 2 2 2 2 2 2 0 2 0 0 1 0 2 0 2 0 1\n",
      " 2 1 2 2 0 1 0 2 0 2 0 2 0 0 1 0 1 0 2 2 0 0 2 0 1 0 0 2 2 0 0 0 2 2 2 0 0\n",
      " 2 2 1 0 1 2 0 1 1 2 0 2 2 0 0 1 1 2 2 0 2 0 2 0 1 2 2 0 2 2 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 2 2 1 0 2 2 2 2 0 2 0 2 0 0 0 0 0 0 0 0 2 0 1 2 0 1 0 0 0 2 0 0\n",
      " 2 2 0 0 1 2 0 2 2 1 0 2 2 0 1 2 2 0 0 0 0 0 0 0 1 2 0 2 0 0 2 2 0 1 1 2 2\n",
      " 0 0 1 2 0 0 0 0 1 0 2 2 2 2 2 0 1 0 0 0 1 0 0 0 0 1 2 1 2 2 0 0 2 2 2 2 0\n",
      " 0 0 2 0 0 0 1 2 2 0 2 1 0 0 0 0 2 2 2 2 0 0 1 2 2 0 2 2 1 2 0 2 0 0 2 0 2\n",
      " 0 0 0 0 2 0 1 2 0 1 2 1 2 2 0 2 0 2 0 0 2 1 2 0 2 0 0 1 2 2 0 0 2 0 2 0 0\n",
      " 1 2 2 2 2 0 1 2 2 0 0 2 1 0 0 2 2 0 0 2 0 2 0 2 2 0 0 1 0 0 0 0 0 2 2 2 2\n",
      " 2 2 0 2 1 1 0 2 1 2 1 0 0 0 0 2 2 2 0 0 2 0 0 0 2 2 2 2 2 2 0 0 0 0 0 2 0\n",
      " 2 2 2 2 2 0 0 2 0 0 1 2 0 2 0 1 0 2 0 1 1 1 1 0 2 0 2 2 2 1 2 2 2 2 0 2 2\n",
      " 1 2 1 0 1 1 0 2 2 1 2 1 2 2 1 2 0 1 1 1 0 2 1 1 2 2 1 1 1 2 0 1 0 2 1 2 2\n",
      " 0 2 1 0 2 1 2 1 2 0 1 0 2 2 0 1 2 2 0 2 2 1 2 2 2 2 2 1 0 2 1 1 1 2 2 0 2\n",
      " 2 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 2 2 2 2 2 2 2 1 2 1 1 1 1 2 1 0 2 2 2 1 1\n",
      " 0 0 2 2 1 2 2 2 1 2 1 2 0 2 2 2 0 0 1 1 2 2 0 0 0 2 2 2 2 0 2 1 1 0 2 0 2\n",
      " 2 0 2 1 1 2 2 1 2 2 2 0 2 1 1 2 0 2 0 0 0 2 0 1 2 2 2 1 1 1 2 1 1 0 1 2 0\n",
      " 1 1 0 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 1 1 0 2 1 1 1 0 1 1 1 2 2 0 0 2 2 0 2\n",
      " 0 1 2 2 2 2 2 1 2 2 2 2 2 0 2 2 2 2 2 2 2 2 1 2 2 2 2 2 0 2 1 2 1 2 1 1 2\n",
      " 0 1 1 2 1 2 2 2 2 2 1 2 2 2 1 1 2 0 0 2 0 2 0 0 2 2 1 2 1 0 0 1 1 1 1 1 2\n",
      " 1 1 2 2 1 1 2 1 2 0 2 2 2 1 2 2 0 2 1 0 1 2 1 1 1 2 2 2 2 2 2 2 2 1 1 2 1\n",
      " 1 2 2 2 1 1 0 2 2 1 2 0 2 2 2 1 2 1 2 0 2 2 2 2 0 2 1 1 1 2 1 1 1 2 2 1 2\n",
      " 1 2 0 0 2 1 0 1 2 1 2 1 2 2 1 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4292\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.92it/s, loss=9.55, val_loss=0.0561, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=9.55, val_loss=0.209, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 22.13it/s, loss=0.396, val_loss=0.209, avg_\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.92it/s, loss=0.396, val_loss=0.209, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.61it/s, loss=0.396, val_loss=0.095, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.064, val_loss=0.095, avg_\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.064, val_loss=0.095, avg_\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.064, val_loss=0.0426, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.23it/s, loss=0.0305, val_loss=0.0426, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 31.65it/s, loss=0.0305, val_loss=0.0426, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 37.24it/s, loss=0.0305, val_loss=0.0315, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.0228, val_loss=0.0315, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 32.16it/s, loss=0.0228, val_loss=0.0315, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.0228, val_loss=0.0245, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.019, val_loss=0.0245, avg\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.019, val_loss=0.0245, avg\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 37.98it/s, loss=0.019, val_loss=0.0202, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.0163, val_loss=0.0202, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.0163, val_loss=0.0202, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.0163, val_loss=0.0173, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.0142, val_loss=0.0173, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.35it/s, loss=0.0142, val_loss=0.0173, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.0142, val_loss=0.0151, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.64it/s, loss=0.0126, val_loss=0.0151, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 32.23it/s, loss=0.0126, val_loss=0.0151, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.87it/s, loss=0.0126, val_loss=0.0133, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.0112, val_loss=0.0133, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.40it/s, loss=0.0112, val_loss=0.0133, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.06it/s, loss=0.0112, val_loss=0.0118, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.0101, val_loss=0.0118, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 32.19it/s, loss=0.0101, val_loss=0.0118, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.0101, val_loss=0.0106, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.00915, val_loss=0.0106, \u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 31.85it/s, loss=0.00915, val_loss=0.0106, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.46it/s, loss=0.00915, val_loss=0.00958,\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00832, val_loss=0.00958,\u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 32.29it/s, loss=0.00832, val_loss=0.00958,\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.00832, val_loss=0.00869,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.30it/s, loss=0.0076, val_loss=0.00869, \u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 31.70it/s, loss=0.0076, val_loss=0.00869, \n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.26it/s, loss=0.0076, val_loss=0.00793, \u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00698, val_loss=0.00793,\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 32.11it/s, loss=0.00698, val_loss=0.00793,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.00698, val_loss=0.00727,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.80it/s, loss=0.00643, val_loss=0.00727,\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.00643, val_loss=0.00727,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.12it/s, loss=0.00643, val_loss=0.00668,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.15it/s, loss=0.00594, val_loss=0.00668,\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 31.52it/s, loss=0.00594, val_loss=0.00668,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.05it/s, loss=0.00594, val_loss=0.00617,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00552, val_loss=0.00617,\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.52it/s, loss=0.00552, val_loss=0.00617,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.18it/s, loss=0.00552, val_loss=0.00573,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00514, val_loss=0.00573,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 32.24it/s, loss=0.00514, val_loss=0.00573,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.87it/s, loss=0.00514, val_loss=0.00533,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.00481, val_loss=0.00533,\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.00481, val_loss=0.00533,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.18it/s, loss=0.00481, val_loss=0.00497,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00452, val_loss=0.00497,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 32.19it/s, loss=0.00452, val_loss=0.00497,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.82it/s, loss=0.00452, val_loss=0.00466,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.00426, val_loss=0.00466,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 31.57it/s, loss=0.00426, val_loss=0.00466,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 37.47it/s, loss=0.00426, val_loss=0.00439,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00403, val_loss=0.00439,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 32.16it/s, loss=0.00403, val_loss=0.00439,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.79it/s, loss=0.00403, val_loss=0.00415,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.80it/s, loss=0.00383, val_loss=0.00415,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.00383, val_loss=0.00415,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00383, val_loss=0.00395,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.00366, val_loss=0.00395,\u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.00366, val_loss=0.00395,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00366, val_loss=0.00377,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.00351, val_loss=0.00377,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.57it/s, loss=0.00351, val_loss=0.00377,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.00351, val_loss=0.00361,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00337, val_loss=0.00361,\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.55it/s, loss=0.00337, val_loss=0.00361,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.00337, val_loss=0.00346,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00325, val_loss=0.00346,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.29it/s, loss=0.00325, val_loss=0.00346,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00325, val_loss=0.00333,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.38it/s, loss=0.00315, val_loss=0.00333,\u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 31.85it/s, loss=0.00315, val_loss=0.00333,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 37.46it/s, loss=0.00315, val_loss=0.00322,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00306, val_loss=0.00322,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 32.22it/s, loss=0.00306, val_loss=0.00322,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=0.00306, val_loss=0.00312,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.84it/s, loss=0.00298, val_loss=0.00312,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.49it/s, loss=0.00298, val_loss=0.00312,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.15it/s, loss=0.00298, val_loss=0.00304,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00291, val_loss=0.00304,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.00291, val_loss=0.00304,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00291, val_loss=0.00296,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.22it/s, loss=0.00284, val_loss=0.00296,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 31.63it/s, loss=0.00284, val_loss=0.00296,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.20it/s, loss=0.00284, val_loss=0.00289,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00279, val_loss=0.00289,\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 32.03it/s, loss=0.00279, val_loss=0.00289,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.00279, val_loss=0.00283,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.81it/s, loss=0.00273, val_loss=0.00283,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.00273, val_loss=0.00283,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.12it/s, loss=0.00273, val_loss=0.00278,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.00269, val_loss=0.00278,\u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 32.09it/s, loss=0.00269, val_loss=0.00278,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.00269, val_loss=0.00272,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00265, val_loss=0.00272,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.46it/s, loss=0.00265, val_loss=0.00272,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.13it/s, loss=0.00265, val_loss=0.00268,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.28it/s, loss=0.00261, val_loss=0.00268,\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 31.72it/s, loss=0.00261, val_loss=0.00268,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.30it/s, loss=0.00261, val_loss=0.00265,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00258, val_loss=0.00265,\u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.29it/s, loss=0.00258, val_loss=0.00265,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.00258, val_loss=0.00261,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00255, val_loss=0.00261,\u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 32.18it/s, loss=0.00255, val_loss=0.00261,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.85it/s, loss=0.00255, val_loss=0.00259,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.52it/s, loss=0.00255, val_loss=0.00259,\u001b[A\n",
      "Sizes of clusters: 284, 364, 552\n",
      "\n",
      "preds: [1 1 2 2 2 2 2 1 1 0 1 0 2 0 1 1 2 0 1 1 2 2 1 1 1 1 2 2 2 2 1 2 0 1 2 1 1\n",
      " 1 1 1 1 2 1 0 2 2 2 1 1 1 2 2 2 0 2 1 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 1 2 1\n",
      " 2 2 2 1 1 0 2 1 1 2 2 1 2 1 2 2 1 1 1 0 1 2 1 1 1 1 2 1 2 2 2 1 1 1 1 2 2\n",
      " 2 2 0 2 0 2 1 2 2 1 2 2 2 2 2 1 2 2 1 1 0 1 1 1 1 1 2 1 1 2 2 1 1 1 2 0 1\n",
      " 2 2 1 1 2 1 2 1 2 2 2 1 1 2 0 2 2 2 2 2 1 2 1 1 2 1 2 2 1 2 1 1 1 1 1 0 1\n",
      " 2 2 1 1 2 2 1 1 2 2 2 2 1 2 1 1 2 2 2 1 2 2 2 1 1 2 0 1 1 2 1 2 2 1 2 2 2\n",
      " 1 1 2 1 1 2 2 1 1 0 1 2 2 2 0 1 1 2 2 2 1 2 2 2 1 1 1 2 1 2 1 2 1 1 1 2 1\n",
      " 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 1 1 2 0 1 2 2 1 1 1 1 2 2 0 2 2 2 2 2 2\n",
      " 2 1 2 2 1 1 2 2 2 2 2 0 2 0 0 2 2 2 1 2 1 1 2 1 1 2 2 1 2 2 0 1 1 1 1 1 2\n",
      " 1 1 1 2 2 2 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1 2 2\n",
      " 1 1 1 1 2 1 2 2 1 1 1 1 2 2 2 2 1 1 2 1 0 1 2 2 1 1 2 1 1 1 2 2 1 2 2 2 0\n",
      " 2 0 2 2 1 2 2 0 2 0 0 2 0 2 0 2 2 2 0 1 2 0 0 0 0 2 0 0 0 0 2 0 2 0 2 0 1\n",
      " 0 1 2 0 0 1 0 2 0 2 0 2 0 0 1 0 2 0 1 2 0 0 1 0 1 0 0 2 2 0 2 0 1 2 2 2 2\n",
      " 2 2 1 0 1 2 0 1 1 2 0 2 2 0 0 1 1 2 2 1 2 2 0 0 1 2 2 0 2 2 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 2 2 1 0 2 2 0 2 0 2 0 2 0 0 0 0 0 0 0 0 2 0 1 2 0 1 0 0 0 2 0 0\n",
      " 2 2 0 0 1 2 0 2 2 1 0 2 2 0 1 0 2 0 2 0 2 0 0 0 1 2 0 2 2 0 2 0 0 1 1 2 2\n",
      " 0 2 1 1 0 2 0 0 1 0 0 2 2 2 2 0 1 0 0 0 2 2 2 0 0 1 2 1 1 0 0 0 2 2 0 2 0\n",
      " 0 0 2 2 0 0 1 2 2 0 1 2 0 0 0 2 2 1 2 2 2 2 1 2 2 0 2 2 1 2 0 2 0 2 2 0 2\n",
      " 0 0 0 0 2 0 1 0 0 1 2 1 2 0 0 2 0 2 0 0 0 1 2 0 2 2 0 1 2 2 0 2 2 0 2 2 0\n",
      " 1 2 0 2 2 0 1 2 0 0 0 2 1 0 0 2 2 0 2 2 0 2 0 2 2 0 0 1 2 0 0 0 0 2 2 2 2\n",
      " 2 0 0 2 1 1 2 2 1 2 2 0 0 0 0 2 2 2 0 0 2 0 0 0 2 1 2 2 2 2 0 0 0 0 0 2 0\n",
      " 2 2 2 2 0 0 0 0 2 0 2 2 0 2 0 2 0 0 0 1 1 1 1 0 2 0 2 2 2 1 2 2 2 0 0 2 2\n",
      " 1 1 1 0 1 2 0 2 2 2 2 2 0 1 1 2 0 1 1 1 0 2 2 1 2 2 1 1 2 2 1 1 0 2 1 2 0\n",
      " 0 2 1 0 2 1 2 1 2 0 2 0 2 2 0 1 2 2 0 2 2 1 2 2 2 0 2 1 0 2 1 1 1 2 0 0 2\n",
      " 2 1 2 2 2 1 2 1 2 2 1 1 0 2 1 2 2 1 2 2 2 2 2 2 2 2 1 1 1 2 1 0 2 2 2 1 1\n",
      " 0 0 2 2 1 2 2 2 2 0 1 2 0 2 2 2 0 0 1 1 2 2 0 0 0 2 2 2 2 0 2 1 1 0 2 2 0\n",
      " 1 0 0 1 1 0 2 1 2 2 1 0 2 1 1 2 0 0 0 0 0 2 0 1 2 2 2 1 1 1 1 1 1 0 1 2 0\n",
      " 1 1 2 1 2 2 2 2 2 2 2 0 1 2 1 1 2 1 1 1 0 1 1 1 1 0 1 1 1 2 2 2 0 2 2 0 2\n",
      " 0 0 2 2 2 2 2 1 2 0 0 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 0 2 1 2 2 2 2 1 2\n",
      " 0 1 1 2 1 2 2 2 2 1 1 2 2 2 1 1 2 0 0 2 2 2 0 0 2 2 1 0 1 2 0 2 2 1 2 1 2\n",
      " 2 1 2 2 2 1 2 2 2 0 2 2 0 1 2 0 0 1 1 0 1 2 1 1 2 0 2 2 2 2 2 2 2 1 1 2 2\n",
      " 2 2 2 2 1 2 0 2 2 1 2 2 2 1 2 1 1 1 2 0 2 0 2 0 0 0 1 2 1 2 1 1 1 2 2 1 2\n",
      " 1 2 0 0 2 1 0 1 2 1 2 1 2 2 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3837\r\n",
      "Purity: 0.4671666666666667+-0.026069351950347944\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K3_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3 # 0.464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=1.61, val_loss=0.0968, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=1.61, val_loss=0.189, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.0855, val_loss=0.189, avg\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 25.24it/s, loss=0.0855, val_loss=0.189, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.0855, val_loss=0.0449, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.0272, val_loss=0.0449, av\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.32it/s, loss=0.0272, val_loss=0.0449, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.0272, val_loss=0.0284, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.50it/s, loss=0.021, val_loss=0.0284, avg\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.021, val_loss=0.0284, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.67it/s, loss=0.021, val_loss=0.0237, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.0178, val_loss=0.0237, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 25.07it/s, loss=0.0178, val_loss=0.0237, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 37.56it/s, loss=0.0178, val_loss=0.0203, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.0155, val_loss=0.0203, av\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 25.29it/s, loss=0.0155, val_loss=0.0203, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 37.81it/s, loss=0.0155, val_loss=0.0177, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.50it/s, loss=0.0138, val_loss=0.0177, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 25.18it/s, loss=0.0138, val_loss=0.0177, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.0138, val_loss=0.0156, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.0124, val_loss=0.0156, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 25.13it/s, loss=0.0124, val_loss=0.0156, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.0124, val_loss=0.0139, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.0113, val_loss=0.0139, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.23it/s, loss=0.0113, val_loss=0.0139, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.78it/s, loss=0.0113, val_loss=0.0125, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0104, val_loss=0.0125, av\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.0104, val_loss=0.0125, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.0104, val_loss=0.0114, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00962, val_loss=0.0114, \u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 25.00it/s, loss=0.00962, val_loss=0.0114, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 37.43it/s, loss=0.00962, val_loss=0.0105, \u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.65it/s, loss=0.00891, val_loss=0.0105, \u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 25.33it/s, loss=0.00891, val_loss=0.0105, \n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00891, val_loss=0.00966,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00827, val_loss=0.00966,\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.00827, val_loss=0.00966,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00827, val_loss=0.00892,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00769, val_loss=0.00892,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.00769, val_loss=0.00892,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.00769, val_loss=0.00826,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00716, val_loss=0.00826,\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.51it/s, loss=0.00716, val_loss=0.00826,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.00716, val_loss=0.00765,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00668, val_loss=0.00765,\u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00668, val_loss=0.00765,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00668, val_loss=0.00709,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00623, val_loss=0.00709,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 25.69it/s, loss=0.00623, val_loss=0.00709,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00623, val_loss=0.00659,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00583, val_loss=0.00659,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 25.52it/s, loss=0.00583, val_loss=0.00659,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.00583, val_loss=0.00613,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.00546, val_loss=0.00613,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 25.45it/s, loss=0.00546, val_loss=0.00613,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00546, val_loss=0.00571,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00514, val_loss=0.00571,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 25.36it/s, loss=0.00514, val_loss=0.00571,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.90it/s, loss=0.00514, val_loss=0.00533,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00485, val_loss=0.00533,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00485, val_loss=0.00533,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00485, val_loss=0.00501,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.0046, val_loss=0.00501, \u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 25.13it/s, loss=0.0046, val_loss=0.00501, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=0.0046, val_loss=0.00472, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00438, val_loss=0.00472,\u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.37it/s, loss=0.00438, val_loss=0.00472,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00438, val_loss=0.00448,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00419, val_loss=0.00448,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 25.22it/s, loss=0.00419, val_loss=0.00448,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00419, val_loss=0.00426,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00402, val_loss=0.00426,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 25.20it/s, loss=0.00402, val_loss=0.00426,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.67it/s, loss=0.00402, val_loss=0.00406,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.00388, val_loss=0.00406,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 25.24it/s, loss=0.00388, val_loss=0.00406,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.77it/s, loss=0.00388, val_loss=0.00388,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.00376, val_loss=0.00388,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00376, val_loss=0.00388,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00376, val_loss=0.00373,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00365, val_loss=0.00373,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00365, val_loss=0.00373,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.25it/s, loss=0.00365, val_loss=0.0036, \u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00355, val_loss=0.0036, \u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.52it/s, loss=0.00355, val_loss=0.0036, \n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00355, val_loss=0.00348,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00347, val_loss=0.00348,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.51it/s, loss=0.00347, val_loss=0.00348,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.00347, val_loss=0.00339,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00339, val_loss=0.00339,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.47it/s, loss=0.00339, val_loss=0.00339,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00339, val_loss=0.0033, \u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00332, val_loss=0.0033, \u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.18it/s, loss=0.00332, val_loss=0.0033, \n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00332, val_loss=0.00322,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.52it/s, loss=0.00326, val_loss=0.00322,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 25.23it/s, loss=0.00326, val_loss=0.00322,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.00326, val_loss=0.00315,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.0032, val_loss=0.00315, \u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 25.36it/s, loss=0.0032, val_loss=0.00315, \n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.0032, val_loss=0.00309, \u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00315, val_loss=0.00309,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00315, val_loss=0.00309,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00315, val_loss=0.00303,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.54it/s, loss=0.0031, val_loss=0.00303, \u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 25.23it/s, loss=0.0031, val_loss=0.00303, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.0031, val_loss=0.00297, \u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00305, val_loss=0.00297,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 25.42it/s, loss=0.00305, val_loss=0.00297,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.00305, val_loss=0.00292,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00301, val_loss=0.00292,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.00301, val_loss=0.00292,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00301, val_loss=0.00287,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00297, val_loss=0.00287,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 25.70it/s, loss=0.00297, val_loss=0.00287,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.00297, val_loss=0.00282,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00293, val_loss=0.00282,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 25.38it/s, loss=0.00293, val_loss=0.00282,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.87it/s, loss=0.00293, val_loss=0.00278,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00293, val_loss=0.00278,\u001b[A\n",
      "Sizes of clusters: 733, 468, 322, 77\n",
      "\n",
      "preds: [1 1 0 1 1 1 1 1 0 0 3 2 0 3 1 0 0 0 1 1 1 1 1 0 0 2 0 3 0 1 1 1 1 0 1 1 1\n",
      " 3 1 0 0 0 0 3 0 0 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 3 0 1 1 3\n",
      " 1 0 1 1 1 1 1 3 0 1 1 1 0 3 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 3 0 3 0 3 0 0 1\n",
      " 1 0 0 1 0 1 2 1 1 1 3 1 1 1 1 2 1 1 1 0 0 1 1 0 1 0 1 3 0 3 3 1 0 2 0 2 0\n",
      " 0 1 1 1 1 3 1 1 1 0 1 1 3 1 0 1 1 3 3 3 1 0 1 0 0 0 0 3 1 0 1 1 0 0 0 1 1\n",
      " 0 0 1 0 2 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 2 1 1 1 1 3\n",
      " 1 1 1 0 0 1 1 1 0 0 1 3 0 1 1 1 1 1 0 1 0 1 1 3 1 3 0 2 0 0 1 0 1 3 3 3 3\n",
      " 0 1 3 1 1 1 1 1 3 1 0 2 0 0 1 1 0 1 1 3 0 1 0 1 0 1 0 1 0 3 1 0 1 1 1 1 0\n",
      " 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 3 0 0 1 0 0 1 0 3 0 1 0 3 0 1 1 2 0 3 0 0 0\n",
      " 1 0 1 3 0 1 3 0 0 3 3 0 1 1 0 0 0 0 0 1 1 0 3 1 1 1 1 1 0 0 1 1 0 1 0 1 3\n",
      " 1 0 1 1 3 0 1 2 0 1 3 1 1 0 1 0 1 0 1 3 0 0 1 0 0 1 3 1 1 1 1 0 2 0 2 0 2\n",
      " 2 2 0 0 2 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 2 2 0 1 0 2 0 1 1 1 0 0 2 1 0 2\n",
      " 0 0 2 2 1 2 2 2 0 1 2 0 0 0 2 0 1 1 0 0 2 0 2 0 0 0 1 0 2 1 0 0 2 2 1 0 0\n",
      " 2 0 2 0 1 2 0 0 0 0 2 1 1 0 0 1 0 0 2 0 2 0 2 2 1 0 1 1 0 0 2 0 1 1 0 2 1\n",
      " 2 3 0 0 2 0 2 2 2 2 0 0 0 3 1 2 2 2 0 0 2 0 2 1 0 2 0 2 0 2 2 0 0 2 0 0 0\n",
      " 1 0 2 0 1 0 2 0 2 2 2 2 0 1 2 0 2 0 0 2 1 1 0 0 0 0 0 0 1 1 2 2 2 2 1 0 0\n",
      " 0 0 0 0 2 2 0 0 1 1 2 2 2 2 0 2 0 2 1 0 0 1 2 2 1 1 0 1 0 0 1 2 2 2 2 2 2\n",
      " 0 2 2 0 3 0 0 0 0 0 0 0 1 2 1 2 1 0 0 0 0 2 2 0 0 1 0 0 2 2 2 0 2 0 0 0 0\n",
      " 2 2 2 2 0 2 1 0 0 0 2 0 2 0 1 0 0 2 0 0 0 0 0 0 0 0 0 1 2 0 0 0 2 0 0 2 0\n",
      " 2 0 0 0 0 0 2 2 2 0 2 2 1 2 0 2 2 0 2 1 1 0 0 1 0 2 0 2 2 2 2 1 0 2 2 1 1\n",
      " 1 2 2 2 1 1 2 2 0 0 2 2 2 2 1 2 2 0 2 0 0 0 0 0 2 0 0 0 2 2 0 2 2 0 2 0 3\n",
      " 2 2 0 0 0 2 1 2 2 0 0 0 0 0 0 1 1 0 1 1 3 0 0 1 1 1 0 1 0 2 0 1 3 0 1 0 3\n",
      " 0 0 2 0 2 2 1 0 0 0 2 1 1 0 1 0 1 1 2 0 0 0 3 0 1 0 0 1 2 0 1 1 0 1 2 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 2 2 1 0 1 0 0 1 2 1\n",
      " 0 0 0 3 0 0 0 2 0 0 0 1 1 1 1 0 0 0 0 1 0 2 1 1 2 0 1 1 0 0 0 2 0 0 0 0 0\n",
      " 1 1 0 0 1 3 0 0 1 1 0 1 1 1 0 0 1 0 3 2 0 1 0 0 1 0 0 0 0 0 2 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 2 1 1 1 3 1 1 1 0 0 1 0 0 0 2 3 0 1 1 3 3 0 0 2 2 0 3 0 0 1 0 1 1 0 0 0 2\n",
      " 0 1 1 0 1 0 0 2 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 2 0 3 1 2 3 0\n",
      " 0 0 0 2 1 2 1 2 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 3 1 1 1 1 0 2 0 3 0 1 0 0 1\n",
      " 0 1 3 2 1 0 0 0 1 1 1 1 0 3 1 1 0 1 1 0 0 0 1 0 2 1 1 1 1 1 0 3 0 0 1 0 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 1 1 2 0 0 2 1 2 0 0 1 0 0 0 0 0 0 0 0 2 2 1 1 1 1 1\n",
      " 2 0 0 0 0 3 1 0 1 1 0 1 0 1 1 2 0 2 1 0 1 0 2 0 2 0 0 0 0 2 2 2 2 0 2 0 3\n",
      " 2 1 2 0 0 0 0 0 2 1 1 2 0 0 0 0 1 0 0 0 0 0 2 2 0 0 2 1 0 2 1 0 0 0 2 2 1\n",
      " 2 0 2 0 2 0 0 2 0 0 2 3 0 2 0 2 0 0 3 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 2 1 0 0 2 2 0 2 0 0 1 0 1 0 0 0 0 0 2 2 0 0 2 0 2 1 2 2 0 1 0 1 0 2 0 1\n",
      " 2 2 0 0 0 2 3 2 1 2 2 0 2 2 2 0 1 3 2 0 2 1 1 2 1 2 0 0 2 2 0 2 1 2 0 1 0\n",
      " 0 0 0 2 0 1 0 1 0 0 0 2 0 2 0 1 2 1 0 0 0 2 0 0 2 2 0 2 2 0 1 0 2 2 0 0 0\n",
      " 0 2 0 1 0 0 0 0 0 2 1 2 0 2 0 0 0 0 0 0 2 1 0 2 1 0 0 0 1 0 0 2 0 0 2 1 1\n",
      " 0 2 0 0 1 0 1 2 1 0 0 2 2 2 0 2 0 2 0 2 2 2 2 2 0 0 0 2 2 0 0 0 0 0 0 1 0\n",
      " 2 1 0 2 2 2 2 2 2 0 2 0 2 1 0 1 2 1 0 0 0 0 2 2 0 1 2 0 1 0 2 2 2 0 2 1 0\n",
      " 0 0 2 2 2 2 2 0 0 1 0 0 2 0 2 2 1 0 1 0 2 0 0 0 0 2 0 0 0 0 0 0 2 1 2 0 2\n",
      " 1 0 2 2 0 2 0 0 2 2 0 2 0 0 0 2 0 2 0 0 0 2 0 2 0 2 0 0 0 0 0 0 2 0 2 1 0\n",
      " 2 1 2 0 0 0 1 0 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.3681\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=2.52, val_loss=0.0976, avg_\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.36it/s, loss=2.52, val_loss=0.0976, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=2.52, val_loss=0.197, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.129, val_loss=0.197, avg_\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 22.96it/s, loss=0.129, val_loss=0.197, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.129, val_loss=0.0632, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.22it/s, loss=0.035, val_loss=0.0632, avg\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 23.64it/s, loss=0.035, val_loss=0.0632, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.24it/s, loss=0.035, val_loss=0.0368, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.0214, val_loss=0.0368, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 23.90it/s, loss=0.0214, val_loss=0.0368, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.0214, val_loss=0.0265, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.31it/s, loss=0.0148, val_loss=0.0265, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 23.70it/s, loss=0.0148, val_loss=0.0265, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.0148, val_loss=0.0191, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.0107, val_loss=0.0191, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.0107, val_loss=0.0191, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.0107, val_loss=0.0138, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00842, val_loss=0.0138, a\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.32it/s, loss=0.00842, val_loss=0.0138, a\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.11it/s, loss=0.00842, val_loss=0.0101, a\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00709, val_loss=0.0101, a\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.12it/s, loss=0.00709, val_loss=0.0101, a\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00709, val_loss=0.0079, a\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00628, val_loss=0.0079, a\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.02it/s, loss=0.00628, val_loss=0.0079, a\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00628, val_loss=0.00667, \u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00574, val_loss=0.00667, \u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 23.96it/s, loss=0.00574, val_loss=0.00667, \n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00574, val_loss=0.00594, \u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00535, val_loss=0.00594,\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.29it/s, loss=0.00535, val_loss=0.00594,\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00535, val_loss=0.00547,\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00505, val_loss=0.00547,\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00505, val_loss=0.00547,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.14it/s, loss=0.00505, val_loss=0.00514,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.00479, val_loss=0.00514,\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 23.92it/s, loss=0.00479, val_loss=0.00514,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.60it/s, loss=0.00479, val_loss=0.00488,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00457, val_loss=0.00488,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.38it/s, loss=0.00457, val_loss=0.00488,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00457, val_loss=0.00466,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00437, val_loss=0.00466,\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.00437, val_loss=0.00466,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.00437, val_loss=0.00445,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.0042, val_loss=0.00445, \u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.0042, val_loss=0.00445, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.0042, val_loss=0.00427, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00404, val_loss=0.00427,\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00404, val_loss=0.00427,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.22it/s, loss=0.00404, val_loss=0.00411,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.0039, val_loss=0.00411, \u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.0039, val_loss=0.00411, \n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.0039, val_loss=0.00396, \u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00378, val_loss=0.00396,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 23.87it/s, loss=0.00378, val_loss=0.00396,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.31it/s, loss=0.00378, val_loss=0.00382,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.00367, val_loss=0.00382,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.06it/s, loss=0.00367, val_loss=0.00382,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.74it/s, loss=0.00367, val_loss=0.00371,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.00358, val_loss=0.00371,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 23.92it/s, loss=0.00358, val_loss=0.00371,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.00358, val_loss=0.00362,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.0035, val_loss=0.00362, \u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.0035, val_loss=0.00362, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.22it/s, loss=0.0035, val_loss=0.00355, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.00343, val_loss=0.00355,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.11it/s, loss=0.00343, val_loss=0.00355,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.00343, val_loss=0.00346,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00336, val_loss=0.00346,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 23.64it/s, loss=0.00336, val_loss=0.00346,\n",
      "Epoch 23:  84%|▊| 54/64 [00:01<00:00, 33.02it/s, loss=0.00336, val_loss=0.00346,\u001b[A\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.00336, val_loss=0.00337,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.18it/s, loss=0.00329, val_loss=0.00337,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 23.61it/s, loss=0.00329, val_loss=0.00337,\n",
      "Epoch 24:  84%|▊| 54/64 [00:01<00:00, 33.06it/s, loss=0.00329, val_loss=0.00337,\u001b[A\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00329, val_loss=0.00329,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00324, val_loss=0.00329,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.11it/s, loss=0.00324, val_loss=0.00329,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.00324, val_loss=0.00323,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.00319, val_loss=0.00323,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 23.83it/s, loss=0.00319, val_loss=0.00323,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00319, val_loss=0.0032, \u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.00315, val_loss=0.0032, \u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.00it/s, loss=0.00315, val_loss=0.0032, \n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.79it/s, loss=0.00315, val_loss=0.00318,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.0031, val_loss=0.00318, \u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 23.82it/s, loss=0.0031, val_loss=0.00318, \n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.0031, val_loss=0.00317, \u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.41it/s, loss=0.00306, val_loss=0.00317,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.88it/s, loss=0.00306, val_loss=0.00317,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.54it/s, loss=0.00306, val_loss=0.00314,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00303, val_loss=0.00314,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 23.80it/s, loss=0.00303, val_loss=0.00314,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.00303, val_loss=0.00309,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00299, val_loss=0.00309,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 23.98it/s, loss=0.00299, val_loss=0.00309,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00299, val_loss=0.00304,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00296, val_loss=0.00304,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 23.93it/s, loss=0.00296, val_loss=0.00304,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.00296, val_loss=0.00299,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.00292, val_loss=0.00299,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.00292, val_loss=0.00299,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.00292, val_loss=0.00294,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.11it/s, loss=0.00289, val_loss=0.00294,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 23.53it/s, loss=0.00289, val_loss=0.00294,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.07it/s, loss=0.00289, val_loss=0.0029, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00286, val_loss=0.0029, \u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.00286, val_loss=0.0029, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00286, val_loss=0.00287,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.65it/s, loss=0.00283, val_loss=0.00287,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.13it/s, loss=0.00283, val_loss=0.00287,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00283, val_loss=0.00284,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.29it/s, loss=0.00281, val_loss=0.00284,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 23.73it/s, loss=0.00281, val_loss=0.00284,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.35it/s, loss=0.00281, val_loss=0.00283,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.00278, val_loss=0.00283,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 24.08it/s, loss=0.00278, val_loss=0.00283,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.00278, val_loss=0.00282,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00276, val_loss=0.00282,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.95it/s, loss=0.00276, val_loss=0.00282,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.66it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.37it/s, loss=0.00276, val_loss=0.0028, \u001b[A\n",
      "Sizes of clusters: 409, 502, 358, 331\n",
      "\n",
      "preds: [2 1 1 2 1 1 1 1 0 1 1 2 2 1 1 2 0 2 1 1 1 1 1 1 2 2 2 1 2 3 1 1 1 2 1 2 1\n",
      " 1 1 2 2 1 1 1 1 2 2 2 1 1 2 3 2 1 1 1 2 2 2 1 2 0 1 2 1 0 1 3 2 1 2 1 1 1\n",
      " 1 2 1 1 1 2 2 1 1 1 3 1 0 1 2 1 0 2 2 2 1 1 2 1 1 1 1 1 1 1 0 1 2 1 2 2 1\n",
      " 3 2 1 1 2 2 2 2 1 1 1 3 1 1 1 2 3 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 0 2 2 2 2\n",
      " 1 1 1 1 1 1 1 1 2 0 1 2 1 1 1 3 1 1 1 1 1 2 2 2 0 2 0 2 1 2 3 1 2 2 0 1 2\n",
      " 2 2 1 2 2 0 0 2 1 2 1 3 1 3 1 2 1 3 1 1 0 1 1 2 1 2 1 1 1 1 2 2 1 1 1 2 1\n",
      " 1 2 2 0 2 1 3 1 2 1 1 1 0 1 1 1 2 2 1 1 1 3 3 1 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 1 1 1 1 1 2 1 1 1 1 2 2 2 1 3 1 1 3 1 0 1 0 1 2 1 1 1 1 1 1 2 1 1 1 1 2\n",
      " 0 3 1 1 2 1 1 1 2 2 1 1 1 2 1 1 2 1 1 2 2 1 2 1 0 1 2 1 2 2 1 2 0 1 2 2 2\n",
      " 1 0 1 1 1 3 1 1 2 1 1 0 3 3 2 0 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 3 1 1 1 2 2 1 1 1 2 1 1 2 1 2 1 1 0 1 1 2 1 1 1 1 3 2 1 3 0 3 2 1 2\n",
      " 2 2 1 3 3 3 2 0 0 3 0 3 1 3 0 3 0 3 1 1 3 0 0 1 3 3 3 0 1 3 1 3 0 3 3 3 3\n",
      " 3 1 2 3 3 2 2 3 1 3 0 3 3 0 2 0 1 3 3 0 0 0 3 1 0 0 3 2 0 3 0 3 3 2 3 2 1\n",
      " 0 0 2 1 1 2 0 3 2 0 2 1 3 2 3 3 2 3 0 1 2 3 0 0 3 3 3 1 0 2 0 1 1 1 2 3 3\n",
      " 3 1 1 0 0 1 0 2 2 3 3 1 0 1 3 3 0 0 3 0 2 2 0 3 1 0 0 0 3 0 0 0 3 0 3 1 1\n",
      " 1 3 3 1 3 3 3 1 2 2 0 2 3 1 0 0 2 3 0 2 3 3 3 0 0 1 1 3 1 3 2 3 0 0 3 3 2\n",
      " 0 0 1 3 2 0 3 0 1 3 2 2 0 0 0 0 2 0 1 1 0 3 0 0 3 3 1 1 2 3 3 2 0 2 2 0 2\n",
      " 0 2 0 0 1 3 3 1 0 3 3 3 1 2 3 2 1 0 2 0 3 2 3 1 1 1 3 3 0 2 2 3 2 3 3 3 3\n",
      " 2 2 2 0 0 0 3 3 3 1 0 3 0 3 3 3 3 0 3 1 1 0 0 3 3 3 0 1 2 1 1 3 2 1 3 0 0\n",
      " 0 1 0 2 3 0 2 0 0 3 2 0 1 0 3 0 3 3 0 1 1 3 3 3 0 3 3 3 2 0 0 3 1 0 2 3 1\n",
      " 2 0 0 0 3 1 0 0 0 3 0 0 3 2 3 2 3 3 0 3 3 3 1 3 0 1 1 2 0 0 3 0 3 2 0 3 1\n",
      " 3 2 3 2 3 3 1 2 0 3 0 1 3 0 3 3 3 0 1 3 1 0 0 1 1 1 0 3 2 0 0 3 1 3 1 2 1\n",
      " 0 1 2 0 3 0 1 3 0 0 0 3 1 2 1 0 1 1 2 3 2 1 3 1 1 0 1 0 2 0 3 3 0 3 2 2 3\n",
      " 0 1 2 0 0 2 3 0 1 0 0 2 0 2 0 3 1 1 1 1 1 0 1 0 3 0 1 0 0 1 0 3 3 0 1 2 1\n",
      " 2 3 0 1 0 0 2 0 1 1 2 3 1 3 3 0 0 0 2 3 2 2 1 3 0 2 1 2 0 1 0 2 2 3 1 0 2\n",
      " 0 1 1 0 1 1 2 1 1 3 0 1 3 3 0 0 1 0 1 0 0 1 0 2 1 0 0 0 2 3 2 3 0 2 1 3 2\n",
      " 0 2 1 3 0 0 1 1 2 0 0 3 3 3 1 0 2 2 2 0 1 1 3 2 0 0 0 0 1 0 2 0 0 1 3 3 0\n",
      " 2 1 1 2 3 3 1 1 1 2 2 0 0 2 2 1 0 2 1 1 1 0 1 0 2 0 1 0 0 1 0 3 1 0 0 2 2\n",
      " 2 1 3 2 1 0 1 2 1 1 1 1 1 2 3 1 0 1 0 0 1 2 0 1 0 3 2 3 1 3 2 0 1 1 2 1 0\n",
      " 2 0 0 2 2 1 1 0 3 1 0 2 2 3 1 2 3 3 0 1 0 2 3 1 3 3 1 0 2 2 0 1 2 3 2 2 3\n",
      " 0 1 1 2 3 3 2 2 0 3 1 1 2 1 1 1 0 3 1 1 0 0 1 2 2 1 0 1 3 3 1 1 2 1 1 2 2\n",
      " 1 1 3 3 1 0 0 1 1 2 0 3 1 2 1 0 2 3 2 2 0 3 1 0 2 3 0 0 0 0 2 2 1 2 1 1 1\n",
      " 2 0 0 0 0 1 3 1 3 1 0 3 0 1 1 2 1 0 3 2 1 2 0 0 2 0 0 0 3 0 2 2 0 1 0 2 1\n",
      " 0 3 0 3 2 0 0 0 0 1 3 2 1 1 0 1 3 1 3 0 3 0 2 2 1 0 0 1 3 0 1 3 3 2 3 0 1\n",
      " 2 1 2 0 2 0 1 0 3 1 2 1 0 0 0 3 2 1 3 3 0 1 3 0 3 3 3 3 3 3 0 0 3 0 3 0 1\n",
      " 1 3 1 3 1 0 0 0 0 3 3 3 3 3 3 3 0 3 1 0 0 0 1 0 0 2 1 0 2 0 3 2 1 0 0 3 3\n",
      " 0 0 0 2 2 0 3 0 3 0 0 3 0 0 0 1 1 1 2 0 0 1 3 2 3 0 2 1 2 0 0 0 3 2 3 0 0\n",
      " 2 1 0 0 1 0 0 1 0 0 3 0 0 0 1 3 2 3 0 0 3 3 2 3 0 2 0 0 0 0 3 2 2 2 0 0 0\n",
      " 3 0 0 1 0 3 2 1 0 2 3 2 3 3 2 3 3 1 3 1 2 3 0 2 1 2 3 0 3 1 3 2 1 3 3 3 3\n",
      " 1 2 1 0 1 0 3 0 1 2 1 2 2 0 0 0 3 2 0 0 3 0 0 0 0 1 2 0 3 1 3 0 1 2 1 3 2\n",
      " 2 2 0 0 2 0 2 0 0 3 2 3 2 1 0 1 0 1 1 0 0 1 2 0 2 1 0 2 2 0 2 2 2 3 0 1 0\n",
      " 3 0 2 0 0 0 0 2 3 1 3 2 0 3 0 0 1 0 1 3 2 3 0 3 1 2 1 3 1 0 2 0 2 1 2 1 2\n",
      " 3 0 2 2 0 3 1 1 0 0 3 2 2 3 0 0 0 3 0 3 3 2 0 2 0 0 0 2 0 1 0 1 2 1 0 1 1\n",
      " 0 1 0 2 3 0 3 3 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4025\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=1.92, val_loss=0.0945, avg_\n",
      "Epoch 0:  58%|▌| 37/64 [00:01<00:01, 25.11it/s, loss=1.92, val_loss=0.0945, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=1.92, val_loss=0.204, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.0946, val_loss=0.204, avg\u001b[A\n",
      "Epoch 1:  80%|▊| 51/64 [00:01<00:00, 32.49it/s, loss=0.0946, val_loss=0.204, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.14it/s, loss=0.0946, val_loss=0.0491, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.0296, val_loss=0.0491, av\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.72it/s, loss=0.0296, val_loss=0.0491, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.35it/s, loss=0.0296, val_loss=0.032, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.0216, val_loss=0.032, avg\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.59it/s, loss=0.0216, val_loss=0.032, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.0216, val_loss=0.0261, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.0177, val_loss=0.0261, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 25.51it/s, loss=0.0177, val_loss=0.0261, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.0177, val_loss=0.0221, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.015, val_loss=0.0221, avg\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 25.66it/s, loss=0.015, val_loss=0.0221, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.015, val_loss=0.019, avg_\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.55it/s, loss=0.013, val_loss=0.019, avg_\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 25.22it/s, loss=0.013, val_loss=0.019, avg_\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.75it/s, loss=0.013, val_loss=0.0164, avg\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.0115, val_loss=0.0164, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.0115, val_loss=0.0164, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.0115, val_loss=0.0142, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.0103, val_loss=0.0142, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.68it/s, loss=0.0103, val_loss=0.0142, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.29it/s, loss=0.0103, val_loss=0.0124, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00933, val_loss=0.0124, a\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 25.52it/s, loss=0.00933, val_loss=0.0124, a\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.00933, val_loss=0.011, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.0085, val_loss=0.011, av\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.0085, val_loss=0.011, av\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.0085, val_loss=0.00975, \u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00778, val_loss=0.00975,\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 25.69it/s, loss=0.00778, val_loss=0.00975,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00778, val_loss=0.00875,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00716, val_loss=0.00875,\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.00716, val_loss=0.00875,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00716, val_loss=0.00792,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00661, val_loss=0.00792,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 25.72it/s, loss=0.00661, val_loss=0.00792,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.34it/s, loss=0.00661, val_loss=0.00722,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.00614, val_loss=0.00722,\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.42it/s, loss=0.00614, val_loss=0.00722,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 37.94it/s, loss=0.00614, val_loss=0.00664,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00573, val_loss=0.00664,\u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 25.58it/s, loss=0.00573, val_loss=0.00664,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00573, val_loss=0.00616,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00538, val_loss=0.00616,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00538, val_loss=0.00616,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.26it/s, loss=0.00538, val_loss=0.00576,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00508, val_loss=0.00576,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 25.37it/s, loss=0.00508, val_loss=0.00576,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00508, val_loss=0.00541,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.32it/s, loss=0.00482, val_loss=0.00541,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 24.92it/s, loss=0.00482, val_loss=0.00541,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.27it/s, loss=0.00482, val_loss=0.00512,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.0046, val_loss=0.00512, \u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 25.26it/s, loss=0.0046, val_loss=0.00512, \n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.0046, val_loss=0.00488, \u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.35it/s, loss=0.00442, val_loss=0.00488,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 25.01it/s, loss=0.00442, val_loss=0.00488,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.45it/s, loss=0.00442, val_loss=0.00467,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 20.98it/s, loss=0.00426, val_loss=0.00467,\u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 24.57it/s, loss=0.00426, val_loss=0.00467,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 36.89it/s, loss=0.00426, val_loss=0.0045, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00413, val_loss=0.0045, \u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.32it/s, loss=0.00413, val_loss=0.0045, \n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.90it/s, loss=0.00413, val_loss=0.00436,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.41it/s, loss=0.00402, val_loss=0.00436,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 25.01it/s, loss=0.00402, val_loss=0.00436,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.00402, val_loss=0.00424,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.24it/s, loss=0.00393, val_loss=0.00424,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 24.85it/s, loss=0.00393, val_loss=0.00424,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.27it/s, loss=0.00393, val_loss=0.00414,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.26it/s, loss=0.00385, val_loss=0.00414,\u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 24.82it/s, loss=0.00385, val_loss=0.00414,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.25it/s, loss=0.00385, val_loss=0.00405,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.50it/s, loss=0.00378, val_loss=0.00405,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.00378, val_loss=0.00405,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00378, val_loss=0.00396,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00372, val_loss=0.00396,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.01it/s, loss=0.00372, val_loss=0.00396,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.47it/s, loss=0.00372, val_loss=0.00389,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00366, val_loss=0.00389,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.11it/s, loss=0.00366, val_loss=0.00389,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00366, val_loss=0.00383,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.53it/s, loss=0.00361, val_loss=0.00383,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00361, val_loss=0.00383,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00361, val_loss=0.00378,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.37it/s, loss=0.00357, val_loss=0.00378,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.03it/s, loss=0.00357, val_loss=0.00378,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 37.45it/s, loss=0.00357, val_loss=0.00372,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00352, val_loss=0.00372,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.11it/s, loss=0.00352, val_loss=0.00372,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00352, val_loss=0.00367,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00348, val_loss=0.00367,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.00348, val_loss=0.00367,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.66it/s, loss=0.00348, val_loss=0.00362,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00345, val_loss=0.00362,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 25.40it/s, loss=0.00345, val_loss=0.00362,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.00345, val_loss=0.00357,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.50it/s, loss=0.00341, val_loss=0.00357,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 25.11it/s, loss=0.00341, val_loss=0.00357,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.71it/s, loss=0.00341, val_loss=0.00353,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.16it/s, loss=0.00337, val_loss=0.00353,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 24.75it/s, loss=0.00337, val_loss=0.00353,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.12it/s, loss=0.00337, val_loss=0.00349,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00334, val_loss=0.00349,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 25.33it/s, loss=0.00334, val_loss=0.00349,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00334, val_loss=0.00345,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0033, val_loss=0.00345, \u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.0033, val_loss=0.00345, \n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.64it/s, loss=0.0033, val_loss=0.00342, \u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00327, val_loss=0.00342,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 25.43it/s, loss=0.00327, val_loss=0.00342,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=0.00327, val_loss=0.00338,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00324, val_loss=0.00338,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 25.19it/s, loss=0.00324, val_loss=0.00338,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.69it/s, loss=0.00324, val_loss=0.00335,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.45it/s, loss=0.00324, val_loss=0.00335,\u001b[A\n",
      "Sizes of clusters: 254, 621, 602, 123\n",
      "\n",
      "preds: [3 1 1 1 1 1 1 1 2 1 3 1 1 3 1 1 2 1 3 1 1 1 1 1 2 1 1 3 1 2 1 3 1 1 1 1 1\n",
      " 3 1 1 3 1 1 3 1 1 1 1 1 1 2 2 3 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 3\n",
      " 2 1 1 1 1 3 1 3 1 1 1 3 2 1 1 3 2 1 1 2 3 1 1 1 1 1 3 3 1 3 2 1 1 1 2 1 1\n",
      " 2 1 1 1 1 3 2 1 1 1 3 1 1 3 1 2 2 1 1 2 1 1 3 1 1 1 1 3 1 3 1 1 0 2 1 1 2\n",
      " 1 1 1 1 1 3 3 1 1 2 3 3 3 1 1 1 1 3 3 3 1 2 3 1 2 1 2 3 1 2 1 3 2 1 2 1 1\n",
      " 2 1 1 1 1 2 2 1 1 1 1 1 1 2 1 1 3 2 2 1 2 1 2 1 1 1 2 3 1 1 3 1 1 3 1 3 3\n",
      " 1 1 1 0 1 1 1 1 3 1 1 3 2 1 1 1 1 3 1 1 1 1 2 3 3 3 1 2 3 2 1 1 1 3 3 1 3\n",
      " 1 1 3 1 3 2 1 3 3 1 1 2 1 3 1 1 1 1 2 3 2 3 2 1 2 1 1 1 1 3 1 1 1 1 1 3 1\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 3 1 3 1 1 2 3 1 2 1\n",
      " 1 2 2 3 1 1 3 1 3 1 1 2 1 1 2 2 1 1 1 1 1 1 3 1 1 3 1 2 1 1 1 3 1 2 1 1 3\n",
      " 1 3 1 1 3 1 1 1 1 1 1 2 1 1 3 2 1 1 1 3 2 1 1 1 1 1 3 2 1 3 3 2 0 2 2 1 0\n",
      " 2 0 1 2 0 1 3 2 2 2 2 1 1 2 2 2 2 2 1 3 1 0 0 1 2 2 0 2 3 2 1 2 2 0 1 0 0\n",
      " 2 1 0 0 2 2 0 0 1 1 2 2 2 2 2 2 3 2 1 2 0 2 0 1 2 2 1 2 0 1 2 2 0 2 2 1 1\n",
      " 0 2 0 1 1 2 2 1 1 2 2 1 1 1 1 1 1 2 0 1 2 2 0 0 1 2 1 1 2 1 0 1 1 1 1 0 2\n",
      " 0 3 1 2 0 1 0 1 2 2 2 1 2 3 2 0 0 0 2 2 2 1 2 2 1 0 2 2 2 0 0 2 2 2 2 1 1\n",
      " 1 2 0 1 1 2 0 1 1 2 0 0 2 3 0 2 0 2 1 2 1 1 2 2 2 1 1 2 1 1 1 0 0 0 2 2 2\n",
      " 1 2 1 1 2 2 2 2 1 2 0 2 0 2 2 0 2 0 3 1 2 2 0 0 2 2 1 1 1 2 1 2 2 2 1 0 2\n",
      " 2 2 0 2 3 2 2 1 2 2 2 1 1 2 1 0 1 2 1 2 1 2 0 1 1 1 1 2 0 0 2 2 2 2 2 1 1\n",
      " 0 1 2 0 2 0 2 2 2 1 2 1 2 1 1 1 0 0 1 1 1 2 2 2 2 1 2 1 2 1 1 1 2 1 1 0 2\n",
      " 2 1 2 1 0 2 0 0 0 1 0 0 1 0 2 0 0 2 0 2 1 1 2 2 2 0 2 0 1 0 2 1 1 0 1 1 3\n",
      " 3 0 0 0 1 1 0 0 2 2 0 0 0 1 1 0 0 2 2 2 0 2 1 2 0 1 1 2 0 0 2 0 0 2 0 2 3\n",
      " 0 2 1 1 2 0 1 2 0 2 2 1 2 2 2 1 2 0 3 2 3 2 2 2 2 1 0 2 2 2 2 1 3 1 2 2 3\n",
      " 2 1 2 2 0 0 1 1 2 2 0 2 1 2 1 2 2 1 1 2 1 1 1 1 1 2 1 2 0 2 2 2 2 2 1 2 2\n",
      " 2 1 1 2 2 1 0 2 2 2 2 2 0 1 2 2 1 1 1 1 3 2 1 2 1 0 1 0 0 1 2 2 2 0 2 1 1\n",
      " 1 0 2 3 2 2 2 0 1 1 1 2 3 2 1 2 2 0 2 2 2 2 2 1 0 2 1 1 2 1 0 1 1 2 1 2 1\n",
      " 2 1 1 2 1 3 1 1 1 1 2 2 1 2 2 2 1 2 1 0 2 2 2 1 1 2 2 2 1 0 2 0 2 1 1 2 1\n",
      " 2 3 1 0 2 2 1 2 2 2 2 1 2 2 1 2 1 2 2 2 1 1 1 2 2 0 2 0 2 2 2 2 0 2 1 2 2\n",
      " 2 2 3 1 1 1 2 1 1 2 1 2 0 2 2 1 2 1 2 1 3 2 1 0 0 2 3 2 2 1 0 2 3 2 2 1 2\n",
      " 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 0 1 2 2 2 3 2 2 3 2\n",
      " 2 2 2 0 3 1 1 2 0 1 2 1 2 2 1 1 0 2 2 1 2 3 2 3 2 1 1 0 1 2 2 3 1 2 2 2 1\n",
      " 2 1 1 2 1 2 2 2 2 2 1 2 2 3 2 2 0 2 2 1 2 0 1 2 1 1 2 2 2 2 1 3 1 1 2 2 2\n",
      " 2 1 2 2 1 2 0 1 1 1 0 2 1 2 1 2 2 1 2 2 0 1 1 2 2 2 0 0 2 2 2 1 2 3 1 1 1\n",
      " 2 2 2 2 2 3 0 1 1 1 2 2 0 2 2 2 1 0 1 2 1 2 0 2 1 2 2 2 0 0 2 0 0 1 2 2 3\n",
      " 0 1 0 2 2 0 2 0 0 3 1 2 1 1 2 1 1 1 2 2 2 2 2 2 1 2 0 3 1 0 1 2 2 2 0 0 1\n",
      " 1 1 0 2 2 2 1 0 2 1 2 3 2 0 2 0 2 1 1 2 0 1 2 2 1 1 1 2 2 0 0 0 2 2 2 2 1\n",
      " 1 0 2 0 1 2 0 2 0 2 2 1 2 1 2 0 2 1 1 0 0 2 1 0 2 0 1 0 2 2 2 2 2 2 0 2 0\n",
      " 0 0 2 1 1 0 1 0 1 0 0 0 0 0 0 1 2 3 2 2 2 1 1 0 2 0 2 1 2 0 0 0 1 2 2 1 0\n",
      " 2 1 2 0 1 2 0 1 2 2 2 0 2 0 1 2 0 1 0 0 2 0 1 0 0 0 2 0 0 2 2 1 0 2 2 1 2\n",
      " 2 0 2 1 2 2 1 1 2 0 1 2 1 0 2 1 2 1 0 1 2 1 2 0 1 1 2 2 2 1 2 2 1 2 0 1 2\n",
      " 1 0 1 2 2 2 1 0 1 2 1 2 0 0 0 0 2 2 2 2 0 0 0 0 2 1 2 0 0 1 0 2 1 1 1 1 1\n",
      " 2 3 2 0 2 2 0 0 0 2 2 2 2 3 2 3 0 1 1 2 2 1 0 0 2 1 0 2 3 2 1 1 1 1 2 1 2\n",
      " 2 0 1 0 0 0 0 2 2 1 2 2 2 2 0 0 1 0 3 2 1 0 2 0 1 2 1 2 1 2 1 0 1 2 2 1 1\n",
      " 1 2 0 0 2 0 1 1 2 0 2 2 2 0 2 2 2 0 0 2 1 0 2 2 2 0 0 2 2 1 2 1 2 1 2 1 1\n",
      " 2 1 0 1 2 2 2 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4075\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=2.3, val_loss=0.0893, avg_v\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=2.3, val_loss=0.0893, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=2.3, val_loss=0.166, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0951, val_loss=0.166, avg\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 23.12it/s, loss=0.0951, val_loss=0.166, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.0951, val_loss=0.0415, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.0237, val_loss=0.0415, av\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.44it/s, loss=0.0237, val_loss=0.0415, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.29it/s, loss=0.0237, val_loss=0.0268, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.0161, val_loss=0.0268, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.0161, val_loss=0.0268, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.0161, val_loss=0.021, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.0127, val_loss=0.021, avg\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.0127, val_loss=0.021, avg\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.0127, val_loss=0.0166, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.0105, val_loss=0.0166, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.46it/s, loss=0.0105, val_loss=0.0166, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.0105, val_loss=0.0132, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.00887, val_loss=0.0132, a\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00887, val_loss=0.0132, a\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.14it/s, loss=0.00887, val_loss=0.0106, a\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.00774, val_loss=0.0106, a\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.00774, val_loss=0.0106, a\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.90it/s, loss=0.00774, val_loss=0.00879, \u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.00689, val_loss=0.00879, \u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.51it/s, loss=0.00689, val_loss=0.00879, \n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.37it/s, loss=0.00689, val_loss=0.00757, \u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00623, val_loss=0.00757, \u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00623, val_loss=0.00757, \n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.00623, val_loss=0.0067, a\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00571, val_loss=0.0067, \u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00571, val_loss=0.0067, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.03it/s, loss=0.00571, val_loss=0.00605,\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00529, val_loss=0.00605,\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.45it/s, loss=0.00529, val_loss=0.00605,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00529, val_loss=0.00555,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00495, val_loss=0.00555,\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00495, val_loss=0.00555,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=0.00495, val_loss=0.00517,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00466, val_loss=0.00517,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.48it/s, loss=0.00466, val_loss=0.00517,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00466, val_loss=0.00486,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.00443, val_loss=0.00486,\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.00443, val_loss=0.00486,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.00443, val_loss=0.0046, \u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00423, val_loss=0.0046, \u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.31it/s, loss=0.00423, val_loss=0.0046, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00423, val_loss=0.0044, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00406, val_loss=0.0044, \u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00406, val_loss=0.0044, \n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00406, val_loss=0.00422,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00392, val_loss=0.00422,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00392, val_loss=0.00422,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.00392, val_loss=0.00406,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00379, val_loss=0.00406,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 24.33it/s, loss=0.00379, val_loss=0.00406,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 38.14it/s, loss=0.00379, val_loss=0.00392,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.00369, val_loss=0.00392,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.14it/s, loss=0.00369, val_loss=0.00392,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.85it/s, loss=0.00369, val_loss=0.0038, \u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.0036, val_loss=0.0038, a\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 23.97it/s, loss=0.0036, val_loss=0.0038, a\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.67it/s, loss=0.0036, val_loss=0.00369, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00351, val_loss=0.00369,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 24.29it/s, loss=0.00351, val_loss=0.00369,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00351, val_loss=0.00361,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00344, val_loss=0.00361,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.17it/s, loss=0.00344, val_loss=0.00361,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 37.99it/s, loss=0.00344, val_loss=0.00353,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00337, val_loss=0.00353,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00337, val_loss=0.00353,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.00337, val_loss=0.00344,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00331, val_loss=0.00344,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 23.98it/s, loss=0.00331, val_loss=0.00344,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00331, val_loss=0.00335,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.00326, val_loss=0.00335,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.00326, val_loss=0.00335,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 37.96it/s, loss=0.00326, val_loss=0.00328,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.0032, val_loss=0.00328, \u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 23.90it/s, loss=0.0032, val_loss=0.00328, \n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.60it/s, loss=0.0032, val_loss=0.00322, \u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.00315, val_loss=0.00322,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.17it/s, loss=0.00315, val_loss=0.00322,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.00315, val_loss=0.00317,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.0031, val_loss=0.00317, \u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 23.85it/s, loss=0.0031, val_loss=0.00317, \n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.52it/s, loss=0.0031, val_loss=0.00311, \u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00306, val_loss=0.00311,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.93it/s, loss=0.00306, val_loss=0.00311,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.00306, val_loss=0.00306,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.00301, val_loss=0.00306,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.11it/s, loss=0.00301, val_loss=0.00306,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 37.82it/s, loss=0.00301, val_loss=0.00302,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00297, val_loss=0.00302,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 24.15it/s, loss=0.00297, val_loss=0.00302,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.87it/s, loss=0.00297, val_loss=0.00297,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00293, val_loss=0.00297,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00293, val_loss=0.00297,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.99it/s, loss=0.00293, val_loss=0.00293,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00289, val_loss=0.00293,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.43it/s, loss=0.00289, val_loss=0.00293,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.00289, val_loss=0.0029, \u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00285, val_loss=0.0029, \u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.00285, val_loss=0.0029, \n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.00285, val_loss=0.00286,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00281, val_loss=0.00286,\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.00281, val_loss=0.00286,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=0.00281, val_loss=0.00282,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.00278, val_loss=0.00282,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.33it/s, loss=0.00278, val_loss=0.00282,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00278, val_loss=0.00279,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00274, val_loss=0.00279,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.00274, val_loss=0.00279,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.03it/s, loss=0.00274, val_loss=0.00275,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.14it/s, loss=0.00271, val_loss=0.00275,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 23.56it/s, loss=0.00271, val_loss=0.00275,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.13it/s, loss=0.00271, val_loss=0.00272,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00268, val_loss=0.00272,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.96it/s, loss=0.00268, val_loss=0.00272,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=0.00268, val_loss=0.00269,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.39it/s, loss=0.00268, val_loss=0.00269,\u001b[A\n",
      "Sizes of clusters: 282, 540, 613, 165\n",
      "\n",
      "preds: [3 1 1 3 1 3 1 3 2 2 3 2 1 3 1 2 2 1 3 1 1 1 1 1 2 2 1 3 1 2 1 3 1 1 1 1 1\n",
      " 3 1 1 1 1 2 3 2 1 3 1 1 1 2 1 3 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 3 1 1 1 3\n",
      " 1 1 1 1 3 3 1 3 1 1 1 3 2 3 3 3 2 1 1 2 3 1 1 3 1 3 3 3 1 3 2 1 2 3 1 2 1\n",
      " 1 1 1 3 1 3 0 3 1 1 3 1 1 3 1 2 1 1 1 1 1 3 3 2 1 1 1 3 1 3 3 1 2 1 1 1 2\n",
      " 1 1 1 1 1 3 3 1 1 1 3 3 3 1 1 1 1 3 3 3 1 2 3 1 2 1 2 3 1 2 1 3 2 1 2 1 3\n",
      " 2 1 1 1 2 2 2 1 1 1 2 1 1 1 1 1 3 1 1 1 2 1 1 1 1 1 1 3 3 1 3 2 1 3 1 3 3\n",
      " 3 1 1 2 1 1 1 1 1 1 1 3 2 1 3 1 1 3 1 1 1 1 2 3 3 3 1 2 1 2 1 2 1 3 3 3 3\n",
      " 1 1 3 3 3 1 3 3 3 1 1 2 1 3 1 1 1 3 1 3 2 3 2 1 2 1 1 1 1 3 1 1 1 1 1 3 1\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 3 1 3 1 1 1 1 1 1 1 3 2 1 1 3 1 3 3 2 2 3 1 2 1\n",
      " 1 2 1 3 1 1 3 2 1 3 3 2 1 1 2 2 1 1 2 1 1 1 3 1 1 3 1 1 1 1 1 3 1 1 1 3 3\n",
      " 3 3 1 2 3 2 1 2 1 1 3 1 1 1 3 2 1 1 1 3 1 1 1 1 2 1 3 1 1 3 3 2 0 0 0 2 0\n",
      " 2 0 2 2 0 1 3 2 1 2 2 2 1 2 2 2 2 1 2 3 1 0 0 1 2 2 0 2 3 2 1 2 2 0 1 0 0\n",
      " 2 2 0 0 1 2 0 0 2 1 1 2 2 2 0 2 3 2 1 2 0 2 0 2 2 2 1 2 0 1 2 2 0 2 1 1 1\n",
      " 0 2 0 1 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 2 2 2 0 0 1 0 1 1 2 1 0 1 1 1 2 2 2\n",
      " 0 3 2 2 0 2 0 1 2 0 2 2 2 3 2 0 2 0 2 2 2 1 2 2 2 0 0 2 2 2 0 2 0 2 2 2 1\n",
      " 1 2 0 2 1 2 0 1 1 2 0 0 2 3 0 2 2 2 1 0 1 1 2 2 2 1 1 0 1 1 2 0 0 0 2 2 2\n",
      " 1 2 1 2 2 2 0 1 1 1 0 0 0 0 2 0 1 1 3 2 2 2 0 0 2 2 1 1 1 2 1 2 2 0 2 0 2\n",
      " 2 2 0 2 3 2 2 1 2 0 2 1 1 2 1 0 1 2 1 2 2 0 2 1 1 1 2 2 0 0 2 2 2 0 2 2 1\n",
      " 2 2 2 0 2 0 2 2 2 1 2 2 2 2 1 2 0 0 2 1 2 2 2 0 2 2 2 3 2 2 1 1 2 1 2 0 2\n",
      " 2 2 2 1 0 0 2 0 0 2 2 0 1 0 2 0 0 0 0 1 1 2 2 2 2 0 0 0 2 0 2 1 1 0 1 1 3\n",
      " 3 0 2 0 1 1 0 0 2 0 2 0 0 2 1 0 2 2 2 2 0 2 1 2 0 1 2 1 0 0 2 0 0 1 0 2 3\n",
      " 0 2 1 1 2 0 1 2 0 2 2 2 0 2 0 1 2 0 3 1 3 2 2 1 1 1 0 2 2 0 2 1 3 1 1 2 3\n",
      " 2 2 2 2 0 0 1 2 2 2 0 1 1 2 1 2 1 1 1 2 1 2 1 1 1 2 2 2 0 0 1 1 0 1 1 1 1\n",
      " 2 2 1 2 0 1 0 2 1 2 0 2 0 2 2 0 1 1 1 1 1 0 1 2 1 0 1 0 0 1 2 0 2 0 2 1 1\n",
      " 1 2 2 3 2 2 1 2 1 2 1 1 3 2 1 0 2 0 2 2 1 0 2 1 2 1 1 3 2 2 2 1 1 2 2 2 1\n",
      " 2 3 2 2 1 3 1 1 1 1 2 1 1 2 2 2 1 2 1 2 2 2 2 2 1 2 2 2 1 0 2 0 2 1 1 1 2\n",
      " 2 3 2 0 2 2 1 1 2 2 2 1 2 2 1 0 3 2 2 2 1 2 1 1 0 0 2 0 1 2 1 0 2 1 1 2 2\n",
      " 2 2 3 1 1 1 2 3 1 2 3 1 2 2 2 3 2 1 1 3 3 2 1 0 0 2 3 2 0 1 0 1 3 2 2 1 2\n",
      " 2 1 2 1 1 2 1 2 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 2 2 1 1 2 1 2 0 2 3 1 2 3 0\n",
      " 2 0 2 0 3 2 1 0 2 1 2 1 1 2 1 1 1 2 2 1 2 3 2 3 2 2 3 2 1 0 2 3 1 2 2 1 2\n",
      " 0 1 3 2 1 2 2 1 2 1 1 1 2 3 1 2 2 1 2 1 2 0 1 2 2 1 2 1 2 2 2 3 3 2 2 2 2\n",
      " 1 1 2 2 1 2 2 1 1 1 0 1 3 2 1 2 2 1 2 2 2 2 2 2 2 2 0 0 0 2 2 2 1 3 1 1 1\n",
      " 2 2 2 2 2 3 0 1 1 1 1 2 0 1 1 0 1 2 2 2 1 2 2 2 2 0 2 2 0 0 2 0 0 2 2 2 3\n",
      " 0 2 2 2 2 0 2 2 0 3 2 2 1 1 2 1 2 2 2 2 2 2 2 2 2 2 0 3 2 0 1 0 2 2 0 0 3\n",
      " 2 2 0 2 0 2 2 0 2 1 2 3 2 0 2 0 2 2 1 2 0 1 2 2 2 1 1 0 0 0 2 0 2 2 2 2 1\n",
      " 1 0 1 0 1 2 2 2 0 2 2 1 2 2 2 0 2 2 2 0 0 2 2 0 2 0 1 0 0 2 1 1 1 2 0 2 2\n",
      " 2 0 2 1 1 0 1 0 1 0 2 0 0 0 0 1 2 3 2 2 0 3 1 0 2 0 2 1 0 0 0 0 2 2 2 1 0\n",
      " 2 2 2 0 1 1 0 1 2 2 2 0 2 0 2 2 0 1 0 0 0 0 1 0 0 0 2 2 0 2 1 2 0 0 2 1 2\n",
      " 2 0 2 1 2 2 3 1 2 0 1 2 2 0 2 1 2 1 2 1 2 2 2 0 1 3 2 1 0 2 2 2 2 0 0 2 2\n",
      " 2 0 2 2 1 2 2 0 1 1 2 2 0 2 2 2 2 0 2 2 0 0 0 0 2 2 2 0 0 1 0 2 2 1 2 1 1\n",
      " 0 1 0 0 2 0 0 0 0 2 0 0 2 3 2 3 0 1 1 1 2 2 0 0 1 1 0 0 3 2 1 2 2 2 0 2 0\n",
      " 2 0 2 0 0 0 0 2 2 1 2 2 2 2 0 0 1 0 3 2 2 0 2 0 1 0 2 0 1 2 1 2 2 1 2 2 1\n",
      " 2 2 2 2 2 0 2 2 2 0 2 2 2 0 2 0 2 0 0 2 2 0 2 2 1 0 0 2 2 1 2 1 0 2 2 1 2\n",
      " 0 1 0 1 0 2 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4081\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=2.5, val_loss=0.0718, avg_v\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=2.5, val_loss=0.0718, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.94it/s, loss=2.5, val_loss=0.159, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.115, val_loss=0.159, avg_\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 23.03it/s, loss=0.115, val_loss=0.159, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.115, val_loss=0.0498, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.0261, val_loss=0.0498, av\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.45it/s, loss=0.0261, val_loss=0.0498, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.0261, val_loss=0.0261, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.0171, val_loss=0.0261, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.26it/s, loss=0.0171, val_loss=0.0261, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.0171, val_loss=0.0198, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.0138, val_loss=0.0198, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.31it/s, loss=0.0138, val_loss=0.0198, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.0138, val_loss=0.016, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.80it/s, loss=0.0118, val_loss=0.016, avg\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.0118, val_loss=0.016, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.0118, val_loss=0.0132, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.0104, val_loss=0.0132, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.18it/s, loss=0.0104, val_loss=0.0132, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.0104, val_loss=0.0113, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.00941, val_loss=0.0113, a\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00941, val_loss=0.0113, a\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00941, val_loss=0.00995, \u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.00861, val_loss=0.00995, \u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.38it/s, loss=0.00861, val_loss=0.00995, \n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00861, val_loss=0.00896, \u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00795, val_loss=0.00896, \u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 24.28it/s, loss=0.00795, val_loss=0.00896, \n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00795, val_loss=0.00818, \u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.55it/s, loss=0.0074, val_loss=0.00818, \u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.02it/s, loss=0.0074, val_loss=0.00818, \n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 37.76it/s, loss=0.0074, val_loss=0.00756, \u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00693, val_loss=0.00756,\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.00693, val_loss=0.00756,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00693, val_loss=0.00706,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.00652, val_loss=0.00706,\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 24.05it/s, loss=0.00652, val_loss=0.00706,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.79it/s, loss=0.00652, val_loss=0.00664,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00617, val_loss=0.00664,\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.19it/s, loss=0.00617, val_loss=0.00664,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.00617, val_loss=0.00626,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00586, val_loss=0.00626,\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00586, val_loss=0.00626,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00586, val_loss=0.00594,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00559, val_loss=0.00594,\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.32it/s, loss=0.00559, val_loss=0.00594,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00559, val_loss=0.00566,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.88it/s, loss=0.00535, val_loss=0.00566,\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.45it/s, loss=0.00535, val_loss=0.00566,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00535, val_loss=0.00541,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00513, val_loss=0.00541,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.32it/s, loss=0.00513, val_loss=0.00541,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00513, val_loss=0.00516,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00494, val_loss=0.00516,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 24.21it/s, loss=0.00494, val_loss=0.00516,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.00494, val_loss=0.00494,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00476, val_loss=0.00494,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.46it/s, loss=0.00476, val_loss=0.00494,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.00476, val_loss=0.00474,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00459, val_loss=0.00474,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 24.18it/s, loss=0.00459, val_loss=0.00474,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.99it/s, loss=0.00459, val_loss=0.00459,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00445, val_loss=0.00459,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 23.91it/s, loss=0.00445, val_loss=0.00459,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.60it/s, loss=0.00445, val_loss=0.00443,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.88it/s, loss=0.00431, val_loss=0.00443,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.44it/s, loss=0.00431, val_loss=0.00443,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.28it/s, loss=0.00431, val_loss=0.00427,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.00418, val_loss=0.00427,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.19it/s, loss=0.00418, val_loss=0.00427,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00418, val_loss=0.00412,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.00406, val_loss=0.00412,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00406, val_loss=0.00412,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.00406, val_loss=0.00398,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.85it/s, loss=0.00396, val_loss=0.00398,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.41it/s, loss=0.00396, val_loss=0.00398,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.00396, val_loss=0.00385,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00385, val_loss=0.00385,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00385, val_loss=0.00385,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.10it/s, loss=0.00385, val_loss=0.00373,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.85it/s, loss=0.00376, val_loss=0.00373,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00376, val_loss=0.00373,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00376, val_loss=0.00362,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.00367, val_loss=0.00362,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 24.01it/s, loss=0.00367, val_loss=0.00362,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 37.80it/s, loss=0.00367, val_loss=0.00353,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00359, val_loss=0.00353,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.00359, val_loss=0.00353,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00359, val_loss=0.00344,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00351, val_loss=0.00344,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.12it/s, loss=0.00351, val_loss=0.00344,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 37.87it/s, loss=0.00351, val_loss=0.00336,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.20it/s, loss=0.00344, val_loss=0.00336,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 23.63it/s, loss=0.00344, val_loss=0.00336,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.20it/s, loss=0.00344, val_loss=0.00329,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00337, val_loss=0.00329,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00337, val_loss=0.00329,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.00337, val_loss=0.00323,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.0033, val_loss=0.00323, \u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.0033, val_loss=0.00323, \n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.77it/s, loss=0.0033, val_loss=0.00316, \u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00324, val_loss=0.00316,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00324, val_loss=0.00316,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.00324, val_loss=0.00308,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.00318, val_loss=0.00308,\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.00318, val_loss=0.00308,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.96it/s, loss=0.00318, val_loss=0.00302,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.55it/s, loss=0.00312, val_loss=0.00302,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.08it/s, loss=0.00312, val_loss=0.00302,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 37.75it/s, loss=0.00312, val_loss=0.00297,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.65it/s, loss=0.00307, val_loss=0.00297,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.17it/s, loss=0.00307, val_loss=0.00297,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00307, val_loss=0.00292,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.85it/s, loss=0.00302, val_loss=0.00292,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00302, val_loss=0.00292,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00302, val_loss=0.00288,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00297, val_loss=0.00288,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.91it/s, loss=0.00297, val_loss=0.00288,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.59it/s, loss=0.00297, val_loss=0.00284,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.36it/s, loss=0.00297, val_loss=0.00284,\u001b[A\n",
      "Sizes of clusters: 591, 521, 271, 217\n",
      "\n",
      "preds: [1 0 1 0 0 0 0 0 2 1 3 3 1 1 0 3 0 1 3 0 0 1 0 1 0 3 1 0 1 2 0 3 0 1 0 1 0\n",
      " 1 0 1 3 1 1 1 1 1 0 3 0 0 0 2 3 0 0 0 0 1 3 0 1 0 0 1 0 0 1 0 1 2 3 0 0 0\n",
      " 2 3 1 0 0 3 1 1 1 0 0 1 0 0 0 3 0 1 1 0 3 0 1 0 1 0 1 3 0 1 2 0 3 0 2 3 0\n",
      " 2 1 1 0 1 3 1 0 0 0 3 1 0 1 0 1 2 1 0 0 1 0 3 1 0 1 0 0 1 1 0 0 2 0 1 3 0\n",
      " 1 0 0 1 0 3 1 1 1 2 3 3 1 0 1 1 0 0 1 1 0 0 3 1 2 1 0 3 0 0 0 3 0 1 0 0 0\n",
      " 0 1 0 1 3 2 2 1 0 3 1 0 1 2 0 3 1 2 2 0 2 1 2 1 1 1 2 3 0 1 3 3 0 3 0 3 1\n",
      " 0 1 1 2 1 0 1 1 3 1 0 0 0 0 0 0 1 3 1 0 1 0 2 2 3 1 1 1 3 0 0 3 0 0 1 2 2\n",
      " 1 0 0 0 3 2 0 3 3 0 1 1 1 3 0 0 1 0 2 0 2 3 0 0 0 0 1 0 1 3 0 3 0 0 1 3 1\n",
      " 0 1 0 0 1 0 0 0 1 0 1 1 1 0 2 2 3 1 1 1 3 0 1 2 0 0 1 1 1 3 0 3 0 1 1 0 1\n",
      " 0 0 2 0 1 0 0 3 3 0 2 0 0 1 0 0 1 1 1 0 0 1 0 0 0 3 0 2 1 1 0 3 1 2 1 0 3\n",
      " 0 3 0 1 1 1 0 3 3 0 2 2 1 1 3 0 0 1 0 1 2 1 0 1 1 0 1 2 0 3 3 0 1 0 1 3 3\n",
      " 1 1 1 0 2 0 3 0 2 0 0 3 0 0 0 0 0 2 3 3 0 2 1 3 2 0 1 0 3 2 0 2 0 1 0 0 2\n",
      " 2 3 3 1 2 1 3 2 3 1 3 2 0 0 1 0 3 2 1 0 1 0 0 3 0 0 0 0 1 0 0 0 1 1 2 1 3\n",
      " 1 0 3 1 0 1 0 1 1 2 1 1 1 3 1 1 1 0 0 3 1 0 1 0 1 0 0 0 0 3 3 1 0 0 3 0 2\n",
      " 1 1 1 0 1 3 3 3 1 3 2 1 0 3 2 1 0 1 0 0 0 1 3 2 1 2 1 3 2 0 1 0 0 3 0 3 1\n",
      " 0 2 1 1 0 0 0 1 3 1 1 3 0 3 1 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 3 1 0 1 2 0 0\n",
      " 1 0 1 3 1 3 0 2 0 2 3 1 1 3 0 2 0 0 3 1 0 2 1 1 2 2 1 1 1 2 1 1 3 1 3 3 1\n",
      " 0 1 2 0 3 0 0 1 0 0 0 1 0 3 1 3 1 0 1 0 1 1 0 1 1 0 1 0 1 3 1 0 1 0 0 1 1\n",
      " 1 3 1 1 0 1 2 0 0 1 3 1 3 1 0 1 2 1 1 3 3 0 0 0 0 1 0 0 3 1 1 1 1 1 1 2 0\n",
      " 3 1 0 1 2 0 1 1 0 3 1 1 0 1 0 2 1 1 3 2 1 1 0 2 0 1 1 1 3 1 3 1 1 1 3 0 1\n",
      " 3 2 0 1 0 1 2 1 0 0 0 1 1 3 0 3 0 0 3 0 2 0 3 0 2 1 1 0 1 1 2 2 0 0 1 2 0\n",
      " 1 1 1 3 2 1 0 1 1 2 0 1 0 0 0 0 2 2 1 2 1 0 0 2 2 1 2 2 0 3 0 0 0 1 2 0 0\n",
      " 0 3 1 0 2 2 1 1 0 0 2 2 1 0 1 0 2 0 3 0 3 3 2 1 1 0 1 0 3 1 2 2 0 2 3 0 2\n",
      " 0 1 1 0 0 3 2 0 2 0 0 0 2 3 0 0 1 1 1 3 3 0 1 0 0 2 0 1 0 0 0 0 2 2 2 3 1\n",
      " 3 2 0 1 0 0 0 2 1 3 3 2 3 2 0 0 0 2 0 2 0 1 0 0 0 0 0 0 0 3 2 3 3 0 3 0 1\n",
      " 0 0 3 0 1 1 1 1 1 1 0 2 0 2 0 0 1 1 0 2 0 2 0 3 1 0 0 0 3 2 1 2 0 1 1 2 3\n",
      " 0 3 3 2 0 1 1 2 0 0 0 1 2 2 0 0 0 0 0 0 0 3 0 0 0 2 0 2 2 0 0 0 2 2 1 0 0\n",
      " 1 2 3 1 0 1 2 0 1 1 0 0 2 0 1 0 0 1 2 0 0 0 1 0 0 0 1 0 0 1 0 2 3 0 0 3 1\n",
      " 0 2 2 0 2 0 1 1 1 0 1 1 0 3 3 1 0 1 0 2 2 0 0 1 1 2 1 2 1 2 1 0 0 2 1 2 0\n",
      " 0 0 0 3 3 3 1 3 2 1 0 1 0 2 1 1 2 2 0 0 1 3 0 0 2 1 0 2 3 1 0 0 1 2 0 0 1\n",
      " 1 1 0 1 1 2 0 0 0 2 1 2 0 1 2 2 2 2 2 1 0 2 1 0 3 1 0 2 2 0 3 1 1 1 2 0 0\n",
      " 2 1 2 2 0 0 2 1 1 3 2 2 0 1 1 0 1 1 0 0 2 1 1 0 0 2 2 2 0 0 1 3 2 3 0 1 1\n",
      " 1 0 0 0 0 2 2 1 0 1 2 2 2 2 2 1 1 0 1 0 1 0 0 2 3 0 0 0 2 1 0 1 1 1 3 0 0\n",
      " 1 1 0 2 0 1 2 0 2 3 1 3 1 1 0 1 1 1 0 2 2 0 1 1 1 0 2 3 3 1 0 2 2 0 1 1 0\n",
      " 3 1 3 0 1 0 1 1 2 1 1 1 2 1 2 2 0 1 2 0 1 1 2 2 1 0 1 2 0 0 0 2 2 0 2 0 0\n",
      " 0 0 2 0 1 3 0 0 0 2 0 0 0 1 0 2 2 1 3 2 1 0 3 1 2 1 0 0 1 0 2 0 2 2 2 0 2\n",
      " 0 1 2 3 1 1 2 2 2 1 2 0 0 1 2 1 2 1 0 0 1 0 0 0 2 1 0 1 1 3 1 3 1 0 0 0 1\n",
      " 0 1 0 2 1 2 1 0 3 0 0 1 2 1 1 2 3 0 1 1 0 0 1 2 1 1 2 0 1 0 2 3 1 1 0 1 2\n",
      " 0 1 2 0 2 2 1 1 0 3 0 0 3 2 0 1 2 1 2 1 1 1 2 0 0 1 0 2 0 3 0 0 1 0 1 1 2\n",
      " 1 3 1 2 2 0 1 2 0 0 1 0 1 0 0 0 2 1 2 3 2 1 2 1 0 3 0 1 2 1 2 0 1 1 1 0 1\n",
      " 1 3 0 2 3 1 1 2 1 2 1 0 1 3 2 3 1 1 1 2 0 1 0 2 0 0 1 1 3 2 3 3 3 1 1 1 0\n",
      " 1 1 3 0 1 0 1 0 0 1 0 0 3 0 2 1 0 1 3 2 3 0 0 2 1 1 1 0 1 1 3 0 3 2 1 1 3\n",
      " 1 0 1 1 0 0 3 3 3 2 0 1 0 2 0 3 0 0 2 2 1 1 0 1 2 1 1 0 0 1 0 1 1 3 3 0 1\n",
      " 3 0 2 1 0 2 2 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.2963\n",
      "\n",
      "Consistency: 0.3530\n",
      "Purity: 0.37650000000000006+-0.04277228951085035\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K4_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.959, val_loss=0.0767, avg\n",
      "Epoch 0:  55%|▌| 44/80 [00:01<00:01, 23.67it/s, loss=0.959, val_loss=0.0767, avg\n",
      "Epoch 0:  76%|▊| 61/80 [00:01<00:00, 31.11it/s, loss=0.959, val_loss=0.0767, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.959, val_loss=0.131, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.0563, val_loss=0.131, avg\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:01<00:01, 26.85it/s, loss=0.0563, val_loss=0.131, avg\n",
      "Epoch 1:  85%|▊| 68/80 [00:02<00:00, 33.85it/s, loss=0.0563, val_loss=0.131, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.88it/s, loss=0.0563, val_loss=0.0386, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.0295, val_loss=0.0386, av\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 26.87it/s, loss=0.0295, val_loss=0.0386, av\n",
      "Epoch 2:  85%|▊| 68/80 [00:02<00:00, 33.86it/s, loss=0.0295, val_loss=0.0386, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.93it/s, loss=0.0295, val_loss=0.03, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.0231, val_loss=0.03, avg_\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 26.87it/s, loss=0.0231, val_loss=0.03, avg_\n",
      "Epoch 3:  85%|▊| 68/80 [00:02<00:00, 33.87it/s, loss=0.0231, val_loss=0.03, avg_\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.0231, val_loss=0.0238, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0188, val_loss=0.0238, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 27.32it/s, loss=0.0188, val_loss=0.0238, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:01<00:00, 34.37it/s, loss=0.0188, val_loss=0.0238, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.0188, val_loss=0.0196, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.09it/s, loss=0.0156, val_loss=0.0196, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 27.42it/s, loss=0.0156, val_loss=0.0196, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:01<00:00, 34.52it/s, loss=0.0156, val_loss=0.0196, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.61it/s, loss=0.0156, val_loss=0.0165, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.0133, val_loss=0.0165, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 27.12it/s, loss=0.0133, val_loss=0.0165, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:01<00:00, 34.17it/s, loss=0.0133, val_loss=0.0165, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.0133, val_loss=0.0141, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.0116, val_loss=0.0141, av\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 27.14it/s, loss=0.0116, val_loss=0.0141, av\n",
      "Epoch 7:  85%|▊| 68/80 [00:01<00:00, 34.20it/s, loss=0.0116, val_loss=0.0141, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.0116, val_loss=0.0122, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.0102, val_loss=0.0122, av\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 27.27it/s, loss=0.0102, val_loss=0.0122, av\n",
      "Epoch 8:  85%|▊| 68/80 [00:01<00:00, 34.35it/s, loss=0.0102, val_loss=0.0122, av\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.0102, val_loss=0.0107, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.00919, val_loss=0.0107, a\u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:01<00:01, 27.32it/s, loss=0.00919, val_loss=0.0107, a\n",
      "Epoch 9:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.00919, val_loss=0.0107, a\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.49it/s, loss=0.00919, val_loss=0.00959, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00834, val_loss=0.00959,\u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 27.16it/s, loss=0.00834, val_loss=0.00959,\n",
      "Epoch 10:  85%|▊| 68/80 [00:01<00:00, 34.21it/s, loss=0.00834, val_loss=0.00959,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00834, val_loss=0.00855,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00762, val_loss=0.00855,\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 26.82it/s, loss=0.00762, val_loss=0.00855,\n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 33.80it/s, loss=0.00762, val_loss=0.00855,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 37.84it/s, loss=0.00762, val_loss=0.00765,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.60it/s, loss=0.00701, val_loss=0.00765,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 26.80it/s, loss=0.00701, val_loss=0.00765,\n",
      "Epoch 12:  85%|▊| 68/80 [00:02<00:00, 33.79it/s, loss=0.00701, val_loss=0.00765,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.83it/s, loss=0.00701, val_loss=0.00699,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00653, val_loss=0.00699,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 26.97it/s, loss=0.00653, val_loss=0.00699,\n",
      "Epoch 13:  85%|▊| 68/80 [00:01<00:00, 34.00it/s, loss=0.00653, val_loss=0.00699,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00653, val_loss=0.00641,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.00614, val_loss=0.00641,\u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 27.06it/s, loss=0.00614, val_loss=0.00641,\n",
      "Epoch 14:  85%|▊| 68/80 [00:01<00:00, 34.08it/s, loss=0.00614, val_loss=0.00641,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.17it/s, loss=0.00614, val_loss=0.00597,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00583, val_loss=0.00597,\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 27.10it/s, loss=0.00583, val_loss=0.00597,\n",
      "Epoch 15:  85%|▊| 68/80 [00:01<00:00, 34.15it/s, loss=0.00583, val_loss=0.00597,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00583, val_loss=0.00556,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00555, val_loss=0.00556,\u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:01<00:01, 26.96it/s, loss=0.00555, val_loss=0.00556,\n",
      "Epoch 16:  85%|▊| 68/80 [00:02<00:00, 33.98it/s, loss=0.00555, val_loss=0.00556,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00555, val_loss=0.00523,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.0053, val_loss=0.00523, \u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:01<00:01, 26.95it/s, loss=0.0053, val_loss=0.00523, \n",
      "Epoch 17:  85%|▊| 68/80 [00:02<00:00, 33.99it/s, loss=0.0053, val_loss=0.00523, \u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.0053, val_loss=0.00501, \u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00509, val_loss=0.00501,\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:01<00:01, 26.72it/s, loss=0.00509, val_loss=0.00501,\n",
      "Epoch 18:  85%|▊| 68/80 [00:02<00:00, 33.69it/s, loss=0.00509, val_loss=0.00501,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 37.74it/s, loss=0.00509, val_loss=0.00483,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00492, val_loss=0.00483,\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:01<00:01, 26.91it/s, loss=0.00492, val_loss=0.00483,\n",
      "Epoch 19:  85%|▊| 68/80 [00:02<00:00, 33.92it/s, loss=0.00492, val_loss=0.00483,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.00492, val_loss=0.00466,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00477, val_loss=0.00466,\u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:01<00:01, 27.07it/s, loss=0.00477, val_loss=0.00466,\n",
      "Epoch 20:  85%|▊| 68/80 [00:01<00:00, 34.13it/s, loss=0.00477, val_loss=0.00466,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.00477, val_loss=0.00451,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00466, val_loss=0.00451,\u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:01<00:01, 26.92it/s, loss=0.00466, val_loss=0.00451,\n",
      "Epoch 21:  85%|▊| 68/80 [00:02<00:00, 33.93it/s, loss=0.00466, val_loss=0.00451,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00466, val_loss=0.0043, \u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00454, val_loss=0.0043, \u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:01<00:01, 26.95it/s, loss=0.00454, val_loss=0.0043, \n",
      "Epoch 22:  85%|▊| 68/80 [00:02<00:00, 33.97it/s, loss=0.00454, val_loss=0.0043, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00454, val_loss=0.00413,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00441, val_loss=0.00413,\u001b[A\n",
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 26.98it/s, loss=0.00441, val_loss=0.00413,\n",
      "Epoch 23:  85%|▊| 68/80 [00:02<00:00, 34.00it/s, loss=0.00441, val_loss=0.00413,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00441, val_loss=0.00403,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00432, val_loss=0.00403,\u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 26.98it/s, loss=0.00432, val_loss=0.00403,\n",
      "Epoch 24:  85%|▊| 68/80 [00:01<00:00, 34.02it/s, loss=0.00432, val_loss=0.00403,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.00432, val_loss=0.00393,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.00424, val_loss=0.00393,\u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:01<00:01, 27.36it/s, loss=0.00424, val_loss=0.00393,\n",
      "Epoch 25:  85%|▊| 68/80 [00:01<00:00, 34.45it/s, loss=0.00424, val_loss=0.00393,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.54it/s, loss=0.00424, val_loss=0.00387,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0042, val_loss=0.00387, \u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:01<00:01, 27.27it/s, loss=0.0042, val_loss=0.00387, \n",
      "Epoch 26:  85%|▊| 68/80 [00:01<00:00, 34.34it/s, loss=0.0042, val_loss=0.00387, \u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.0042, val_loss=0.00381, \u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00417, val_loss=0.00381,\u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00417, val_loss=0.00381,\n",
      "Epoch 27:  85%|▊| 68/80 [00:01<00:00, 34.32it/s, loss=0.00417, val_loss=0.00381,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00417, val_loss=0.00369,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00412, val_loss=0.00369,\u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:01<00:01, 27.27it/s, loss=0.00412, val_loss=0.00369,\n",
      "Epoch 28:  85%|▊| 68/80 [00:01<00:00, 34.37it/s, loss=0.00412, val_loss=0.00369,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00412, val_loss=0.00356,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.00402, val_loss=0.00356,\u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:01<00:01, 27.05it/s, loss=0.00402, val_loss=0.00356,\n",
      "Epoch 29:  85%|▊| 68/80 [00:01<00:00, 34.09it/s, loss=0.00402, val_loss=0.00356,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.17it/s, loss=0.00402, val_loss=0.0036, \u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 22.09it/s, loss=0.0039, val_loss=0.0036, a\u001b[A\n",
      "Epoch 30:  64%|▋| 51/80 [00:01<00:01, 27.42it/s, loss=0.0039, val_loss=0.0036, a\n",
      "Epoch 30:  85%|▊| 68/80 [00:01<00:00, 34.52it/s, loss=0.0039, val_loss=0.0036, a\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.62it/s, loss=0.0039, val_loss=0.00365, \u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.0038, val_loss=0.00365, \u001b[A\n",
      "Epoch 31:  64%|▋| 51/80 [00:01<00:01, 27.21it/s, loss=0.0038, val_loss=0.00365, \n",
      "Epoch 31:  85%|▊| 68/80 [00:01<00:00, 34.27it/s, loss=0.0038, val_loss=0.00365, \u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.0038, val_loss=0.00358, \u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00371, val_loss=0.00358,\u001b[A\n",
      "Epoch 32:  64%|▋| 51/80 [00:01<00:01, 27.30it/s, loss=0.00371, val_loss=0.00358,\n",
      "Epoch 32:  85%|▊| 68/80 [00:01<00:00, 34.38it/s, loss=0.00371, val_loss=0.00358,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00371, val_loss=0.00351,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00365, val_loss=0.00351,\u001b[A\n",
      "Epoch 33:  64%|▋| 51/80 [00:01<00:01, 27.15it/s, loss=0.00365, val_loss=0.00351,\n",
      "Epoch 33:  85%|▊| 68/80 [00:01<00:00, 34.20it/s, loss=0.00365, val_loss=0.00351,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00365, val_loss=0.00338,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00363, val_loss=0.00338,\u001b[A\n",
      "Epoch 34:  64%|▋| 51/80 [00:01<00:01, 27.25it/s, loss=0.00363, val_loss=0.00338,\n",
      "Epoch 34:  85%|▊| 68/80 [00:01<00:00, 34.32it/s, loss=0.00363, val_loss=0.00338,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.00363, val_loss=0.00329,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00362, val_loss=0.00329,\u001b[A\n",
      "Epoch 35:  64%|▋| 51/80 [00:01<00:01, 27.22it/s, loss=0.00362, val_loss=0.00329,\n",
      "Epoch 35:  85%|▊| 68/80 [00:01<00:00, 34.29it/s, loss=0.00362, val_loss=0.00329,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00362, val_loss=0.00329,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00359, val_loss=0.00329,\u001b[A\n",
      "Epoch 36:  64%|▋| 51/80 [00:01<00:01, 27.21it/s, loss=0.00359, val_loss=0.00329,\n",
      "Epoch 36:  85%|▊| 68/80 [00:01<00:00, 34.27it/s, loss=0.00359, val_loss=0.00329,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00359, val_loss=0.00335,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00357, val_loss=0.00335,\u001b[A\n",
      "Epoch 37:  64%|▋| 51/80 [00:01<00:01, 27.22it/s, loss=0.00357, val_loss=0.00335,\n",
      "Epoch 37:  85%|▊| 68/80 [00:01<00:00, 34.26it/s, loss=0.00357, val_loss=0.00335,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.00357, val_loss=0.00334,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0036, val_loss=0.00334, \u001b[A\n",
      "Epoch 38:  64%|▋| 51/80 [00:01<00:01, 27.27it/s, loss=0.0036, val_loss=0.00334, \n",
      "Epoch 38:  85%|▊| 68/80 [00:01<00:00, 34.35it/s, loss=0.0036, val_loss=0.00334, \u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.0036, val_loss=0.00324, \u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00364, val_loss=0.00324,\u001b[A\n",
      "Epoch 39:  64%|▋| 51/80 [00:01<00:01, 27.28it/s, loss=0.00364, val_loss=0.00324,\n",
      "Epoch 39:  85%|▊| 68/80 [00:01<00:00, 34.36it/s, loss=0.00364, val_loss=0.00324,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00364, val_loss=0.00303,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00364, val_loss=0.00303,\u001b[A\n",
      "Sizes of clusters: 296, 298, 484, 518, 404\n",
      "\n",
      "preds: [1 4 0 3 3 1 4 4 3 4 0 3 3 4 3 2 1 1 4 2 0 1 0 3 3 1 4 4 3 1 0 3 3 0 3 3 3\n",
      " 0 3 0 3 0 3 2 3 4 0 3 4 3 2 0 0 1 3 2 1 1 4 1 1 1 2 3 2 2 2 0 2 2 1 2 0 3\n",
      " 1 4 1 2 3 2 3 1 3 3 1 3 2 1 0 4 1 3 3 3 2 2 4 3 3 1 0 3 0 0 2 3 3 3 1 0 3\n",
      " 4 3 3 3 1 0 1 1 3 3 3 1 4 3 4 4 4 3 1 3 3 3 4 0 1 4 3 0 0 1 3 0 3 2 3 4 1\n",
      " 3 3 1 2 1 3 4 2 3 4 4 3 0 0 3 2 3 2 3 3 3 3 3 0 3 3 3 3 0 2 0 4 3 3 1 2 1\n",
      " 1 4 3 4 3 3 4 4 3 2 0 3 4 3 3 4 1 2 2 4 3 3 3 3 1 1 2 1 2 3 3 4 3 0 1 2 3\n",
      " 2 3 3 0 3 0 0 3 3 3 3 3 1 0 1 3 1 3 3 2 2 3 4 2 3 3 2 4 4 3 3 3 3 3 3 2 4\n",
      " 1 1 1 1 4 3 2 2 4 0 2 2 3 0 3 2 3 1 4 4 2 3 0 1 2 2 3 4 3 3 2 0 3 4 3 3 3\n",
      " 1 4 2 3 1 1 0 3 1 2 0 3 3 2 3 1 0 3 3 1 3 1 2 2 1 0 3 3 2 3 0 2 0 2 3 0 0\n",
      " 2 1 0 3 2 1 3 1 0 1 2 1 2 3 3 2 3 1 0 3 1 3 4 0 1 4 1 3 3 4 3 3 3 1 3 3 3\n",
      " 3 3 4 3 3 1 2 3 1 0 3 3 3 4 3 3 4 0 1 2 0 3 1 1 2 1 2 2 4 2 4 3 2 2 3 4 4\n",
      " 4 4 4 4 2 2 3 0 0 4 3 2 0 1 4 1 3 1 0 3 4 2 3 0 0 3 4 4 1 3 2 2 1 0 3 4 2\n",
      " 1 4 0 2 4 1 2 4 2 2 0 2 0 1 2 3 2 4 2 4 4 3 4 1 3 4 4 2 0 4 1 4 2 1 0 4 1\n",
      " 1 4 2 2 0 0 0 2 3 0 4 2 2 4 3 2 0 1 1 2 4 0 0 2 0 4 4 2 2 4 1 4 1 4 0 2 4\n",
      " 2 0 2 2 0 2 1 2 3 0 2 0 0 2 4 0 4 4 0 0 4 1 0 3 3 2 2 3 4 3 4 1 0 4 4 1 4\n",
      " 2 4 4 4 0 0 4 4 4 1 2 3 3 4 4 0 2 0 4 0 3 3 0 4 3 3 2 3 4 4 0 3 4 2 1 3 4\n",
      " 1 4 4 4 0 1 2 2 4 4 2 2 1 4 4 1 0 2 1 4 2 1 2 0 3 4 2 4 2 4 2 2 2 4 4 2 1\n",
      " 2 4 4 2 4 3 2 3 3 0 3 4 0 4 2 0 4 3 1 4 4 4 4 4 0 0 1 4 4 3 1 1 3 4 4 4 3\n",
      " 4 4 4 4 4 4 4 2 4 0 4 2 2 3 3 4 4 2 3 0 4 4 0 2 0 4 3 0 4 3 1 4 2 3 1 1 3\n",
      " 4 2 4 4 3 1 3 3 1 4 3 1 1 0 0 0 4 3 4 0 1 2 3 3 3 4 4 4 3 3 2 2 2 2 0 2 2\n",
      " 4 4 1 2 0 4 4 2 4 2 1 4 1 4 1 2 0 2 4 2 4 1 2 4 1 1 4 0 0 2 1 1 2 0 4 4 0\n",
      " 4 2 4 2 2 1 0 0 1 3 1 3 0 4 4 4 2 2 3 2 4 1 3 1 3 2 0 3 3 0 3 0 2 3 1 0 2\n",
      " 2 0 1 4 3 3 2 2 2 3 3 3 3 2 1 0 3 3 3 2 3 0 3 3 4 2 3 0 1 3 2 3 0 0 3 3 3\n",
      " 3 0 0 0 3 1 4 0 3 1 0 1 3 4 3 2 0 2 1 3 3 0 4 2 3 3 1 2 0 1 0 1 4 0 3 2 1\n",
      " 1 4 2 3 3 0 1 3 2 2 1 0 2 2 4 4 3 0 0 3 2 3 1 1 3 0 2 4 2 1 3 3 1 2 4 2 2\n",
      " 1 1 3 4 3 3 3 3 3 2 0 0 4 2 3 3 2 1 4 2 2 0 0 2 3 4 0 3 3 3 4 1 1 4 2 3 0\n",
      " 3 3 4 3 0 2 3 3 3 1 0 0 3 0 2 3 2 2 3 3 1 1 0 1 4 4 2 4 0 2 4 1 2 3 2 0 2\n",
      " 2 2 0 2 0 3 0 3 4 3 2 3 3 3 4 2 1 0 3 3 3 3 1 4 2 3 2 0 3 2 0 0 2 1 1 3 3\n",
      " 2 0 1 3 1 3 3 2 3 2 4 0 3 1 1 0 3 2 2 1 3 0 0 4 2 1 1 3 2 3 0 3 2 0 3 2 1\n",
      " 1 2 0 3 3 0 1 3 0 0 3 3 4 3 3 2 4 4 1 2 0 3 2 1 0 3 3 3 2 2 3 0 3 0 0 2 3\n",
      " 0 4 0 0 3 3 3 1 3 2 2 1 0 3 3 2 3 0 3 1 3 4 1 4 2 4 3 3 3 3 2 0 3 1 1 3 2\n",
      " 2 1 3 2 1 0 2 0 2 3 0 3 0 0 0 0 2 2 0 4 1 4 3 2 1 3 3 2 2 2 3 3 2 0 2 2 3\n",
      " 3 3 3 4 3 1 2 1 0 2 1 2 3 0 3 3 2 4 4 4 4 1 4 4 4 2 2 2 2 3 4 4 2 2 4 1 4\n",
      " 4 2 2 4 2 2 4 4 0 4 2 2 0 1 2 4 2 4 1 4 4 2 4 2 4 2 1 2 2 4 4 2 4 2 2 4 2\n",
      " 4 4 2 2 2 2 2 2 1 2 2 3 2 4 2 1 2 2 2 0 2 4 4 2 2 2 1 4 2 4 1 2 3 2 4 3 2\n",
      " 2 2 0 4 2 3 4 4 2 2 4 4 2 1 3 1 2 4 4 2 4 1 2 4 4 2 1 2 2 2 4 4 2 2 4 2 4\n",
      " 2 4 0 2 4 4 4 2 4 2 2 1 0 1 4 2 4 4 2 0 4 4 0 4 4 4 4 3 1 1 2 0 1 4 1 2 4\n",
      " 4 4 2 1 4 2 2 4 2 0 4 4 2 1 2 4 2 2 4 2 2 1 2 2 1 0 2 2 4 2 4 2 4 2 1 2 2\n",
      " 4 4 4 4 2 2 4 3 2 2 2 4 2 1 1 4 4 1 2 2 2 4 2 2 4 2 2 2 2 4 4 0 2 4 2 2 0\n",
      " 0 1 4 4 2 2 2 2 4 4 3 4 2 4 4 2 4 3 2 4 2 4 2 2 2 2 0 4 4 0 4 2 1 2 2 4 2\n",
      " 2 2 2 1 2 2 0 0 2 2 4 0 0 4 4 1 4 4 4 2 1 2 4 2 2 4 4 2 2 2 2 2 4 2 2 2 2\n",
      " 2 2 0 4 4 1 2 2 4 2 2 1 2 4 2 4 4 4 1 2 1 2 2 2 2 3 4 2 4 2 4 4 1 2 3 0 4\n",
      " 2 4 2 4 2 4 2 2 2 2 3 4 4 1 2 4 2 2 4 2 2 0 2 2 3 2 2 4 4 4 4 4 2 4 2 2 2\n",
      " 4 1 3 4 2 2 3 2 4 3 3 3 1 4 0 1 0 4 0 0 2 3 3 3 2 1 3 2 3 4 1 3 0 3 4 0 0\n",
      " 1 3 1 4 3 1 3 0 0 1 0 2 3 1 3 3 3 2 3 1 1 1 3 3 4 3 0 0 3 3 4 1 3 2 1 0 2\n",
      " 1 2 2 3 4 0 2 0 4 3 1 0 2 4 0 0 2 0 3 3 4 1 3 1 0 4 3 3 1 3 0 1 0 3 3 4 4\n",
      " 1 3 3 3 2 2 3 1 3 1 3 1 3 2 2 1 4 4 3 3 1 2 1 2 3 1 3 3 3 0 1 1 4 3 0 3 3\n",
      " 3 1 0 0 3 3 3 1 0 3 1 0 3 0 4 2 4 2 4 3 2 3 1 3 3 4 3 1 2 0 0 3 2 3 3 1 3\n",
      " 1 2 0 3 3 2 0 1 3 3 3 3 2 3 0 2 1 0 4 2 3 4 0 4 3 1 0 3 2 3 0 2 4 3 3 3 2\n",
      " 3 3 0 3 1 2 1 4 4 3 4 2 3 1 3 3 0 3 1 3 2 2 2 1 4 0 3 1 1 0 1 3 1 3 3 3 4\n",
      " 3 3 0 2 1 4 0 1 0 3 3 3 1 0 0 3 1 3 3 3 0 2 1 3 2 2 0 2 3 3 3 0 3 0 0 3 1\n",
      " 2 3 1 3 1 3 4 4 4 0 4 3 1 0 3 3 3 0 3 4 4 3 3 4 3 0 0 3 1 3 3 4 3 3 1 2 2\n",
      " 0 1 0 2 4 3 2 3 1 3 3 0 1 3 3 3 3 1 4 3 1 2 0 1 1 2 3 2 0 3 3 3 0 3 0 0 0\n",
      " 4 0 3 3 1 0 2 2 1 0 0 2 1 2 2 1 3 0 0 0 3 3 4 3 3 2 3 0 4 3 3 2 3 2 0 3 3\n",
      " 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3145\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.23it/s, loss=0.998, val_loss=0.0795, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  74%|▋| 59/80 [00:02<00:00, 28.37it/s, loss=0.998, val_loss=0.0795, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 35.75it/s, loss=0.998, val_loss=0.115, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0562, val_loss=0.115, avg\u001b[A\n",
      "Epoch 1:  71%|▋| 57/80 [00:01<00:00, 29.85it/s, loss=0.0562, val_loss=0.115, avg\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.30it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.0562, val_loss=0.0422, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.0288, val_loss=0.0422, av\u001b[A\n",
      "Epoch 2:  71%|▋| 57/80 [00:01<00:00, 29.46it/s, loss=0.0288, val_loss=0.0422, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.02it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.0288, val_loss=0.0306, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.0212, val_loss=0.0306, av\u001b[A\n",
      "Epoch 3:  71%|▋| 57/80 [00:01<00:00, 29.89it/s, loss=0.0212, val_loss=0.0306, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.45it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.0212, val_loss=0.0234, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.0167, val_loss=0.0234, av\u001b[A\n",
      "Epoch 4:  71%|▋| 57/80 [00:01<00:00, 28.99it/s, loss=0.0167, val_loss=0.0234, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.19it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 37.43it/s, loss=0.0167, val_loss=0.0187, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.0136, val_loss=0.0187, av\u001b[A\n",
      "Epoch 5:  71%|▋| 57/80 [00:01<00:00, 29.57it/s, loss=0.0136, val_loss=0.0187, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.79it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.0136, val_loss=0.0152, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.47it/s, loss=0.0114, val_loss=0.0152, av\u001b[A\n",
      "Epoch 6:  71%|▋| 57/80 [00:01<00:00, 29.17it/s, loss=0.0114, val_loss=0.0152, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.20it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 37.66it/s, loss=0.0114, val_loss=0.0126, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00981, val_loss=0.0126, a\u001b[A\n",
      "Epoch 7:  71%|▋| 57/80 [00:01<00:00, 29.46it/s, loss=0.00981, val_loss=0.0126, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.17it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00981, val_loss=0.0106, a\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00856, val_loss=0.0106, a\u001b[A\n",
      "Epoch 8:  71%|▋| 57/80 [00:01<00:00, 29.71it/s, loss=0.00856, val_loss=0.0106, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.24it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00856, val_loss=0.00905, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00758, val_loss=0.00905, \u001b[A\n",
      "Epoch 9:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00758, val_loss=0.00905, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.15it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00758, val_loss=0.0079, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.42it/s, loss=0.00677, val_loss=0.0079, \u001b[A\n",
      "Epoch 10:  71%|▋| 57/80 [00:01<00:00, 29.13it/s, loss=0.00677, val_loss=0.0079, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.44it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 37.58it/s, loss=0.00677, val_loss=0.007, a\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00611, val_loss=0.007, a\u001b[A\n",
      "Epoch 11:  71%|▋| 57/80 [00:01<00:00, 29.50it/s, loss=0.00611, val_loss=0.007, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.47it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.00611, val_loss=0.0063, \u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00557, val_loss=0.0063, \u001b[A\n",
      "Epoch 12:  71%|▋| 57/80 [00:01<00:00, 29.45it/s, loss=0.00557, val_loss=0.0063, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.31it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00557, val_loss=0.00574,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00511, val_loss=0.00574,\u001b[A\n",
      "Epoch 13:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00511, val_loss=0.00574,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.33it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00511, val_loss=0.00527,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00473, val_loss=0.00527,\u001b[A\n",
      "Epoch 14:  71%|▋| 57/80 [00:01<00:00, 29.63it/s, loss=0.00473, val_loss=0.00527,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.74it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00473, val_loss=0.00488,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.00442, val_loss=0.00488,\u001b[A\n",
      "Epoch 15:  71%|▋| 57/80 [00:01<00:00, 29.91it/s, loss=0.00442, val_loss=0.00488,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.31it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.50it/s, loss=0.00442, val_loss=0.00454,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00416, val_loss=0.00454,\u001b[A\n",
      "Epoch 16:  71%|▋| 57/80 [00:01<00:00, 29.66it/s, loss=0.00416, val_loss=0.00454,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.43it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.00416, val_loss=0.0043, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00394, val_loss=0.0043, \u001b[A\n",
      "Epoch 17:  71%|▋| 57/80 [00:01<00:00, 29.54it/s, loss=0.00394, val_loss=0.0043, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.93it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00394, val_loss=0.00412,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00375, val_loss=0.00412,\u001b[A\n",
      "Epoch 18:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00375, val_loss=0.00412,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.95it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00375, val_loss=0.00398,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.0036, val_loss=0.00398, \u001b[A\n",
      "Epoch 19:  71%|▋| 57/80 [00:01<00:00, 29.79it/s, loss=0.0036, val_loss=0.00398, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.26it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.0036, val_loss=0.00385, \u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00346, val_loss=0.00385,\u001b[A\n",
      "Epoch 20:  71%|▋| 57/80 [00:01<00:00, 29.85it/s, loss=0.00346, val_loss=0.00385,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.18it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00346, val_loss=0.00369,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.41it/s, loss=0.00335, val_loss=0.00369,\u001b[A\n",
      "Epoch 21:  71%|▋| 57/80 [00:01<00:00, 29.10it/s, loss=0.00335, val_loss=0.00369,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.41it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.55it/s, loss=0.00335, val_loss=0.00354,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00325, val_loss=0.00354,\u001b[A\n",
      "Epoch 22:  71%|▋| 57/80 [00:01<00:00, 29.21it/s, loss=0.00325, val_loss=0.00354,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.54it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00325, val_loss=0.00342,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.00316, val_loss=0.00342,\u001b[A\n",
      "Epoch 23:  71%|▋| 57/80 [00:01<00:00, 29.43it/s, loss=0.00316, val_loss=0.00342,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.95it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00316, val_loss=0.00334,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00308, val_loss=0.00334,\u001b[A\n",
      "Epoch 24:  71%|▋| 57/80 [00:01<00:00, 29.57it/s, loss=0.00308, val_loss=0.00334,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.25it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00308, val_loss=0.00329,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00301, val_loss=0.00329,\u001b[A\n",
      "Epoch 25:  71%|▋| 57/80 [00:01<00:00, 29.60it/s, loss=0.00301, val_loss=0.00329,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.78it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.00301, val_loss=0.00321,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00295, val_loss=0.00321,\u001b[A\n",
      "Epoch 26:  71%|▋| 57/80 [00:01<00:00, 29.83it/s, loss=0.00295, val_loss=0.00321,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.49it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00295, val_loss=0.00313,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00289, val_loss=0.00313,\u001b[A\n",
      "Epoch 27:  71%|▋| 57/80 [00:01<00:00, 29.90it/s, loss=0.00289, val_loss=0.00313,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.25it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.49it/s, loss=0.00289, val_loss=0.00304,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00284, val_loss=0.00304,\u001b[A\n",
      "Epoch 28:  71%|▋| 57/80 [00:01<00:00, 29.65it/s, loss=0.00284, val_loss=0.00304,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.38it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.19it/s, loss=0.00284, val_loss=0.00295,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00279, val_loss=0.00295,\u001b[A\n",
      "Epoch 29:  71%|▋| 57/80 [00:01<00:00, 29.55it/s, loss=0.00279, val_loss=0.00295,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.23it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00279, val_loss=0.00288,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 22.08it/s, loss=0.00275, val_loss=0.00288,\u001b[A\n",
      "Epoch 30:  71%|▋| 57/80 [00:01<00:00, 29.98it/s, loss=0.00275, val_loss=0.00288,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.95it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.62it/s, loss=0.00275, val_loss=0.00282,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00271, val_loss=0.00282,\u001b[A\n",
      "Epoch 31:  71%|▋| 57/80 [00:01<00:00, 29.85it/s, loss=0.00271, val_loss=0.00282,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.56it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00271, val_loss=0.00276,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00267, val_loss=0.00276,\u001b[A\n",
      "Epoch 32:  71%|▋| 57/80 [00:01<00:00, 29.84it/s, loss=0.00267, val_loss=0.00276,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.85it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.00267, val_loss=0.00271,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00263, val_loss=0.00271,\u001b[A\n",
      "Epoch 33:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00263, val_loss=0.00271,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.42it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00263, val_loss=0.00267,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.0026, val_loss=0.00267, \u001b[A\n",
      "Epoch 34:  71%|▋| 57/80 [00:01<00:00, 29.44it/s, loss=0.0026, val_loss=0.00267, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.88it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.0026, val_loss=0.00262, \u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00257, val_loss=0.00262,\u001b[A\n",
      "Epoch 35:  71%|▋| 57/80 [00:01<00:00, 29.18it/s, loss=0.00257, val_loss=0.00262,\n",
      "Validating:  42%|████████████▊                 | 17/40 [00:00<00:00, 167.82it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 37.62it/s, loss=0.00257, val_loss=0.00256,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00254, val_loss=0.00256,\u001b[A\n",
      "Epoch 36:  71%|▋| 57/80 [00:01<00:00, 29.52it/s, loss=0.00254, val_loss=0.00256,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.34it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.00254, val_loss=0.0025, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.35it/s, loss=0.00251, val_loss=0.0025, \u001b[A\n",
      "Epoch 37:  71%|▋| 57/80 [00:01<00:00, 29.02it/s, loss=0.00251, val_loss=0.0025, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.01it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.46it/s, loss=0.00251, val_loss=0.00244,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00249, val_loss=0.00244,\u001b[A\n",
      "Epoch 38:  71%|▋| 57/80 [00:01<00:00, 29.52it/s, loss=0.00249, val_loss=0.00244,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.78it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00249, val_loss=0.00238,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00247, val_loss=0.00238,\u001b[A\n",
      "Epoch 39:  71%|▋| 57/80 [00:01<00:00, 29.47it/s, loss=0.00247, val_loss=0.00238,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.49it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.00247, val_loss=0.00233,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.76it/s, loss=0.00247, val_loss=0.00233,\u001b[A\n",
      "Sizes of clusters: 517, 137, 434, 228, 684\n",
      "\n",
      "preds: [1 4 0 2 0 2 4 4 4 0 0 4 4 4 3 0 4 1 4 2 4 4 4 2 4 4 4 4 4 4 4 2 0 0 4 4 0\n",
      " 0 4 0 0 0 0 1 0 2 4 4 4 0 0 3 0 4 2 2 2 1 4 4 1 0 4 0 4 4 4 2 4 2 2 0 0 4\n",
      " 4 0 4 4 0 4 0 2 4 2 4 4 4 2 0 4 2 4 3 4 1 2 3 2 0 1 4 0 3 2 0 0 2 0 1 4 0\n",
      " 2 2 3 0 4 0 4 2 0 0 0 4 4 4 4 2 2 2 2 0 4 4 2 3 4 4 4 0 4 1 0 4 3 0 0 0 1\n",
      " 0 2 2 2 4 0 2 4 4 2 0 0 0 0 4 4 4 1 3 0 0 4 3 0 2 0 0 0 4 2 3 1 2 0 2 4 1\n",
      " 4 4 2 2 0 4 4 2 3 2 3 0 2 3 4 2 2 4 2 2 4 4 4 0 0 1 4 2 4 2 4 4 0 2 1 2 3\n",
      " 4 3 0 3 2 0 0 4 0 0 3 4 2 3 2 4 1 4 0 0 2 4 4 4 3 0 4 4 2 0 0 0 0 4 4 1 4\n",
      " 4 4 4 2 2 4 2 4 2 3 4 0 4 4 0 2 0 1 4 4 2 0 4 4 2 2 3 4 0 3 1 4 0 2 0 4 2\n",
      " 2 4 2 0 2 2 3 0 4 2 2 2 0 1 0 1 4 2 0 1 0 2 4 2 4 3 0 0 2 0 4 1 0 2 0 2 2\n",
      " 4 2 3 0 1 2 4 4 3 4 1 1 4 0 4 1 0 1 4 0 1 2 4 4 0 4 4 0 0 4 3 4 2 0 0 3 0\n",
      " 2 4 4 3 2 2 4 4 2 0 0 0 0 4 3 2 0 4 2 4 0 0 2 4 4 4 4 2 4 1 4 2 1 1 0 4 2\n",
      " 2 0 2 3 0 4 0 3 4 1 4 2 0 2 4 1 0 2 4 4 0 2 0 3 4 0 4 2 1 0 4 4 1 4 4 2 4\n",
      " 2 2 4 4 0 2 4 2 4 4 0 1 4 4 1 3 4 0 2 4 2 4 4 4 4 4 0 2 0 2 4 0 1 2 0 2 1\n",
      " 4 0 2 2 4 3 3 4 4 0 2 0 0 4 0 4 4 2 1 0 0 0 0 1 3 4 2 4 4 4 1 2 2 4 0 2 4\n",
      " 4 2 2 1 3 0 1 4 0 4 4 4 4 2 2 4 1 4 0 3 2 1 0 4 0 4 4 4 4 4 2 1 0 4 0 2 4\n",
      " 4 4 4 4 4 3 0 4 2 2 4 4 4 2 4 2 4 4 2 3 4 0 0 0 2 0 2 4 0 2 4 4 2 2 4 4 3\n",
      " 2 4 1 4 2 4 4 2 2 4 2 2 2 2 2 1 4 2 1 4 4 2 1 4 2 2 0 2 1 2 2 2 4 4 3 2 4\n",
      " 4 2 0 1 4 4 4 0 4 0 4 2 0 4 1 4 2 0 2 4 2 2 2 4 0 4 4 4 0 0 1 1 4 2 2 4 0\n",
      " 0 4 2 4 4 2 4 2 2 0 2 2 1 0 2 4 2 2 2 0 4 4 3 2 3 2 0 4 2 0 4 2 4 2 2 2 0\n",
      " 0 0 4 2 4 2 3 4 4 4 4 2 2 0 0 0 2 4 4 3 2 2 2 3 4 2 2 4 4 0 2 4 1 4 4 1 0\n",
      " 4 4 2 1 0 1 2 4 4 4 4 0 1 0 2 4 4 0 4 4 3 1 4 2 4 1 4 4 3 2 4 1 2 3 2 4 4\n",
      " 2 2 4 2 4 2 2 0 2 0 1 4 4 2 4 4 2 2 4 4 2 4 0 0 0 0 3 0 3 0 3 3 4 0 4 0 0\n",
      " 3 3 0 0 3 3 4 4 4 3 3 0 4 0 4 0 0 1 4 0 3 0 3 3 3 0 4 0 4 0 0 3 3 3 2 0 3\n",
      " 4 4 4 3 3 0 4 3 3 2 3 0 0 2 3 4 0 3 4 0 3 3 3 2 4 3 2 3 0 4 0 4 0 3 0 4 4\n",
      " 4 4 0 3 0 3 0 3 2 0 2 3 0 3 4 4 0 0 0 3 4 4 0 2 0 2 2 4 4 2 3 0 4 2 3 2 0\n",
      " 4 1 0 4 3 3 0 3 3 4 3 0 3 3 0 3 3 4 4 2 3 3 4 0 0 4 3 3 0 0 4 0 4 4 3 0 3\n",
      " 3 3 4 3 3 4 0 2 3 3 3 0 0 3 4 0 0 4 4 3 1 4 3 2 0 4 0 0 3 2 0 1 4 0 0 0 0\n",
      " 3 4 3 0 3 0 0 0 4 0 0 0 0 3 4 4 2 3 0 3 0 0 0 2 0 0 0 0 0 0 3 0 2 4 2 3 0\n",
      " 4 4 4 3 0 3 0 4 4 0 4 4 3 0 3 3 3 4 0 4 0 3 4 4 0 4 1 3 4 0 3 4 2 4 3 2 3\n",
      " 3 0 3 3 0 0 4 0 4 3 3 3 4 0 0 0 2 2 4 3 3 3 0 4 3 0 3 3 4 2 0 0 3 3 4 4 0\n",
      " 0 4 3 3 3 0 3 4 0 0 4 0 0 3 3 2 3 0 2 4 0 3 3 3 0 3 0 3 0 3 0 3 3 2 4 3 0\n",
      " 4 0 3 4 4 3 4 3 2 3 0 3 0 3 2 4 0 4 3 3 4 4 0 3 0 3 3 2 4 3 3 3 0 3 1 3 4\n",
      " 0 0 0 0 2 2 2 2 0 2 4 2 0 0 2 0 2 0 0 4 4 4 3 4 2 4 1 4 0 4 4 0 4 2 0 4 0\n",
      " 4 0 0 4 0 4 4 0 4 4 4 2 0 2 1 3 0 4 2 4 3 0 4 2 4 2 4 1 2 0 4 1 0 4 2 4 4\n",
      " 4 0 2 4 4 2 4 2 4 4 4 3 0 4 0 2 0 2 0 2 0 4 1 0 0 1 4 4 2 4 0 0 3 0 2 0 2\n",
      " 4 4 0 4 4 2 2 0 0 4 4 4 2 2 3 4 0 0 0 2 4 4 2 4 3 0 2 4 0 4 4 4 3 0 2 2 4\n",
      " 0 4 0 4 4 4 4 3 4 2 2 4 0 2 2 2 0 4 0 0 0 2 0 4 2 2 3 0 4 1 4 2 4 4 2 4 1\n",
      " 4 4 0 1 3 4 3 4 2 4 4 3 0 0 4 4 4 2 0 0 0 1 0 0 4 4 3 0 0 0 0 4 0 4 4 4 0\n",
      " 2 4 4 2 4 0 4 3 0 2 2 0 4 0 0 0 3 1 0 4 3 2 2 1 2 0 0 0 2 4 4 3 4 0 2 0 0\n",
      " 0 1 0 4 2 2 0 2 3 2 3 4 4 2 4 2 4 0 2 4 0 0 2 4 4 0 0 0 0 0 4 3 4 2 4 2 2\n",
      " 4 0 1 1 2 4 0 0 2 2 3 0 3 3 0 2 4 0 0 0 2 2 4 2 4 4 0 0 2 2 4 4 2 4 0 2 0\n",
      " 0 0 2 4 4 4 0 2 4 2 0 1 4 4 3 4 0 0 4 0 1 4 2 1 0 4 4 4 1 4 4 0 4 0 4 4 0\n",
      " 3 0 1 0 0 4 2 2 0 4 2 2 4 1 0 4 2 2 1 0 4 0 1 0 0 0 0 3 4 2 4 4 4 4 2 4 2\n",
      " 4 3 3 0 4 0 0 2 4 0 3 4 1 4 4 2 0 4 0 4 2 2 0 0 4 4 0 2 0 4 4 0 3 4 0 2 0\n",
      " 1 0 1 1 0 2 2 4 4 4 0 4 4 1 0 4 0 1 4 2 2 4 2 0 2 0 3 4 1 0 1 4 0 2 2 2 2\n",
      " 4 1 2 0 4 4 0 4 2 2 1 0 1 4 0 3 4 4 3 2 2 2 0 4 2 4 2 4 4 4 0 4 2 0 4 2 2\n",
      " 4 4 1 0 0 2 3 4 4 2 3 1 2 4 0 2 4 2 0 2 1 1 1 1 4 1 4 0 0 3 2 4 4 0 4 2 4\n",
      " 4 1 4 4 0 0 4 2 4 3 1 4 0 4 2 1 4 1 2 2 4 2 3 4 0 4 0 2 4 4 2 2 4 0 2 1 4\n",
      " 4 4 4 0 0 1 0 2 0 4 4 4 2 4 0 1 1 4 4 4 0 2 4 4 4 1 4 2 4 4 4 2 4 2 4 2 1\n",
      " 3 2 2 0 4 4 1 4 4 4 4 4 2 2 2 3 0 2 1 4 2 4 2 4 4 4 4 1 1 3 4 2 4 4 0 0 4\n",
      " 4 0 4 2 2 4 2 4 0 2 2 0 2 0 4 0 1 4 0 4 4 2 4 4 2 2 0 2 2 2 0 2 0 2 0 2 1\n",
      " 2 0 4 4 2 0 4 4 4 4 2 0 1 0 0 0 0 2 4 4 2 4 2 2 4 0 0 1 1 2 4 4 3 3 4 4 1\n",
      " 4 0 4 4 0 0 4 4 4 0 2 2 4 4 0 2 2 4 4 2 2 2 4 2 2 4 0 1 2 4 4 4 0 4 0 0 4\n",
      " 4 4 3 3 2 0 4 4 2 4 0 4 4 4 1 4 0 4 2 0 0 2 4 2 2 2 0 4 4 2 0 4 0 4 4 1 0\n",
      " 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.2875\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.735, val_loss=0.0651, avg\n",
      "Epoch 0:  52%|▌| 42/80 [00:01<00:01, 22.76it/s, loss=0.735, val_loss=0.0651, avg\n",
      "Epoch 0:  75%|▊| 60/80 [00:01<00:00, 30.73it/s, loss=0.735, val_loss=0.0651, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.735, val_loss=0.32, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.0471, val_loss=0.32, avg_\u001b[A\n",
      "Epoch 1:  68%|▋| 54/80 [00:01<00:00, 28.00it/s, loss=0.0471, val_loss=0.32, avg_\n",
      "Epoch 1:  90%|▉| 72/80 [00:02<00:00, 35.23it/s, loss=0.0471, val_loss=0.32, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 37.74it/s, loss=0.0471, val_loss=0.0429, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.25it/s, loss=0.0255, val_loss=0.0429, av\u001b[A\n",
      "Epoch 2:  68%|▋| 54/80 [00:01<00:00, 27.64it/s, loss=0.0255, val_loss=0.0429, av\n",
      "Epoch 2:  90%|▉| 72/80 [00:02<00:00, 34.79it/s, loss=0.0255, val_loss=0.0429, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.30it/s, loss=0.0255, val_loss=0.0263, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.019, val_loss=0.0263, avg\u001b[A\n",
      "Epoch 3:  68%|▋| 54/80 [00:01<00:00, 28.11it/s, loss=0.019, val_loss=0.0263, avg\n",
      "Epoch 3:  90%|▉| 72/80 [00:02<00:00, 35.34it/s, loss=0.019, val_loss=0.0263, avg\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 37.87it/s, loss=0.019, val_loss=0.0208, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.02it/s, loss=0.0152, val_loss=0.0208, av\u001b[A\n",
      "Epoch 4:  68%|▋| 54/80 [00:01<00:00, 27.37it/s, loss=0.0152, val_loss=0.0208, av\n",
      "Epoch 4:  90%|▉| 72/80 [00:02<00:00, 34.46it/s, loss=0.0152, val_loss=0.0208, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 36.95it/s, loss=0.0152, val_loss=0.0168, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.0126, val_loss=0.0168, av\u001b[A\n",
      "Epoch 5:  68%|▋| 54/80 [00:01<00:00, 28.40it/s, loss=0.0126, val_loss=0.0168, av\n",
      "Epoch 5:  90%|▉| 72/80 [00:02<00:00, 35.69it/s, loss=0.0126, val_loss=0.0168, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.0126, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.50it/s, loss=0.0109, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.0109, val_loss=0.0141, av\n",
      "Epoch 6:  90%|▉| 72/80 [00:02<00:00, 35.16it/s, loss=0.0109, val_loss=0.0141, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 37.65it/s, loss=0.0109, val_loss=0.0116, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00968, val_loss=0.0116, a\u001b[A\n",
      "Epoch 7:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00968, val_loss=0.0116, a\n",
      "Epoch 7:  90%|▉| 72/80 [00:02<00:00, 35.55it/s, loss=0.00968, val_loss=0.0116, a\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00968, val_loss=0.0101, a\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00877, val_loss=0.0101, a\u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:01<00:00, 28.34it/s, loss=0.00877, val_loss=0.0101, a\n",
      "Epoch 8:  90%|▉| 72/80 [00:02<00:00, 35.62it/s, loss=0.00877, val_loss=0.0101, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.00877, val_loss=0.00902, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00805, val_loss=0.00902, \u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:01<00:00, 28.26it/s, loss=0.00805, val_loss=0.00902, \n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 35.51it/s, loss=0.00805, val_loss=0.00902, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.00805, val_loss=0.00842, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00744, val_loss=0.00842,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:01<00:00, 28.51it/s, loss=0.00744, val_loss=0.00842,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 35.81it/s, loss=0.00744, val_loss=0.00842,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00744, val_loss=0.00752,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00691, val_loss=0.00752,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00691, val_loss=0.00752,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00691, val_loss=0.00752,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00691, val_loss=0.00726,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.57it/s, loss=0.00646, val_loss=0.00726,\u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:01<00:00, 28.03it/s, loss=0.00646, val_loss=0.00726,\n",
      "Epoch 12:  90%|▉| 72/80 [00:02<00:00, 35.25it/s, loss=0.00646, val_loss=0.00726,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.77it/s, loss=0.00646, val_loss=0.00701,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00607, val_loss=0.00701,\u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:01<00:00, 28.21it/s, loss=0.00607, val_loss=0.00701,\n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 35.46it/s, loss=0.00607, val_loss=0.00701,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.00607, val_loss=0.00612,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.62it/s, loss=0.00574, val_loss=0.00612,\u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 28.12it/s, loss=0.00574, val_loss=0.00612,\n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 35.36it/s, loss=0.00574, val_loss=0.00612,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.88it/s, loss=0.00574, val_loss=0.00588,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00545, val_loss=0.00588,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:01<00:00, 28.49it/s, loss=0.00545, val_loss=0.00588,\n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 35.78it/s, loss=0.00545, val_loss=0.00588,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.00545, val_loss=0.00552,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00519, val_loss=0.00552,\u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:01<00:00, 27.94it/s, loss=0.00519, val_loss=0.00552,\n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 35.15it/s, loss=0.00519, val_loss=0.00552,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.66it/s, loss=0.00519, val_loss=0.0057, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00495, val_loss=0.0057, \u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:01<00:00, 28.10it/s, loss=0.00495, val_loss=0.0057, \n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00495, val_loss=0.0057, \u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.00495, val_loss=0.00561,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.35it/s, loss=0.00475, val_loss=0.00561,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:01<00:00, 27.76it/s, loss=0.00475, val_loss=0.00561,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 34.96it/s, loss=0.00475, val_loss=0.00561,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 37.47it/s, loss=0.00475, val_loss=0.00509,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00455, val_loss=0.00509,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:01<00:00, 28.16it/s, loss=0.00455, val_loss=0.00509,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 35.43it/s, loss=0.00455, val_loss=0.00509,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00455, val_loss=0.00517,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.00439, val_loss=0.00517,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:01<00:00, 27.83it/s, loss=0.00439, val_loss=0.00517,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 35.02it/s, loss=0.00439, val_loss=0.00517,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 37.52it/s, loss=0.00439, val_loss=0.00473,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00423, val_loss=0.00473,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:01<00:00, 28.16it/s, loss=0.00423, val_loss=0.00473,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 35.41it/s, loss=0.00423, val_loss=0.00473,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.93it/s, loss=0.00423, val_loss=0.00522,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.00411, val_loss=0.00522,\u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 27.97it/s, loss=0.00411, val_loss=0.00522,\n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 35.18it/s, loss=0.00411, val_loss=0.00522,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.47it/s, loss=0.00411, val_loss=0.00574,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.61it/s, loss=0.00398, val_loss=0.00574,\u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 28.09it/s, loss=0.00398, val_loss=0.00574,\n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 35.35it/s, loss=0.00398, val_loss=0.00574,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.87it/s, loss=0.00398, val_loss=0.00446,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.36it/s, loss=0.00389, val_loss=0.00446,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 27.79it/s, loss=0.00389, val_loss=0.00446,\n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 34.98it/s, loss=0.00389, val_loss=0.00446,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.47it/s, loss=0.00389, val_loss=0.0042, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00378, val_loss=0.0042, \u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.00378, val_loss=0.0042, \n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.00378, val_loss=0.0042, \u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.00378, val_loss=0.00478,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00371, val_loss=0.00478,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.00371, val_loss=0.00478,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 35.15it/s, loss=0.00371, val_loss=0.00478,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 37.66it/s, loss=0.00371, val_loss=0.00487,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.80it/s, loss=0.00363, val_loss=0.00487,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:01<00:00, 28.35it/s, loss=0.00363, val_loss=0.00487,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 35.61it/s, loss=0.00363, val_loss=0.00487,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00363, val_loss=0.00446,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00358, val_loss=0.00446,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:01<00:00, 28.25it/s, loss=0.00358, val_loss=0.00446,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 35.51it/s, loss=0.00358, val_loss=0.00446,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00358, val_loss=0.00452,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00352, val_loss=0.00452,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 28.37it/s, loss=0.00352, val_loss=0.00452,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 35.65it/s, loss=0.00352, val_loss=0.00452,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.18it/s, loss=0.00352, val_loss=0.00469,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00347, val_loss=0.00469,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 28.20it/s, loss=0.00347, val_loss=0.00469,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 35.45it/s, loss=0.00347, val_loss=0.00469,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00347, val_loss=0.00436,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00342, val_loss=0.00436,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00342, val_loss=0.00436,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 35.55it/s, loss=0.00342, val_loss=0.00436,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00342, val_loss=0.00425,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00338, val_loss=0.00425,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:01<00:00, 28.32it/s, loss=0.00338, val_loss=0.00425,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00338, val_loss=0.00425,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.00338, val_loss=0.00478,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.00331, val_loss=0.00478,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00331, val_loss=0.00478,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 35.65it/s, loss=0.00331, val_loss=0.00478,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00331, val_loss=0.00448,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00324, val_loss=0.00448,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.00324, val_loss=0.00448,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00324, val_loss=0.00448,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00324, val_loss=0.00385,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.50it/s, loss=0.00316, val_loss=0.00385,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.00316, val_loss=0.00385,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 35.19it/s, loss=0.00316, val_loss=0.00385,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 37.70it/s, loss=0.00316, val_loss=0.00422,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00311, val_loss=0.00422,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.00311, val_loss=0.00422,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00311, val_loss=0.00422,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00311, val_loss=0.00389,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00306, val_loss=0.00389,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 27.98it/s, loss=0.00306, val_loss=0.00389,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 35.19it/s, loss=0.00306, val_loss=0.00389,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00306, val_loss=0.00414,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00302, val_loss=0.00414,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:01<00:00, 28.20it/s, loss=0.00302, val_loss=0.00414,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00302, val_loss=0.00414,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00302, val_loss=0.00384,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00297, val_loss=0.00384,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 28.18it/s, loss=0.00297, val_loss=0.00384,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 35.44it/s, loss=0.00297, val_loss=0.00384,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00297, val_loss=0.0038, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.70it/s, loss=0.00297, val_loss=0.0038, \u001b[A\n",
      "Sizes of clusters: 414, 261, 548, 243, 534\n",
      "\n",
      "preds: [1 0 0 4 4 1 2 3 4 3 2 4 1 0 4 4 4 1 3 2 2 4 2 4 4 1 0 0 4 4 2 2 4 3 4 4 4\n",
      " 0 1 0 4 4 4 2 4 2 2 4 0 4 0 3 2 4 4 2 1 1 3 4 1 1 2 4 2 2 2 4 4 4 1 0 2 4\n",
      " 1 3 4 2 4 2 4 1 1 4 1 4 2 1 3 0 1 4 4 4 1 2 0 4 0 2 2 4 0 2 0 4 4 4 1 4 4\n",
      " 2 4 4 4 4 0 4 2 4 4 1 1 0 4 0 2 2 4 1 4 1 1 2 0 4 0 4 0 0 4 4 2 1 0 1 3 1\n",
      " 4 1 1 0 4 4 3 2 4 2 3 4 0 0 2 2 1 2 4 4 4 4 0 0 4 1 4 4 2 4 4 2 4 4 4 2 1\n",
      " 4 0 4 2 4 4 0 2 4 2 0 1 2 4 4 2 1 2 2 2 4 1 1 4 1 1 2 1 2 2 1 2 4 2 1 2 4\n",
      " 2 1 4 4 4 0 2 4 1 4 4 4 1 0 2 1 1 4 4 4 4 1 0 2 2 1 2 0 2 4 4 4 1 4 1 2 3\n",
      " 4 1 4 1 2 4 4 2 2 0 2 4 1 4 4 2 4 1 0 2 0 4 2 4 2 2 4 0 4 4 1 2 4 2 4 4 4\n",
      " 1 0 2 0 1 1 0 4 4 2 4 4 4 2 1 2 2 1 4 2 4 1 2 2 4 0 4 4 2 4 4 2 0 2 4 2 2\n",
      " 2 1 4 4 2 1 4 4 0 4 2 1 2 4 0 2 4 1 2 4 1 4 0 2 1 0 4 4 4 3 4 1 4 1 4 0 4\n",
      " 4 1 4 4 4 1 2 1 1 2 4 4 4 0 4 4 0 2 1 2 0 4 1 4 2 1 4 2 0 2 4 1 2 2 1 2 2\n",
      " 2 3 2 3 0 4 4 4 2 2 4 2 2 1 2 1 1 1 2 1 3 2 1 2 4 4 3 2 1 4 2 2 1 2 1 2 2\n",
      " 1 2 2 2 2 1 2 2 2 2 2 2 2 1 2 0 2 2 1 0 2 1 3 1 4 2 2 2 2 2 1 3 2 1 2 2 1\n",
      " 1 2 2 1 3 0 3 2 4 2 2 4 4 2 4 2 4 1 1 4 3 4 2 1 3 2 2 2 2 3 1 2 2 0 2 2 2\n",
      " 2 2 2 2 4 4 1 2 4 2 2 2 2 1 2 2 2 0 2 3 2 1 2 4 4 2 2 4 3 4 3 1 2 2 2 1 2\n",
      " 2 3 2 2 2 4 2 3 2 2 2 1 1 2 3 2 2 2 2 2 4 1 4 3 4 1 2 4 2 3 4 4 2 1 1 1 2\n",
      " 1 3 2 3 2 1 2 4 2 2 2 2 1 2 2 1 2 2 1 2 2 1 2 2 4 2 4 2 2 2 2 4 2 2 3 2 4\n",
      " 2 2 3 2 0 4 2 1 1 3 1 2 2 0 2 2 2 1 1 2 2 2 2 3 2 2 1 0 2 4 1 1 4 2 2 3 4\n",
      " 3 2 2 2 3 2 2 2 2 2 2 1 2 4 1 4 3 2 4 2 2 2 0 2 3 2 4 2 2 4 1 2 2 4 1 1 4\n",
      " 2 4 2 2 1 2 2 1 4 2 1 1 1 2 2 2 2 4 2 4 1 2 4 4 1 2 2 4 1 4 2 2 2 2 2 2 4\n",
      " 0 2 1 2 2 2 2 2 2 2 1 2 1 2 1 2 4 4 2 2 2 1 2 3 4 1 2 2 0 2 1 1 2 3 2 0 2\n",
      " 3 1 2 2 2 2 4 2 1 4 1 4 2 2 2 3 2 2 2 2 2 1 4 4 0 0 0 0 0 3 0 0 4 4 1 3 0\n",
      " 0 3 2 3 0 0 2 2 0 0 3 0 4 3 4 2 4 2 1 0 0 3 0 0 3 0 4 2 4 4 0 0 3 3 4 4 0\n",
      " 0 0 0 3 0 0 0 0 0 4 0 0 4 2 3 0 0 3 4 0 4 0 3 2 1 0 1 0 3 4 0 4 3 3 4 4 4\n",
      " 1 0 3 4 4 0 1 4 2 0 4 0 3 0 3 3 4 0 0 0 2 0 0 1 4 4 2 3 2 4 4 1 4 3 3 0 0\n",
      " 4 2 4 3 0 0 4 0 4 2 0 2 3 3 0 3 0 4 3 2 0 0 2 0 0 0 3 0 0 4 3 4 4 3 3 0 3\n",
      " 0 4 2 0 0 2 4 4 4 0 3 2 0 3 2 0 0 2 2 3 1 0 3 4 3 3 3 3 3 0 3 1 0 4 3 0 3\n",
      " 3 0 3 0 3 0 3 1 0 4 0 0 0 0 3 2 1 0 0 0 4 4 0 2 0 0 0 0 4 0 3 0 2 0 1 0 4\n",
      " 0 2 4 0 4 3 0 2 2 3 0 2 0 4 4 3 0 2 4 4 0 0 0 0 3 4 1 0 3 0 3 4 2 2 0 2 0\n",
      " 4 0 0 0 0 3 1 4 2 3 4 4 0 4 0 2 2 2 1 3 3 0 3 0 0 4 0 4 2 2 0 3 0 3 2 2 4\n",
      " 3 3 0 3 0 4 0 4 0 0 2 0 0 4 0 2 0 0 4 4 0 3 0 3 0 3 4 0 4 4 3 3 4 1 4 4 3\n",
      " 0 0 3 2 4 3 2 3 2 3 3 0 3 0 2 0 0 2 3 3 4 0 0 0 4 0 4 2 3 0 0 4 0 3 2 0 4\n",
      " 0 4 4 3 2 1 2 1 0 2 4 2 4 0 2 4 4 0 3 0 3 4 3 0 3 3 2 0 0 4 0 0 0 0 3 4 3\n",
      " 3 0 4 0 4 4 2 3 2 3 2 2 4 4 2 3 0 0 1 0 0 0 2 2 2 2 4 2 4 0 3 2 3 2 1 3 3\n",
      " 0 3 1 3 3 2 2 4 4 0 2 0 0 2 0 1 2 2 2 4 0 0 2 0 0 2 4 3 0 0 4 0 4 0 0 4 4\n",
      " 3 4 2 3 4 4 3 3 0 4 2 0 2 1 4 4 0 0 0 4 3 4 4 0 3 0 2 0 0 3 0 0 0 0 3 3 3\n",
      " 0 3 0 3 3 3 0 0 0 2 3 4 3 2 0 2 0 3 0 0 0 3 0 3 3 2 3 4 4 1 4 4 4 0 4 2 2\n",
      " 0 2 0 1 3 0 0 3 4 0 0 3 0 4 4 0 0 4 3 0 0 2 2 3 4 2 4 3 0 0 3 4 3 4 4 0 0\n",
      " 3 0 0 0 0 0 3 4 0 2 4 3 3 0 0 0 0 2 0 2 0 0 2 2 2 3 2 0 4 0 0 0 4 3 2 2 0\n",
      " 3 2 4 2 4 0 0 2 3 3 4 2 0 3 3 4 3 4 1 2 0 3 4 4 0 0 0 3 3 2 3 0 4 4 3 0 2\n",
      " 3 0 2 1 2 0 3 0 2 4 3 0 0 0 3 0 3 2 3 0 1 2 0 4 3 2 3 0 2 2 2 4 3 3 0 4 0\n",
      " 0 0 4 2 0 4 0 4 0 4 0 1 0 3 0 2 3 3 4 0 1 4 4 1 0 0 2 4 2 3 2 3 4 0 1 0 3\n",
      " 0 3 2 3 0 3 4 2 0 0 4 0 3 1 0 0 4 2 2 0 2 0 2 0 4 0 0 0 3 0 0 0 2 4 4 4 0\n",
      " 0 4 4 0 0 2 4 4 3 4 4 1 1 0 2 4 0 3 2 2 0 4 1 4 2 4 1 2 4 0 1 4 0 4 3 2 4\n",
      " 1 4 1 2 0 2 4 2 0 4 3 2 4 1 4 4 4 2 4 1 1 1 4 4 2 4 0 2 1 4 2 4 4 2 1 2 2\n",
      " 1 2 0 0 0 4 0 2 2 4 1 2 2 0 0 0 2 3 4 1 2 1 4 1 4 3 4 4 4 4 2 4 4 4 1 3 2\n",
      " 4 2 4 0 0 2 0 4 1 1 4 1 4 2 0 1 3 2 1 4 1 1 1 1 1 1 4 4 4 3 1 4 0 4 2 2 4\n",
      " 4 1 2 2 4 4 4 1 2 4 1 2 4 0 3 2 2 2 3 4 2 4 0 1 0 0 4 1 4 2 2 4 2 4 4 1 4\n",
      " 4 2 2 4 4 2 3 1 4 1 4 4 2 4 0 2 1 2 0 4 4 2 2 3 1 1 2 4 2 4 4 2 3 4 4 4 2\n",
      " 0 1 2 4 4 2 2 0 3 4 3 2 1 1 4 0 0 4 1 4 2 2 2 4 3 2 1 4 1 0 4 4 1 4 4 4 3\n",
      " 1 4 2 2 1 3 2 1 0 4 4 4 1 2 2 4 1 4 4 4 2 2 1 4 2 2 0 4 4 4 4 2 4 4 0 4 1\n",
      " 2 0 4 1 1 4 3 0 0 0 2 4 1 0 4 1 4 2 4 0 0 4 4 3 1 0 3 1 1 4 1 0 4 0 4 2 2\n",
      " 2 2 2 2 3 4 2 1 4 4 4 4 4 1 4 4 4 4 3 4 1 2 2 1 1 2 0 2 2 4 4 1 2 4 0 3 2\n",
      " 0 2 4 0 1 0 2 2 2 2 2 2 4 2 4 4 4 0 4 2 4 4 0 4 4 2 1 2 0 1 4 2 4 2 2 2 4\n",
      " 2 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3455\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.551, val_loss=0.0686, avg\n",
      "Epoch 0:  65%|▋| 52/80 [00:01<00:01, 27.81it/s, loss=0.551, val_loss=0.0686, avg\n",
      "Epoch 0:  85%|▊| 68/80 [00:01<00:00, 34.47it/s, loss=0.551, val_loss=0.0686, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.56it/s, loss=0.551, val_loss=0.092, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0467, val_loss=0.092, avg\u001b[A\n",
      "Epoch 1:  60%|▌| 48/80 [00:01<00:01, 25.93it/s, loss=0.0467, val_loss=0.092, avg\n",
      "Epoch 1:  81%|▊| 65/80 [00:01<00:00, 33.23it/s, loss=0.0467, val_loss=0.092, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.0467, val_loss=0.037, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0275, val_loss=0.037, avg\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 27.32it/s, loss=0.0275, val_loss=0.037, avg\n",
      "Epoch 2:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.0275, val_loss=0.037, avg\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.0275, val_loss=0.0283, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.0215, val_loss=0.0283, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 27.17it/s, loss=0.0215, val_loss=0.0283, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:01<00:00, 34.24it/s, loss=0.0215, val_loss=0.0283, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.0215, val_loss=0.0227, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 22.02it/s, loss=0.0178, val_loss=0.0227, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 27.33it/s, loss=0.0178, val_loss=0.0227, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:01<00:00, 34.42it/s, loss=0.0178, val_loss=0.0227, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.0178, val_loss=0.019, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.17it/s, loss=0.015, val_loss=0.019, avg_\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 27.51it/s, loss=0.015, val_loss=0.019, avg_\n",
      "Epoch 5:  85%|▊| 68/80 [00:01<00:00, 34.64it/s, loss=0.015, val_loss=0.019, avg_\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.75it/s, loss=0.015, val_loss=0.0162, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 22.06it/s, loss=0.0129, val_loss=0.0162, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 27.38it/s, loss=0.0129, val_loss=0.0162, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:01<00:00, 34.48it/s, loss=0.0129, val_loss=0.0162, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.0129, val_loss=0.0139, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.27it/s, loss=0.0111, val_loss=0.0139, av\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 26.26it/s, loss=0.0111, val_loss=0.0139, av\n",
      "Epoch 7:  86%|▊| 69/80 [00:02<00:00, 33.69it/s, loss=0.0111, val_loss=0.0139, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.34it/s, loss=0.0111, val_loss=0.0119, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00963, val_loss=0.0119, a\u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00963, val_loss=0.0119, a\n",
      "Epoch 8:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00963, val_loss=0.0119, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00963, val_loss=0.0103, a\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00843, val_loss=0.0103, a\u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:01<00:00, 28.18it/s, loss=0.00843, val_loss=0.0103, a\n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 35.41it/s, loss=0.00843, val_loss=0.0103, a\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00843, val_loss=0.00899, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.52it/s, loss=0.00748, val_loss=0.00899,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:01<00:00, 27.98it/s, loss=0.00748, val_loss=0.00899,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 35.19it/s, loss=0.00748, val_loss=0.00899,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00748, val_loss=0.00789,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00671, val_loss=0.00789,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:01<00:00, 28.21it/s, loss=0.00671, val_loss=0.00789,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00671, val_loss=0.00789,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00671, val_loss=0.00701,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.44it/s, loss=0.00608, val_loss=0.00701,\u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:01<00:00, 27.89it/s, loss=0.00608, val_loss=0.00701,\n",
      "Epoch 12:  90%|▉| 72/80 [00:02<00:00, 35.10it/s, loss=0.00608, val_loss=0.00701,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.61it/s, loss=0.00608, val_loss=0.00625,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00557, val_loss=0.00625,\u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:01<00:00, 28.18it/s, loss=0.00557, val_loss=0.00625,\n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 35.41it/s, loss=0.00557, val_loss=0.00625,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00557, val_loss=0.00565,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.32it/s, loss=0.00516, val_loss=0.00565,\u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 27.72it/s, loss=0.00516, val_loss=0.00565,\n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 34.89it/s, loss=0.00516, val_loss=0.00565,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.39it/s, loss=0.00516, val_loss=0.00523,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00483, val_loss=0.00523,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:01<00:00, 28.52it/s, loss=0.00483, val_loss=0.00523,\n",
      "Epoch 15:  90%|▉| 72/80 [00:02<00:00, 35.82it/s, loss=0.00483, val_loss=0.00523,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00483, val_loss=0.00491,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.55it/s, loss=0.00457, val_loss=0.00491,\u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:01<00:00, 28.03it/s, loss=0.00457, val_loss=0.00491,\n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 35.25it/s, loss=0.00457, val_loss=0.00491,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.77it/s, loss=0.00457, val_loss=0.00465,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00437, val_loss=0.00465,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:01<00:00, 28.27it/s, loss=0.00437, val_loss=0.00465,\n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 35.56it/s, loss=0.00437, val_loss=0.00465,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00437, val_loss=0.00443,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00421, val_loss=0.00443,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00421, val_loss=0.00443,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 35.57it/s, loss=0.00421, val_loss=0.00443,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.00421, val_loss=0.00424,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.00407, val_loss=0.00424,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.00407, val_loss=0.00424,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 35.20it/s, loss=0.00407, val_loss=0.00424,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00407, val_loss=0.00407,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00395, val_loss=0.00407,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:01<00:00, 28.17it/s, loss=0.00395, val_loss=0.00407,\n",
      "Epoch 20:  90%|▉| 72/80 [00:02<00:00, 35.42it/s, loss=0.00395, val_loss=0.00407,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00395, val_loss=0.00396,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.48it/s, loss=0.00385, val_loss=0.00396,\u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:01<00:00, 27.95it/s, loss=0.00385, val_loss=0.00396,\n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 35.15it/s, loss=0.00385, val_loss=0.00396,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00385, val_loss=0.00383,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00377, val_loss=0.00383,\u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 28.31it/s, loss=0.00377, val_loss=0.00383,\n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00377, val_loss=0.00383,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00377, val_loss=0.00372,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.0037, val_loss=0.00372, \u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.0037, val_loss=0.00372, \n",
      "Epoch 23:  90%|▉| 72/80 [00:02<00:00, 35.57it/s, loss=0.0037, val_loss=0.00372, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.0037, val_loss=0.00364, \u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.00364, val_loss=0.00364,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 27.75it/s, loss=0.00364, val_loss=0.00364,\n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 34.93it/s, loss=0.00364, val_loss=0.00364,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.45it/s, loss=0.00364, val_loss=0.00353,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00358, val_loss=0.00353,\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 28.54it/s, loss=0.00358, val_loss=0.00353,\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 35.87it/s, loss=0.00358, val_loss=0.00353,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00358, val_loss=0.00348,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00353, val_loss=0.00348,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:01<00:00, 28.22it/s, loss=0.00353, val_loss=0.00348,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 35.49it/s, loss=0.00353, val_loss=0.00348,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.00353, val_loss=0.00341,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00349, val_loss=0.00341,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:01<00:00, 28.28it/s, loss=0.00349, val_loss=0.00341,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 35.56it/s, loss=0.00349, val_loss=0.00341,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.00349, val_loss=0.00329,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00345, val_loss=0.00329,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:01<00:00, 28.40it/s, loss=0.00345, val_loss=0.00329,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.00345, val_loss=0.00329,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.00345, val_loss=0.00325,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.33it/s, loss=0.0034, val_loss=0.00325, \u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 27.75it/s, loss=0.0034, val_loss=0.00325, \n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 34.93it/s, loss=0.0034, val_loss=0.00325, \u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.45it/s, loss=0.0034, val_loss=0.0032, a\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.64it/s, loss=0.00338, val_loss=0.0032, \u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 28.14it/s, loss=0.00338, val_loss=0.0032, \n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 35.40it/s, loss=0.00338, val_loss=0.0032, \u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.00338, val_loss=0.00309,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00337, val_loss=0.00309,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:01<00:00, 28.21it/s, loss=0.00337, val_loss=0.00309,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 35.46it/s, loss=0.00337, val_loss=0.00309,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00337, val_loss=0.00312,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00334, val_loss=0.00312,\u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:01<00:00, 28.18it/s, loss=0.00334, val_loss=0.00312,\n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 35.41it/s, loss=0.00334, val_loss=0.00312,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00334, val_loss=0.00323,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00324, val_loss=0.00323,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:01<00:00, 28.24it/s, loss=0.00324, val_loss=0.00323,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 35.50it/s, loss=0.00324, val_loss=0.00323,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00324, val_loss=0.0031, \u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00316, val_loss=0.0031, \u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 28.20it/s, loss=0.00316, val_loss=0.0031, \n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 35.44it/s, loss=0.00316, val_loss=0.0031, \u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00316, val_loss=0.00302,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00313, val_loss=0.00302,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 28.32it/s, loss=0.00313, val_loss=0.00302,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 35.60it/s, loss=0.00313, val_loss=0.00302,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00313, val_loss=0.00298,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.00308, val_loss=0.00298,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:01<00:00, 28.13it/s, loss=0.00308, val_loss=0.00298,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 35.39it/s, loss=0.00308, val_loss=0.00298,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 37.91it/s, loss=0.00308, val_loss=0.00296,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00305, val_loss=0.00296,\u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 28.21it/s, loss=0.00305, val_loss=0.00296,\n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00305, val_loss=0.00296,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00305, val_loss=0.00293,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.003, val_loss=0.00293, a\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:01<00:00, 27.93it/s, loss=0.003, val_loss=0.00293, a\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 35.13it/s, loss=0.003, val_loss=0.00293, a\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.65it/s, loss=0.003, val_loss=0.00298, a\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00298, val_loss=0.00298,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 28.15it/s, loss=0.00298, val_loss=0.00298,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 35.40it/s, loss=0.00298, val_loss=0.00298,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.93it/s, loss=0.00298, val_loss=0.00297,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00298, val_loss=0.00297,\u001b[A\n",
      "Sizes of clusters: 517, 471, 353, 305, 354\n",
      "\n",
      "preds: [4 0 0 4 1 1 2 2 1 0 0 1 1 2 3 3 1 1 2 4 2 1 4 4 1 1 2 0 1 1 2 4 1 0 1 1 1\n",
      " 4 1 0 1 0 3 4 3 4 4 1 0 0 0 0 0 1 4 4 1 1 2 1 4 3 1 0 0 4 1 2 0 2 1 0 0 1\n",
      " 1 0 1 0 3 1 0 1 1 4 3 1 1 1 0 0 1 0 3 1 4 4 0 4 0 4 2 0 0 2 3 1 4 0 4 0 3\n",
      " 2 4 3 3 1 1 1 4 3 0 3 3 0 0 0 4 2 4 1 1 3 1 4 0 1 0 1 0 4 4 3 2 3 0 3 0 4\n",
      " 3 4 1 4 1 3 2 1 1 4 0 0 0 0 1 1 1 4 3 3 3 1 3 0 4 3 0 0 2 2 3 2 4 3 1 1 4\n",
      " 1 0 0 2 3 1 0 4 3 4 3 3 4 3 1 4 1 0 4 4 1 1 1 3 3 4 1 1 1 4 3 2 1 2 4 4 3\n",
      " 0 3 0 0 4 0 1 1 3 1 3 1 1 0 1 3 4 0 1 3 2 1 0 0 3 3 0 0 4 1 0 0 3 1 1 4 2\n",
      " 1 3 1 1 2 0 2 1 4 0 0 3 1 0 0 4 3 4 0 2 4 0 2 1 4 4 3 0 3 3 4 1 0 4 0 1 0\n",
      " 1 0 4 1 1 1 0 3 1 4 2 4 3 4 3 4 4 4 1 4 0 1 0 4 1 0 3 1 4 1 0 4 0 4 3 2 2\n",
      " 0 1 0 3 4 1 0 1 0 1 4 4 0 3 4 4 1 1 4 0 4 0 0 2 3 0 1 3 3 2 3 1 0 3 1 3 0\n",
      " 0 3 0 3 4 1 1 1 1 0 3 3 1 0 3 4 0 2 1 1 0 3 1 1 1 1 0 4 0 4 0 4 4 4 3 2 2\n",
      " 2 0 4 0 0 0 0 0 2 2 1 4 0 1 2 1 3 1 2 3 0 4 0 0 0 3 2 2 4 3 0 0 4 2 1 4 1\n",
      " 1 4 2 0 0 1 4 4 1 0 0 4 2 3 4 3 0 0 0 0 4 3 2 3 1 2 0 4 0 4 3 0 4 1 0 4 4\n",
      " 3 0 4 0 2 3 0 1 1 0 4 3 3 2 0 1 0 1 4 0 0 0 0 4 0 2 2 0 0 2 1 4 1 0 0 4 2\n",
      " 0 2 2 4 0 0 4 4 1 4 0 4 2 0 4 2 2 2 1 0 2 1 0 1 3 0 0 1 2 1 2 4 0 2 0 1 2\n",
      " 0 2 2 0 2 0 0 2 2 1 1 3 3 4 2 2 0 2 2 0 1 3 0 2 4 3 4 1 0 2 0 1 4 0 3 3 3\n",
      " 1 2 2 2 2 1 0 2 4 2 4 4 1 2 4 4 2 4 1 0 0 1 4 2 4 2 3 4 4 2 4 2 1 2 2 4 1\n",
      " 1 4 2 4 2 1 1 3 1 2 1 2 0 0 4 2 2 3 1 2 4 4 2 2 0 2 1 0 0 3 4 1 1 4 4 2 3\n",
      " 0 2 2 2 2 4 2 4 2 0 2 0 4 0 2 0 2 4 0 0 2 0 0 0 0 4 1 4 4 0 3 2 0 0 1 1 0\n",
      " 0 0 2 4 3 1 3 0 1 2 3 1 1 2 3 0 4 1 2 0 1 4 0 3 1 2 2 0 3 0 0 0 4 0 2 4 3\n",
      " 0 2 1 4 0 2 2 0 0 1 3 0 4 0 1 1 0 3 2 0 0 1 4 2 1 4 2 4 0 4 3 4 4 0 2 2 2\n",
      " 2 0 2 4 0 1 2 0 1 1 4 1 2 2 2 4 4 4 1 0 2 3 0 3 1 0 3 1 3 0 3 3 0 3 1 0 0\n",
      " 3 0 1 0 3 3 1 1 0 3 3 0 1 1 1 0 1 4 1 3 3 1 3 3 0 0 1 0 1 1 0 3 3 0 4 1 3\n",
      " 4 4 4 0 3 1 0 0 3 4 2 3 3 4 3 4 0 3 1 0 3 3 0 4 1 3 1 3 0 1 0 1 0 0 3 0 1\n",
      " 1 0 1 3 1 3 3 3 4 0 1 3 0 3 2 2 1 0 1 3 1 4 1 1 3 2 4 2 1 1 3 3 1 4 0 4 0\n",
      " 1 4 3 2 3 3 3 3 3 4 0 1 0 3 0 3 3 1 2 4 3 3 1 0 1 0 3 3 0 3 2 3 1 2 3 0 0\n",
      " 3 3 2 3 3 4 3 4 3 3 0 1 0 3 1 0 3 1 1 3 4 1 3 4 0 2 1 0 1 4 2 1 0 3 0 0 1\n",
      " 3 4 3 3 0 0 4 3 0 3 0 1 0 3 2 1 1 3 1 3 3 1 1 4 3 1 0 0 3 3 0 1 4 1 1 3 1\n",
      " 0 2 1 3 3 3 1 4 1 1 0 4 0 3 3 0 3 1 3 1 0 3 2 0 1 1 4 3 0 0 3 1 2 4 3 2 3\n",
      " 3 3 3 3 0 0 3 1 2 0 3 3 0 1 0 1 4 4 1 3 0 3 1 1 3 3 3 3 1 2 0 4 3 1 2 1 1\n",
      " 4 2 3 3 3 1 3 1 0 3 1 3 0 3 3 4 3 1 4 1 1 0 3 0 3 0 1 3 1 3 1 0 3 1 1 3 0\n",
      " 0 1 3 1 1 0 1 3 4 3 4 3 0 3 2 2 3 1 0 0 1 0 1 3 3 3 3 4 1 3 3 3 0 1 4 3 1\n",
      " 0 3 3 0 4 1 4 1 0 4 1 4 3 1 4 1 2 0 0 2 2 1 0 0 2 0 4 0 0 0 2 0 0 2 2 1 2\n",
      " 2 0 0 0 0 0 2 2 4 2 1 4 0 4 4 0 0 2 1 0 0 0 2 4 2 2 1 4 2 0 2 4 0 1 0 2 0\n",
      " 0 2 0 0 0 2 0 2 1 0 1 3 0 2 0 1 1 2 1 2 0 2 2 0 0 4 1 2 4 2 0 0 3 0 2 3 2\n",
      " 1 0 0 2 0 0 2 2 0 2 2 0 4 1 3 1 0 0 0 2 2 1 2 2 0 0 4 2 0 0 0 0 0 0 2 2 2\n",
      " 0 2 0 0 2 2 0 3 2 4 2 1 2 1 2 4 0 2 0 2 0 2 0 2 2 2 0 0 1 4 0 2 1 0 1 4 2\n",
      " 0 2 0 4 2 0 3 2 2 2 0 0 0 0 2 2 0 2 0 0 0 4 1 0 1 2 3 0 0 0 2 0 2 0 1 0 0\n",
      " 2 0 0 2 0 0 2 3 0 4 2 0 0 0 3 0 0 4 0 0 3 2 2 4 4 0 1 0 2 0 0 0 0 2 4 1 2\n",
      " 2 4 0 2 2 4 0 4 0 2 3 2 0 2 2 2 2 0 0 2 0 2 2 0 0 0 2 0 2 0 2 0 1 2 0 2 4\n",
      " 0 3 2 4 2 2 2 2 4 2 0 0 0 0 2 1 2 0 2 0 1 0 2 2 0 2 2 0 4 0 0 0 2 0 0 2 0\n",
      " 3 0 2 2 0 1 0 2 0 2 0 4 0 2 3 2 2 2 1 0 4 2 2 4 0 2 2 0 2 0 2 2 1 0 1 2 0\n",
      " 0 2 4 2 0 2 2 2 0 0 0 2 2 4 0 0 2 4 2 0 0 2 4 0 0 0 0 0 2 2 2 2 0 2 2 0 2\n",
      " 0 3 3 2 2 1 0 2 2 3 3 1 4 0 4 1 0 2 2 4 4 4 3 3 4 1 3 4 1 0 1 1 3 1 0 2 0\n",
      " 4 3 1 2 1 4 4 2 4 1 0 1 1 4 3 1 1 4 1 1 1 3 4 3 4 1 0 4 4 1 2 1 1 2 1 2 4\n",
      " 1 4 4 1 0 0 3 2 2 0 4 1 4 0 1 0 1 2 3 4 2 1 1 1 2 2 0 0 1 1 1 1 2 1 1 4 4\n",
      " 1 1 4 1 3 4 3 1 1 1 3 4 4 1 0 1 2 4 3 4 4 4 4 4 1 1 0 3 1 0 1 1 0 3 4 4 0\n",
      " 1 1 4 4 3 1 0 1 4 3 1 4 1 4 2 4 2 4 2 4 1 4 3 1 0 0 1 1 0 1 2 4 1 3 4 4 1\n",
      " 1 1 1 1 3 4 4 1 1 1 1 1 4 1 4 4 4 4 0 0 3 2 2 2 1 4 4 0 1 1 0 4 2 4 0 4 4\n",
      " 3 4 2 3 1 1 4 0 4 1 2 1 4 1 4 3 0 4 4 1 4 1 4 1 2 1 1 4 4 3 1 4 3 1 1 3 2\n",
      " 1 1 4 4 1 2 2 1 1 4 4 3 1 1 1 1 4 0 1 1 4 4 1 1 4 4 1 2 4 0 1 4 1 2 1 4 4\n",
      " 4 1 1 1 1 3 4 0 0 2 2 1 4 0 1 3 1 2 1 0 2 0 0 4 1 0 0 4 4 4 3 0 3 3 1 1 4\n",
      " 2 1 2 1 0 1 1 1 1 3 0 2 1 1 1 4 4 1 2 4 1 4 2 1 1 1 1 4 2 1 0 1 1 0 0 0 2\n",
      " 0 2 3 3 1 0 4 1 1 4 0 1 1 1 2 1 3 4 2 1 1 4 0 0 4 4 3 4 0 1 1 1 1 1 2 4 3\n",
      " 4 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3545\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.77, val_loss=0.0646, avg_\n",
      "Epoch 0:  55%|▌| 44/80 [00:01<00:01, 24.01it/s, loss=0.77, val_loss=0.0646, avg_\n",
      "Epoch 0:  76%|▊| 61/80 [00:01<00:00, 31.51it/s, loss=0.77, val_loss=0.0646, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.77, val_loss=0.115, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.0425, val_loss=0.115, avg\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:01<00:01, 26.99it/s, loss=0.0425, val_loss=0.115, avg\n",
      "Epoch 1:  85%|▊| 68/80 [00:01<00:00, 34.02it/s, loss=0.0425, val_loss=0.115, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.0425, val_loss=0.0297, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.02, val_loss=0.0297, avg_\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 27.11it/s, loss=0.02, val_loss=0.0297, avg_\n",
      "Epoch 2:  85%|▊| 68/80 [00:01<00:00, 34.15it/s, loss=0.02, val_loss=0.0297, avg_\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.02, val_loss=0.021, avg_v\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.0139, val_loss=0.021, avg\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 26.99it/s, loss=0.0139, val_loss=0.021, avg\n",
      "Epoch 3:  85%|▊| 68/80 [00:01<00:00, 34.00it/s, loss=0.0139, val_loss=0.021, avg\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.0139, val_loss=0.015, avg\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.0104, val_loss=0.015, avg\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 27.27it/s, loss=0.0104, val_loss=0.015, avg\n",
      "Epoch 4:  85%|▊| 68/80 [00:01<00:00, 34.34it/s, loss=0.0104, val_loss=0.015, avg\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.0104, val_loss=0.0112, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.09it/s, loss=0.00826, val_loss=0.0112, a\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 27.41it/s, loss=0.00826, val_loss=0.0112, a\n",
      "Epoch 5:  85%|▊| 68/80 [00:01<00:00, 34.52it/s, loss=0.00826, val_loss=0.0112, a\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.60it/s, loss=0.00826, val_loss=0.00885, \u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00682, val_loss=0.00885, \u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 27.29it/s, loss=0.00682, val_loss=0.00885, \n",
      "Epoch 6:  85%|▊| 68/80 [00:01<00:00, 34.29it/s, loss=0.00682, val_loss=0.00885, \u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00682, val_loss=0.00732, \u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00583, val_loss=0.00732, \u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 26.75it/s, loss=0.00583, val_loss=0.00732, \n",
      "Epoch 7:  85%|▊| 68/80 [00:02<00:00, 33.73it/s, loss=0.00583, val_loss=0.00732, \u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 37.75it/s, loss=0.00583, val_loss=0.00624, \u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00511, val_loss=0.00624, \u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 27.28it/s, loss=0.00511, val_loss=0.00624, \n",
      "Epoch 8:  85%|▊| 68/80 [00:01<00:00, 34.35it/s, loss=0.00511, val_loss=0.00624, \u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00511, val_loss=0.00541, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00458, val_loss=0.00541, \u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00458, val_loss=0.00541, \n",
      "Epoch 9:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00458, val_loss=0.00541, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.36it/s, loss=0.00458, val_loss=0.0048, a\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.00418, val_loss=0.0048, \u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 27.36it/s, loss=0.00418, val_loss=0.0048, \n",
      "Epoch 10:  85%|▊| 68/80 [00:01<00:00, 34.44it/s, loss=0.00418, val_loss=0.0048, \u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.55it/s, loss=0.00418, val_loss=0.00435,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00388, val_loss=0.00435,\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 26.93it/s, loss=0.00388, val_loss=0.00435,\n",
      "Epoch 11:  85%|▊| 68/80 [00:02<00:00, 33.95it/s, loss=0.00388, val_loss=0.00435,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.00388, val_loss=0.00401,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00365, val_loss=0.00401,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00365, val_loss=0.00401,\n",
      "Epoch 12:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00365, val_loss=0.00401,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00365, val_loss=0.00374,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00347, val_loss=0.00374,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 27.25it/s, loss=0.00347, val_loss=0.00374,\n",
      "Epoch 13:  85%|▊| 68/80 [00:01<00:00, 34.33it/s, loss=0.00347, val_loss=0.00374,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00347, val_loss=0.00352,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00333, val_loss=0.00352,\u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00333, val_loss=0.00352,\n",
      "Epoch 14:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00333, val_loss=0.00352,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00333, val_loss=0.00333,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 22.10it/s, loss=0.00321, val_loss=0.00333,\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 27.42it/s, loss=0.00321, val_loss=0.00333,\n",
      "Epoch 15:  85%|▊| 68/80 [00:01<00:00, 34.54it/s, loss=0.00321, val_loss=0.00333,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.64it/s, loss=0.00321, val_loss=0.0032, \u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00311, val_loss=0.0032, \u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:01<00:01, 27.26it/s, loss=0.00311, val_loss=0.0032, \n",
      "Epoch 16:  85%|▊| 68/80 [00:01<00:00, 34.33it/s, loss=0.00311, val_loss=0.0032, \u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00311, val_loss=0.0031, \u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00302, val_loss=0.0031, \u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:01<00:01, 27.22it/s, loss=0.00302, val_loss=0.0031, \n",
      "Epoch 17:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00302, val_loss=0.0031, \u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00302, val_loss=0.00299,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00295, val_loss=0.00299,\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:01<00:01, 27.29it/s, loss=0.00295, val_loss=0.00299,\n",
      "Epoch 18:  85%|▊| 68/80 [00:01<00:00, 34.38it/s, loss=0.00295, val_loss=0.00299,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00295, val_loss=0.00291,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00289, val_loss=0.00291,\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:01<00:01, 26.99it/s, loss=0.00289, val_loss=0.00291,\n",
      "Epoch 19:  85%|▊| 68/80 [00:01<00:00, 34.01it/s, loss=0.00289, val_loss=0.00291,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.92it/s, loss=0.00289, val_loss=0.00282,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00284, val_loss=0.00282,\u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:01<00:01, 27.02it/s, loss=0.00284, val_loss=0.00282,\n",
      "Epoch 20:  85%|▊| 68/80 [00:01<00:00, 34.06it/s, loss=0.00284, val_loss=0.00282,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00284, val_loss=0.00274,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.43it/s, loss=0.00279, val_loss=0.00274,\u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:01<00:01, 26.60it/s, loss=0.00279, val_loss=0.00274,\n",
      "Epoch 21:  85%|▊| 68/80 [00:02<00:00, 33.28it/s, loss=0.00279, val_loss=0.00274,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.51it/s, loss=0.00279, val_loss=0.00269,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.55it/s, loss=0.00274, val_loss=0.00269,\u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:01<00:01, 26.73it/s, loss=0.00274, val_loss=0.00269,\n",
      "Epoch 22:  85%|▊| 68/80 [00:02<00:00, 33.70it/s, loss=0.00274, val_loss=0.00269,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.77it/s, loss=0.00274, val_loss=0.00263,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.65it/s, loss=0.00271, val_loss=0.00263,\u001b[A\n",
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 26.87it/s, loss=0.00271, val_loss=0.00263,\n",
      "Epoch 23:  85%|▊| 68/80 [00:02<00:00, 33.87it/s, loss=0.00271, val_loss=0.00263,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00271, val_loss=0.00259,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.07it/s, loss=0.00267, val_loss=0.00259,\u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 26.16it/s, loss=0.00267, val_loss=0.00259,\n",
      "Epoch 24:  85%|▊| 68/80 [00:02<00:00, 33.01it/s, loss=0.00267, val_loss=0.00259,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.03it/s, loss=0.00267, val_loss=0.00255,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00264, val_loss=0.00255,\u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:01<00:01, 27.11it/s, loss=0.00264, val_loss=0.00255,\n",
      "Epoch 25:  85%|▊| 68/80 [00:01<00:00, 34.16it/s, loss=0.00264, val_loss=0.00255,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.25it/s, loss=0.00264, val_loss=0.00251,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.00261, val_loss=0.00251,\u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:01<00:01, 26.93it/s, loss=0.00261, val_loss=0.00251,\n",
      "Epoch 26:  85%|▊| 68/80 [00:02<00:00, 33.95it/s, loss=0.00261, val_loss=0.00251,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.00261, val_loss=0.00247,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00258, val_loss=0.00247,\u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:01<00:01, 26.89it/s, loss=0.00258, val_loss=0.00247,\n",
      "Epoch 27:  85%|▊| 68/80 [00:02<00:00, 33.91it/s, loss=0.00258, val_loss=0.00247,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00258, val_loss=0.00241,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.00255, val_loss=0.00241,\u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:01<00:01, 26.63it/s, loss=0.00255, val_loss=0.00241,\n",
      "Epoch 28:  85%|▊| 68/80 [00:02<00:00, 33.59it/s, loss=0.00255, val_loss=0.00241,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 37.63it/s, loss=0.00255, val_loss=0.00236,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00253, val_loss=0.00236,\u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:01<00:01, 26.72it/s, loss=0.00253, val_loss=0.00236,\n",
      "Epoch 29:  85%|▊| 68/80 [00:02<00:00, 33.68it/s, loss=0.00253, val_loss=0.00236,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.74it/s, loss=0.00253, val_loss=0.00231,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00251, val_loss=0.00231,\u001b[A\n",
      "Epoch 30:  64%|▋| 51/80 [00:01<00:01, 27.13it/s, loss=0.00251, val_loss=0.00231,\n",
      "Epoch 30:  85%|▊| 68/80 [00:01<00:00, 34.20it/s, loss=0.00251, val_loss=0.00231,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.00251, val_loss=0.00228,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00249, val_loss=0.00228,\u001b[A\n",
      "Epoch 31:  64%|▋| 51/80 [00:01<00:01, 26.89it/s, loss=0.00249, val_loss=0.00228,\n",
      "Epoch 31:  85%|▊| 68/80 [00:02<00:00, 33.88it/s, loss=0.00249, val_loss=0.00228,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00249, val_loss=0.00225,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00247, val_loss=0.00225,\u001b[A\n",
      "Epoch 32:  64%|▋| 51/80 [00:01<00:01, 26.96it/s, loss=0.00247, val_loss=0.00225,\n",
      "Epoch 32:  85%|▊| 68/80 [00:02<00:00, 33.98it/s, loss=0.00247, val_loss=0.00225,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.00247, val_loss=0.00223,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.00245, val_loss=0.00223,\u001b[A\n",
      "Epoch 33:  64%|▋| 51/80 [00:01<00:01, 27.30it/s, loss=0.00245, val_loss=0.00223,\n",
      "Epoch 33:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.00245, val_loss=0.00223,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.49it/s, loss=0.00245, val_loss=0.00221,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00243, val_loss=0.00221,\u001b[A\n",
      "Epoch 34:  64%|▋| 51/80 [00:01<00:01, 27.08it/s, loss=0.00243, val_loss=0.00221,\n",
      "Epoch 34:  85%|▊| 68/80 [00:01<00:00, 34.18it/s, loss=0.00243, val_loss=0.00221,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00243, val_loss=0.00218,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.18it/s, loss=0.00241, val_loss=0.00218,\u001b[A\n",
      "Epoch 35:  64%|▋| 51/80 [00:01<00:01, 26.29it/s, loss=0.00241, val_loss=0.00218,\n",
      "Epoch 35:  85%|▊| 68/80 [00:02<00:00, 33.18it/s, loss=0.00241, val_loss=0.00218,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 37.19it/s, loss=0.00241, val_loss=0.00215,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.0024, val_loss=0.00215, \u001b[A\n",
      "Epoch 36:  64%|▋| 51/80 [00:01<00:01, 26.96it/s, loss=0.0024, val_loss=0.00215, \n",
      "Epoch 36:  85%|▊| 68/80 [00:02<00:00, 33.96it/s, loss=0.0024, val_loss=0.00215, \u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.0024, val_loss=0.00212, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.17it/s, loss=0.00238, val_loss=0.00212,\u001b[A\n",
      "Epoch 37:  64%|▋| 51/80 [00:01<00:01, 26.27it/s, loss=0.00238, val_loss=0.00212,\n",
      "Epoch 37:  85%|▊| 68/80 [00:02<00:00, 33.16it/s, loss=0.00238, val_loss=0.00212,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.15it/s, loss=0.00238, val_loss=0.0021, \u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.00237, val_loss=0.0021, \u001b[A\n",
      "Epoch 38:  64%|▋| 51/80 [00:01<00:01, 26.96it/s, loss=0.00237, val_loss=0.0021, \n",
      "Epoch 38:  85%|▊| 68/80 [00:02<00:00, 33.98it/s, loss=0.00237, val_loss=0.0021, \u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.06it/s, loss=0.00237, val_loss=0.00208,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00236, val_loss=0.00208,\u001b[A\n",
      "Epoch 39:  64%|▋| 51/80 [00:01<00:01, 26.87it/s, loss=0.00236, val_loss=0.00208,\n",
      "Epoch 39:  85%|▊| 68/80 [00:02<00:00, 33.89it/s, loss=0.00236, val_loss=0.00208,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00236, val_loss=0.00206,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.71it/s, loss=0.00236, val_loss=0.00206,\u001b[A\n",
      "Sizes of clusters: 426, 122, 613, 710, 129\n",
      "\n",
      "preds: [1 3 3 2 3 2 3 0 2 0 0 2 2 3 0 3 3 1 0 2 2 3 2 2 2 2 3 3 2 3 2 2 0 0 2 2 2\n",
      " 3 2 3 3 3 3 1 3 2 2 2 3 3 0 3 0 3 2 2 2 1 3 2 1 3 3 3 2 3 3 2 3 3 2 0 0 2\n",
      " 2 0 3 3 3 3 3 1 2 2 3 2 3 2 0 3 2 2 0 2 1 2 4 2 0 1 2 3 4 2 0 3 2 3 1 3 0\n",
      " 2 2 0 3 3 3 3 2 3 3 2 2 3 3 3 2 2 2 2 3 2 2 2 0 3 3 2 3 3 1 3 2 3 0 2 0 1\n",
      " 3 1 2 3 3 3 3 2 2 2 0 3 3 3 1 3 2 2 0 0 3 2 0 3 2 2 3 3 2 2 3 2 2 3 2 3 1\n",
      " 3 3 2 2 3 2 3 2 0 2 4 2 2 3 2 2 2 3 2 2 2 2 2 3 3 1 3 2 3 2 2 3 2 2 1 2 0\n",
      " 2 0 3 0 2 3 3 2 2 3 0 2 2 0 2 2 2 3 3 3 3 2 3 2 0 2 2 3 2 3 3 3 2 2 2 1 3\n",
      " 3 2 3 2 2 2 2 3 2 0 2 3 2 3 3 2 3 2 3 3 2 3 2 3 2 2 0 3 3 0 1 2 3 2 3 2 2\n",
      " 2 3 2 3 2 2 0 3 3 3 2 2 3 2 3 1 2 1 3 1 3 2 2 2 3 0 3 3 2 3 3 2 3 2 3 2 2\n",
      " 2 1 0 3 2 2 3 3 0 3 2 1 3 3 3 2 2 1 2 3 1 2 3 2 3 3 3 3 3 0 3 2 2 3 3 0 3\n",
      " 2 2 3 3 2 2 3 2 2 0 3 3 2 3 3 2 0 2 2 3 3 3 2 3 3 2 3 2 3 2 3 1 1 1 3 3 2\n",
      " 2 0 2 4 0 3 3 0 2 2 2 2 0 2 3 1 2 2 2 2 0 3 3 0 3 3 0 2 1 0 2 2 2 2 2 2 3\n",
      " 2 2 2 3 0 2 3 2 3 2 0 1 2 2 1 0 2 0 2 3 2 2 0 3 2 3 3 2 3 2 3 0 1 2 0 2 1\n",
      " 2 0 2 2 2 0 0 3 2 3 2 3 3 3 3 3 3 2 1 0 0 3 0 1 0 3 2 2 3 0 1 2 2 3 0 2 3\n",
      " 2 2 3 2 0 0 1 3 3 2 2 2 3 2 2 3 1 3 3 0 2 1 3 2 3 2 3 2 0 2 3 1 3 3 0 2 3\n",
      " 2 0 3 3 2 0 0 0 2 2 3 2 2 1 3 2 2 2 2 0 2 2 3 0 2 2 2 2 3 3 3 2 2 2 2 2 0\n",
      " 2 0 2 0 2 2 3 2 2 3 2 3 2 2 2 2 3 2 1 3 2 1 1 2 2 2 3 2 2 2 2 3 3 3 4 2 3\n",
      " 3 2 4 2 3 2 3 2 2 0 2 2 3 3 2 2 2 2 2 3 2 2 2 0 0 2 2 3 0 3 1 1 2 2 2 0 0\n",
      " 0 3 2 3 0 2 3 2 2 0 2 2 1 3 2 3 3 2 2 3 3 3 0 2 0 1 3 2 2 3 2 2 2 2 2 2 3\n",
      " 0 0 3 2 2 2 0 2 3 3 2 1 1 3 3 3 2 2 3 0 1 2 2 0 2 2 2 3 2 3 2 2 1 2 2 1 3\n",
      " 3 3 1 2 0 1 2 2 3 3 2 0 1 3 1 3 3 3 3 3 0 1 3 3 3 1 3 2 0 2 2 1 2 0 2 3 2\n",
      " 3 2 3 2 2 2 2 3 1 2 1 2 2 2 3 3 2 2 2 2 2 3 3 0 3 0 0 0 4 0 0 4 3 3 2 0 0\n",
      " 4 0 0 0 0 0 3 3 0 0 0 0 3 0 3 3 3 1 2 0 0 3 0 0 4 0 2 0 3 3 0 0 4 4 2 3 4\n",
      " 3 3 3 4 4 3 3 0 4 3 4 4 3 2 4 0 3 4 3 0 0 0 4 3 2 0 2 4 0 3 3 3 0 4 3 3 3\n",
      " 2 3 0 0 3 0 3 0 3 0 2 4 4 4 3 0 3 3 0 4 3 0 3 2 3 2 3 0 3 2 0 2 2 2 4 3 0\n",
      " 3 1 3 0 0 4 3 0 3 3 0 3 4 0 0 0 4 3 3 3 4 0 2 0 3 3 4 0 0 3 0 0 2 0 0 0 0\n",
      " 0 0 3 4 3 3 3 2 0 4 0 3 0 4 3 0 0 3 2 4 1 3 0 2 0 0 0 0 0 3 0 1 0 3 4 3 0\n",
      " 0 0 4 0 0 0 0 2 3 3 0 3 0 0 3 3 2 0 3 4 3 0 3 2 0 3 0 3 3 0 0 2 2 3 2 0 3\n",
      " 0 2 3 4 3 4 3 3 2 4 3 2 4 0 4 0 4 3 3 3 0 4 3 3 0 3 2 0 0 0 4 2 3 2 0 3 4\n",
      " 4 0 4 0 0 0 3 3 3 4 3 3 3 3 0 0 2 2 2 0 0 0 0 3 4 3 4 0 3 3 0 0 0 0 2 2 3\n",
      " 0 3 4 4 4 3 4 3 0 0 3 4 3 0 0 3 0 3 2 0 0 4 4 4 0 4 3 4 3 0 0 0 0 2 3 0 4\n",
      " 0 3 0 3 3 4 3 4 2 4 3 4 0 4 2 3 0 3 0 4 3 3 3 4 0 0 0 3 0 4 4 4 0 0 2 4 3\n",
      " 0 3 3 0 2 2 3 1 3 2 3 3 3 0 2 3 3 0 0 3 0 3 4 3 3 0 1 0 0 3 3 0 0 0 4 3 4\n",
      " 0 0 0 3 0 3 3 4 2 0 3 3 3 2 1 4 0 0 2 3 4 0 3 2 3 3 3 1 3 0 0 2 0 3 2 0 0\n",
      " 3 4 2 0 0 3 3 2 3 0 3 4 0 3 0 2 0 3 0 2 0 3 2 0 0 2 3 0 3 3 0 0 4 0 3 0 3\n",
      " 0 0 0 0 3 2 3 4 0 3 3 3 3 2 0 3 0 0 0 3 0 3 3 0 4 4 2 0 0 0 3 3 4 0 3 3 0\n",
      " 0 3 0 0 3 0 3 4 0 2 0 0 0 2 3 3 0 0 0 0 0 3 3 0 3 2 4 3 3 1 0 2 3 3 2 3 2\n",
      " 3 3 4 1 4 0 4 0 3 3 3 4 0 0 0 0 0 2 0 0 0 1 0 4 3 2 4 4 0 0 0 3 0 3 3 0 0\n",
      " 3 3 3 3 0 4 3 4 0 2 2 0 0 0 4 0 4 1 0 3 4 3 3 2 2 4 0 0 3 3 3 4 3 4 3 0 0\n",
      " 0 2 0 3 3 3 0 2 4 3 0 3 0 0 0 3 0 3 2 3 4 0 3 3 0 0 0 0 4 0 0 4 3 3 0 3 3\n",
      " 0 0 2 2 3 0 0 0 3 3 4 3 0 4 4 3 0 0 4 0 2 3 3 2 0 3 0 0 3 3 3 0 3 0 0 3 0\n",
      " 0 4 2 3 3 3 0 3 3 3 0 2 0 4 4 3 4 4 0 0 1 3 3 1 0 0 3 3 2 0 3 4 3 0 2 3 0\n",
      " 4 4 1 4 0 3 2 3 0 0 2 3 4 1 0 3 3 3 2 0 3 0 2 0 3 4 0 4 0 3 3 0 3 0 3 3 0\n",
      " 3 0 0 4 0 0 3 3 0 3 0 2 1 3 2 2 3 3 3 2 3 2 2 3 3 3 2 2 2 3 2 3 3 2 0 2 3\n",
      " 1 3 1 2 0 2 2 3 3 3 0 3 2 1 3 3 3 1 2 1 2 3 2 3 2 3 0 2 1 3 2 3 3 3 2 2 2\n",
      " 2 2 2 3 3 3 0 2 2 2 2 3 2 3 3 0 3 2 0 1 2 2 3 2 2 3 2 3 3 2 3 2 2 2 2 2 1\n",
      " 3 2 1 3 0 2 0 3 2 2 3 1 2 3 0 2 3 2 2 2 1 1 1 1 2 1 3 3 3 0 2 2 3 3 2 2 2\n",
      " 2 1 2 2 3 3 3 1 2 0 1 2 3 3 3 1 3 2 3 2 3 2 4 2 0 3 2 1 3 2 2 2 2 3 2 1 2\n",
      " 3 3 2 3 3 2 3 2 3 2 2 2 2 2 3 2 1 2 3 3 3 2 3 0 2 1 2 2 3 3 2 2 3 2 3 2 2\n",
      " 0 1 2 3 3 3 1 3 2 2 3 3 1 1 2 0 3 2 1 3 2 2 2 3 3 2 2 1 1 3 3 2 2 2 3 3 3\n",
      " 2 3 2 3 1 0 2 2 3 2 2 3 2 3 2 3 1 3 2 2 2 2 2 2 3 3 3 2 2 2 3 1 3 2 3 2 1\n",
      " 2 3 3 2 1 3 3 3 3 3 2 3 2 3 2 3 3 2 2 3 3 3 2 2 2 3 0 1 1 2 2 3 3 0 3 2 1\n",
      " 2 3 2 3 0 3 3 2 3 3 2 2 3 2 3 2 2 3 3 2 2 2 2 2 2 3 3 1 2 2 3 2 3 3 3 0 2\n",
      " 3 2 3 4 2 3 3 3 2 2 3 3 3 3 2 3 3 2 2 3 2 2 3 2 2 3 3 2 3 1 3 3 2 3 2 1 2\n",
      " 1 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3057\r\n",
      "Purity: 0.3217+-0.024878906728391402\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_sin_K5_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5 # 0.3054"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.03it/s, loss=119, val_loss=0.0801, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 36.86it/s, loss=119, val_loss=0.552, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=1.47, val_loss=0.552, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=1.47, val_loss=0.702, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.50it/s, loss=0.28, val_loss=0.702, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.60it/s, loss=0.28, val_loss=0.402, avg_v\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.0754, val_loss=0.402, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.47it/s, loss=0.0754, val_loss=0.151, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.0381, val_loss=0.151, avg\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.0381, val_loss=0.0513, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.0261, val_loss=0.0513, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.75it/s, loss=0.0261, val_loss=0.0325, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.28it/s, loss=0.0212, val_loss=0.0325, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.22it/s, loss=0.0212, val_loss=0.0272, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.0187, val_loss=0.0272, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.0187, val_loss=0.024, avg\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.0169, val_loss=0.024, avg\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.68it/s, loss=0.0169, val_loss=0.0213, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.0156, val_loss=0.0213, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.0156, val_loss=0.019, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0146, val_loss=0.019, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.0146, val_loss=0.0172, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0137, val_loss=0.0172, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.89it/s, loss=0.0137, val_loss=0.0159, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.013, val_loss=0.0159, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.30it/s, loss=0.013, val_loss=0.0147, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0124, val_loss=0.0147, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.0124, val_loss=0.0138, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0119, val_loss=0.0138, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.0119, val_loss=0.013, av\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.27it/s, loss=0.0115, val_loss=0.013, av\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.21it/s, loss=0.0115, val_loss=0.0123, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.0111, val_loss=0.0123, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0111, val_loss=0.0117, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0108, val_loss=0.0117, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.0108, val_loss=0.0112, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.0104, val_loss=0.0112, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.41it/s, loss=0.0104, val_loss=0.0107, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0101, val_loss=0.0107, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.91it/s, loss=0.0101, val_loss=0.0104, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00985, val_loss=0.0104, \n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00985, val_loss=0.01, av\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.26it/s, loss=0.00959, val_loss=0.01, av\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.20it/s, loss=0.00959, val_loss=0.0097, \n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.00935, val_loss=0.0097, \n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.00935, val_loss=0.00942,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00912, val_loss=0.00942,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.00912, val_loss=0.00915,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.29it/s, loss=0.00891, val_loss=0.00915,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.24it/s, loss=0.00891, val_loss=0.00891,\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0087, val_loss=0.00891, \n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.0087, val_loss=0.00869, \n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.00851, val_loss=0.00869,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.00851, val_loss=0.00848,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00833, val_loss=0.00848,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.97it/s, loss=0.00833, val_loss=0.00829,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00816, val_loss=0.00829,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.00816, val_loss=0.00811,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.008, val_loss=0.00811, a\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.008, val_loss=0.00793, a\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00785, val_loss=0.00793,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.78it/s, loss=0.00785, val_loss=0.00777,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.23it/s, loss=0.00771, val_loss=0.00777,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.21it/s, loss=0.00771, val_loss=0.00762,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.00758, val_loss=0.00762,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.00758, val_loss=0.00748,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00745, val_loss=0.00748,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.00745, val_loss=0.00735,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00733, val_loss=0.00735,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.41it/s, loss=0.00733, val_loss=0.00722,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00722, val_loss=0.00722,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.00722, val_loss=0.00711,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00711, val_loss=0.00711,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.00711, val_loss=0.007, a\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.41it/s, loss=0.00701, val_loss=0.007, a\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.44it/s, loss=0.00701, val_loss=0.00689,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.00691, val_loss=0.00689,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.00691, val_loss=0.0068, \n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.79it/s, loss=0.00682, val_loss=0.0068, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.06it/s, loss=0.00682, val_loss=0.0067, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.00682, val_loss=0.0067, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of clusters: 443, 357\n",
      "\n",
      "preds: [0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1\n",
      " 1 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
      " 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1\n",
      " 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.7163\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=123, val_loss=0.0939, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=123, val_loss=0.147, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=2.86, val_loss=0.147, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.24it/s, loss=2.86, val_loss=0.128, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.529, val_loss=0.128, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=0.529, val_loss=0.0871, avg\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.132, val_loss=0.0871, avg\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.132, val_loss=0.0608, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0512, val_loss=0.0608, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.0512, val_loss=0.0423, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.0314, val_loss=0.0423, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.0314, val_loss=0.0324, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0247, val_loss=0.0324, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.91it/s, loss=0.0247, val_loss=0.0261, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.0214, val_loss=0.0261, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.12it/s, loss=0.0214, val_loss=0.0224, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0191, val_loss=0.0224, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.0191, val_loss=0.0199, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0174, val_loss=0.0199, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.63it/s, loss=0.0174, val_loss=0.0181, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.58it/s, loss=0.016, val_loss=0.0181, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.69it/s, loss=0.016, val_loss=0.0168, av\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0149, val_loss=0.0168, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.84it/s, loss=0.0149, val_loss=0.0157, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.014, val_loss=0.0157, av\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.58it/s, loss=0.014, val_loss=0.0147, av\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0132, val_loss=0.0147, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.0132, val_loss=0.0138, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.0125, val_loss=0.0138, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0125, val_loss=0.013, av\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.46it/s, loss=0.0119, val_loss=0.013, av\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.57it/s, loss=0.0119, val_loss=0.0122, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0113, val_loss=0.0122, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0113, val_loss=0.0116, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0108, val_loss=0.0116, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.91it/s, loss=0.0108, val_loss=0.011, av\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.0104, val_loss=0.011, av\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.53it/s, loss=0.0104, val_loss=0.0105, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.16it/s, loss=0.00995, val_loss=0.0105, \n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.10it/s, loss=0.00995, val_loss=0.01, av\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00958, val_loss=0.01, av\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.00958, val_loss=0.00961,\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.38it/s, loss=0.00924, val_loss=0.00961,\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.45it/s, loss=0.00924, val_loss=0.00923,\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00893, val_loss=0.00923,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00893, val_loss=0.00889,\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00865, val_loss=0.00889,\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.00865, val_loss=0.00858,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.40it/s, loss=0.00839, val_loss=0.00858,\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.47it/s, loss=0.00839, val_loss=0.0083, \n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00815, val_loss=0.0083, \n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.00815, val_loss=0.00804,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00793, val_loss=0.00804,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.00793, val_loss=0.00779,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.00772, val_loss=0.00779,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.94it/s, loss=0.00772, val_loss=0.00756,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.00752, val_loss=0.00756,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.59it/s, loss=0.00752, val_loss=0.00735,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00734, val_loss=0.00735,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.99it/s, loss=0.00734, val_loss=0.00716,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.00717, val_loss=0.00716,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.00717, val_loss=0.00698,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.34it/s, loss=0.00701, val_loss=0.00698,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.00701, val_loss=0.00682,\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00687, val_loss=0.00682,\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.94it/s, loss=0.00687, val_loss=0.00667,\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.21it/s, loss=0.00673, val_loss=0.00667,\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.17it/s, loss=0.00673, val_loss=0.00655,\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.00661, val_loss=0.00655,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.52it/s, loss=0.00661, val_loss=0.00643,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0065, val_loss=0.00643, \n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.97it/s, loss=0.0065, val_loss=0.00631, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.0064, val_loss=0.00631, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.0064, val_loss=0.00619, \n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.40it/s, loss=0.00631, val_loss=0.00619,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.47it/s, loss=0.00631, val_loss=0.00606,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.00623, val_loss=0.00606,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.00623, val_loss=0.00592,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00615, val_loss=0.00592,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00615, val_loss=0.00576,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.52it/s, loss=0.00615, val_loss=0.00576,\n",
      "Sizes of clusters: 482, 318\n",
      "\n",
      "preds: [1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 0\n",
      " 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1\n",
      " 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0\n",
      " 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1\n",
      " 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0\n",
      " 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5350\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=129, val_loss=0.081, avg_va\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=129, val_loss=0.0772, avg_v\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.88it/s, loss=2.27, val_loss=0.0772, avg_\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=2.27, val_loss=0.287, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.81it/s, loss=0.439, val_loss=0.287, avg_\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.439, val_loss=0.138, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.114, val_loss=0.138, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 38.03it/s, loss=0.114, val_loss=0.0659, avg\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.0516, val_loss=0.0659, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.0516, val_loss=0.0422, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.0349, val_loss=0.0422, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.37it/s, loss=0.0349, val_loss=0.0336, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.09it/s, loss=0.0286, val_loss=0.0336, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.00it/s, loss=0.0286, val_loss=0.0292, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.93it/s, loss=0.0252, val_loss=0.0292, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=0.0252, val_loss=0.0262, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.0229, val_loss=0.0262, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 38.15it/s, loss=0.0229, val_loss=0.024, avg\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.0212, val_loss=0.024, avg\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.0212, val_loss=0.0223, av\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0199, val_loss=0.0223, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0199, val_loss=0.0209, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.0188, val_loss=0.0209, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=0.0188, val_loss=0.0198, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0179, val_loss=0.0198, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0179, val_loss=0.0189, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 22.01it/s, loss=0.0171, val_loss=0.0189, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 38.44it/s, loss=0.0171, val_loss=0.0181, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0165, val_loss=0.0181, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 38.33it/s, loss=0.0165, val_loss=0.0173, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.0158, val_loss=0.0173, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.83it/s, loss=0.0158, val_loss=0.0167, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=0.0153, val_loss=0.0167, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.0153, val_loss=0.0161, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.0148, val_loss=0.0161, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 38.26it/s, loss=0.0148, val_loss=0.0156, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.0143, val_loss=0.0156, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.75it/s, loss=0.0143, val_loss=0.0151, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.0139, val_loss=0.0151, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.0139, val_loss=0.0146, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=0.0135, val_loss=0.0146, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=0.0135, val_loss=0.0141, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.0131, val_loss=0.0141, a\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.98it/s, loss=0.0131, val_loss=0.0137, a\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=0.0128, val_loss=0.0137, a\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.0128, val_loss=0.0133, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.0124, val_loss=0.0133, a\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.0124, val_loss=0.0129, a\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.76it/s, loss=0.0121, val_loss=0.0129, a\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 38.00it/s, loss=0.0121, val_loss=0.0125, a\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.97it/s, loss=0.0118, val_loss=0.0125, a\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 38.31it/s, loss=0.0118, val_loss=0.0122, a\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.0116, val_loss=0.0122, a\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 38.30it/s, loss=0.0116, val_loss=0.0118, a\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.98it/s, loss=0.0113, val_loss=0.0118, a\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.0113, val_loss=0.0116, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.73it/s, loss=0.011, val_loss=0.0116, av\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.99it/s, loss=0.011, val_loss=0.0113, av\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.94it/s, loss=0.0108, val_loss=0.0113, a\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 38.30it/s, loss=0.0108, val_loss=0.011, av\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.0106, val_loss=0.011, av\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.0106, val_loss=0.0107, a\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.0104, val_loss=0.0107, a\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.0104, val_loss=0.0105, a\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.0102, val_loss=0.0105, a\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 38.27it/s, loss=0.0102, val_loss=0.0103, a\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.95it/s, loss=0.01, val_loss=0.0103, avg\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 38.34it/s, loss=0.01, val_loss=0.0101, avg\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.75it/s, loss=0.00982, val_loss=0.0101, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.99it/s, loss=0.00982, val_loss=0.00988,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.00964, val_loss=0.00988,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.00964, val_loss=0.0097, \n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.85it/s, loss=0.00947, val_loss=0.0097, \n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=0.00947, val_loss=0.00952,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.0093, val_loss=0.00952, \n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.0093, val_loss=0.00935, \n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.83it/s, loss=0.00913, val_loss=0.00935,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 38.14it/s, loss=0.00913, val_loss=0.00918,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.00897, val_loss=0.00918,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=0.00897, val_loss=0.009, a\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 38.02it/s, loss=0.00897, val_loss=0.009, a\n",
      "Sizes of clusters: 457, 343\n",
      "\n",
      "preds: [0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1\n",
      " 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0\n",
      " 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 0\n",
      " 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0\n",
      " 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0\n",
      " 1 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
      " 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1\n",
      " 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5463\n",
      "============= RUN 4 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.90it/s, loss=122, val_loss=0.0713, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.28it/s, loss=122, val_loss=0.113, avg_va\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.99it/s, loss=2.52, val_loss=0.113, avg_v\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.39it/s, loss=2.52, val_loss=0.143, avg_v\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.77it/s, loss=0.46, val_loss=0.143, avg_v\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 38.04it/s, loss=0.46, val_loss=0.0856, avg_\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.30it/s, loss=0.12, val_loss=0.0856, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.30it/s, loss=0.12, val_loss=0.0494, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.32it/s, loss=0.0488, val_loss=0.0494, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.0488, val_loss=0.0364, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.52it/s, loss=0.0301, val_loss=0.0364, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 37.61it/s, loss=0.0301, val_loss=0.0308, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.0229, val_loss=0.0308, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.38it/s, loss=0.0229, val_loss=0.0266, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.55it/s, loss=0.0194, val_loss=0.0266, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 37.65it/s, loss=0.0194, val_loss=0.0232, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.31it/s, loss=0.0171, val_loss=0.0232, av\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.26it/s, loss=0.0171, val_loss=0.0204, av\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.04it/s, loss=0.0154, val_loss=0.0204, av\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 36.87it/s, loss=0.0154, val_loss=0.018, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.0141, val_loss=0.018, av\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.0141, val_loss=0.0161, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.0132, val_loss=0.0161, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.0132, val_loss=0.0145, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.47it/s, loss=0.0124, val_loss=0.0145, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.59it/s, loss=0.0124, val_loss=0.0133, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.0118, val_loss=0.0133, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.0118, val_loss=0.0123, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.0113, val_loss=0.0123, a\n",
      "Epoch 14:  81%|▊| 26/32 [00:00<00:00, 33.16it/s, loss=0.0113, val_loss=0.0123, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.0113, val_loss=0.0116, a\u001b[A\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.30it/s, loss=0.0108, val_loss=0.0116, a\u001b[A\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.26it/s, loss=0.0108, val_loss=0.0109, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0105, val_loss=0.0109, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.0105, val_loss=0.0104, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.0101, val_loss=0.0104, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.79it/s, loss=0.0101, val_loss=0.00999, \n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.00982, val_loss=0.00999,\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.00982, val_loss=0.00963,\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.72it/s, loss=0.00955, val_loss=0.00963,\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.00955, val_loss=0.00929,\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0093, val_loss=0.00929, \n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.0093, val_loss=0.00895, \n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.36it/s, loss=0.00908, val_loss=0.00895,\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.42it/s, loss=0.00908, val_loss=0.00866,\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.12it/s, loss=0.00888, val_loss=0.00866,\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.04it/s, loss=0.00888, val_loss=0.0084, \n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.39it/s, loss=0.00869, val_loss=0.0084, \n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.00869, val_loss=0.00818,\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.37it/s, loss=0.0085, val_loss=0.00818, \n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.34it/s, loss=0.0085, val_loss=0.00796, \n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00832, val_loss=0.00796,\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00832, val_loss=0.00775,\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00814, val_loss=0.00775,\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.83it/s, loss=0.00814, val_loss=0.00753,\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.00796, val_loss=0.00753,\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.72it/s, loss=0.00796, val_loss=0.00731,\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.29it/s, loss=0.00779, val_loss=0.00731,\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.31it/s, loss=0.00779, val_loss=0.00711,\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.00763, val_loss=0.00711,\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.00763, val_loss=0.00694,\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.62it/s, loss=0.00747, val_loss=0.00694,\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.00747, val_loss=0.00681,\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.00732, val_loss=0.00681,\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.57it/s, loss=0.00732, val_loss=0.0067, \n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.00716, val_loss=0.0067, \n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.00716, val_loss=0.0066, \n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.007, val_loss=0.0066, av\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.73it/s, loss=0.007, val_loss=0.0065, av\n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.45it/s, loss=0.00684, val_loss=0.0065, \n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.55it/s, loss=0.00684, val_loss=0.00639,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.64it/s, loss=0.00668, val_loss=0.00639,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.85it/s, loss=0.00668, val_loss=0.00626,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.63it/s, loss=0.00652, val_loss=0.00626,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.76it/s, loss=0.00652, val_loss=0.00611,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 21.12it/s, loss=0.00637, val_loss=0.00611,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 37.02it/s, loss=0.00637, val_loss=0.00597,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.00623, val_loss=0.00597,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.00623, val_loss=0.00582,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.23it/s, loss=0.0061, val_loss=0.00582, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.20it/s, loss=0.0061, val_loss=0.00568, \n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 36.92it/s, loss=0.0061, val_loss=0.00568, \n",
      "Sizes of clusters: 450, 350\n",
      "\n",
      "preds: [1 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1\n",
      " 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0\n",
      " 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0\n",
      " 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0\n",
      " 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0\n",
      " 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 0\n",
      " 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0\n",
      " 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5625\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 16/32 [00:00<00:00, 21.87it/s, loss=151, val_loss=0.0882, avg_v\n",
      "Epoch 0: 100%|█| 32/32 [00:00<00:00, 38.19it/s, loss=151, val_loss=0.0961, avg_v\n",
      "Epoch 1:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=3.46, val_loss=0.0961, avg_\n",
      "Epoch 1: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=3.46, val_loss=0.0911, avg_\n",
      "Epoch 2:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.561, val_loss=0.0911, avg\n",
      "Epoch 2: 100%|█| 32/32 [00:00<00:00, 37.92it/s, loss=0.561, val_loss=0.0991, avg\n",
      "Epoch 3:  50%|▌| 16/32 [00:00<00:00, 21.60it/s, loss=0.15, val_loss=0.0991, avg_\n",
      "Epoch 3: 100%|█| 32/32 [00:00<00:00, 37.80it/s, loss=0.15, val_loss=0.0747, avg_\n",
      "Epoch 4:  50%|▌| 16/32 [00:00<00:00, 21.96it/s, loss=0.0613, val_loss=0.0747, av\n",
      "Epoch 4: 100%|█| 32/32 [00:00<00:00, 38.35it/s, loss=0.0613, val_loss=0.0516, av\n",
      "Epoch 5:  50%|▌| 16/32 [00:00<00:00, 21.91it/s, loss=0.0377, val_loss=0.0516, av\n",
      "Epoch 5: 100%|█| 32/32 [00:00<00:00, 38.29it/s, loss=0.0377, val_loss=0.0404, av\n",
      "Epoch 6:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.0299, val_loss=0.0404, av\n",
      "Epoch 6: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0299, val_loss=0.0339, av\n",
      "Epoch 7:  50%|▌| 16/32 [00:00<00:00, 21.92it/s, loss=0.0257, val_loss=0.0339, av\n",
      "Epoch 7: 100%|█| 32/32 [00:00<00:00, 38.20it/s, loss=0.0257, val_loss=0.0294, av\n",
      "Epoch 8:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.023, val_loss=0.0294, avg\n",
      "Epoch 8: 100%|█| 32/32 [00:00<00:00, 37.90it/s, loss=0.023, val_loss=0.026, avg_\n",
      "Epoch 9:  50%|▌| 16/32 [00:00<00:00, 21.32it/s, loss=0.021, val_loss=0.026, avg_\n",
      "Epoch 9: 100%|█| 32/32 [00:00<00:00, 37.29it/s, loss=0.021, val_loss=0.0235, avg\n",
      "Epoch 10:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.0194, val_loss=0.0235, a\n",
      "Epoch 10: 100%|█| 32/32 [00:00<00:00, 37.36it/s, loss=0.0194, val_loss=0.0215, a\n",
      "Epoch 11:  50%|▌| 16/32 [00:00<00:00, 21.56it/s, loss=0.0182, val_loss=0.0215, a\n",
      "Epoch 11: 100%|█| 32/32 [00:00<00:00, 37.68it/s, loss=0.0182, val_loss=0.0199, a\n",
      "Epoch 12:  50%|▌| 16/32 [00:00<00:00, 21.43it/s, loss=0.0172, val_loss=0.0199, a\n",
      "Epoch 12: 100%|█| 32/32 [00:00<00:00, 37.46it/s, loss=0.0172, val_loss=0.0185, a\n",
      "Epoch 13:  50%|▌| 16/32 [00:00<00:00, 21.69it/s, loss=0.0164, val_loss=0.0185, a\n",
      "Epoch 13: 100%|█| 32/32 [00:00<00:00, 37.88it/s, loss=0.0164, val_loss=0.0173, a\n",
      "Epoch 14:  50%|▌| 16/32 [00:00<00:00, 21.49it/s, loss=0.0158, val_loss=0.0173, a\n",
      "Epoch 14: 100%|█| 32/32 [00:00<00:00, 37.59it/s, loss=0.0158, val_loss=0.0164, a\n",
      "Epoch 15:  50%|▌| 16/32 [00:00<00:00, 21.26it/s, loss=0.0152, val_loss=0.0164, a\n",
      "Epoch 15: 100%|█| 32/32 [00:00<00:00, 37.23it/s, loss=0.0152, val_loss=0.0157, a\n",
      "Epoch 16:  50%|▌| 16/32 [00:00<00:00, 21.33it/s, loss=0.0147, val_loss=0.0157, a\n",
      "Epoch 16: 100%|█| 32/32 [00:00<00:00, 37.31it/s, loss=0.0147, val_loss=0.0151, a\n",
      "Epoch 17:  50%|▌| 16/32 [00:00<00:00, 21.66it/s, loss=0.0143, val_loss=0.0151, a\n",
      "Epoch 17: 100%|█| 32/32 [00:00<00:00, 37.81it/s, loss=0.0143, val_loss=0.0146, a\n",
      "Epoch 18:  50%|▌| 16/32 [00:00<00:00, 21.42it/s, loss=0.0139, val_loss=0.0146, a\n",
      "Epoch 18: 100%|█| 32/32 [00:00<00:00, 37.50it/s, loss=0.0139, val_loss=0.0141, a\n",
      "Epoch 19:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0135, val_loss=0.0141, a\n",
      "Epoch 19: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0135, val_loss=0.0137, a\n",
      "Epoch 20:  50%|▌| 16/32 [00:00<00:00, 21.03it/s, loss=0.0132, val_loss=0.0137, a\n",
      "Epoch 20: 100%|█| 32/32 [00:00<00:00, 36.89it/s, loss=0.0132, val_loss=0.0133, a\n",
      "Epoch 21:  50%|▌| 16/32 [00:00<00:00, 21.25it/s, loss=0.0128, val_loss=0.0133, a\n",
      "Epoch 21: 100%|█| 32/32 [00:00<00:00, 37.21it/s, loss=0.0128, val_loss=0.013, av\n",
      "Epoch 22:  50%|▌| 16/32 [00:00<00:00, 21.68it/s, loss=0.0125, val_loss=0.013, av\n",
      "Epoch 22: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.0125, val_loss=0.0127, a\n",
      "Epoch 23:  50%|▌| 16/32 [00:00<00:00, 21.67it/s, loss=0.0122, val_loss=0.0127, a\n",
      "Epoch 23: 100%|█| 32/32 [00:00<00:00, 37.87it/s, loss=0.0122, val_loss=0.0124, a\n",
      "Epoch 24:  50%|▌| 16/32 [00:00<00:00, 21.46it/s, loss=0.012, val_loss=0.0124, av\n",
      "Epoch 24: 100%|█| 32/32 [00:00<00:00, 37.57it/s, loss=0.012, val_loss=0.0121, av\n",
      "Epoch 25:  50%|▌| 16/32 [00:00<00:00, 21.74it/s, loss=0.0117, val_loss=0.0121, a\n",
      "Epoch 25: 100%|█| 32/32 [00:00<00:00, 37.99it/s, loss=0.0117, val_loss=0.0118, a\n",
      "Epoch 26:  50%|▌| 16/32 [00:00<00:00, 21.59it/s, loss=0.0114, val_loss=0.0118, a\n",
      "Epoch 26: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.0114, val_loss=0.0116, a\n",
      "Epoch 27:  50%|▌| 16/32 [00:00<00:00, 21.26it/s, loss=0.0112, val_loss=0.0116, a\n",
      "Epoch 27: 100%|█| 32/32 [00:00<00:00, 37.21it/s, loss=0.0112, val_loss=0.0113, a\n",
      "Epoch 28:  50%|▌| 16/32 [00:00<00:00, 21.10it/s, loss=0.011, val_loss=0.0113, av\n",
      "Epoch 28: 100%|█| 32/32 [00:00<00:00, 37.00it/s, loss=0.011, val_loss=0.0111, av\n",
      "Epoch 29:  50%|▌| 16/32 [00:00<00:00, 21.65it/s, loss=0.0107, val_loss=0.0111, a\n",
      "Epoch 29: 100%|█| 32/32 [00:00<00:00, 37.86it/s, loss=0.0107, val_loss=0.0108, a\n",
      "Epoch 30:  50%|▌| 16/32 [00:00<00:00, 21.71it/s, loss=0.0105, val_loss=0.0108, a\n",
      "Epoch 30: 100%|█| 32/32 [00:00<00:00, 37.95it/s, loss=0.0105, val_loss=0.0106, a\n",
      "Epoch 31:  50%|▌| 16/32 [00:00<00:00, 21.27it/s, loss=0.0103, val_loss=0.0106, a\n",
      "Epoch 31: 100%|█| 32/32 [00:00<00:00, 37.26it/s, loss=0.0103, val_loss=0.0104, a\n",
      "Epoch 32:  50%|▌| 16/32 [00:00<00:00, 21.61it/s, loss=0.0101, val_loss=0.0104, a\n",
      "Epoch 32: 100%|█| 32/32 [00:00<00:00, 37.77it/s, loss=0.0101, val_loss=0.0102, a\n",
      "Epoch 33:  50%|▌| 16/32 [00:00<00:00, 21.70it/s, loss=0.0099, val_loss=0.0102, a\n",
      "Epoch 33: 100%|█| 32/32 [00:00<00:00, 37.93it/s, loss=0.0099, val_loss=0.00998, \n",
      "Epoch 34:  50%|▌| 16/32 [00:00<00:00, 21.44it/s, loss=0.00971, val_loss=0.00998,\n",
      "Epoch 34: 100%|█| 32/32 [00:00<00:00, 37.47it/s, loss=0.00971, val_loss=0.00978,\n",
      "Epoch 35:  50%|▌| 16/32 [00:00<00:00, 21.57it/s, loss=0.00953, val_loss=0.00978,\n",
      "Epoch 35: 100%|█| 32/32 [00:00<00:00, 37.74it/s, loss=0.00953, val_loss=0.00959,\n",
      "Epoch 36:  50%|▌| 16/32 [00:00<00:00, 21.32it/s, loss=0.00935, val_loss=0.00959,\n",
      "Epoch 36: 100%|█| 32/32 [00:00<00:00, 37.33it/s, loss=0.00935, val_loss=0.00941,\n",
      "Epoch 37:  50%|▌| 16/32 [00:00<00:00, 20.74it/s, loss=0.00918, val_loss=0.00941,\n",
      "Epoch 37: 100%|█| 32/32 [00:00<00:00, 36.45it/s, loss=0.00918, val_loss=0.00923,\n",
      "Epoch 38:  50%|▌| 16/32 [00:00<00:00, 21.01it/s, loss=0.00901, val_loss=0.00923,\n",
      "Epoch 38: 100%|█| 32/32 [00:00<00:00, 36.40it/s, loss=0.00901, val_loss=0.00905,\n",
      "Epoch 39:  50%|▌| 16/32 [00:00<00:00, 21.51it/s, loss=0.00885, val_loss=0.00905,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.63it/s, loss=0.00885, val_loss=0.00888,\n",
      "Epoch 39: 100%|█| 32/32 [00:00<00:00, 37.24it/s, loss=0.00885, val_loss=0.00888,\n",
      "Sizes of clusters: 353, 447\n",
      "\n",
      "preds: [1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1\n",
      " 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1\n",
      " 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1\n",
      " 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1\n",
      " 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1\n",
      " 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
      " 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0\n",
      " 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1\n",
      " 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1\n",
      " 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 1 0 1\n",
      " 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1\n",
      " 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0\n",
      " 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "Purity: 0.5413\n",
      "\n",
      "Consistency: 0.5253\n",
      "Purity: 0.58025+-0.06860849072818904\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K2_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=11.6, val_loss=0.124, avg_v\n",
      "Epoch 0:  75%|▊| 36/48 [00:01<00:00, 30.56it/s, loss=11.6, val_loss=0.124, avg_v\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 37.50it/s, loss=11.6, val_loss=0.192, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.43, val_loss=0.192, avg_v\u001b[A\n",
      "Epoch 1:  54%|▌| 26/48 [00:01<00:00, 23.14it/s, loss=0.43, val_loss=0.192, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 37.58it/s, loss=0.43, val_loss=0.0764, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.0709, val_loss=0.0764, av\u001b[A\n",
      "Epoch 2:  75%|▊| 36/48 [00:01<00:00, 30.80it/s, loss=0.0709, val_loss=0.0764, av\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 37.77it/s, loss=0.0709, val_loss=0.0508, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.0339, val_loss=0.0508, av\u001b[A\n",
      "Epoch 3:  75%|▊| 36/48 [00:01<00:00, 31.12it/s, loss=0.0339, val_loss=0.0508, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.12it/s, loss=0.0339, val_loss=0.0384, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.0263, val_loss=0.0384, av\u001b[A\n",
      "Epoch 4:  75%|▊| 36/48 [00:01<00:00, 30.79it/s, loss=0.0263, val_loss=0.0384, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.0263, val_loss=0.0316, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.0225, val_loss=0.0316, av\u001b[A\n",
      "Epoch 5:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.0225, val_loss=0.0316, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.0225, val_loss=0.0266, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.02, val_loss=0.0266, avg_\u001b[A\n",
      "Epoch 6:  75%|▊| 36/48 [00:01<00:00, 30.69it/s, loss=0.02, val_loss=0.0266, avg_\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.67it/s, loss=0.02, val_loss=0.0229, avg_\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.0182, val_loss=0.0229, av\u001b[A\n",
      "Epoch 7:  75%|▊| 36/48 [00:01<00:00, 31.05it/s, loss=0.0182, val_loss=0.0229, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.0182, val_loss=0.0204, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.0169, val_loss=0.0204, av\u001b[A\n",
      "Epoch 8:  75%|▊| 36/48 [00:01<00:00, 30.70it/s, loss=0.0169, val_loss=0.0204, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.66it/s, loss=0.0169, val_loss=0.0183, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.0159, val_loss=0.0183, av\u001b[A\n",
      "Epoch 9:  75%|▊| 36/48 [00:01<00:00, 30.93it/s, loss=0.0159, val_loss=0.0183, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.0159, val_loss=0.0168, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.0151, val_loss=0.0168, a\u001b[A\n",
      "Epoch 10:  75%|▊| 36/48 [00:01<00:00, 30.64it/s, loss=0.0151, val_loss=0.0168, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.59it/s, loss=0.0151, val_loss=0.0155, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.0144, val_loss=0.0155, a\u001b[A\n",
      "Epoch 11:  75%|▊| 36/48 [00:01<00:00, 30.94it/s, loss=0.0144, val_loss=0.0155, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=0.0144, val_loss=0.0145, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.0137, val_loss=0.0145, a\u001b[A\n",
      "Epoch 12:  75%|▊| 36/48 [00:01<00:00, 30.55it/s, loss=0.0137, val_loss=0.0145, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.51it/s, loss=0.0137, val_loss=0.0137, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0131, val_loss=0.0137, a\u001b[A\n",
      "Epoch 13:  75%|▊| 36/48 [00:01<00:00, 31.01it/s, loss=0.0131, val_loss=0.0137, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.0131, val_loss=0.0131, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.0126, val_loss=0.0131, a\u001b[A\n",
      "Epoch 14:  75%|▊| 36/48 [00:01<00:00, 30.79it/s, loss=0.0126, val_loss=0.0131, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.77it/s, loss=0.0126, val_loss=0.0125, a\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.0121, val_loss=0.0125, a\u001b[A\n",
      "Epoch 15:  75%|▊| 36/48 [00:01<00:00, 30.65it/s, loss=0.0121, val_loss=0.0125, a\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.0121, val_loss=0.012, av\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.0116, val_loss=0.012, av\u001b[A\n",
      "Epoch 16:  75%|▊| 36/48 [00:01<00:00, 30.52it/s, loss=0.0116, val_loss=0.012, av\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.46it/s, loss=0.0116, val_loss=0.0115, a\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.0112, val_loss=0.0115, a\u001b[A\n",
      "Epoch 17:  75%|▊| 36/48 [00:01<00:00, 30.92it/s, loss=0.0112, val_loss=0.0115, a\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.0112, val_loss=0.011, av\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.0108, val_loss=0.011, av\u001b[A\n",
      "Epoch 18:  75%|▊| 36/48 [00:01<00:00, 30.72it/s, loss=0.0108, val_loss=0.011, av\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.0108, val_loss=0.0106, a\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0104, val_loss=0.0106, a\u001b[A\n",
      "Epoch 19:  75%|▊| 36/48 [00:01<00:00, 30.99it/s, loss=0.0104, val_loss=0.0106, a\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 37.98it/s, loss=0.0104, val_loss=0.0102, a\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.0101, val_loss=0.0102, a\u001b[A\n",
      "Epoch 20:  75%|▊| 36/48 [00:01<00:00, 30.77it/s, loss=0.0101, val_loss=0.0102, a\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.79it/s, loss=0.0101, val_loss=0.00991, \u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00977, val_loss=0.00991,\u001b[A\n",
      "Epoch 21:  75%|▊| 36/48 [00:01<00:00, 30.82it/s, loss=0.00977, val_loss=0.00991,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00977, val_loss=0.00959,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.54it/s, loss=0.00947, val_loss=0.00959,\u001b[A\n",
      "Epoch 22:  75%|▊| 36/48 [00:01<00:00, 30.72it/s, loss=0.00947, val_loss=0.00959,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00947, val_loss=0.00929,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.0092, val_loss=0.00929, \u001b[A\n",
      "Epoch 23:  75%|▊| 36/48 [00:01<00:00, 30.88it/s, loss=0.0092, val_loss=0.00929, \n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.87it/s, loss=0.0092, val_loss=0.00902, \u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00894, val_loss=0.00902,\u001b[A\n",
      "Epoch 24:  75%|▊| 36/48 [00:01<00:00, 30.76it/s, loss=0.00894, val_loss=0.00902,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00894, val_loss=0.00877,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00871, val_loss=0.00877,\u001b[A\n",
      "Epoch 25:  75%|▊| 36/48 [00:01<00:00, 31.02it/s, loss=0.00871, val_loss=0.00877,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.00871, val_loss=0.00854,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00849, val_loss=0.00854,\u001b[A\n",
      "Epoch 26:  75%|▊| 36/48 [00:01<00:00, 31.04it/s, loss=0.00849, val_loss=0.00854,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00849, val_loss=0.00831,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.0083, val_loss=0.00831, \u001b[A\n",
      "Epoch 27:  75%|▊| 36/48 [00:01<00:00, 30.85it/s, loss=0.0083, val_loss=0.00831, \n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.0083, val_loss=0.0081, a\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00811, val_loss=0.0081, \u001b[A\n",
      "Epoch 28:  75%|▊| 36/48 [00:01<00:00, 30.98it/s, loss=0.00811, val_loss=0.0081, \n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.00811, val_loss=0.0079, \u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00795, val_loss=0.0079, \u001b[A\n",
      "Epoch 29:  75%|▊| 36/48 [00:01<00:00, 30.73it/s, loss=0.00795, val_loss=0.0079, \n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00795, val_loss=0.00771,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0078, val_loss=0.00771, \u001b[A\n",
      "Epoch 30:  75%|▊| 36/48 [00:01<00:00, 30.99it/s, loss=0.0078, val_loss=0.00771, \n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.0078, val_loss=0.00755, \u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.50it/s, loss=0.00766, val_loss=0.00755,\u001b[A\n",
      "Epoch 31:  75%|▊| 36/48 [00:01<00:00, 30.67it/s, loss=0.00766, val_loss=0.00755,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00766, val_loss=0.0074, \u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00753, val_loss=0.0074, \u001b[A\n",
      "Epoch 32:  75%|▊| 36/48 [00:01<00:00, 30.94it/s, loss=0.00753, val_loss=0.0074, \n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.00753, val_loss=0.00727,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00741, val_loss=0.00727,\u001b[A\n",
      "Epoch 33:  75%|▊| 36/48 [00:01<00:00, 30.67it/s, loss=0.00741, val_loss=0.00727,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00741, val_loss=0.00715,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00731, val_loss=0.00715,\u001b[A\n",
      "Epoch 34:  75%|▊| 36/48 [00:01<00:00, 31.05it/s, loss=0.00731, val_loss=0.00715,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.00731, val_loss=0.00704,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00721, val_loss=0.00704,\u001b[A\n",
      "Epoch 35:  75%|▊| 36/48 [00:01<00:00, 30.71it/s, loss=0.00721, val_loss=0.00704,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.68it/s, loss=0.00721, val_loss=0.00695,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.00712, val_loss=0.00695,\u001b[A\n",
      "Epoch 36:  75%|▊| 36/48 [00:01<00:00, 31.03it/s, loss=0.00712, val_loss=0.00695,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00712, val_loss=0.00686,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00703, val_loss=0.00686,\u001b[A\n",
      "Epoch 37:  75%|▊| 36/48 [00:01<00:00, 30.81it/s, loss=0.00703, val_loss=0.00686,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00703, val_loss=0.00678,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00695, val_loss=0.00678,\u001b[A\n",
      "Epoch 38:  75%|▊| 36/48 [00:01<00:00, 30.98it/s, loss=0.00695, val_loss=0.00678,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.98it/s, loss=0.00695, val_loss=0.00671,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00687, val_loss=0.00671,\u001b[A\n",
      "Epoch 39:  75%|▊| 36/48 [00:01<00:00, 30.75it/s, loss=0.00687, val_loss=0.00671,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.00687, val_loss=0.00664,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.44it/s, loss=0.00687, val_loss=0.00664,\u001b[A\n",
      "Sizes of clusters: 315, 321, 564\n",
      "\n",
      "preds: [2 2 0 2 1 2 2 2 2 2 2 2 0 2 2 2 0 2 0 2 2 1 0 0 2 0 2 0 1 2 0 0 0 2 2 0 2\n",
      " 0 0 1 2 0 2 2 1 0 0 2 2 2 2 0 1 2 2 0 2 2 1 2 2 0 2 0 2 2 2 1 2 2 0 0 2 1\n",
      " 0 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 1 2 1 1 2 2 2 1 2 2 2 2 0 2 2 2 2 0 0 2\n",
      " 2 2 2 1 2 2 2 0 0 1 2 2 0 1 0 2 2 2 2 0 2 2 2 0 2 2 2 0 2 2 0 0 2 0 2 2 2\n",
      " 1 2 2 0 2 0 0 0 0 0 2 2 1 0 2 1 2 1 1 1 2 2 2 2 0 0 0 2 2 2 1 0 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 1 2 0 2 0 2 2 1 2 2 2 2 2 1 2 2 2 2 0 2 0 2 0 0 2 2\n",
      " 2 1 2 2 2 1 2 2 0 2 2 0 2 2 0 0 2 2 0 1 0 1 2 2 1 2 0 2 0 0 0 0 2 0 1 0 0\n",
      " 1 0 2 1 2 0 2 2 2 0 2 2 1 0 0 2 2 2 2 2 0 2 0 1 0 2 1 0 0 2 2 1 2 2 2 2 0\n",
      " 2 2 1 2 2 0 2 2 0 2 0 2 0 2 0 0 2 2 0 0 2 2 2 2 2 2 2 0 1 2 0 0 0 2 2 0 2\n",
      " 2 0 1 2 2 2 2 2 2 2 1 2 2 0 2 2 2 0 2 0 2 2 0 0 2 2 2 2 2 2 1 0 0 2 2 0 2\n",
      " 0 0 0 1 2 0 2 2 0 2 1 2 1 0 0 2 2 0 0 1 2 0 0 0 2 2 0 0 2 1 2 1 2 2 2 2 2\n",
      " 0 2 2 2 0 2 2 2 2 0 2 1 2 2 2 2 1 2 2 2 1 0 0 0 1 2 2 2 2 2 2 1 1 0 2 0 2\n",
      " 0 1 2 0 1 0 2 0 2 2 0 0 2 1 0 0 1 0 1 0 0 2 2 2 2 2 2 0 2 0 0 2 1 0 0 2 1\n",
      " 2 0 2 2 2 0 0 2 2 0 0 0 2 0 0 2 2 0 0 2 2 0 1 2 0 2 2 2 0 0 0 2 0 0 0 1 2\n",
      " 1 0 2 2 0 2 2 1 0 1 2 0 0 2 0 2 2 0 2 2 2 2 0 2 2 2 0 2 2 0 2 2 2 0 2 0 2\n",
      " 0 1 2 2 2 2 0 0 2 2 2 2 0 0 2 1 0 1 2 2 2 0 0 2 2 2 2 2 0 2 1 0 1 2 0 2 2\n",
      " 0 0 2 2 1 1 2 0 0 0 0 0 2 2 2 0 2 2 2 0 2 0 0 2 0 2 2 2 2 2 0 2 2 1 0 2 2\n",
      " 2 1 0 1 2 2 2 0 0 2 0 1 2 1 1 0 1 1 0 2 0 1 2 2 2 2 0 0 0 2 2 0 0 0 0 0 2\n",
      " 2 1 0 2 2 1 1 2 2 0 2 2 2 0 1 1 2 2 2 2 2 2 1 0 0 0 2 2 0 0 0 1 2 0 1 0 2\n",
      " 0 0 2 2 2 0 1 1 0 0 2 2 2 0 2 0 2 2 2 1 2 2 0 1 0 1 2 2 2 2 2 1 0 2 0 2 1\n",
      " 1 2 2 2 1 2 1 2 0 2 2 1 2 2 0 2 0 0 2 1 2 2 1 2 0 0 0 0 2 0 2 2 2 0 0 0 1\n",
      " 1 2 0 0 0 1 2 0 2 0 0 0 0 2 1 1 0 2 2 2 0 2 2 1 0 1 0 1 1 2 1 1 1 2 1 2 2\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 2 2 0 1 2 1 1 2 1 0 1 0 2 2 2 2 1 0 2 2 0 0 2 1 0\n",
      " 0 0 2 1 2 2 1 2 1 1 2 0 1 1 2 2 1 0 2 2 1 1 1 1 0 1 2 0 2 1 0 1 1 1 2 1 2\n",
      " 2 1 2 2 1 2 1 2 1 2 2 2 2 0 1 1 1 0 1 1 1 1 1 2 1 1 2 0 1 1 0 1 2 0 2 1 2\n",
      " 0 0 2 1 1 1 1 1 0 2 1 1 1 1 0 2 0 1 0 0 2 1 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1\n",
      " 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 0 2 1 0 1 2 2 0 1 2 2 1 0 1 1 1 1 1 1 2 1\n",
      " 0 2 1 1 2 2 2 1 1 0 1 2 1 0 2 2 1 0 2 0 0 1 2 1 2 1 1 1 1 1 1 2 1 1 2 1 2\n",
      " 2 1 1 1 1 1 1 1 0 2 2 1 1 1 1 0 1 2 0 1 2 1 2 2 0 2 1 2 1 1 0 0 1 2 2 0 1\n",
      " 1 1 2 0 2 0 2 1 0 2 0 1 2 1 2 1 1 2 1 1 1 1 2 2 0 1 2 2 1 1 0 2 1 1 1 1 1\n",
      " 2 1 1 1 1 2 1 2 1 0 2 1 1 2 1 1 0 1 2 2 1 1 2 1 1 0 2 2 1 1 2 0 2 0 2 1 1\n",
      " 1 1 2 2 1 1 1 1 1 0 1 2 2 2 2 2 2 1 1 1 0 2 1 1 2 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 2 1 1 1 2 1 1 2 2 2 2 0 1 1 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.4842\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=10.6, val_loss=0.118, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=10.6, val_loss=0.342, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.354, val_loss=0.342, avg_\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.66it/s, loss=0.354, val_loss=0.342, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=0.354, val_loss=0.121, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.0745, val_loss=0.121, avg\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.52it/s, loss=0.0745, val_loss=0.121, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.0745, val_loss=0.0535, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.0389, val_loss=0.0535, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.66it/s, loss=0.0389, val_loss=0.0535, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=0.0389, val_loss=0.0372, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0301, val_loss=0.0372, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 32.41it/s, loss=0.0301, val_loss=0.0372, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.0301, val_loss=0.0303, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.94it/s, loss=0.0255, val_loss=0.0303, av\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.66it/s, loss=0.0255, val_loss=0.0303, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.0255, val_loss=0.026, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0223, val_loss=0.026, avg\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 32.42it/s, loss=0.0223, val_loss=0.026, avg\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.0223, val_loss=0.0228, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.0198, val_loss=0.0228, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.66it/s, loss=0.0198, val_loss=0.0228, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=0.0198, val_loss=0.0202, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.0178, val_loss=0.0202, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 32.56it/s, loss=0.0178, val_loss=0.0202, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 38.21it/s, loss=0.0178, val_loss=0.0181, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.91it/s, loss=0.0161, val_loss=0.0181, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.64it/s, loss=0.0161, val_loss=0.0181, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.0161, val_loss=0.0162, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0147, val_loss=0.0162, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.0147, val_loss=0.0162, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 38.04it/s, loss=0.0147, val_loss=0.0146, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 22.00it/s, loss=0.0134, val_loss=0.0146, a\u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 32.74it/s, loss=0.0134, val_loss=0.0146, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.44it/s, loss=0.0134, val_loss=0.0131, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.0124, val_loss=0.0131, a\u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 32.43it/s, loss=0.0124, val_loss=0.0131, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 38.08it/s, loss=0.0124, val_loss=0.0119, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.0114, val_loss=0.0119, a\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 32.69it/s, loss=0.0114, val_loss=0.0119, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.35it/s, loss=0.0114, val_loss=0.0109, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.0106, val_loss=0.0109, a\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 32.14it/s, loss=0.0106, val_loss=0.0109, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.82it/s, loss=0.0106, val_loss=0.01, avg\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00988, val_loss=0.01, av\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.42it/s, loss=0.00988, val_loss=0.01, av\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.00988, val_loss=0.00929,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.37it/s, loss=0.00924, val_loss=0.00929,\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 31.85it/s, loss=0.00924, val_loss=0.00929,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.45it/s, loss=0.00924, val_loss=0.00867,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00869, val_loss=0.00867,\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.21it/s, loss=0.00869, val_loss=0.00867,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00869, val_loss=0.00814,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00822, val_loss=0.00814,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 32.02it/s, loss=0.00822, val_loss=0.00814,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.66it/s, loss=0.00822, val_loss=0.0077, \u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.0078, val_loss=0.0077, a\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.0078, val_loss=0.0077, a\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 37.97it/s, loss=0.0078, val_loss=0.00733, \u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.39it/s, loss=0.00745, val_loss=0.00733,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 31.81it/s, loss=0.00745, val_loss=0.00733,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.34it/s, loss=0.00745, val_loss=0.00702,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.00716, val_loss=0.00702,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 32.17it/s, loss=0.00716, val_loss=0.00702,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00716, val_loss=0.00675,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.31it/s, loss=0.00691, val_loss=0.00675,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 31.75it/s, loss=0.00691, val_loss=0.00675,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.34it/s, loss=0.00691, val_loss=0.00652,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00669, val_loss=0.00652,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.23it/s, loss=0.00669, val_loss=0.00652,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.83it/s, loss=0.00669, val_loss=0.0063, \u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.16it/s, loss=0.00651, val_loss=0.0063, \u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 31.55it/s, loss=0.00651, val_loss=0.0063, \n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.11it/s, loss=0.00651, val_loss=0.00611,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00634, val_loss=0.00611,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.25it/s, loss=0.00634, val_loss=0.00611,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 37.86it/s, loss=0.00634, val_loss=0.00595,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00619, val_loss=0.00595,\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.23it/s, loss=0.00619, val_loss=0.00595,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00619, val_loss=0.00583,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.50it/s, loss=0.00606, val_loss=0.00583,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.02it/s, loss=0.00606, val_loss=0.00583,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.66it/s, loss=0.00606, val_loss=0.00572,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00595, val_loss=0.00572,\u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 32.19it/s, loss=0.00595, val_loss=0.00572,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00595, val_loss=0.00561,\u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.00586, val_loss=0.00561,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 31.93it/s, loss=0.00586, val_loss=0.00561,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.55it/s, loss=0.00586, val_loss=0.00552,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00578, val_loss=0.00552,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.27it/s, loss=0.00578, val_loss=0.00552,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.00578, val_loss=0.00544,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.33it/s, loss=0.00572, val_loss=0.00544,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 31.74it/s, loss=0.00572, val_loss=0.00544,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.36it/s, loss=0.00572, val_loss=0.00539,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00566, val_loss=0.00539,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.23it/s, loss=0.00566, val_loss=0.00539,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.87it/s, loss=0.00566, val_loss=0.00537,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.22it/s, loss=0.00561, val_loss=0.00537,\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 31.61it/s, loss=0.00561, val_loss=0.00537,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.21it/s, loss=0.00561, val_loss=0.00536,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00557, val_loss=0.00536,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.25it/s, loss=0.00557, val_loss=0.00536,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.00557, val_loss=0.00537,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.17it/s, loss=0.00554, val_loss=0.00537,\u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 31.56it/s, loss=0.00554, val_loss=0.00537,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.13it/s, loss=0.00554, val_loss=0.0054, \u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00552, val_loss=0.0054, \u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.00552, val_loss=0.0054, \n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00552, val_loss=0.00543,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.00551, val_loss=0.00543,\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 31.97it/s, loss=0.00551, val_loss=0.00543,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.00551, val_loss=0.00542,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00549, val_loss=0.00542,\u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.00549, val_loss=0.00542,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.91it/s, loss=0.00549, val_loss=0.00534,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 20.97it/s, loss=0.00546, val_loss=0.00534,\u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 31.28it/s, loss=0.00546, val_loss=0.00534,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 36.85it/s, loss=0.00546, val_loss=0.0052, \u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 36.64it/s, loss=0.00546, val_loss=0.0052, \u001b[A\n",
      "Sizes of clusters: 461, 418, 321\n",
      "\n",
      "preds: [1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 2 1 1 0 1 1 0 0 0 1 0 1 1\n",
      " 0 1 1 0 2 0 0 1 0 0 1 0 2 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 1 2 1 1 1 0 1 1 0\n",
      " 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1\n",
      " 2 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 1 2 1 1 0 0 1 1 0 1 1 1 0\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 0 2 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 2 1 0 0 1 0 1 0\n",
      " 0 1 1 0 1 0 1 0 1 1 0 0 1 2 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 0 1 2 0 1 0 1 0 1\n",
      " 2 0 0 0 2 1 1 1 1 1 1 1 0 0 1 1 2 0 0 1 1 0 1 1 1 1 0 1 1 1 2 2 0 0 0 1 0\n",
      " 2 0 2 2 0 0 1 1 2 0 1 2 0 0 1 2 0 1 2 1 1 1 1 0 0 0 0 0 0 0 0 0 2 0 2 2 1\n",
      " 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 0 0 1 0 0 2 0 1 0 1 2 0 1 0 1 0 0 0 1 1\n",
      " 1 1 0 0 1 0 2 2 1 0 0 0 2 1 1 1 1 0 1 1 1 0 1 2 0 2 1 1 1 1 2 1 0 0 0 0 1\n",
      " 2 1 1 0 0 0 1 1 0 2 1 1 2 0 0 0 0 0 0 0 0 2 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 2 1 2 0 1 0 1 0 0 0 0 0 1 0 0 1 2 0 0 1 0 2 0 2 1 0 0 0 0 1 2 0 2 2 1\n",
      " 0 0 0 0 1 1 2 2 1 0 1 0 1 0 2 1 0 0 2 1 0 1 1 2 2 0 0 1 0 1 1 0 1 1 0 0 2\n",
      " 0 0 1 0 0 0 2 1 1 0 0 0 1 1 0 0 1 1 0 1 1 2 2 0 1 1 0 1 0 1 0 0 1 1 1 0 0\n",
      " 0 2 2 0 0 1 1 0 2 0 1 2 2 1 1 0 0 0 1 0 1 2 0 0 2 0 0 0 2 1 0 2 0 0 2 2 1\n",
      " 0 2 1 0 1 0 2 1 2 1 0 2 1 1 0 1 1 2 0 1 0 2 2 1 2 1 0 2 1 0 0 0 1 2 0 0 1\n",
      " 1 1 1 0 1 1 1 0 2 2 2 0 0 0 1 2 1 1 1 0 0 0 2 0 2 0 0 0 0 2 2 2 2 2 2 0 2\n",
      " 2 2 2 2 1 2 2 2 2 2 2 2 2 2 0 1 0 2 2 0 2 2 2 2 0 0 2 0 2 2 0 0 2 0 2 2 2\n",
      " 2 2 2 2 0 0 0 0 2 2 0 2 0 2 2 2 0 2 1 2 2 0 2 2 0 2 0 0 0 2 0 0 0 0 2 2 0\n",
      " 0 2 0 2 2 0 0 0 2 0 1 0 1 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 2 2 2 2\n",
      " 0 2 1 0 0 2 2 0 2 0 2 2 0 2 2 0 2 0 2 1 1 2 0 1 2 2 2 0 2 1 2 0 2 2 0 0 1\n",
      " 1 0 2 2 2 2 1 0 0 0 2 2 2 0 0 0 2 0 2 2 2 2 0 0 2 2 2 2 0 2 2 2 2 2 2 2 0\n",
      " 0 1 2 2 2 2 2 2 2 2 2 0 0 1 0 2 0 2 1 0 2 2 0 2 2 2 2 1 2 2 2 0 2 0 2 2 0\n",
      " 0 2 2 2 2 0 0 0 0 2 0 2 0 2 2 0 2 2 0 2 0 0 2 2 0 2 2 2 0 2 0 0 0 2 2 2 2\n",
      " 0 2 0 2 0 0 2 2 2 0 0 2 0 2 2 0 0 0 0 2 2 2 0 0 2 2 2 0 2 0 2 1 0 2 0 1 2\n",
      " 2 2 2 2 2 0 2 2 2 0 0 0 2 2 2 0 2 2 1 1 2 2 2 2 2 2 1 0 0 2 0 2 0 2 2 2 2\n",
      " 0 2 2 2 2 2 2 2 2 1 2 2 0 1 2 0 2 2 2 2 0 0 0 2 1 0 1 2 2 0 2 2 0 2 2 2 2\n",
      " 2 2 2 0 2 0 0 0 2 2 2 0 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5483\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=9.61, val_loss=0.081, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 37.94it/s, loss=9.61, val_loss=0.227, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.441, val_loss=0.227, avg_\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.63it/s, loss=0.441, val_loss=0.227, avg_\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.32it/s, loss=0.441, val_loss=0.0966, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0681, val_loss=0.0966, av\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.40it/s, loss=0.0681, val_loss=0.0966, av\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.0681, val_loss=0.0423, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0297, val_loss=0.0423, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.36it/s, loss=0.0297, val_loss=0.0423, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 37.98it/s, loss=0.0297, val_loss=0.0291, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.46it/s, loss=0.0226, val_loss=0.0291, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 31.96it/s, loss=0.0226, val_loss=0.0291, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.58it/s, loss=0.0226, val_loss=0.0245, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.019, val_loss=0.0245, avg\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.35it/s, loss=0.019, val_loss=0.0245, avg\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.00it/s, loss=0.019, val_loss=0.0209, avg\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.13it/s, loss=0.0164, val_loss=0.0209, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 31.51it/s, loss=0.0164, val_loss=0.0209, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.07it/s, loss=0.0164, val_loss=0.0181, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.0144, val_loss=0.0181, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.48it/s, loss=0.0144, val_loss=0.0181, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=0.0144, val_loss=0.0159, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.0128, val_loss=0.0159, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 32.14it/s, loss=0.0128, val_loss=0.0159, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.75it/s, loss=0.0128, val_loss=0.014, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.0116, val_loss=0.014, avg\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.11it/s, loss=0.0116, val_loss=0.014, avg\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 37.74it/s, loss=0.0116, val_loss=0.0125, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.0106, val_loss=0.0125, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 32.14it/s, loss=0.0106, val_loss=0.0125, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.77it/s, loss=0.0106, val_loss=0.0112, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00986, val_loss=0.0112, \u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 32.45it/s, loss=0.00986, val_loss=0.0112, \n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00986, val_loss=0.0102, \u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 20.96it/s, loss=0.00925, val_loss=0.0102, \u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 31.24it/s, loss=0.00925, val_loss=0.0102, \n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 36.81it/s, loss=0.00925, val_loss=0.00936,\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.00876, val_loss=0.00936,\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 32.46it/s, loss=0.00876, val_loss=0.00936,\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 38.11it/s, loss=0.00876, val_loss=0.00872,\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.49it/s, loss=0.00836, val_loss=0.00872,\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.00836, val_loss=0.00872,\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.60it/s, loss=0.00836, val_loss=0.00821,\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00803, val_loss=0.00821,\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.21it/s, loss=0.00803, val_loss=0.00821,\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=0.00803, val_loss=0.00779,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00775, val_loss=0.00779,\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 32.06it/s, loss=0.00775, val_loss=0.00779,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.68it/s, loss=0.00775, val_loss=0.00745,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00753, val_loss=0.00745,\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.00753, val_loss=0.00745,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.00753, val_loss=0.00716,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.00733, val_loss=0.00716,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 32.18it/s, loss=0.00733, val_loss=0.00716,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.00733, val_loss=0.00693,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.47it/s, loss=0.00717, val_loss=0.00693,\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 31.95it/s, loss=0.00717, val_loss=0.00693,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00717, val_loss=0.00674,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.00702, val_loss=0.00674,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.00702, val_loss=0.00674,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.75it/s, loss=0.00702, val_loss=0.00658,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.0069, val_loss=0.00658, \u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 32.40it/s, loss=0.0069, val_loss=0.00658, \n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.06it/s, loss=0.0069, val_loss=0.00643, \u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.59it/s, loss=0.00679, val_loss=0.00643,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 32.14it/s, loss=0.00679, val_loss=0.00643,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.78it/s, loss=0.00679, val_loss=0.00631,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.00669, val_loss=0.00631,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.11it/s, loss=0.00669, val_loss=0.00631,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.00669, val_loss=0.00619,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.0066, val_loss=0.00619, \u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 32.01it/s, loss=0.0066, val_loss=0.00619, \n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.57it/s, loss=0.0066, val_loss=0.00609, \u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00651, val_loss=0.00609,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.00651, val_loss=0.00609,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.00651, val_loss=0.006, a\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.65it/s, loss=0.00644, val_loss=0.006, a\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.22it/s, loss=0.00644, val_loss=0.006, a\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=0.00644, val_loss=0.00591,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00636, val_loss=0.00591,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.04it/s, loss=0.00636, val_loss=0.00591,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00636, val_loss=0.00583,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.0063, val_loss=0.00583, \u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 32.28it/s, loss=0.0063, val_loss=0.00583, \n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.0063, val_loss=0.00576, \u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00623, val_loss=0.00576,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 32.05it/s, loss=0.00623, val_loss=0.00576,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.69it/s, loss=0.00623, val_loss=0.00569,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.38it/s, loss=0.00618, val_loss=0.00569,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 31.85it/s, loss=0.00618, val_loss=0.00569,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 37.40it/s, loss=0.00618, val_loss=0.00562,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.53it/s, loss=0.00612, val_loss=0.00562,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.06it/s, loss=0.00612, val_loss=0.00562,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00612, val_loss=0.00556,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00606, val_loss=0.00556,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.09it/s, loss=0.00606, val_loss=0.00556,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.71it/s, loss=0.00606, val_loss=0.0055, \u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.57it/s, loss=0.00601, val_loss=0.0055, \u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 32.13it/s, loss=0.00601, val_loss=0.0055, \n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.00601, val_loss=0.00543,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00596, val_loss=0.00543,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.36it/s, loss=0.00596, val_loss=0.00543,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.00596, val_loss=0.00537,\u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.00592, val_loss=0.00537,\u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 31.89it/s, loss=0.00592, val_loss=0.00537,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.55it/s, loss=0.00592, val_loss=0.00532,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.00587, val_loss=0.00532,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.30it/s, loss=0.00587, val_loss=0.00532,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00587, val_loss=0.00526,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.32it/s, loss=0.00582, val_loss=0.00526,\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 31.78it/s, loss=0.00582, val_loss=0.00526,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.37it/s, loss=0.00582, val_loss=0.0052, \u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00578, val_loss=0.0052, \u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.30it/s, loss=0.00578, val_loss=0.0052, \n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00578, val_loss=0.00514,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.00574, val_loss=0.00514,\u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 31.94it/s, loss=0.00574, val_loss=0.00514,\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.55it/s, loss=0.00574, val_loss=0.00509,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.28it/s, loss=0.00574, val_loss=0.00509,\u001b[A\n",
      "Sizes of clusters: 579, 291, 330\n",
      "\n",
      "preds: [1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 2 2 0 0 0 0\n",
      " 0 1 1 0 2 2 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 0 2 1 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 1 2 0 0 0 0 1 1 0 0 1 2 1 1 0\n",
      " 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1\n",
      " 2 0 2 1 1 1 0 1 0 1 1 0 0 2 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 2 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 2 1 0 1 0 1 1 0 2 2 1 1 1 1 0 0 0 0 1 0 1 1 0 2 0 1 1 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 0 2 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 2 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 2 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 2 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 2 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0\n",
      " 2 0 0 0 1 0 1 0 0 1 0 0 0 0 0 2 1 0 0 0 2 1 0 0 0 0 1 0 0 2 2 1 0 0 2 2 1\n",
      " 0 0 0 1 0 1 2 0 0 0 0 0 1 0 0 0 0 0 2 1 0 2 2 0 0 0 1 2 2 0 0 0 2 2 2 1 0\n",
      " 0 0 0 0 0 0 0 2 0 1 0 2 0 1 1 1 1 0 0 0 0 0 2 0 0 2 2 1 1 0 2 1 0 0 0 0 1\n",
      " 2 0 0 0 0 1 1 0 1 2 0 1 2 0 0 0 2 2 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 2 1 0\n",
      " 0 0 0 0 2 0 0 0 1 0 2 2 0 1 0 0 0 0 2 2 0 0 2 0 0 2 1 0 1 0 0 0 2 0 2 2 1\n",
      " 0 0 0 0 1 1 2 2 0 0 0 0 1 1 0 0 1 0 2 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 2\n",
      " 0 1 0 0 0 0 0 1 1 2 1 0 0 0 0 0 1 0 0 1 1 2 0 0 1 0 0 1 0 0 0 1 0 2 1 0 0\n",
      " 2 2 0 0 0 1 1 0 2 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 1 0 0 2 0 2 2 1\n",
      " 1 2 0 2 1 0 0 0 2 0 0 0 1 1 2 1 0 2 2 1 2 0 0 0 2 0 2 2 1 0 0 0 1 2 0 0 1\n",
      " 1 1 0 2 0 1 0 0 0 2 2 0 0 0 1 0 0 1 0 1 2 1 0 0 2 1 2 0 0 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 1 0 2 0 2 2 2 2 0 0 2 2 0 0 2 2 2 2 0 2 0 2 2 0 1 2 2 0 2 2\n",
      " 2 2 2 2 0 0 0 0 2 2 0 2 2 0 2 2 0 2 0 0 2 2 2 2 2 2 0 2 0 0 0 0 2 0 2 0 0\n",
      " 0 2 2 2 2 0 2 0 2 2 1 0 0 2 0 2 2 2 2 0 2 2 2 0 0 2 2 2 2 2 0 2 2 2 2 0 2\n",
      " 2 2 1 0 1 2 0 2 2 0 2 2 0 0 2 0 2 0 2 0 1 2 0 1 0 2 2 0 2 0 2 0 2 2 2 0 1\n",
      " 1 0 2 0 2 2 1 0 0 0 2 2 2 1 0 1 2 1 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 2 0 2 0\n",
      " 0 1 2 2 2 0 2 0 2 2 2 2 0 0 2 2 0 2 0 2 2 2 0 2 2 2 0 1 0 2 2 0 2 0 2 2 2\n",
      " 0 0 2 2 0 0 0 0 2 2 0 0 0 2 2 2 2 2 2 2 0 0 2 2 2 0 2 0 0 2 2 2 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 0 2 2 0 2 2 1 0 0 0 2 2 2 0 0 2 2 2 0 2 0 2 0 1 2 0 1 0\n",
      " 2 0 2 2 2 0 2 2 2 0 0 0 2 2 2 0 2 2 1 0 2 2 2 2 2 2 0 2 2 0 0 2 2 2 2 2 2\n",
      " 0 0 2 2 2 0 2 2 0 0 2 2 2 0 2 0 2 2 2 0 0 2 0 2 0 0 0 2 2 0 0 2 0 2 2 2 2\n",
      " 2 2 2 0 2 0 0 0 2 2 2 2 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5392\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 22.00it/s, loss=9.9, val_loss=0.0751, avg_v\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.42it/s, loss=9.9, val_loss=0.511, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.5, val_loss=0.511, avg_va\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.60it/s, loss=0.5, val_loss=0.511, avg_va\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.5, val_loss=0.133, avg_va\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0778, val_loss=0.133, avg\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.40it/s, loss=0.0778, val_loss=0.133, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.0778, val_loss=0.0527, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.0339, val_loss=0.0527, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.58it/s, loss=0.0339, val_loss=0.0527, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.0339, val_loss=0.0357, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.0259, val_loss=0.0357, av\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 32.60it/s, loss=0.0259, val_loss=0.0357, av\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 38.22it/s, loss=0.0259, val_loss=0.0288, av\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.0224, val_loss=0.0288, av\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.71it/s, loss=0.0224, val_loss=0.0288, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 38.39it/s, loss=0.0224, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.77it/s, loss=0.0201, val_loss=0.0246, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 32.41it/s, loss=0.0201, val_loss=0.0246, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 38.06it/s, loss=0.0201, val_loss=0.0216, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.0183, val_loss=0.0216, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.68it/s, loss=0.0183, val_loss=0.0216, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.34it/s, loss=0.0183, val_loss=0.0194, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.0169, val_loss=0.0194, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 31.89it/s, loss=0.0169, val_loss=0.0194, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.51it/s, loss=0.0169, val_loss=0.0178, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.0157, val_loss=0.0178, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.36it/s, loss=0.0157, val_loss=0.0178, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.0157, val_loss=0.0163, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.58it/s, loss=0.0146, val_loss=0.0163, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.0146, val_loss=0.0163, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.76it/s, loss=0.0146, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0137, val_loss=0.0152, a\u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 32.37it/s, loss=0.0137, val_loss=0.0152, a\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 38.02it/s, loss=0.0137, val_loss=0.0141, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.0129, val_loss=0.0141, a\u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 32.03it/s, loss=0.0129, val_loss=0.0141, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.66it/s, loss=0.0129, val_loss=0.0131, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.70it/s, loss=0.0121, val_loss=0.0131, a\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 32.28it/s, loss=0.0121, val_loss=0.0131, a\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.0121, val_loss=0.0123, a\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.40it/s, loss=0.0115, val_loss=0.0123, a\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 31.87it/s, loss=0.0115, val_loss=0.0123, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.48it/s, loss=0.0115, val_loss=0.0115, a\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.85it/s, loss=0.0109, val_loss=0.0115, a\u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.0109, val_loss=0.0115, a\n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.0109, val_loss=0.0108, a\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.0104, val_loss=0.0108, a\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 32.46it/s, loss=0.0104, val_loss=0.0108, a\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 38.10it/s, loss=0.0104, val_loss=0.0102, a\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00989, val_loss=0.0102, \u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.59it/s, loss=0.00989, val_loss=0.0102, \n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.00989, val_loss=0.00963,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.82it/s, loss=0.00947, val_loss=0.00963,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 32.51it/s, loss=0.00947, val_loss=0.00963,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 38.16it/s, loss=0.00947, val_loss=0.0091, \u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00909, val_loss=0.0091, \u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.64it/s, loss=0.00909, val_loss=0.0091, \n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 38.30it/s, loss=0.00909, val_loss=0.00865,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.78it/s, loss=0.00875, val_loss=0.00865,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 32.40it/s, loss=0.00875, val_loss=0.00865,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00875, val_loss=0.00828,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.00844, val_loss=0.00828,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 32.41it/s, loss=0.00844, val_loss=0.00828,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00844, val_loss=0.00795,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.79it/s, loss=0.00817, val_loss=0.00795,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 32.47it/s, loss=0.00817, val_loss=0.00795,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 38.09it/s, loss=0.00817, val_loss=0.00764,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.00793, val_loss=0.00764,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.61it/s, loss=0.00793, val_loss=0.00764,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 38.28it/s, loss=0.00793, val_loss=0.00737,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.80it/s, loss=0.00771, val_loss=0.00737,\u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 32.48it/s, loss=0.00771, val_loss=0.00737,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=0.00771, val_loss=0.00713,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.00752, val_loss=0.00713,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.69it/s, loss=0.00752, val_loss=0.00713,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 38.36it/s, loss=0.00752, val_loss=0.00692,\u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.93it/s, loss=0.00734, val_loss=0.00692,\u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.57it/s, loss=0.00734, val_loss=0.00692,\n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 38.24it/s, loss=0.00734, val_loss=0.00673,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.00718, val_loss=0.00673,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.02it/s, loss=0.00718, val_loss=0.00673,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.64it/s, loss=0.00718, val_loss=0.00656,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.88it/s, loss=0.00704, val_loss=0.00656,\u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 32.59it/s, loss=0.00704, val_loss=0.00656,\n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.00704, val_loss=0.0064, \u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.00691, val_loss=0.0064, \u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.00691, val_loss=0.0064, \n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 38.05it/s, loss=0.00691, val_loss=0.00626,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.95it/s, loss=0.00679, val_loss=0.00626,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.67it/s, loss=0.00679, val_loss=0.00626,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 38.37it/s, loss=0.00679, val_loss=0.00613,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.62it/s, loss=0.00668, val_loss=0.00613,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.19it/s, loss=0.00668, val_loss=0.00613,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.81it/s, loss=0.00668, val_loss=0.00602,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00658, val_loss=0.00602,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.07it/s, loss=0.00658, val_loss=0.00602,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.67it/s, loss=0.00658, val_loss=0.00591,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.74it/s, loss=0.00649, val_loss=0.00591,\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 32.39it/s, loss=0.00649, val_loss=0.00591,\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 38.01it/s, loss=0.00649, val_loss=0.00581,\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.90it/s, loss=0.0064, val_loss=0.00581, \u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.57it/s, loss=0.0064, val_loss=0.00581, \n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 38.26it/s, loss=0.0064, val_loss=0.00571, \u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00632, val_loss=0.00571,\u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 32.33it/s, loss=0.00632, val_loss=0.00571,\n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.97it/s, loss=0.00632, val_loss=0.00563,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.96it/s, loss=0.00624, val_loss=0.00563,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.69it/s, loss=0.00624, val_loss=0.00563,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 38.33it/s, loss=0.00624, val_loss=0.00555,\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00617, val_loss=0.00555,\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 32.32it/s, loss=0.00617, val_loss=0.00555,\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00617, val_loss=0.00547,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.97it/s, loss=0.0061, val_loss=0.00547, \u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.72it/s, loss=0.0061, val_loss=0.00547, \n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 38.38it/s, loss=0.0061, val_loss=0.0054, a\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.69it/s, loss=0.00604, val_loss=0.0054, \u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 32.32it/s, loss=0.00604, val_loss=0.0054, \n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.96it/s, loss=0.00604, val_loss=0.00533,\u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.75it/s, loss=0.00604, val_loss=0.00533,\u001b[A\n",
      "Sizes of clusters: 503, 424, 273\n",
      "\n",
      "preds: [1 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 0\n",
      " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1\n",
      " 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1\n",
      " 2 0 2 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1\n",
      " 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 0 0 2 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0\n",
      " 2 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 2 1 0 2 1\n",
      " 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 2 1 0 0 1 2 0 1 0 0 0 0 2 0 1\n",
      " 0 1 0 0 1 0 0 2 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 2 1 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 1 1 0 0 1 2 1 0 0 0 2 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 0 1 1\n",
      " 1 0 0 0 2 0 1 0 1 1 0 0 1 1 1 1 0 1 2 0 1 1 0 0 0 2 1 0 1 0 1 1 2 0 0 2 1\n",
      " 1 0 1 0 1 1 2 2 1 0 1 0 1 0 2 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 2 1 1 0 1 0 1 1 0 0 1 0 0 1 1 2 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1\n",
      " 0 2 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 1 0 2 0 0 2 2 1\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 1 1 0 1 1 2 0 0 2 0 0 1 0 1 0 2 1 1 0 0 1 0 0 0 1\n",
      " 1 1 1 0 1 1 1 1 0 0 2 0 0 0 1 0 1 1 0 0 0 1 0 0 2 0 2 0 0 2 2 2 2 0 2 2 2\n",
      " 2 2 2 2 0 2 2 0 2 2 0 2 2 2 0 0 0 2 2 0 2 2 2 2 2 0 2 0 2 2 0 1 2 0 0 2 2\n",
      " 2 2 2 2 0 0 0 0 2 2 0 0 2 2 2 2 0 0 1 0 2 2 2 2 0 2 0 0 0 0 0 2 2 2 2 2 0\n",
      " 0 2 2 2 2 0 2 1 0 0 1 0 0 2 2 2 2 2 2 2 2 2 2 0 2 2 0 0 2 2 0 2 2 2 2 2 2\n",
      " 0 0 1 0 0 2 2 2 2 0 2 2 0 2 2 0 2 0 0 0 1 2 0 1 0 2 2 0 2 0 2 0 2 2 0 0 0\n",
      " 1 0 2 2 2 2 1 0 2 2 2 2 2 0 0 1 2 1 2 2 2 2 2 1 2 2 0 2 0 0 2 2 2 2 2 2 0\n",
      " 1 1 2 2 2 0 2 2 2 2 2 2 0 0 0 2 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 0 2 0 2 2 0\n",
      " 0 2 2 2 2 0 2 2 0 0 0 0 2 2 2 0 2 0 0 2 1 2 2 2 0 0 2 0 0 2 0 0 2 2 2 2 2\n",
      " 2 2 0 0 2 2 2 2 2 0 0 2 0 2 2 1 0 0 0 2 2 2 0 0 2 2 2 0 2 2 2 0 1 2 0 1 0\n",
      " 0 0 2 2 2 0 2 2 2 0 0 0 2 2 2 0 2 2 1 0 2 2 2 2 2 0 0 0 2 0 0 2 0 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 2 1 2 2 2 1 2 0 2 2 2 2 0 0 0 2 0 2 0 2 2 0 0 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 2 0 2 2 2 0 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5633\n",
      "============= RUN 5 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 24/48 [00:01<00:01, 21.80it/s, loss=8.98, val_loss=0.0813, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 48/48 [00:01<00:00, 38.14it/s, loss=8.98, val_loss=0.49, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 24/48 [00:01<00:01, 21.98it/s, loss=0.296, val_loss=0.49, avg_v\u001b[A\n",
      "Epoch 1:  79%|▊| 38/48 [00:01<00:00, 32.70it/s, loss=0.296, val_loss=0.49, avg_v\n",
      "Epoch 1: 100%|█| 48/48 [00:01<00:00, 38.41it/s, loss=0.296, val_loss=0.118, avg_\u001b[A\n",
      "Epoch 2:  50%|▌| 24/48 [00:01<00:01, 21.76it/s, loss=0.0542, val_loss=0.118, avg\u001b[A\n",
      "Epoch 2:  79%|▊| 38/48 [00:01<00:00, 32.42it/s, loss=0.0542, val_loss=0.118, avg\n",
      "Epoch 2: 100%|█| 48/48 [00:01<00:00, 38.06it/s, loss=0.0542, val_loss=0.0514, av\u001b[A\n",
      "Epoch 3:  50%|▌| 24/48 [00:01<00:01, 21.83it/s, loss=0.0285, val_loss=0.0514, av\u001b[A\n",
      "Epoch 3:  79%|▊| 38/48 [00:01<00:00, 32.52it/s, loss=0.0285, val_loss=0.0514, av\n",
      "Epoch 3: 100%|█| 48/48 [00:01<00:00, 38.17it/s, loss=0.0285, val_loss=0.0335, av\u001b[A\n",
      "Epoch 4:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.023, val_loss=0.0335, avg\u001b[A\n",
      "Epoch 4:  79%|▊| 38/48 [00:01<00:00, 31.93it/s, loss=0.023, val_loss=0.0335, avg\n",
      "Epoch 4: 100%|█| 48/48 [00:01<00:00, 37.53it/s, loss=0.023, val_loss=0.0261, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 24/48 [00:01<00:01, 21.64it/s, loss=0.0201, val_loss=0.0261, av\u001b[A\n",
      "Epoch 5:  79%|▊| 38/48 [00:01<00:00, 32.18it/s, loss=0.0201, val_loss=0.0261, av\n",
      "Epoch 5: 100%|█| 48/48 [00:01<00:00, 37.80it/s, loss=0.0201, val_loss=0.0216, av\u001b[A\n",
      "Epoch 6:  50%|▌| 24/48 [00:01<00:01, 21.56it/s, loss=0.0181, val_loss=0.0216, av\u001b[A\n",
      "Epoch 6:  79%|▊| 38/48 [00:01<00:00, 32.12it/s, loss=0.0181, val_loss=0.0216, av\n",
      "Epoch 6: 100%|█| 48/48 [00:01<00:00, 37.75it/s, loss=0.0181, val_loss=0.0186, av\u001b[A\n",
      "Epoch 7:  50%|▌| 24/48 [00:01<00:01, 21.75it/s, loss=0.0165, val_loss=0.0186, av\u001b[A\n",
      "Epoch 7:  79%|▊| 38/48 [00:01<00:00, 32.38it/s, loss=0.0165, val_loss=0.0186, av\n",
      "Epoch 7: 100%|█| 48/48 [00:01<00:00, 38.03it/s, loss=0.0165, val_loss=0.0166, av\u001b[A\n",
      "Epoch 8:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.0152, val_loss=0.0166, av\u001b[A\n",
      "Epoch 8:  79%|▊| 38/48 [00:01<00:00, 32.08it/s, loss=0.0152, val_loss=0.0166, av\n",
      "Epoch 8: 100%|█| 48/48 [00:01<00:00, 37.72it/s, loss=0.0152, val_loss=0.0151, av\u001b[A\n",
      "Epoch 9:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.0142, val_loss=0.0151, av\u001b[A\n",
      "Epoch 9:  79%|▊| 38/48 [00:01<00:00, 32.16it/s, loss=0.0142, val_loss=0.0151, av\n",
      "Epoch 9: 100%|█| 48/48 [00:01<00:00, 37.62it/s, loss=0.0142, val_loss=0.0139, av\u001b[A\n",
      "Epoch 10:  50%|▌| 24/48 [00:01<00:01, 21.42it/s, loss=0.0132, val_loss=0.0139, a\u001b[A\n",
      "Epoch 10:  79%|▊| 38/48 [00:01<00:00, 31.89it/s, loss=0.0132, val_loss=0.0139, a\n",
      "Epoch 10: 100%|█| 48/48 [00:01<00:00, 37.49it/s, loss=0.0132, val_loss=0.013, av\u001b[A\n",
      "Epoch 11:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.0124, val_loss=0.013, av\u001b[A\n",
      "Epoch 11:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.0124, val_loss=0.013, av\n",
      "Epoch 11: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.0124, val_loss=0.0121, a\u001b[A\n",
      "Epoch 12:  50%|▌| 24/48 [00:01<00:01, 21.49it/s, loss=0.0117, val_loss=0.0121, a\u001b[A\n",
      "Epoch 12:  79%|▊| 38/48 [00:01<00:00, 31.97it/s, loss=0.0117, val_loss=0.0121, a\n",
      "Epoch 12: 100%|█| 48/48 [00:01<00:00, 37.61it/s, loss=0.0117, val_loss=0.0114, a\u001b[A\n",
      "Epoch 13:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.011, val_loss=0.0114, av\u001b[A\n",
      "Epoch 13:  79%|▊| 38/48 [00:01<00:00, 32.26it/s, loss=0.011, val_loss=0.0114, av\n",
      "Epoch 13: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.011, val_loss=0.0107, av\u001b[A\n",
      "Epoch 14:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.0105, val_loss=0.0107, a\u001b[A\n",
      "Epoch 14:  79%|▊| 38/48 [00:01<00:00, 31.89it/s, loss=0.0105, val_loss=0.0107, a\n",
      "Epoch 14: 100%|█| 48/48 [00:01<00:00, 37.47it/s, loss=0.0105, val_loss=0.0102, a\u001b[A\n",
      "Epoch 15:  50%|▌| 24/48 [00:01<00:01, 21.63it/s, loss=0.00995, val_loss=0.0102, \u001b[A\n",
      "Epoch 15:  79%|▊| 38/48 [00:01<00:00, 32.19it/s, loss=0.00995, val_loss=0.0102, \n",
      "Epoch 15: 100%|█| 48/48 [00:01<00:00, 37.85it/s, loss=0.00995, val_loss=0.00966,\u001b[A\n",
      "Epoch 16:  50%|▌| 24/48 [00:01<00:01, 21.18it/s, loss=0.00948, val_loss=0.00966,\u001b[A\n",
      "Epoch 16:  79%|▊| 38/48 [00:01<00:00, 31.32it/s, loss=0.00948, val_loss=0.00966,\n",
      "Epoch 16: 100%|█| 48/48 [00:01<00:00, 37.10it/s, loss=0.00948, val_loss=0.00921,\u001b[A\n",
      "Epoch 17:  50%|▌| 24/48 [00:01<00:01, 21.72it/s, loss=0.00906, val_loss=0.00921,\u001b[A\n",
      "Epoch 17:  79%|▊| 38/48 [00:01<00:00, 32.30it/s, loss=0.00906, val_loss=0.00921,\n",
      "Epoch 17: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.00906, val_loss=0.00879,\u001b[A\n",
      "Epoch 18:  50%|▌| 24/48 [00:01<00:01, 21.43it/s, loss=0.00868, val_loss=0.00879,\u001b[A\n",
      "Epoch 18:  79%|▊| 38/48 [00:01<00:00, 31.91it/s, loss=0.00868, val_loss=0.00879,\n",
      "Epoch 18: 100%|█| 48/48 [00:01<00:00, 37.55it/s, loss=0.00868, val_loss=0.00843,\u001b[A\n",
      "Epoch 19:  50%|▌| 24/48 [00:01<00:01, 21.71it/s, loss=0.00835, val_loss=0.00843,\u001b[A\n",
      "Epoch 19:  79%|▊| 38/48 [00:01<00:00, 32.28it/s, loss=0.00835, val_loss=0.00843,\n",
      "Epoch 19: 100%|█| 48/48 [00:01<00:00, 37.95it/s, loss=0.00835, val_loss=0.00811,\u001b[A\n",
      "Epoch 20:  50%|▌| 24/48 [00:01<00:01, 21.44it/s, loss=0.00804, val_loss=0.00811,\u001b[A\n",
      "Epoch 20:  79%|▊| 38/48 [00:01<00:00, 31.94it/s, loss=0.00804, val_loss=0.00811,\n",
      "Epoch 20: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00804, val_loss=0.00782,\u001b[A\n",
      "Epoch 21:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00777, val_loss=0.00782,\u001b[A\n",
      "Epoch 21:  79%|▊| 38/48 [00:01<00:00, 32.25it/s, loss=0.00777, val_loss=0.00782,\n",
      "Epoch 21: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00777, val_loss=0.00757,\u001b[A\n",
      "Epoch 22:  50%|▌| 24/48 [00:01<00:01, 21.50it/s, loss=0.00753, val_loss=0.00757,\u001b[A\n",
      "Epoch 22:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.00753, val_loss=0.00757,\n",
      "Epoch 22: 100%|█| 48/48 [00:01<00:00, 37.63it/s, loss=0.00753, val_loss=0.00735,\u001b[A\n",
      "Epoch 23:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00731, val_loss=0.00735,\u001b[A\n",
      "Epoch 23:  79%|▊| 38/48 [00:01<00:00, 32.25it/s, loss=0.00731, val_loss=0.00735,\n",
      "Epoch 23: 100%|█| 48/48 [00:01<00:00, 37.89it/s, loss=0.00731, val_loss=0.00715,\u001b[A\n",
      "Epoch 24:  50%|▌| 24/48 [00:01<00:01, 21.41it/s, loss=0.00711, val_loss=0.00715,\u001b[A\n",
      "Epoch 24:  79%|▊| 38/48 [00:01<00:00, 31.50it/s, loss=0.00711, val_loss=0.00715,\n",
      "Epoch 24: 100%|█| 48/48 [00:01<00:00, 37.45it/s, loss=0.00711, val_loss=0.00697,\u001b[A\n",
      "Epoch 25:  50%|▌| 24/48 [00:01<00:01, 21.67it/s, loss=0.00693, val_loss=0.00697,\u001b[A\n",
      "Epoch 25:  79%|▊| 38/48 [00:01<00:00, 32.22it/s, loss=0.00693, val_loss=0.00697,\n",
      "Epoch 25: 100%|█| 48/48 [00:01<00:00, 37.85it/s, loss=0.00693, val_loss=0.0068, \u001b[A\n",
      "Epoch 26:  50%|▌| 24/48 [00:01<00:01, 21.66it/s, loss=0.00677, val_loss=0.0068, \u001b[A\n",
      "Epoch 26:  79%|▊| 38/48 [00:01<00:00, 32.21it/s, loss=0.00677, val_loss=0.0068, \n",
      "Epoch 26: 100%|█| 48/48 [00:01<00:00, 37.88it/s, loss=0.00677, val_loss=0.00666,\u001b[A\n",
      "Epoch 27:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00663, val_loss=0.00666,\u001b[A\n",
      "Epoch 27:  79%|▊| 38/48 [00:01<00:00, 32.01it/s, loss=0.00663, val_loss=0.00666,\n",
      "Epoch 27: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.00663, val_loss=0.00653,\u001b[A\n",
      "Epoch 28:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.0065, val_loss=0.00653, \u001b[A\n",
      "Epoch 28:  79%|▊| 38/48 [00:01<00:00, 32.27it/s, loss=0.0065, val_loss=0.00653, \n",
      "Epoch 28: 100%|█| 48/48 [00:01<00:00, 37.93it/s, loss=0.0065, val_loss=0.00642, \u001b[A\n",
      "Epoch 29:  50%|▌| 24/48 [00:01<00:01, 21.55it/s, loss=0.00638, val_loss=0.00642,\u001b[A\n",
      "Epoch 29:  79%|▊| 38/48 [00:01<00:00, 32.08it/s, loss=0.00638, val_loss=0.00642,\n",
      "Epoch 29: 100%|█| 48/48 [00:01<00:00, 37.73it/s, loss=0.00638, val_loss=0.00633,\u001b[A\n",
      "Epoch 30:  50%|▌| 24/48 [00:01<00:01, 21.73it/s, loss=0.00627, val_loss=0.00633,\u001b[A\n",
      "Epoch 30:  79%|▊| 38/48 [00:01<00:00, 32.34it/s, loss=0.00627, val_loss=0.00633,\n",
      "Epoch 30: 100%|█| 48/48 [00:01<00:00, 37.99it/s, loss=0.00627, val_loss=0.00626,\u001b[A\n",
      "Epoch 31:  50%|▌| 24/48 [00:01<00:01, 21.51it/s, loss=0.00617, val_loss=0.00626,\u001b[A\n",
      "Epoch 31:  79%|▊| 38/48 [00:01<00:00, 32.02it/s, loss=0.00617, val_loss=0.00626,\n",
      "Epoch 31: 100%|█| 48/48 [00:01<00:00, 37.65it/s, loss=0.00617, val_loss=0.00622,\u001b[A\n",
      "Epoch 32:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00608, val_loss=0.00622,\u001b[A\n",
      "Epoch 32:  79%|▊| 38/48 [00:01<00:00, 32.27it/s, loss=0.00608, val_loss=0.00622,\n",
      "Epoch 32: 100%|█| 48/48 [00:01<00:00, 37.92it/s, loss=0.00608, val_loss=0.00619,\u001b[A\n",
      "Epoch 33:  50%|▌| 24/48 [00:01<00:01, 21.48it/s, loss=0.006, val_loss=0.00619, a\u001b[A\n",
      "Epoch 33:  79%|▊| 38/48 [00:01<00:00, 31.99it/s, loss=0.006, val_loss=0.00619, a\n",
      "Epoch 33: 100%|█| 48/48 [00:01<00:00, 37.60it/s, loss=0.006, val_loss=0.00615, a\u001b[A\n",
      "Epoch 34:  50%|▌| 24/48 [00:01<00:01, 21.61it/s, loss=0.00592, val_loss=0.00615,\u001b[A\n",
      "Epoch 34:  79%|▊| 38/48 [00:01<00:00, 32.17it/s, loss=0.00592, val_loss=0.00615,\n",
      "Epoch 34: 100%|█| 48/48 [00:01<00:00, 37.82it/s, loss=0.00592, val_loss=0.0061, \u001b[A\n",
      "Epoch 35:  50%|▌| 24/48 [00:01<00:01, 21.46it/s, loss=0.00584, val_loss=0.0061, \u001b[A\n",
      "Epoch 35:  79%|▊| 38/48 [00:01<00:00, 31.95it/s, loss=0.00584, val_loss=0.0061, \n",
      "Epoch 35: 100%|█| 48/48 [00:01<00:00, 37.56it/s, loss=0.00584, val_loss=0.00605,\u001b[A\n",
      "Epoch 36:  50%|▌| 24/48 [00:01<00:01, 21.68it/s, loss=0.00578, val_loss=0.00605,\u001b[A\n",
      "Epoch 36:  79%|▊| 38/48 [00:01<00:00, 32.25it/s, loss=0.00578, val_loss=0.00605,\n",
      "Epoch 36: 100%|█| 48/48 [00:01<00:00, 37.90it/s, loss=0.00578, val_loss=0.006, a\u001b[A\n",
      "Epoch 37:  50%|▌| 24/48 [00:01<00:01, 20.96it/s, loss=0.00571, val_loss=0.006, a\u001b[A\n",
      "Epoch 37:  79%|▊| 38/48 [00:01<00:00, 31.19it/s, loss=0.00571, val_loss=0.006, a\n",
      "Epoch 37: 100%|█| 48/48 [00:01<00:00, 36.81it/s, loss=0.00571, val_loss=0.00595,\u001b[A\n",
      "Epoch 38:  50%|▌| 24/48 [00:01<00:01, 21.60it/s, loss=0.00565, val_loss=0.00595,\u001b[A\n",
      "Epoch 38:  79%|▊| 38/48 [00:01<00:00, 32.15it/s, loss=0.00565, val_loss=0.00595,\n",
      "Epoch 38: 100%|█| 48/48 [00:01<00:00, 37.79it/s, loss=0.00565, val_loss=0.00591,\u001b[A\n",
      "Epoch 39:  50%|▌| 24/48 [00:01<00:01, 21.41it/s, loss=0.0056, val_loss=0.00591, \u001b[A\n",
      "Epoch 39:  79%|▊| 38/48 [00:01<00:00, 31.87it/s, loss=0.0056, val_loss=0.00591, \n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.50it/s, loss=0.0056, val_loss=0.00586, \u001b[A\n",
      "Epoch 39: 100%|█| 48/48 [00:01<00:00, 37.23it/s, loss=0.0056, val_loss=0.00586, \u001b[A\n",
      "Sizes of clusters: 501, 401, 298\n",
      "\n",
      "preds: [1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 2 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 1 1\n",
      " 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 0 2 1 1 1 1 1 0 0 0 1\n",
      " 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1\n",
      " 2 0 2 1 1 0 1 1 1 1 1 0 0 2 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1\n",
      " 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 2 0 1 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0\n",
      " 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 2 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0\n",
      " 2 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 2 1 0 2 1\n",
      " 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 2 2 1 0 0 1 2 0 1 0 0 0 0 2 0 1\n",
      " 0 1 2 0 0 0 0 2 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 2 1 1 1 0 2 1 0 0 0 0 1\n",
      " 0 2 1 0 0 1 1 1 1 0 1 1 2 1 0 0 0 2 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1\n",
      " 1 0 0 0 2 0 1 0 1 0 0 0 1 1 1 1 0 1 2 0 1 1 2 0 0 2 1 0 1 0 1 1 2 0 0 2 1\n",
      " 0 0 1 0 1 1 2 2 1 0 1 2 1 0 2 0 1 2 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 1 0 1 0 1 1 2 0 1 0 0 1 1 2 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0\n",
      " 2 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 1 0 2 0 0 0 2 1\n",
      " 0 0 0 0 0 0 0 1 2 0 0 0 1 1 0 1 1 2 0 0 2 0 0 1 0 1 0 2 1 0 0 0 1 0 0 0 1\n",
      " 1 1 1 0 0 1 1 1 0 0 2 0 0 0 1 0 1 1 0 1 0 1 0 2 2 0 2 0 0 2 2 2 2 2 2 2 2\n",
      " 2 2 0 2 0 2 2 0 0 2 0 2 2 0 2 0 0 2 2 0 2 2 2 2 2 0 2 0 2 2 0 1 2 0 0 2 2\n",
      " 2 2 2 2 0 2 0 0 2 2 0 0 2 2 2 2 0 2 1 0 2 2 2 2 2 2 0 2 0 0 0 2 2 2 2 2 0\n",
      " 0 2 2 2 2 0 2 0 2 2 1 0 0 2 2 2 2 2 2 2 2 2 2 0 2 2 0 0 2 2 0 2 2 2 2 2 2\n",
      " 2 0 1 2 0 2 2 2 2 0 2 2 0 0 2 0 2 0 0 0 1 2 0 1 0 2 2 0 2 0 2 0 2 2 2 0 0\n",
      " 1 0 2 2 2 2 1 0 2 2 2 2 2 0 0 1 2 1 2 2 2 2 2 0 2 2 0 2 0 0 2 2 2 2 2 2 0\n",
      " 0 1 2 2 2 0 2 2 2 2 2 2 2 0 0 2 0 0 0 0 0 2 0 2 2 2 0 0 2 2 2 0 2 0 2 2 2\n",
      " 0 2 2 2 2 0 2 2 2 0 0 0 2 2 2 0 2 0 2 2 0 2 2 2 0 0 2 0 0 2 0 0 2 2 2 2 2\n",
      " 2 2 0 0 2 2 2 2 2 2 2 2 0 2 2 1 0 0 0 2 2 2 0 0 2 2 2 0 2 2 2 0 1 2 0 1 2\n",
      " 0 0 2 2 2 0 2 2 2 0 0 2 2 2 2 0 2 2 1 0 2 2 2 2 2 0 0 0 2 0 0 2 0 2 2 2 2\n",
      " 2 2 0 2 2 2 2 2 0 1 2 2 2 1 2 0 2 2 2 2 0 0 0 2 0 2 0 2 2 0 0 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 0 2 2 2 0 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "\n",
      "Purity: 0.5700\n",
      "\n",
      "Consistency: 0.3910\n",
      "Purity: 0.541+-0.030420205273615268\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K3_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=1.48, val_loss=0.0971, avg_\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 37.78it/s, loss=1.48, val_loss=0.167, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.0881, val_loss=0.167, avg\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 25.38it/s, loss=0.0881, val_loss=0.167, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.0881, val_loss=0.0493, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.70it/s, loss=0.0294, val_loss=0.0493, av\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.40it/s, loss=0.0294, val_loss=0.0493, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 37.99it/s, loss=0.0294, val_loss=0.0335, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.67it/s, loss=0.0207, val_loss=0.0335, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.35it/s, loss=0.0207, val_loss=0.0335, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.93it/s, loss=0.0207, val_loss=0.0255, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.0167, val_loss=0.0255, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 25.30it/s, loss=0.0167, val_loss=0.0255, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 37.88it/s, loss=0.0167, val_loss=0.0198, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.0141, val_loss=0.0198, av\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.0141, val_loss=0.0198, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.28it/s, loss=0.0141, val_loss=0.0158, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0124, val_loss=0.0158, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.0124, val_loss=0.0158, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.0124, val_loss=0.0133, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.0111, val_loss=0.0133, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 25.48it/s, loss=0.0111, val_loss=0.0133, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.0111, val_loss=0.0115, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.0102, val_loss=0.0115, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.74it/s, loss=0.0102, val_loss=0.0115, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.48it/s, loss=0.0102, val_loss=0.0103, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00945, val_loss=0.0103, a\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 25.44it/s, loss=0.00945, val_loss=0.0103, a\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.00945, val_loss=0.00946, \u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.00889, val_loss=0.00946,\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 25.58it/s, loss=0.00889, val_loss=0.00946,\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.22it/s, loss=0.00889, val_loss=0.00881,\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00844, val_loss=0.00881,\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00844, val_loss=0.00881,\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00844, val_loss=0.00829,\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00807, val_loss=0.00829,\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.60it/s, loss=0.00807, val_loss=0.00829,\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00807, val_loss=0.00788,\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00776, val_loss=0.00788,\u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00776, val_loss=0.00788,\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00776, val_loss=0.00755,\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.88it/s, loss=0.00749, val_loss=0.00755,\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.62it/s, loss=0.00749, val_loss=0.00755,\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00749, val_loss=0.00728,\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00726, val_loss=0.00728,\u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.00726, val_loss=0.00728,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00726, val_loss=0.00704,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.97it/s, loss=0.00705, val_loss=0.00704,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 25.69it/s, loss=0.00705, val_loss=0.00704,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.38it/s, loss=0.00705, val_loss=0.00682,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00687, val_loss=0.00682,\u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 25.52it/s, loss=0.00687, val_loss=0.00682,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00687, val_loss=0.00661,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00671, val_loss=0.00661,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00671, val_loss=0.00661,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00671, val_loss=0.00642,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.00656, val_loss=0.00642,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 25.70it/s, loss=0.00656, val_loss=0.00642,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.42it/s, loss=0.00656, val_loss=0.00623,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00643, val_loss=0.00623,\u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 25.62it/s, loss=0.00643, val_loss=0.00623,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00643, val_loss=0.00606,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00631, val_loss=0.00606,\u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 25.44it/s, loss=0.00631, val_loss=0.00606,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.00631, val_loss=0.00592,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.0062, val_loss=0.00592, \u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.56it/s, loss=0.0062, val_loss=0.00592, \n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.0062, val_loss=0.00582, \u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00609, val_loss=0.00582,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 25.46it/s, loss=0.00609, val_loss=0.00582,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00609, val_loss=0.00573,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.56it/s, loss=0.00599, val_loss=0.00573,\u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 25.27it/s, loss=0.00599, val_loss=0.00573,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.79it/s, loss=0.00599, val_loss=0.00565,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.0059, val_loss=0.00565, \u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 25.73it/s, loss=0.0059, val_loss=0.00565, \n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.41it/s, loss=0.0059, val_loss=0.00557, \u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00582, val_loss=0.00557,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.47it/s, loss=0.00582, val_loss=0.00557,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00582, val_loss=0.00549,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00574, val_loss=0.00549,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00574, val_loss=0.00549,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00574, val_loss=0.0054, \u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00566, val_loss=0.0054, \u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.50it/s, loss=0.00566, val_loss=0.0054, \n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00566, val_loss=0.00532,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.0056, val_loss=0.00532, \u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.46it/s, loss=0.0056, val_loss=0.00532, \n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.0056, val_loss=0.00523, \u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00553, val_loss=0.00523,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.63it/s, loss=0.00553, val_loss=0.00523,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.29it/s, loss=0.00553, val_loss=0.00515,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00547, val_loss=0.00515,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.38it/s, loss=0.00547, val_loss=0.00515,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 37.94it/s, loss=0.00547, val_loss=0.00507,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00541, val_loss=0.00507,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 25.49it/s, loss=0.00541, val_loss=0.00507,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00541, val_loss=0.00499,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.00536, val_loss=0.00499,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 25.64it/s, loss=0.00536, val_loss=0.00499,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.35it/s, loss=0.00536, val_loss=0.00492,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00531, val_loss=0.00492,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 25.50it/s, loss=0.00531, val_loss=0.00492,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00531, val_loss=0.00486,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00527, val_loss=0.00486,\u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 25.36it/s, loss=0.00527, val_loss=0.00486,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.93it/s, loss=0.00527, val_loss=0.00481,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00523, val_loss=0.00481,\u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.00523, val_loss=0.00481,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.19it/s, loss=0.00523, val_loss=0.00477,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.65it/s, loss=0.00519, val_loss=0.00477,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.34it/s, loss=0.00519, val_loss=0.00477,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00519, val_loss=0.00473,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.00515, val_loss=0.00473,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00515, val_loss=0.00473,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00515, val_loss=0.00469,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00512, val_loss=0.00469,\u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 25.38it/s, loss=0.00512, val_loss=0.00469,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.98it/s, loss=0.00512, val_loss=0.00466,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.73it/s, loss=0.00512, val_loss=0.00466,\u001b[A\n",
      "Sizes of clusters: 270, 270, 553, 507\n",
      "\n",
      "preds: [0 2 2 2 1 3 0 3 2 2 2 3 3 2 3 2 3 2 0 3 3 2 0 3 0 3 3 2 3 3 0 2 2 2 1 3 2\n",
      " 0 3 2 2 0 2 3 1 0 3 1 3 2 2 0 0 3 0 3 2 3 3 1 3 2 2 3 2 3 2 3 0 3 3 3 3 0\n",
      " 2 2 3 3 1 2 0 0 2 3 3 3 3 0 0 0 3 3 3 3 2 0 2 0 0 1 3 2 2 3 2 0 3 2 2 2 2\n",
      " 3 3 2 2 0 3 3 2 0 2 3 2 0 2 2 2 2 3 2 3 2 3 2 0 3 0 2 0 0 0 2 2 0 3 1 0 3\n",
      " 3 3 3 2 2 3 0 3 3 3 2 3 3 3 3 2 3 2 3 2 2 3 2 2 3 2 3 2 2 2 3 0 2 2 2 0 0\n",
      " 0 2 2 3 2 3 2 2 3 2 3 2 2 3 1 3 3 3 1 3 2 0 2 3 3 3 2 2 2 1 3 2 2 3 2 2 0\n",
      " 2 1 2 3 0 3 3 3 2 3 0 2 0 0 1 3 2 3 1 3 3 2 3 2 0 0 2 3 2 2 2 2 2 3 3 3 3\n",
      " 2 3 2 3 1 3 0 3 3 3 3 3 2 3 3 1 0 2 3 2 2 3 3 2 3 3 3 2 0 0 0 2 2 0 2 2 3\n",
      " 0 3 1 2 3 2 3 3 2 0 1 3 3 2 1 3 1 2 0 2 3 0 0 2 2 2 2 3 0 1 3 2 1 2 2 2 2\n",
      " 3 2 0 2 2 2 3 3 1 2 3 3 3 0 3 3 3 2 3 2 1 3 1 2 3 0 3 2 3 2 0 2 2 2 1 3 3\n",
      " 2 2 0 3 0 3 2 3 3 1 3 3 3 3 2 3 1 0 3 2 2 2 3 3 3 3 3 0 0 0 0 2 0 3 0 2 2\n",
      " 2 0 3 0 2 0 0 2 2 2 0 0 2 0 2 3 2 2 3 0 0 2 2 2 3 2 2 0 0 2 0 0 2 3 2 2 2\n",
      " 0 2 3 0 3 0 3 2 0 0 2 0 0 2 0 0 0 0 0 0 2 2 0 2 0 2 0 0 0 2 0 2 2 0 2 0 0\n",
      " 2 2 2 2 2 0 0 2 2 3 0 2 3 0 2 1 2 3 2 0 0 0 3 2 2 2 0 0 0 2 0 2 2 3 2 3 2\n",
      " 2 0 2 2 0 0 0 2 3 3 2 0 2 0 2 2 0 2 2 0 0 0 2 2 0 2 2 0 0 2 0 2 2 2 2 2 0\n",
      " 0 3 2 1 2 2 3 2 2 0 0 0 3 2 2 2 2 2 0 2 0 2 0 2 2 2 2 2 2 3 0 2 3 0 3 2 2\n",
      " 2 0 2 2 2 2 3 3 2 0 2 0 2 2 0 2 2 3 2 0 2 2 0 0 3 0 0 2 2 2 2 2 0 2 0 2 2\n",
      " 0 2 0 2 0 0 0 0 0 2 3 0 2 2 2 2 2 0 2 2 0 2 0 2 2 0 0 2 0 2 0 0 2 2 2 2 2\n",
      " 3 0 0 3 0 2 0 2 2 0 2 0 0 2 2 3 3 0 2 0 0 0 0 0 3 2 0 2 0 3 0 2 0 2 0 2 0\n",
      " 0 2 2 3 3 3 3 3 3 0 2 2 0 0 0 2 2 2 2 3 2 1 0 2 0 0 2 0 2 3 2 2 0 0 0 0 2\n",
      " 2 0 3 3 3 2 0 0 2 2 2 2 0 3 0 2 0 0 2 0 0 0 0 2 2 3 2 2 0 0 2 0 0 0 2 0 2\n",
      " 2 0 3 3 2 2 2 2 0 2 0 0 2 2 2 0 2 0 0 2 2 0 2 2 3 1 1 1 3 3 2 1 1 1 2 3 3\n",
      " 1 3 1 1 2 2 0 0 3 0 3 2 3 3 3 1 1 2 1 3 3 3 2 3 1 1 2 3 3 2 1 2 3 3 2 1 2\n",
      " 3 1 2 1 3 3 1 1 3 3 2 3 2 1 1 1 1 1 2 3 3 2 2 3 3 3 3 3 3 1 2 0 3 2 1 3 3\n",
      " 1 1 1 3 3 3 2 0 1 3 2 3 2 3 2 1 1 1 1 3 2 3 2 2 0 3 3 1 1 3 2 1 1 1 3 0 1\n",
      " 3 1 1 2 1 3 1 3 3 3 3 3 2 1 2 1 3 2 1 2 3 1 0 2 3 2 2 1 1 3 2 3 1 2 1 2 3\n",
      " 2 3 3 3 3 3 1 3 1 2 2 2 3 2 1 2 2 2 1 1 0 3 3 3 3 1 2 3 1 2 2 2 1 2 2 1 1\n",
      " 1 1 0 2 3 3 3 2 1 2 3 3 3 1 2 1 0 1 2 3 2 3 3 1 3 3 2 1 3 3 3 1 2 2 0 1 3\n",
      " 3 3 3 1 1 1 2 0 1 1 3 2 2 2 1 1 3 3 3 2 3 2 3 3 3 3 0 3 3 3 3 2 1 2 1 1 1\n",
      " 1 3 3 3 0 0 3 1 3 1 2 1 3 3 3 1 2 2 1 2 2 2 2 3 2 1 1 3 1 2 1 1 1 2 2 2 1\n",
      " 3 1 3 3 1 1 1 3 3 1 3 1 3 3 3 1 2 3 3 1 3 0 3 1 2 1 3 0 3 3 2 1 2 1 1 2 3\n",
      " 1 1 1 2 2 3 1 2 3 3 2 1 3 3 3 3 2 3 1 3 1 1 3 2 2 3 3 2 2 2 3 3 3 2 1 2 2\n",
      " 1 1 2 0 2 3 3 1 1 2 3 3 2 1 3 3 2 3 2 3 3 1 1 1 1 1 3 1 2 3 3 1 3 0 3 2 1\n",
      " 1 3 2 3 0 1 3 3 1 1 1 2 1 0 3 2 3 3 3 2 2 1 3 3 3 1 1 3 3 1 3 2 2 1 3 3 1\n",
      " 2 2 3 2 3 2 3 1 3 1 1 1 1 3 2 3 3 2 2 1 1 2 3 3 2 2 2 1 1 2 0 2 1 0 2 3 2\n",
      " 0 3 2 3 2 1 1 3 2 1 2 3 3 3 1 3 3 0 2 3 1 3 3 3 1 2 2 2 1 2 2 3 1 2 1 2 1\n",
      " 1 3 3 3 2 0 3 1 3 2 0 3 1 0 1 2 3 1 1 3 3 1 1 3 1 3 2 2 1 3 1 2 3 2 3 2 2\n",
      " 2 0 3 2 2 3 3 3 1 2 2 3 3 3 1 2 3 1 3 3 3 3 1 1 2 3 3 1 2 1 2 3 3 1 3 1 1\n",
      " 0 1 2 3 1 2 1 3 3 3 2 1 1 1 3 1 1 2 1 1 3 3 2 3 1 3 3 3 1 3 3 3 1 1 3 2 3\n",
      " 3 3 2 3 2 0 3 2 3 3 2 3 1 2 2 3 3 3 1 3 2 3 1 2 2 0 1 3 1 1 1 1 2 3 2 0 2\n",
      " 3 3 1 2 2 1 2 2 3 2 2 1 3 1 2 3 2 2 3 2 1 2 1 1 3 3 3 3 2 0 3 0 2 3 2 2 2\n",
      " 3 1 3 3 3 2 3 1 3 1 1 2 2 1 3 0 3 2 3 0 1 1 2 3 3 3 2 2 2 2 1 1 0 1 0 2 0\n",
      " 2 3 3 3 2 1 1 2 1 0 1 2 2 3 2 1 1 3 3 3 3 1 1 2 1 2 1 0 3 3 2 1 0 3 2 2 3\n",
      " 1 3 1 1 3 0 1 3 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.3938\n",
      "============= RUN 2 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=3.13, val_loss=0.0654, avg_\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.52it/s, loss=3.13, val_loss=0.0654, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.41it/s, loss=3.13, val_loss=0.177, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.146, val_loss=0.177, avg_\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 23.23it/s, loss=0.146, val_loss=0.177, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.37it/s, loss=0.146, val_loss=0.0743, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.0426, val_loss=0.0743, av\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.44it/s, loss=0.0426, val_loss=0.0743, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.29it/s, loss=0.0426, val_loss=0.0478, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.97it/s, loss=0.0314, val_loss=0.0478, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.52it/s, loss=0.0314, val_loss=0.0478, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.41it/s, loss=0.0314, val_loss=0.0359, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 22.04it/s, loss=0.0261, val_loss=0.0359, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.59it/s, loss=0.0261, val_loss=0.0359, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.52it/s, loss=0.0261, val_loss=0.0286, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 22.13it/s, loss=0.0225, val_loss=0.0286, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.71it/s, loss=0.0225, val_loss=0.0286, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.68it/s, loss=0.0225, val_loss=0.0242, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.0199, val_loss=0.0242, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.53it/s, loss=0.0199, val_loss=0.0242, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.42it/s, loss=0.0199, val_loss=0.0213, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.99it/s, loss=0.018, val_loss=0.0213, avg\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.55it/s, loss=0.018, val_loss=0.0213, avg\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.47it/s, loss=0.018, val_loss=0.0192, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 22.04it/s, loss=0.0165, val_loss=0.0192, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.59it/s, loss=0.0165, val_loss=0.0192, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.54it/s, loss=0.0165, val_loss=0.0175, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.0153, val_loss=0.0175, av\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.0153, val_loss=0.0175, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.0153, val_loss=0.0161, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 22.03it/s, loss=0.0143, val_loss=0.0161, a\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.60it/s, loss=0.0143, val_loss=0.0161, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.49it/s, loss=0.0143, val_loss=0.015, av\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 22.08it/s, loss=0.0135, val_loss=0.015, av\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.62it/s, loss=0.0135, val_loss=0.015, av\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.56it/s, loss=0.0135, val_loss=0.014, av\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.44it/s, loss=0.0127, val_loss=0.014, av\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 23.90it/s, loss=0.0127, val_loss=0.014, av\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.57it/s, loss=0.0127, val_loss=0.0132, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0121, val_loss=0.0132, a\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 23.94it/s, loss=0.0121, val_loss=0.0132, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 37.65it/s, loss=0.0121, val_loss=0.0124, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0115, val_loss=0.0124, a\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.0115, val_loss=0.0124, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 37.85it/s, loss=0.0115, val_loss=0.0117, a\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.011, val_loss=0.0117, av\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 23.91it/s, loss=0.011, val_loss=0.0117, av\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 37.61it/s, loss=0.011, val_loss=0.0112, av\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.0105, val_loss=0.0112, a\u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.0105, val_loss=0.0112, a\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.0105, val_loss=0.0106, a\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.0101, val_loss=0.0106, a\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.0101, val_loss=0.0106, a\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.0101, val_loss=0.0102, a\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.57it/s, loss=0.00973, val_loss=0.0102, \u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 24.04it/s, loss=0.00973, val_loss=0.0102, \n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.79it/s, loss=0.00973, val_loss=0.00976,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00939, val_loss=0.00976,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.10it/s, loss=0.00939, val_loss=0.00976,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 37.87it/s, loss=0.00939, val_loss=0.00937,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00908, val_loss=0.00937,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 24.21it/s, loss=0.00908, val_loss=0.00937,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00908, val_loss=0.00901,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.72it/s, loss=0.0088, val_loss=0.00901, \u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 24.18it/s, loss=0.0088, val_loss=0.00901, \n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.0088, val_loss=0.00868, \u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00853, val_loss=0.00868,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.00853, val_loss=0.00868,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.00853, val_loss=0.00839,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00829, val_loss=0.00839,\u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.24it/s, loss=0.00829, val_loss=0.00839,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00829, val_loss=0.00812,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00807, val_loss=0.00812,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 24.29it/s, loss=0.00807, val_loss=0.00812,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00807, val_loss=0.00788,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00786, val_loss=0.00788,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.24it/s, loss=0.00786, val_loss=0.00788,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.00786, val_loss=0.00766,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00767, val_loss=0.00766,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00767, val_loss=0.00766,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.00767, val_loss=0.00745,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.0075, val_loss=0.00745, \u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.0075, val_loss=0.00745, \n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.26it/s, loss=0.0075, val_loss=0.00727, \u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.00734, val_loss=0.00727,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00734, val_loss=0.00727,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00734, val_loss=0.0071, \u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00719, val_loss=0.0071, \u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00719, val_loss=0.0071, \n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00719, val_loss=0.00695,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.00705, val_loss=0.00695,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.00705, val_loss=0.00695,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00705, val_loss=0.0068, \u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00692, val_loss=0.0068, \u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 24.28it/s, loss=0.00692, val_loss=0.0068, \n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00692, val_loss=0.00668,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00681, val_loss=0.00668,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.13it/s, loss=0.00681, val_loss=0.00668,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00681, val_loss=0.00656,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.0067, val_loss=0.00656, \u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.0067, val_loss=0.00656, \n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.0067, val_loss=0.00646, \u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.0066, val_loss=0.00646, \u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.0066, val_loss=0.00646, \n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.0066, val_loss=0.00637, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00651, val_loss=0.00637,\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.00651, val_loss=0.00637,\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 38.04it/s, loss=0.00651, val_loss=0.00628,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.00643, val_loss=0.00628,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.00643, val_loss=0.00628,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00643, val_loss=0.0062, \u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.00635, val_loss=0.0062, \u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.00635, val_loss=0.0062, \n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 37.84it/s, loss=0.00635, val_loss=0.00613,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00628, val_loss=0.00613,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 24.41it/s, loss=0.00628, val_loss=0.00613,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.00628, val_loss=0.00607,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.49it/s, loss=0.00622, val_loss=0.00607,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.94it/s, loss=0.00622, val_loss=0.00607,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00622, val_loss=0.00602,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.42it/s, loss=0.00622, val_loss=0.00602,\u001b[A\n",
      "Sizes of clusters: 548, 285, 203, 564\n",
      "\n",
      "preds: [2 0 3 3 2 1 2 2 3 1 0 1 2 1 0 2 1 0 3 2 3 2 1 1 0 0 0 0 3 1 0 1 0 3 0 0 0\n",
      " 0 1 0 1 1 1 0 2 3 0 3 1 0 3 3 0 1 1 0 2 2 3 2 2 0 0 0 0 0 3 3 1 0 0 3 2 1\n",
      " 2 2 1 2 0 3 3 1 0 2 2 2 0 3 1 3 2 2 3 0 1 1 1 0 3 3 0 2 1 1 3 1 0 3 3 0 0\n",
      " 3 2 3 1 1 0 0 1 3 2 0 1 1 0 1 1 0 3 3 3 3 0 0 0 0 0 2 1 3 3 3 1 0 1 0 3 2\n",
      " 2 3 1 1 3 2 3 1 1 3 2 1 1 2 2 0 0 0 2 0 1 0 2 1 1 0 2 3 2 3 2 0 1 2 3 1 3\n",
      " 3 3 0 3 1 3 3 1 1 3 0 0 3 2 3 0 0 2 0 0 0 3 3 3 2 0 1 3 2 1 0 1 1 3 1 0 2\n",
      " 3 0 3 3 1 0 0 0 3 0 0 1 3 1 2 3 2 0 0 1 2 3 2 3 0 1 1 0 0 1 3 0 3 3 0 0 2\n",
      " 0 2 0 2 0 0 0 2 1 2 2 2 2 3 3 3 3 3 1 3 1 0 0 2 3 1 0 0 1 3 3 1 3 1 0 1 1\n",
      " 0 0 0 0 3 2 2 0 0 0 2 2 1 0 3 0 0 0 3 3 3 0 0 2 3 0 0 1 3 2 3 2 2 0 0 3 2\n",
      " 2 0 0 3 0 0 2 2 2 0 2 0 3 3 1 0 3 1 3 1 0 3 0 0 0 3 0 3 3 1 0 3 3 3 3 3 1\n",
      " 3 1 0 1 3 3 2 2 1 0 2 2 1 3 1 1 0 1 3 0 2 3 0 3 3 1 0 1 3 3 0 0 3 0 0 0 3\n",
      " 0 0 0 3 1 3 3 0 0 3 3 3 3 1 1 0 3 3 0 3 0 0 0 0 1 3 0 1 3 3 1 3 1 0 3 3 2\n",
      " 0 0 0 1 0 3 3 3 2 3 0 0 3 3 3 0 3 3 1 0 0 0 2 3 3 2 0 0 0 3 2 0 0 0 0 2 1\n",
      " 3 1 2 0 0 0 2 1 0 2 0 3 2 0 3 2 0 0 0 1 3 3 2 0 2 1 3 0 3 0 0 3 3 1 0 3 3\n",
      " 0 3 2 1 0 3 2 3 0 0 3 3 2 3 0 2 0 0 3 2 2 3 0 2 1 3 0 2 0 3 1 2 0 1 0 0 0\n",
      " 3 2 0 2 1 3 3 3 0 0 0 3 2 0 0 3 3 2 3 3 0 1 2 2 3 0 3 2 1 2 0 1 3 2 0 3 3\n",
      " 2 3 0 3 0 3 0 0 3 3 0 3 2 0 0 0 0 0 0 3 0 3 0 0 1 0 2 0 3 2 3 3 0 0 3 2 0\n",
      " 2 3 3 0 3 3 3 0 3 2 0 1 0 2 0 0 0 2 0 1 2 0 2 0 2 3 0 0 1 3 3 3 1 0 0 3 0\n",
      " 2 1 0 3 3 0 3 1 1 0 0 1 3 0 3 0 0 3 3 2 3 3 1 0 3 0 3 3 3 2 3 3 0 0 3 3 0\n",
      " 2 0 3 0 1 0 0 2 0 3 1 0 0 3 0 3 3 0 3 0 0 3 3 3 2 3 1 0 0 3 1 0 2 1 0 0 1\n",
      " 3 3 0 3 0 3 3 3 3 3 0 3 3 3 0 3 3 0 0 1 2 3 0 2 3 0 0 3 0 3 3 0 0 0 0 0 0\n",
      " 3 1 0 0 3 0 0 0 0 0 2 1 0 2 0 3 3 3 0 0 0 1 0 2 2 0 2 0 0 3 3 0 2 0 1 2 1\n",
      " 0 0 0 0 2 0 0 3 2 3 2 0 0 0 3 0 3 3 1 0 3 2 0 0 3 1 0 3 1 0 3 3 2 0 3 3 3\n",
      " 3 2 1 3 3 1 0 1 0 3 3 3 0 1 0 0 3 2 3 0 3 0 3 3 3 2 3 3 3 1 0 3 0 3 3 0 3\n",
      " 0 3 3 3 0 3 3 1 3 0 0 0 0 3 3 0 0 0 1 3 0 0 0 3 0 0 2 0 3 0 0 3 2 1 0 0 3\n",
      " 2 0 3 0 2 3 3 3 0 1 3 3 2 3 1 0 3 2 3 0 0 0 1 3 0 2 3 3 1 3 3 0 0 1 3 0 0\n",
      " 3 3 3 3 2 0 2 0 0 0 3 0 1 0 0 0 3 3 3 1 0 0 0 0 0 3 0 3 3 0 3 2 0 3 0 3 3\n",
      " 3 0 1 0 3 1 1 2 3 3 0 3 2 0 0 0 1 1 0 3 3 3 3 0 0 1 3 2 2 0 0 3 3 3 1 0 3\n",
      " 3 3 3 3 0 2 1 1 2 2 3 1 0 3 2 0 1 0 3 1 3 3 2 1 2 1 3 0 3 1 3 0 0 0 0 3 2\n",
      " 0 1 3 2 0 0 0 3 2 3 0 3 0 1 0 2 0 0 2 1 0 3 0 3 3 2 3 2 2 0 0 0 3 2 3 2 3\n",
      " 0 0 3 2 0 0 0 0 0 0 3 0 0 3 0 0 0 2 1 1 3 3 3 3 0 0 3 0 0 0 2 0 0 0 3 0 3\n",
      " 0 2 3 3 3 3 1 3 0 0 0 3 0 3 1 0 3 0 2 0 0 0 0 2 2 3 0 3 3 3 0 2 0 0 3 3 3\n",
      " 2 2 1 0 0 3 2 3 1 3 3 0 3 2 0 3 1 1 1 1 1 1 3 2 3 1 1 3 1 1 3 3 1 0 3 2 0\n",
      " 3 2 3 1 3 1 3 1 1 1 3 1 0 0 3 0 0 3 3 0 0 1 0 1 1 1 1 3 3 0 0 0 3 0 0 3 3\n",
      " 3 3 3 0 0 3 1 3 3 1 3 3 1 3 3 3 0 3 2 3 3 3 3 1 3 0 3 3 0 3 3 1 0 0 1 3 1\n",
      " 3 0 3 3 3 3 3 1 0 3 0 0 3 3 1 0 1 3 0 3 1 0 0 3 1 0 1 0 3 3 1 0 1 1 3 0 3\n",
      " 3 3 0 3 1 0 3 3 0 3 1 3 1 3 3 3 1 0 0 0 3 1 1 3 0 0 0 0 1 0 2 1 1 3 3 0 3\n",
      " 1 0 0 3 3 1 0 3 3 0 1 0 3 1 3 3 0 3 0 1 3 2 1 3 3 3 3 1 0 1 0 1 0 3 0 0 1\n",
      " 0 3 0 3 2 1 1 0 3 3 3 0 1 3 1 1 1 3 3 1 3 3 0 1 2 2 2 3 1 2 3 3 1 3 1 3 0\n",
      " 3 0 0 3 1 1 1 3 0 1 3 0 3 3 3 0 0 0 1 3 1 0 0 0 3 1 1 3 3 1 3 0 3 3 2 3 2\n",
      " 3 3 1 1 3 3 3 0 3 1 1 3 0 3 1 3 0 0 3 3 1 0 3 1 0 1 1 0 3 2 0 0 1 0 3 0 0\n",
      " 3 3 1 2 1 1 3 3 3 3 3 1 3 3 2 1 3 1 0 1 3 1 1 0 1 0 3 2 1 1 3 2 3 0 0 0 0\n",
      " 0 3 3 3 3 1 3 3 1 3 1 3 1 3 1 1 3 1 3 3 0 3 3 1 3 3 3 0 0 3 0 1 0 0 0 3 3\n",
      " 1 0 0 3 3 3 3 1 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.3231\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=1.49, val_loss=0.0842, avg_\n",
      "Epoch 0:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=1.49, val_loss=0.0842, avg_\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=1.49, val_loss=0.124, avg_v\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.0992, val_loss=0.124, avg\u001b[A\n",
      "Epoch 1:  53%|▌| 34/64 [00:01<00:01, 23.32it/s, loss=0.0992, val_loss=0.124, avg\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.51it/s, loss=0.0992, val_loss=0.0542, av\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 22.14it/s, loss=0.0361, val_loss=0.0542, av\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.73it/s, loss=0.0361, val_loss=0.0542, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.69it/s, loss=0.0361, val_loss=0.0378, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.0252, val_loss=0.0378, av\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.0252, val_loss=0.0378, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.0252, val_loss=0.0288, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.0201, val_loss=0.0288, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.21it/s, loss=0.0201, val_loss=0.0288, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=0.0201, val_loss=0.0231, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.0172, val_loss=0.0231, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.45it/s, loss=0.0172, val_loss=0.0231, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.0172, val_loss=0.0192, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.0154, val_loss=0.0192, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.28it/s, loss=0.0154, val_loss=0.0192, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.0154, val_loss=0.0166, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.0142, val_loss=0.0166, av\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.20it/s, loss=0.0142, val_loss=0.0166, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 37.99it/s, loss=0.0142, val_loss=0.015, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.0132, val_loss=0.015, avg\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.44it/s, loss=0.0132, val_loss=0.015, avg\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.0132, val_loss=0.014, avg\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.61it/s, loss=0.0124, val_loss=0.014, avg\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 24.09it/s, loss=0.0124, val_loss=0.014, avg\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.0124, val_loss=0.0131, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.0118, val_loss=0.0131, a\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.0118, val_loss=0.0131, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.0118, val_loss=0.0124, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.0112, val_loss=0.0124, a\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.41it/s, loss=0.0112, val_loss=0.0124, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.29it/s, loss=0.0112, val_loss=0.0119, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.41it/s, loss=0.0107, val_loss=0.0119, a\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 23.86it/s, loss=0.0107, val_loss=0.0119, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.55it/s, loss=0.0107, val_loss=0.0113, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0103, val_loss=0.0113, a\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.32it/s, loss=0.0103, val_loss=0.0113, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.0103, val_loss=0.0109, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00989, val_loss=0.0109, \u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 24.24it/s, loss=0.00989, val_loss=0.0109, \n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.00989, val_loss=0.0105, \u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00955, val_loss=0.0105, \u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00955, val_loss=0.0105, \n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00955, val_loss=0.0101, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.41it/s, loss=0.00924, val_loss=0.0101, \u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 23.85it/s, loss=0.00924, val_loss=0.0101, \n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 37.55it/s, loss=0.00924, val_loss=0.00978,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00897, val_loss=0.00978,\u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00897, val_loss=0.00978,\n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00897, val_loss=0.00948,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.36it/s, loss=0.00873, val_loss=0.00948,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 23.81it/s, loss=0.00873, val_loss=0.00948,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.46it/s, loss=0.00873, val_loss=0.00919,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.95it/s, loss=0.00851, val_loss=0.00919,\u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.47it/s, loss=0.00851, val_loss=0.00919,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.39it/s, loss=0.00851, val_loss=0.00892,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00831, val_loss=0.00892,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00831, val_loss=0.00892,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 38.01it/s, loss=0.00831, val_loss=0.00869,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00813, val_loss=0.00869,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 24.14it/s, loss=0.00813, val_loss=0.00869,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00813, val_loss=0.00848,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00796, val_loss=0.00848,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.46it/s, loss=0.00796, val_loss=0.00848,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.35it/s, loss=0.00796, val_loss=0.00829,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.0078, val_loss=0.00829, \u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.23it/s, loss=0.0078, val_loss=0.00829, \n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.0078, val_loss=0.00812, \u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.45it/s, loss=0.00765, val_loss=0.00812,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 23.92it/s, loss=0.00765, val_loss=0.00812,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.60it/s, loss=0.00765, val_loss=0.00797,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00751, val_loss=0.00797,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00751, val_loss=0.00797,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00751, val_loss=0.00784,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00738, val_loss=0.00784,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 24.12it/s, loss=0.00738, val_loss=0.00784,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.91it/s, loss=0.00738, val_loss=0.00772,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00726, val_loss=0.00772,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.41it/s, loss=0.00726, val_loss=0.00772,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00726, val_loss=0.00761,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.00714, val_loss=0.00761,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 24.36it/s, loss=0.00714, val_loss=0.00761,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.22it/s, loss=0.00714, val_loss=0.0075, \u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.34it/s, loss=0.00704, val_loss=0.0075, \u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 23.79it/s, loss=0.00704, val_loss=0.0075, \n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.44it/s, loss=0.00704, val_loss=0.00742,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.92it/s, loss=0.00694, val_loss=0.00742,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.44it/s, loss=0.00694, val_loss=0.00742,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.00694, val_loss=0.00735,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00684, val_loss=0.00735,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 24.21it/s, loss=0.00684, val_loss=0.00735,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 38.02it/s, loss=0.00684, val_loss=0.00727,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00675, val_loss=0.00727,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00675, val_loss=0.00727,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00675, val_loss=0.0072, \u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.19it/s, loss=0.00667, val_loss=0.0072, \u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 23.60it/s, loss=0.00667, val_loss=0.0072, \n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 37.19it/s, loss=0.00667, val_loss=0.00713,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00658, val_loss=0.00713,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.00658, val_loss=0.00713,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00658, val_loss=0.00706,\u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.60it/s, loss=0.0065, val_loss=0.00706, \u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.07it/s, loss=0.0065, val_loss=0.00706, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.74it/s, loss=0.0065, val_loss=0.00701, \u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.00643, val_loss=0.00701,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.35it/s, loss=0.00643, val_loss=0.00701,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.00643, val_loss=0.00696,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00636, val_loss=0.00696,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.30it/s, loss=0.00636, val_loss=0.00696,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00636, val_loss=0.00692,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00629, val_loss=0.00692,\u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 24.36it/s, loss=0.00629, val_loss=0.00692,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 37.93it/s, loss=0.00629, val_loss=0.00688,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.51it/s, loss=0.00623, val_loss=0.00688,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 23.99it/s, loss=0.00623, val_loss=0.00688,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00623, val_loss=0.00685,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.44it/s, loss=0.00623, val_loss=0.00685,\u001b[A\n",
      "Sizes of clusters: 442, 332, 672, 154\n",
      "\n",
      "preds: [0 0 0 2 2 2 2 2 1 1 0 1 0 2 0 1 2 2 2 2 0 0 2 2 2 1 2 0 1 1 1 1 0 2 0 2 2\n",
      " 2 1 2 1 1 1 0 2 2 1 1 1 2 0 1 0 1 1 0 1 0 1 2 2 1 2 2 0 1 2 0 0 2 2 2 0 1\n",
      " 0 0 2 1 2 2 1 1 2 0 0 0 0 2 1 2 0 0 2 0 1 0 1 0 2 2 2 3 1 1 2 2 2 2 2 2 2\n",
      " 1 2 0 2 2 2 1 1 1 2 0 1 1 2 1 2 0 2 2 2 2 2 0 2 0 2 2 2 1 0 1 2 2 1 0 2 1\n",
      " 0 2 1 1 0 1 1 2 2 0 2 2 1 2 0 0 0 0 2 2 1 0 0 2 1 2 2 2 2 2 3 2 1 1 2 2 1\n",
      " 2 1 2 2 1 0 2 2 1 1 2 2 1 1 1 2 1 0 2 2 0 2 2 2 2 2 1 2 2 1 2 1 2 1 1 2 0\n",
      " 1 2 2 2 0 2 0 2 2 2 0 2 2 1 0 2 0 0 2 1 0 0 2 1 2 1 1 2 0 1 2 0 2 1 2 2 1\n",
      " 2 1 2 0 2 0 2 0 1 1 2 2 3 0 1 2 2 2 1 1 1 2 0 0 2 2 0 0 1 1 2 1 1 1 1 2 2\n",
      " 2 2 1 0 2 3 0 0 0 2 2 2 2 0 0 1 1 0 1 2 0 2 2 0 1 0 2 1 2 1 2 0 0 2 2 1 0\n",
      " 2 2 0 2 2 0 2 2 2 0 0 2 1 2 1 2 2 1 2 1 2 0 2 2 2 2 2 1 2 1 2 1 0 0 1 1 1\n",
      " 0 2 0 2 1 2 0 1 1 0 0 0 2 2 1 1 0 1 2 0 0 0 2 0 2 2 2 1 2 2 0 2 1 2 2 0 1\n",
      " 2 2 0 1 1 2 2 2 3 1 2 1 0 1 2 0 2 2 2 1 0 2 1 0 2 2 1 1 2 1 2 0 2 2 0 2 2\n",
      " 2 2 2 1 0 2 2 0 3 1 1 2 1 2 2 2 2 2 1 2 2 2 2 2 1 2 1 2 2 1 0 2 2 0 2 2 1\n",
      " 2 1 0 0 2 0 1 1 1 2 3 1 2 0 2 0 0 1 2 1 1 2 0 0 2 2 1 1 1 0 2 2 2 1 2 2 0\n",
      " 0 0 2 2 0 1 0 2 2 2 1 0 2 2 2 0 2 2 2 0 2 1 0 2 2 2 0 1 2 2 2 2 2 2 2 2 0\n",
      " 2 1 0 0 1 2 1 2 2 0 2 2 1 1 2 0 2 0 1 2 1 2 0 2 2 0 2 3 1 3 2 2 1 0 2 0 1\n",
      " 1 1 2 2 2 0 0 2 2 2 0 1 0 3 2 2 2 2 1 2 2 2 2 0 2 0 0 0 1 1 2 0 0 2 1 2 1\n",
      " 2 2 1 2 1 2 2 1 2 0 0 1 2 0 0 1 2 2 2 1 0 0 1 3 0 1 0 2 1 2 1 1 1 0 0 1 0\n",
      " 0 2 2 2 2 2 2 2 2 2 0 1 2 2 2 0 0 2 2 0 2 2 2 0 2 1 2 2 0 2 1 1 2 0 1 2 2\n",
      " 2 2 2 2 2 2 2 2 0 2 1 0 0 1 2 2 0 2 2 0 2 1 2 1 2 1 1 3 2 2 2 0 0 1 2 0 2\n",
      " 0 2 2 0 1 2 2 2 1 0 0 2 1 1 2 2 2 0 2 1 2 2 2 2 2 2 1 2 2 0 1 2 0 2 2 0 0\n",
      " 0 1 2 2 0 0 0 2 2 0 0 1 0 0 2 2 0 0 0 0 2 0 2 3 2 3 3 3 2 3 0 3 3 3 0 3 0\n",
      " 3 1 0 3 3 2 2 1 3 2 3 0 3 3 2 3 3 2 0 2 3 0 2 3 3 3 0 2 2 0 2 2 0 2 2 3 1\n",
      " 2 3 3 3 0 2 3 2 2 3 0 2 0 2 0 3 3 0 3 0 0 3 0 2 2 3 0 3 2 2 0 2 0 0 3 3 3\n",
      " 0 0 0 0 0 3 2 1 0 0 0 0 0 2 2 3 3 0 3 3 2 0 3 0 2 3 3 3 3 0 0 0 3 2 3 0 3\n",
      " 3 0 0 3 3 0 0 0 3 0 0 2 3 0 0 3 2 2 0 0 3 3 1 0 0 0 0 0 0 2 2 0 3 3 3 3 2\n",
      " 0 0 0 3 0 1 3 0 3 0 3 3 0 3 3 0 2 0 3 0 2 2 0 2 2 0 0 2 0 0 2 1 0 0 3 3 0\n",
      " 0 3 0 0 0 0 0 2 3 0 3 2 0 3 2 3 0 0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 1 0 0 3 3 3 0 3 0 0 2 0 0 3 3 0 0 0 0 3 2 3 0 0 2 0 0 0 2 3 0 3 0 3 0 3\n",
      " 3 3 0 3 3 2 3 2 3 0 0 3 0 2 0 0 3 0 3 0 0 0 2 0 3 3 0 3 3 0 3 3 0 3 1 3 0\n",
      " 3 0 3 2 3 0 3 3 3 3 0 3 3 3 2 3 3 3 0 0 0 2 0 0 3 3 2 2 0 0 0 3 2 3 0 0 0\n",
      " 0 3 2 3 0 0 2 3 3 0 2 0 3 2 3 2 0 3 3 0 3 0 0 3 3 0 2 1 0 3 3 0 2 0 3 0 3\n",
      " 0 0 0 2 0 0 0 0 0 0 0 2 2 3 0 0 1 1 2 2 2 2 2 2 2 1 1 2 2 2 0 1 1 2 2 2 2\n",
      " 2 0 1 2 2 1 2 1 1 1 0 1 0 3 2 2 0 1 0 2 2 2 1 2 2 2 1 1 2 0 2 1 1 0 2 2 1\n",
      " 2 2 2 2 2 0 2 2 2 2 2 2 1 0 2 2 0 2 2 2 2 1 1 1 1 2 0 2 0 2 2 0 0 2 2 2 1\n",
      " 1 1 2 2 2 2 2 1 0 2 2 0 2 2 1 0 2 2 1 2 2 0 0 2 1 1 1 1 2 2 1 2 2 1 0 3 2\n",
      " 1 2 0 2 2 2 0 2 2 1 2 1 0 1 2 2 1 2 0 0 2 1 1 2 0 0 2 0 2 1 2 2 1 1 1 2 2\n",
      " 1 2 0 2 2 1 2 1 1 0 1 0 2 2 1 2 2 0 0 2 2 2 0 2 1 2 2 2 0 2 2 1 2 1 1 2 2\n",
      " 2 2 0 2 2 1 0 1 2 1 1 2 1 1 2 2 1 1 2 2 0 2 2 2 0 0 1 2 2 2 2 1 2 2 2 1 0\n",
      " 1 2 2 2 1 1 2 2 2 2 0 0 0 1 0 1 0 1 2 2 2 0 2 1 1 2 1 2 2 1 2 0 2 2 0 1 3\n",
      " 2 2 1 1 2 2 2 2 0 2 2 1 1 2 2 2 2 1 2 2 2 0 0 2 0 2 1 2 1 2 2 2 1 1 1 2 0\n",
      " 1 2 2 2 1 1 2 1 2 2 2 1 2 2 0 1 1 2 2 1 2 1 1 2 2 0 2 2 1 1 1 0 2 2 0 2 2\n",
      " 2 1 2 2 1 1 1 2 2 1 1 1 1 2 2 1 2 1 2 0 2 1 1 1 1 2 1 2 2 2 0 1 2 0 0 2 2\n",
      " 1 0 0 1 2 0 2 2 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4031\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=3.5, val_loss=0.102, avg_va\n",
      "Epoch 0:  55%|▌| 35/64 [00:01<00:01, 23.57it/s, loss=3.5, val_loss=0.102, avg_va\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=3.5, val_loss=0.285, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 22.03it/s, loss=0.143, val_loss=0.285, avg_\u001b[A\n",
      "Epoch 1:  56%|▌| 36/64 [00:01<00:01, 24.59it/s, loss=0.143, val_loss=0.285, avg_\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.50it/s, loss=0.143, val_loss=0.0681, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 22.17it/s, loss=0.036, val_loss=0.0681, avg\u001b[A\n",
      "Epoch 2:  56%|▌| 36/64 [00:01<00:01, 24.78it/s, loss=0.036, val_loss=0.0681, avg\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.73it/s, loss=0.036, val_loss=0.035, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.98it/s, loss=0.0258, val_loss=0.035, avg\u001b[A\n",
      "Epoch 3:  56%|▌| 36/64 [00:01<00:01, 24.53it/s, loss=0.0258, val_loss=0.035, avg\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 38.40it/s, loss=0.0258, val_loss=0.0285, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.55it/s, loss=0.0217, val_loss=0.0285, av\u001b[A\n",
      "Epoch 4:  56%|▌| 36/64 [00:01<00:01, 24.07it/s, loss=0.0217, val_loss=0.0285, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 37.77it/s, loss=0.0217, val_loss=0.0243, av\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 22.16it/s, loss=0.0192, val_loss=0.0243, av\u001b[A\n",
      "Epoch 5:  56%|▌| 36/64 [00:01<00:01, 24.76it/s, loss=0.0192, val_loss=0.0243, av\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 38.71it/s, loss=0.0192, val_loss=0.0211, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 22.07it/s, loss=0.0173, val_loss=0.0211, av\u001b[A\n",
      "Epoch 6:  56%|▌| 36/64 [00:01<00:01, 24.65it/s, loss=0.0173, val_loss=0.0211, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.54it/s, loss=0.0173, val_loss=0.0187, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 22.06it/s, loss=0.016, val_loss=0.0187, avg\u001b[A\n",
      "Epoch 7:  56%|▌| 36/64 [00:01<00:01, 24.62it/s, loss=0.016, val_loss=0.0187, avg\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.53it/s, loss=0.016, val_loss=0.0169, avg\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.97it/s, loss=0.0149, val_loss=0.0169, av\u001b[A\n",
      "Epoch 8:  56%|▌| 36/64 [00:01<00:01, 24.49it/s, loss=0.0149, val_loss=0.0169, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.40it/s, loss=0.0149, val_loss=0.0154, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.97it/s, loss=0.0139, val_loss=0.0154, av\u001b[A\n",
      "Epoch 9:  56%|▌| 36/64 [00:01<00:01, 24.51it/s, loss=0.0139, val_loss=0.0154, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 38.37it/s, loss=0.0139, val_loss=0.0143, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.0131, val_loss=0.0143, a\u001b[A\n",
      "Epoch 10:  56%|▌| 36/64 [00:01<00:01, 24.59it/s, loss=0.0131, val_loss=0.0143, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.48it/s, loss=0.0131, val_loss=0.0134, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 22.11it/s, loss=0.0124, val_loss=0.0134, a\u001b[A\n",
      "Epoch 11:  56%|▌| 36/64 [00:01<00:01, 24.70it/s, loss=0.0124, val_loss=0.0134, a\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.64it/s, loss=0.0124, val_loss=0.0125, a\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 22.00it/s, loss=0.0117, val_loss=0.0125, a\u001b[A\n",
      "Epoch 12:  56%|▌| 36/64 [00:01<00:01, 24.57it/s, loss=0.0117, val_loss=0.0125, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 38.46it/s, loss=0.0117, val_loss=0.0118, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 22.14it/s, loss=0.0112, val_loss=0.0118, a\u001b[A\n",
      "Epoch 13:  56%|▌| 36/64 [00:01<00:01, 24.67it/s, loss=0.0112, val_loss=0.0118, a\n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.64it/s, loss=0.0112, val_loss=0.0111, a\u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.40it/s, loss=0.0106, val_loss=0.0111, a\u001b[A\n",
      "Epoch 14:  56%|▌| 36/64 [00:01<00:01, 23.84it/s, loss=0.0106, val_loss=0.0111, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 37.50it/s, loss=0.0106, val_loss=0.0105, a\u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.0101, val_loss=0.0105, a\u001b[A\n",
      "Epoch 15:  56%|▌| 36/64 [00:01<00:01, 24.18it/s, loss=0.0101, val_loss=0.0105, a\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.0101, val_loss=0.00997, \u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 21.88it/s, loss=0.0097, val_loss=0.00997, \u001b[A\n",
      "Epoch 16:  56%|▌| 36/64 [00:01<00:01, 24.39it/s, loss=0.0097, val_loss=0.00997, \n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.0097, val_loss=0.0095, a\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00931, val_loss=0.0095, \u001b[A\n",
      "Epoch 17:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00931, val_loss=0.0095, \n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00931, val_loss=0.00908,\u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.00897, val_loss=0.00908,\u001b[A\n",
      "Epoch 18:  56%|▌| 36/64 [00:01<00:01, 24.19it/s, loss=0.00897, val_loss=0.00908,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00897, val_loss=0.0087, \u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00866, val_loss=0.0087, \u001b[A\n",
      "Epoch 19:  56%|▌| 36/64 [00:01<00:01, 24.37it/s, loss=0.00866, val_loss=0.0087, \n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.23it/s, loss=0.00866, val_loss=0.00836,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.64it/s, loss=0.00839, val_loss=0.00836,\u001b[A\n",
      "Epoch 20:  56%|▌| 36/64 [00:01<00:01, 24.13it/s, loss=0.00839, val_loss=0.00836,\n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.00839, val_loss=0.00807,\u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.75it/s, loss=0.00815, val_loss=0.00807,\u001b[A\n",
      "Epoch 21:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00815, val_loss=0.00807,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00815, val_loss=0.00782,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00794, val_loss=0.00782,\u001b[A\n",
      "Epoch 22:  56%|▌| 36/64 [00:01<00:01, 24.34it/s, loss=0.00794, val_loss=0.00782,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00794, val_loss=0.0076, \u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.62it/s, loss=0.00775, val_loss=0.0076, \u001b[A\n",
      "Epoch 23:  56%|▌| 36/64 [00:01<00:01, 24.10it/s, loss=0.00775, val_loss=0.0076, \n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.86it/s, loss=0.00775, val_loss=0.00741,\u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00757, val_loss=0.00741,\u001b[A\n",
      "Epoch 24:  56%|▌| 36/64 [00:01<00:01, 24.22it/s, loss=0.00757, val_loss=0.00741,\n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00757, val_loss=0.00723,\u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.00741, val_loss=0.00723,\u001b[A\n",
      "Epoch 25:  56%|▌| 36/64 [00:01<00:01, 24.38it/s, loss=0.00741, val_loss=0.00723,\n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.23it/s, loss=0.00741, val_loss=0.00707,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00727, val_loss=0.00707,\u001b[A\n",
      "Epoch 26:  56%|▌| 36/64 [00:01<00:01, 24.26it/s, loss=0.00727, val_loss=0.00707,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 38.08it/s, loss=0.00727, val_loss=0.00692,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00713, val_loss=0.00692,\u001b[A\n",
      "Epoch 27:  56%|▌| 36/64 [00:01<00:01, 24.42it/s, loss=0.00713, val_loss=0.00692,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00713, val_loss=0.00677,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00701, val_loss=0.00677,\u001b[A\n",
      "Epoch 28:  56%|▌| 36/64 [00:01<00:01, 24.26it/s, loss=0.00701, val_loss=0.00677,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.05it/s, loss=0.00701, val_loss=0.00664,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.78it/s, loss=0.00689, val_loss=0.00664,\u001b[A\n",
      "Epoch 29:  56%|▌| 36/64 [00:01<00:01, 24.29it/s, loss=0.00689, val_loss=0.00664,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 38.09it/s, loss=0.00689, val_loss=0.00652,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00678, val_loss=0.00652,\u001b[A\n",
      "Epoch 30:  56%|▌| 36/64 [00:01<00:01, 24.41it/s, loss=0.00678, val_loss=0.00652,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.32it/s, loss=0.00678, val_loss=0.00643,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.85it/s, loss=0.00667, val_loss=0.00643,\u001b[A\n",
      "Epoch 31:  56%|▌| 36/64 [00:01<00:01, 24.36it/s, loss=0.00667, val_loss=0.00643,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00667, val_loss=0.00635,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00656, val_loss=0.00635,\u001b[A\n",
      "Epoch 32:  56%|▌| 36/64 [00:01<00:01, 24.27it/s, loss=0.00656, val_loss=0.00635,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00656, val_loss=0.00627,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00646, val_loss=0.00627,\u001b[A\n",
      "Epoch 33:  56%|▌| 36/64 [00:01<00:01, 24.39it/s, loss=0.00646, val_loss=0.00627,\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.26it/s, loss=0.00646, val_loss=0.00618,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.00638, val_loss=0.00618,\u001b[A\n",
      "Epoch 34:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.00638, val_loss=0.00618,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 37.96it/s, loss=0.00638, val_loss=0.0061, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.69it/s, loss=0.0063, val_loss=0.0061, a\u001b[A\n",
      "Epoch 35:  56%|▌| 36/64 [00:01<00:01, 24.16it/s, loss=0.0063, val_loss=0.0061, a\n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.0063, val_loss=0.00602, \u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00622, val_loss=0.00602,\u001b[A\n",
      "Epoch 36:  56%|▌| 36/64 [00:01<00:01, 24.40it/s, loss=0.00622, val_loss=0.00602,\n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.27it/s, loss=0.00622, val_loss=0.00596,\u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.76it/s, loss=0.00616, val_loss=0.00596,\u001b[A\n",
      "Epoch 37:  56%|▌| 36/64 [00:01<00:01, 24.25it/s, loss=0.00616, val_loss=0.00596,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.06it/s, loss=0.00616, val_loss=0.0059, \u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.85it/s, loss=0.00609, val_loss=0.0059, \u001b[A\n",
      "Epoch 38:  56%|▌| 36/64 [00:01<00:01, 24.33it/s, loss=0.00609, val_loss=0.0059, \n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.00609, val_loss=0.00583,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.68it/s, loss=0.00603, val_loss=0.00583,\u001b[A\n",
      "Epoch 39:  56%|▌| 36/64 [00:01<00:01, 24.17it/s, loss=0.00603, val_loss=0.00583,\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.95it/s, loss=0.00603, val_loss=0.00571,\u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.70it/s, loss=0.00603, val_loss=0.00571,\u001b[A\n",
      "Sizes of clusters: 379, 418, 279, 524\n",
      "\n",
      "preds: [0 3 3 1 0 2 0 0 2 2 3 2 0 2 1 0 2 3 3 1 2 0 2 2 3 3 3 3 2 2 3 2 1 1 0 1 0\n",
      " 3 2 0 2 2 2 0 0 3 0 2 2 3 3 3 0 2 2 1 0 1 2 0 1 3 3 3 1 1 3 2 2 3 1 1 0 2\n",
      " 0 0 2 0 1 3 2 2 1 0 0 0 1 3 2 3 0 0 0 1 2 2 2 3 3 1 3 0 2 2 2 2 3 3 2 3 0\n",
      " 2 0 1 2 2 3 3 2 2 0 0 2 2 3 2 2 3 1 3 1 3 1 3 3 1 3 0 2 3 2 2 1 1 2 0 2 0\n",
      " 0 1 2 2 1 0 3 2 2 0 0 2 2 0 0 0 1 3 0 3 2 0 0 1 2 3 0 3 0 3 0 3 2 0 3 2 3\n",
      " 3 3 1 1 2 1 3 2 2 3 1 3 3 0 0 1 0 0 0 0 3 2 3 1 0 1 2 3 0 2 3 2 2 2 2 1 0\n",
      " 3 0 3 2 2 1 1 3 3 0 3 2 2 2 0 1 0 1 0 2 0 1 0 2 3 2 2 1 3 2 3 3 3 2 1 0 0\n",
      " 3 0 0 0 0 1 3 0 1 1 0 0 0 2 3 1 3 3 3 2 2 3 1 0 1 2 1 3 2 3 3 2 2 2 3 2 2\n",
      " 3 3 1 3 2 0 1 1 0 3 1 0 2 1 1 3 1 3 3 3 2 3 3 0 3 3 3 2 3 0 1 1 0 3 3 3 0\n",
      " 0 0 3 3 3 3 0 0 0 1 0 1 3 3 2 1 2 2 2 2 0 1 0 0 3 2 1 3 1 2 3 2 2 3 1 2 2\n",
      " 2 1 0 2 3 1 0 3 2 1 1 0 2 1 2 2 1 2 1 3 0 2 1 1 3 2 3 2 3 3 3 3 3 0 3 3 3\n",
      " 3 3 0 3 2 3 3 3 3 3 3 3 3 2 1 0 3 3 0 3 3 3 3 0 1 3 3 2 3 3 2 3 3 0 1 3 0\n",
      " 3 0 3 2 0 3 1 0 0 3 3 3 3 2 3 3 2 3 2 3 3 3 0 3 3 0 0 3 0 3 0 0 3 3 3 0 2\n",
      " 3 3 0 0 3 3 3 2 3 0 3 3 0 3 3 0 3 0 0 2 3 3 0 0 0 1 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 0 2 0 3 0 3 0 3 3 3 0 2 3 0 3 3 3 0 0 3 3 0 2 3 0 0 3 3 2 0 3 2 3 3 3\n",
      " 2 0 0 0 2 3 3 3 3 3 3 3 0 3 3 3 3 0 2 3 3 1 0 3 3 3 3 0 3 0 3 2 3 0 0 3 3\n",
      " 0 3 0 3 3 3 0 0 3 2 3 3 0 0 3 3 3 3 0 3 3 3 3 0 1 3 0 3 3 0 3 3 3 3 2 0 0\n",
      " 0 3 3 0 2 2 3 3 3 0 1 2 3 0 3 0 3 0 3 2 3 0 3 0 0 3 0 3 2 3 3 3 3 3 1 3 3\n",
      " 0 2 3 1 3 0 3 2 3 3 3 3 3 0 3 1 0 3 3 0 3 3 2 3 1 3 3 3 3 0 3 3 3 3 3 3 3\n",
      " 0 3 3 0 2 3 3 0 1 3 3 0 3 2 3 3 1 3 3 1 3 0 3 3 0 3 2 3 0 3 2 0 0 2 3 3 2\n",
      " 3 3 1 3 3 3 3 3 2 3 3 3 3 1 3 3 3 3 3 2 0 3 0 3 3 0 3 3 3 3 3 3 3 3 0 3 0\n",
      " 3 3 0 1 1 3 3 3 3 3 0 2 0 0 3 3 1 3 3 3 3 3 0 0 0 0 0 0 1 1 1 0 0 0 2 0 2\n",
      " 1 3 0 1 0 3 3 3 0 3 0 1 1 0 1 1 1 3 1 1 1 0 0 0 1 1 1 3 2 0 1 2 0 3 2 1 3\n",
      " 1 1 2 1 1 1 1 2 0 1 1 1 1 2 0 1 1 0 1 0 1 0 2 3 3 0 2 1 1 2 3 3 0 3 1 0 1\n",
      " 1 1 1 1 1 1 3 2 1 0 3 0 1 1 3 1 1 0 1 1 3 1 0 2 3 0 0 1 1 0 3 1 0 1 1 3 1\n",
      " 0 0 1 0 0 1 1 1 1 2 1 1 0 1 2 1 1 0 1 3 1 1 2 3 1 0 1 1 1 1 3 0 0 2 1 1 0\n",
      " 2 1 1 2 0 0 0 1 1 1 1 3 2 1 1 3 3 3 1 2 3 3 0 3 0 1 3 1 1 0 2 0 0 3 1 1 1\n",
      " 1 1 2 0 1 1 2 0 1 1 1 1 0 1 3 0 2 1 0 2 3 3 1 1 0 2 2 0 0 1 0 1 1 3 2 1 3\n",
      " 1 2 1 1 1 0 2 2 0 0 1 2 3 3 0 1 2 1 1 3 1 1 0 2 0 2 3 1 1 2 1 3 0 1 1 1 0\n",
      " 0 2 1 1 1 3 0 1 1 1 0 1 1 2 1 0 1 0 0 1 0 1 3 2 1 0 1 0 0 0 0 1 1 0 3 0 1\n",
      " 1 0 2 0 0 0 1 1 0 1 1 1 1 1 1 0 1 0 2 2 1 3 1 1 1 1 3 3 0 0 0 1 3 1 1 0 2\n",
      " 1 0 2 1 1 1 1 1 1 0 3 2 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 3 3 1 1 0 1 0 1 1 1\n",
      " 0 0 3 3 3 2 0 1 1 1 1 1 1 0 0 1 2 2 2 2 2 1 1 0 1 1 2 1 2 3 1 1 2 3 1 0 0\n",
      " 0 0 3 2 3 2 1 2 1 2 1 2 0 0 1 0 1 3 1 0 3 1 1 3 2 1 1 2 3 0 3 0 3 0 3 1 1\n",
      " 3 3 1 1 0 1 2 0 3 2 0 1 1 1 3 1 1 3 0 0 1 3 2 2 3 3 3 0 1 3 3 2 1 3 1 3 2\n",
      " 3 0 3 3 3 1 1 2 3 1 1 1 2 3 1 1 1 3 3 1 1 0 0 1 1 0 2 3 1 3 2 0 1 2 1 0 1\n",
      " 1 1 0 1 1 3 1 0 3 2 2 3 1 3 1 3 2 0 1 0 1 2 1 3 0 0 3 3 1 3 0 2 1 3 3 3 2\n",
      " 2 3 0 2 3 2 3 3 0 3 3 1 1 2 3 2 0 1 1 1 1 0 1 1 3 1 3 1 3 2 3 2 0 1 1 1 1\n",
      " 3 1 0 1 0 2 1 1 3 2 3 1 1 1 2 1 2 2 0 3 1 1 3 2 0 0 0 1 3 0 1 1 2 1 3 3 1\n",
      " 1 1 0 1 3 3 2 3 3 2 3 0 1 3 1 1 0 3 1 1 2 1 0 3 3 2 1 1 1 2 1 0 3 1 0 3 0\n",
      " 3 1 2 3 3 0 3 3 1 2 1 1 3 1 2 3 3 3 3 3 2 0 0 1 0 2 1 1 2 0 1 3 2 0 3 3 3\n",
      " 2 0 1 0 3 2 1 0 1 0 0 2 3 2 0 2 3 2 0 2 1 3 2 1 2 1 3 3 2 2 1 0 3 0 3 0 3\n",
      " 0 2 1 1 3 1 0 2 1 2 1 2 3 3 2 1 1 1 1 3 0 0 1 2 1 3 0 3 0 1 0 2 3 1 0 3 1\n",
      " 3 0 0 1 3 3 1 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4106\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=1.94, val_loss=0.107, avg_v\n",
      "Epoch 0:  80%|▊| 51/64 [00:01<00:00, 32.42it/s, loss=1.94, val_loss=0.107, avg_v\n",
      "Epoch 0: 100%|█| 64/64 [00:01<00:00, 38.07it/s, loss=1.94, val_loss=0.33, avg_va\u001b[A\n",
      "Epoch 1:  50%|▌| 32/64 [00:01<00:01, 22.02it/s, loss=0.107, val_loss=0.33, avg_v\u001b[A\n",
      "Epoch 1:  59%|▌| 38/64 [00:01<00:01, 25.82it/s, loss=0.107, val_loss=0.33, avg_v\n",
      "Epoch 1: 100%|█| 64/64 [00:01<00:00, 38.48it/s, loss=0.107, val_loss=0.0571, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 32/64 [00:01<00:01, 22.09it/s, loss=0.0332, val_loss=0.0571, av\u001b[A\n",
      "Epoch 2:  59%|▌| 38/64 [00:01<00:01, 25.92it/s, loss=0.0332, val_loss=0.0571, av\n",
      "Epoch 2: 100%|█| 64/64 [00:01<00:00, 38.62it/s, loss=0.0332, val_loss=0.0333, av\u001b[A\n",
      "Epoch 3:  50%|▌| 32/64 [00:01<00:01, 21.43it/s, loss=0.0243, val_loss=0.0333, av\u001b[A\n",
      "Epoch 3:  59%|▌| 38/64 [00:01<00:01, 25.10it/s, loss=0.0243, val_loss=0.0333, av\n",
      "Epoch 3: 100%|█| 64/64 [00:01<00:00, 37.57it/s, loss=0.0243, val_loss=0.0265, av\u001b[A\n",
      "Epoch 4:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.0201, val_loss=0.0265, av\u001b[A\n",
      "Epoch 4:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.0201, val_loss=0.0265, av\n",
      "Epoch 4: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.0201, val_loss=0.022, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 32/64 [00:01<00:01, 21.47it/s, loss=0.0174, val_loss=0.022, avg\u001b[A\n",
      "Epoch 5:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.0174, val_loss=0.022, avg\n",
      "Epoch 5: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.0174, val_loss=0.0188, av\u001b[A\n",
      "Epoch 6:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.0155, val_loss=0.0188, av\u001b[A\n",
      "Epoch 6:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.0155, val_loss=0.0188, av\n",
      "Epoch 6: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.0155, val_loss=0.0165, av\u001b[A\n",
      "Epoch 7:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.0141, val_loss=0.0165, av\u001b[A\n",
      "Epoch 7:  59%|▌| 38/64 [00:01<00:01, 25.39it/s, loss=0.0141, val_loss=0.0165, av\n",
      "Epoch 7: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.0141, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  50%|▌| 32/64 [00:01<00:01, 21.96it/s, loss=0.0131, val_loss=0.0147, av\u001b[A\n",
      "Epoch 8:  59%|▌| 38/64 [00:01<00:01, 25.71it/s, loss=0.0131, val_loss=0.0147, av\n",
      "Epoch 8: 100%|█| 64/64 [00:01<00:00, 38.40it/s, loss=0.0131, val_loss=0.0135, av\u001b[A\n",
      "Epoch 9:  50%|▌| 32/64 [00:01<00:01, 21.50it/s, loss=0.0122, val_loss=0.0135, av\u001b[A\n",
      "Epoch 9:  59%|▌| 38/64 [00:01<00:01, 25.15it/s, loss=0.0122, val_loss=0.0135, av\n",
      "Epoch 9: 100%|█| 64/64 [00:01<00:00, 37.68it/s, loss=0.0122, val_loss=0.0125, av\u001b[A\n",
      "Epoch 10:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.0115, val_loss=0.0125, a\u001b[A\n",
      "Epoch 10:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.0115, val_loss=0.0125, a\n",
      "Epoch 10: 100%|█| 64/64 [00:01<00:00, 38.21it/s, loss=0.0115, val_loss=0.0118, a\u001b[A\n",
      "Epoch 11:  50%|▌| 32/64 [00:01<00:01, 21.93it/s, loss=0.011, val_loss=0.0118, av\u001b[A\n",
      "Epoch 11:  59%|▌| 38/64 [00:01<00:01, 25.64it/s, loss=0.011, val_loss=0.0118, av\n",
      "Epoch 11: 100%|█| 64/64 [00:01<00:00, 38.34it/s, loss=0.011, val_loss=0.0111, av\u001b[A\n",
      "Epoch 12:  50%|▌| 32/64 [00:01<00:01, 21.63it/s, loss=0.0104, val_loss=0.0111, a\u001b[A\n",
      "Epoch 12:  59%|▌| 38/64 [00:01<00:01, 25.32it/s, loss=0.0104, val_loss=0.0111, a\n",
      "Epoch 12: 100%|█| 64/64 [00:01<00:00, 37.88it/s, loss=0.0104, val_loss=0.0106, a\u001b[A\n",
      "Epoch 13:  50%|▌| 32/64 [00:01<00:01, 21.83it/s, loss=0.00999, val_loss=0.0106, \u001b[A\n",
      "Epoch 13:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.00999, val_loss=0.0106, \n",
      "Epoch 13: 100%|█| 64/64 [00:01<00:00, 38.17it/s, loss=0.00999, val_loss=0.0101, \u001b[A\n",
      "Epoch 14:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.0096, val_loss=0.0101, a\u001b[A\n",
      "Epoch 14:  59%|▌| 38/64 [00:01<00:01, 25.51it/s, loss=0.0096, val_loss=0.0101, a\n",
      "Epoch 14: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.0096, val_loss=0.00967, \u001b[A\n",
      "Epoch 15:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00926, val_loss=0.00967,\u001b[A\n",
      "Epoch 15:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.00926, val_loss=0.00967,\n",
      "Epoch 15: 100%|█| 64/64 [00:01<00:00, 38.16it/s, loss=0.00926, val_loss=0.00927,\u001b[A\n",
      "Epoch 16:  50%|▌| 32/64 [00:01<00:01, 22.01it/s, loss=0.00896, val_loss=0.00927,\u001b[A\n",
      "Epoch 16:  59%|▌| 38/64 [00:01<00:01, 25.77it/s, loss=0.00896, val_loss=0.00927,\n",
      "Epoch 16: 100%|█| 64/64 [00:01<00:00, 38.47it/s, loss=0.00896, val_loss=0.00894,\u001b[A\n",
      "Epoch 17:  50%|▌| 32/64 [00:01<00:01, 21.58it/s, loss=0.0087, val_loss=0.00894, \u001b[A\n",
      "Epoch 17:  59%|▌| 38/64 [00:01<00:01, 25.28it/s, loss=0.0087, val_loss=0.00894, \n",
      "Epoch 17: 100%|█| 64/64 [00:01<00:00, 37.82it/s, loss=0.0087, val_loss=0.00867, \u001b[A\n",
      "Epoch 18:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00848, val_loss=0.00867,\u001b[A\n",
      "Epoch 18:  59%|▌| 38/64 [00:01<00:01, 25.42it/s, loss=0.00848, val_loss=0.00867,\n",
      "Epoch 18: 100%|█| 64/64 [00:01<00:00, 37.97it/s, loss=0.00848, val_loss=0.00841,\u001b[A\n",
      "Epoch 19:  50%|▌| 32/64 [00:01<00:01, 21.89it/s, loss=0.00828, val_loss=0.00841,\u001b[A\n",
      "Epoch 19:  59%|▌| 38/64 [00:01<00:01, 25.61it/s, loss=0.00828, val_loss=0.00841,\n",
      "Epoch 19: 100%|█| 64/64 [00:01<00:00, 38.25it/s, loss=0.00828, val_loss=0.00819,\u001b[A\n",
      "Epoch 20:  50%|▌| 32/64 [00:01<00:01, 21.84it/s, loss=0.0081, val_loss=0.00819, \u001b[A\n",
      "Epoch 20:  59%|▌| 38/64 [00:01<00:01, 25.55it/s, loss=0.0081, val_loss=0.00819, \n",
      "Epoch 20: 100%|█| 64/64 [00:01<00:00, 38.20it/s, loss=0.0081, val_loss=0.00801, \u001b[A\n",
      "Epoch 21:  50%|▌| 32/64 [00:01<00:01, 21.82it/s, loss=0.00794, val_loss=0.00801,\u001b[A\n",
      "Epoch 21:  59%|▌| 38/64 [00:01<00:01, 25.54it/s, loss=0.00794, val_loss=0.00801,\n",
      "Epoch 21: 100%|█| 64/64 [00:01<00:00, 38.18it/s, loss=0.00794, val_loss=0.00788,\u001b[A\n",
      "Epoch 22:  50%|▌| 32/64 [00:01<00:01, 21.94it/s, loss=0.00779, val_loss=0.00788,\u001b[A\n",
      "Epoch 22:  59%|▌| 38/64 [00:01<00:01, 25.70it/s, loss=0.00779, val_loss=0.00788,\n",
      "Epoch 22: 100%|█| 64/64 [00:01<00:00, 38.37it/s, loss=0.00779, val_loss=0.00774,\u001b[A\n",
      "Epoch 23:  50%|▌| 32/64 [00:01<00:01, 21.77it/s, loss=0.00765, val_loss=0.00774,\u001b[A\n",
      "Epoch 23:  59%|▌| 38/64 [00:01<00:01, 25.43it/s, loss=0.00765, val_loss=0.00774,\n",
      "Epoch 23: 100%|█| 64/64 [00:01<00:00, 37.72it/s, loss=0.00765, val_loss=0.0076, \u001b[A\n",
      "Epoch 24:  50%|▌| 32/64 [00:01<00:01, 21.39it/s, loss=0.00753, val_loss=0.0076, \u001b[A\n",
      "Epoch 24:  59%|▌| 38/64 [00:01<00:01, 25.05it/s, loss=0.00753, val_loss=0.0076, \n",
      "Epoch 24: 100%|█| 64/64 [00:01<00:00, 37.51it/s, loss=0.00753, val_loss=0.0075, \u001b[A\n",
      "Epoch 25:  50%|▌| 32/64 [00:01<00:01, 21.87it/s, loss=0.00742, val_loss=0.0075, \u001b[A\n",
      "Epoch 25:  59%|▌| 38/64 [00:01<00:01, 25.61it/s, loss=0.00742, val_loss=0.0075, \n",
      "Epoch 25: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.00742, val_loss=0.00738,\u001b[A\n",
      "Epoch 26:  50%|▌| 32/64 [00:01<00:01, 21.46it/s, loss=0.00732, val_loss=0.00738,\u001b[A\n",
      "Epoch 26:  59%|▌| 38/64 [00:01<00:01, 25.13it/s, loss=0.00732, val_loss=0.00738,\n",
      "Epoch 26: 100%|█| 64/64 [00:01<00:00, 37.63it/s, loss=0.00732, val_loss=0.00726,\u001b[A\n",
      "Epoch 27:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00722, val_loss=0.00726,\u001b[A\n",
      "Epoch 27:  59%|▌| 38/64 [00:01<00:01, 25.62it/s, loss=0.00722, val_loss=0.00726,\n",
      "Epoch 27: 100%|█| 64/64 [00:01<00:00, 38.30it/s, loss=0.00722, val_loss=0.00716,\u001b[A\n",
      "Epoch 28:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00713, val_loss=0.00716,\u001b[A\n",
      "Epoch 28:  59%|▌| 38/64 [00:01<00:01, 25.45it/s, loss=0.00713, val_loss=0.00716,\n",
      "Epoch 28: 100%|█| 64/64 [00:01<00:00, 38.13it/s, loss=0.00713, val_loss=0.00706,\u001b[A\n",
      "Epoch 29:  50%|▌| 32/64 [00:01<00:01, 21.48it/s, loss=0.00704, val_loss=0.00706,\u001b[A\n",
      "Epoch 29:  59%|▌| 38/64 [00:01<00:01, 25.14it/s, loss=0.00704, val_loss=0.00706,\n",
      "Epoch 29: 100%|█| 64/64 [00:01<00:00, 37.62it/s, loss=0.00704, val_loss=0.00697,\u001b[A\n",
      "Epoch 30:  50%|▌| 32/64 [00:01<00:01, 21.90it/s, loss=0.00695, val_loss=0.00697,\u001b[A\n",
      "Epoch 30:  59%|▌| 38/64 [00:01<00:01, 25.65it/s, loss=0.00695, val_loss=0.00697,\n",
      "Epoch 30: 100%|█| 64/64 [00:01<00:00, 38.31it/s, loss=0.00695, val_loss=0.00689,\u001b[A\n",
      "Epoch 31:  50%|▌| 32/64 [00:01<00:01, 21.79it/s, loss=0.00687, val_loss=0.00689,\u001b[A\n",
      "Epoch 31:  59%|▌| 38/64 [00:01<00:01, 25.52it/s, loss=0.00687, val_loss=0.00689,\n",
      "Epoch 31: 100%|█| 64/64 [00:01<00:00, 38.14it/s, loss=0.00687, val_loss=0.00681,\u001b[A\n",
      "Epoch 32:  50%|▌| 32/64 [00:01<00:01, 21.74it/s, loss=0.00679, val_loss=0.00681,\u001b[A\n",
      "Epoch 32:  59%|▌| 38/64 [00:01<00:01, 25.43it/s, loss=0.00679, val_loss=0.00681,\n",
      "Epoch 32: 100%|█| 64/64 [00:01<00:00, 38.02it/s, loss=0.00679, val_loss=0.00673,\u001b[A\n",
      "Epoch 33:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00672, val_loss=0.00673,\u001b[A\n",
      "Epoch 33:  59%|▌| 38/64 [00:01<00:01, 25.64it/s, loss=0.00672, val_loss=0.00673,\n",
      "Epoch 33:  89%|▉| 57/64 [00:01<00:00, 35.59it/s, loss=0.00672, val_loss=0.00673,\u001b[A\n",
      "Epoch 33: 100%|█| 64/64 [00:01<00:00, 38.12it/s, loss=0.00672, val_loss=0.00666,\u001b[A\n",
      "Epoch 34:  50%|▌| 32/64 [00:01<00:01, 21.73it/s, loss=0.00664, val_loss=0.00666,\u001b[A\n",
      "Epoch 34:  59%|▌| 38/64 [00:01<00:01, 25.43it/s, loss=0.00664, val_loss=0.00666,\n",
      "Epoch 34: 100%|█| 64/64 [00:01<00:00, 38.03it/s, loss=0.00664, val_loss=0.0066, \u001b[A\n",
      "Epoch 35:  50%|▌| 32/64 [00:01<00:01, 21.66it/s, loss=0.00657, val_loss=0.0066, \u001b[A\n",
      "Epoch 35:  59%|▌| 38/64 [00:01<00:01, 25.34it/s, loss=0.00657, val_loss=0.0066, \n",
      "Epoch 35: 100%|█| 64/64 [00:01<00:00, 37.92it/s, loss=0.00657, val_loss=0.00654,\u001b[A\n",
      "Epoch 36:  50%|▌| 32/64 [00:01<00:01, 21.86it/s, loss=0.0065, val_loss=0.00654, \u001b[A\n",
      "Epoch 36:  59%|▌| 38/64 [00:01<00:01, 25.57it/s, loss=0.0065, val_loss=0.00654, \n",
      "Epoch 36: 100%|█| 64/64 [00:01<00:00, 38.24it/s, loss=0.0065, val_loss=0.00647, \u001b[A\n",
      "Epoch 37:  50%|▌| 32/64 [00:01<00:01, 21.71it/s, loss=0.00643, val_loss=0.00647,\u001b[A\n",
      "Epoch 37:  59%|▌| 38/64 [00:01<00:01, 25.40it/s, loss=0.00643, val_loss=0.00647,\n",
      "Epoch 37: 100%|█| 64/64 [00:01<00:00, 38.00it/s, loss=0.00643, val_loss=0.00642,\u001b[A\n",
      "Epoch 38:  50%|▌| 32/64 [00:01<00:01, 21.91it/s, loss=0.00636, val_loss=0.00642,\u001b[A\n",
      "Epoch 38:  59%|▌| 38/64 [00:01<00:01, 25.64it/s, loss=0.00636, val_loss=0.00642,\n",
      "Epoch 38: 100%|█| 64/64 [00:01<00:00, 38.33it/s, loss=0.00636, val_loss=0.00637,\u001b[A\n",
      "Epoch 39:  50%|▌| 32/64 [00:01<00:01, 21.81it/s, loss=0.0063, val_loss=0.00637, \u001b[A\n",
      "Epoch 39:  59%|▌| 38/64 [00:01<00:01, 25.53it/s, loss=0.0063, val_loss=0.00637, \n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 38.15it/s, loss=0.0063, val_loss=0.00632, \u001b[A\n",
      "Epoch 39: 100%|█| 64/64 [00:01<00:00, 37.89it/s, loss=0.0063, val_loss=0.00632, \u001b[A\n",
      "Sizes of clusters: 675, 164, 470, 291\n",
      "\n",
      "preds: [0 2 0 0 0 2 3 0 0 0 2 2 0 2 2 3 1 3 0 2 2 0 2 2 3 3 0 2 0 2 3 2 2 0 0 0 3\n",
      " 3 2 0 0 3 0 0 2 3 3 0 2 0 0 3 0 0 2 2 3 2 2 0 2 3 0 0 2 2 0 2 2 0 0 0 2 2\n",
      " 0 0 2 3 2 0 0 0 2 2 0 0 2 3 0 3 0 0 3 2 0 2 0 0 3 1 0 2 0 2 2 2 0 0 2 0 0\n",
      " 2 0 2 2 2 0 0 0 0 3 0 0 2 3 2 0 0 2 0 2 0 2 0 3 2 0 0 2 3 2 0 0 2 2 0 2 3\n",
      " 0 2 2 2 2 3 3 2 2 0 3 2 2 0 2 2 2 0 0 0 0 2 0 0 2 0 0 0 3 0 2 3 2 3 0 2 3\n",
      " 0 3 2 2 0 2 0 2 2 3 2 0 3 3 3 2 3 0 2 0 0 2 0 0 0 2 2 0 3 2 0 0 2 2 2 2 3\n",
      " 0 0 0 2 2 0 2 0 0 0 3 2 2 2 0 2 0 2 2 2 0 2 3 0 3 3 0 2 0 2 0 2 0 2 0 0 0\n",
      " 0 3 3 0 2 2 3 2 0 0 3 3 0 1 0 2 3 0 0 0 3 0 2 0 2 2 2 0 0 3 3 0 2 0 3 2 2\n",
      " 0 0 0 0 2 2 2 2 0 0 2 0 2 2 2 0 0 2 3 0 1 3 3 2 3 2 0 2 0 0 2 2 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 3 0 2 2 1 0 2 0 0 2 0 0 0 0 2 3 0 0 3 0 2 0 0 0 2\n",
      " 2 0 0 2 3 0 0 0 2 2 2 0 2 2 0 2 2 0 0 0 0 2 0 2 0 2 0 0 0 3 0 0 3 0 0 0 3\n",
      " 0 0 0 3 0 3 0 0 2 0 0 3 0 0 0 2 0 3 0 3 0 0 3 0 0 0 3 3 3 3 0 3 0 0 2 0 3\n",
      " 3 3 0 0 0 0 2 0 0 3 3 0 3 0 0 3 0 3 0 3 0 0 3 0 3 3 3 0 3 3 0 0 0 3 0 3 3\n",
      " 0 3 0 0 0 0 3 0 3 3 2 3 0 2 0 0 2 3 3 3 3 0 0 3 0 0 3 3 3 2 3 0 0 3 0 0 0\n",
      " 0 0 3 0 0 3 0 0 0 0 3 0 0 0 0 0 3 0 0 3 3 3 0 3 0 0 0 3 3 0 0 3 0 2 0 3 3\n",
      " 2 3 0 0 3 0 0 0 0 0 3 3 3 3 0 2 0 0 3 0 3 0 0 3 0 0 3 0 0 0 3 0 0 3 0 2 0\n",
      " 3 3 3 0 0 0 0 0 0 2 0 3 0 2 3 0 0 0 3 0 0 0 0 3 0 0 0 0 3 3 0 2 0 3 3 3 3\n",
      " 3 0 3 0 3 2 3 0 3 0 2 3 0 0 0 3 3 3 3 0 3 0 3 2 3 3 0 0 3 0 3 3 3 0 2 3 0\n",
      " 0 0 0 2 3 3 3 2 0 3 0 3 3 3 0 2 0 3 0 3 3 3 0 3 0 3 3 0 0 3 3 3 3 0 3 0 3\n",
      " 3 0 0 0 2 0 0 3 2 0 3 0 2 3 3 0 2 0 0 2 0 3 0 3 3 3 0 2 3 0 2 0 3 0 2 0 2\n",
      " 2 3 0 0 3 3 3 0 3 2 0 0 3 0 3 0 0 0 0 0 3 0 3 0 0 3 3 0 3 2 3 0 3 0 3 0 0\n",
      " 0 3 3 2 2 0 0 0 3 2 3 0 0 0 0 0 2 0 0 0 0 0 0 2 3 2 1 1 2 1 2 1 2 1 1 2 1\n",
      " 1 0 2 1 2 0 3 3 1 3 2 2 1 1 2 1 1 0 1 0 1 0 3 2 1 1 2 0 2 2 2 0 0 0 0 1 3\n",
      " 2 1 1 1 2 2 1 1 0 1 2 2 2 2 2 1 1 2 1 2 1 1 2 0 0 2 1 1 2 0 0 0 2 0 1 2 1\n",
      " 2 2 2 2 1 1 0 0 2 2 0 2 2 2 0 1 1 2 1 1 0 1 2 2 3 1 2 1 1 0 2 2 1 2 1 2 1\n",
      " 2 2 1 1 1 2 1 2 1 1 2 2 2 2 1 1 2 3 1 0 1 1 2 2 1 0 2 1 1 2 0 0 2 1 1 1 0\n",
      " 2 2 2 1 0 3 1 2 1 2 2 2 1 1 1 0 0 0 1 2 3 0 0 0 0 2 2 0 1 2 2 3 2 2 1 1 2\n",
      " 1 1 2 0 2 2 1 0 1 2 1 2 2 1 0 1 1 1 2 2 0 0 2 2 0 1 1 2 2 1 0 2 2 0 2 2 0\n",
      " 2 0 2 2 1 2 1 2 1 2 2 2 2 2 1 1 1 1 1 2 1 2 1 2 0 1 0 2 2 1 1 0 1 2 1 1 1\n",
      " 1 1 2 1 1 0 2 2 1 2 2 1 2 2 2 2 1 0 2 2 2 2 0 1 2 1 2 1 2 0 1 1 2 2 3 2 2\n",
      " 1 2 1 0 1 2 1 1 2 1 1 1 1 1 0 1 1 1 1 1 1 0 2 2 1 1 0 0 2 0 0 1 0 1 1 0 2\n",
      " 1 1 1 1 2 2 2 1 2 0 0 1 2 2 1 0 2 1 1 2 1 2 1 2 1 2 2 3 0 1 1 2 2 0 1 2 1\n",
      " 2 0 2 3 2 1 0 1 1 2 2 0 0 2 2 2 0 0 2 2 2 0 0 0 0 0 0 2 0 0 1 0 2 3 0 3 2\n",
      " 0 0 3 2 3 2 2 2 0 2 1 3 2 0 0 3 2 0 2 0 0 0 0 0 2 0 0 0 0 0 0 3 0 2 0 2 0\n",
      " 0 0 2 2 0 2 1 0 0 2 0 2 0 2 3 0 2 0 3 0 2 0 0 2 0 0 0 0 2 0 3 1 2 3 0 0 2\n",
      " 3 3 0 0 0 0 2 2 0 0 2 2 2 3 0 2 0 0 3 0 2 2 0 2 0 3 2 0 0 0 0 0 2 0 2 2 2\n",
      " 2 2 2 2 0 3 2 0 0 0 0 3 2 3 2 0 0 0 2 2 2 2 2 3 0 0 0 0 2 0 0 0 0 3 0 0 2\n",
      " 0 3 2 2 0 0 0 0 3 0 0 2 2 2 3 2 3 2 2 0 0 3 2 2 3 0 0 0 0 2 0 2 0 0 0 2 2\n",
      " 0 2 0 0 0 0 2 0 0 0 3 0 0 2 2 2 2 0 3 0 2 2 3 2 0 0 3 2 0 0 2 0 2 0 3 3 2\n",
      " 0 2 3 0 3 3 2 0 0 2 0 2 2 3 2 0 0 3 0 2 2 2 0 0 3 2 0 2 2 2 2 0 0 0 0 3 2\n",
      " 0 2 3 0 0 0 0 3 2 2 0 0 0 0 2 0 0 3 0 0 2 0 0 2 0 2 0 0 0 3 0 0 0 3 3 0 0\n",
      " 0 0 0 0 3 2 0 3 2 0 0 0 0 2 0 0 0 0 0 0 0 3 0 2 2 2 3 3 0 2 2 0 0 0 0 0 3\n",
      " 3 0 2 2 3 0 3 2 2 3 0 3 3 0 2 0 2 0 2 0 0 3 0 0 0 0 3 0 0 2 2 2 3 2 0 0 0\n",
      " 3 0 0 0 0 0 0 2 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "Purity: 0.4225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.3281\r\n",
      "Purity: 0.390625+-0.03503792588039424\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K4_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py:57: DeprecationWarning: PILLOW_VERSION is deprecated and will be removed in a future release. Use __version__ instead.\n",
      "  from PIL import PILLOW_VERSION\n",
      "/usr/local/lib/python3.7/dist-packages/_pytest/mark/structures.py:370: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n",
      "============= RUN 1 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.762, val_loss=0.135, avg_\n",
      "Epoch 0:  54%|▌| 43/80 [00:01<00:01, 23.01it/s, loss=0.762, val_loss=0.135, avg_\n",
      "Epoch 0:  76%|▊| 61/80 [00:01<00:00, 30.89it/s, loss=0.762, val_loss=0.135, avg_\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 37.71it/s, loss=0.762, val_loss=0.102, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.0468, val_loss=0.102, avg\u001b[A\n",
      "Epoch 1:  68%|▋| 54/80 [00:01<00:00, 28.34it/s, loss=0.0468, val_loss=0.102, avg\n",
      "Epoch 1:  90%|▉| 72/80 [00:02<00:00, 35.59it/s, loss=0.0468, val_loss=0.102, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.0468, val_loss=0.0423, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.0252, val_loss=0.0423, av\u001b[A\n",
      "Epoch 2:  68%|▋| 54/80 [00:01<00:00, 28.12it/s, loss=0.0252, val_loss=0.0423, av\n",
      "Epoch 2:  90%|▉| 72/80 [00:02<00:00, 35.36it/s, loss=0.0252, val_loss=0.0423, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.87it/s, loss=0.0252, val_loss=0.0308, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.0192, val_loss=0.0308, av\u001b[A\n",
      "Epoch 3:  68%|▋| 54/80 [00:01<00:00, 28.17it/s, loss=0.0192, val_loss=0.0308, av\n",
      "Epoch 3:  90%|▉| 72/80 [00:02<00:00, 35.42it/s, loss=0.0192, val_loss=0.0308, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.0192, val_loss=0.0232, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.0158, val_loss=0.0232, av\u001b[A\n",
      "Epoch 4:  68%|▋| 54/80 [00:01<00:00, 28.51it/s, loss=0.0158, val_loss=0.0232, av\n",
      "Epoch 4:  90%|▉| 72/80 [00:02<00:00, 35.82it/s, loss=0.0158, val_loss=0.0232, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.0158, val_loss=0.0185, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.09it/s, loss=0.0137, val_loss=0.0185, av\u001b[A\n",
      "Epoch 5:  68%|▋| 54/80 [00:01<00:00, 28.73it/s, loss=0.0137, val_loss=0.0185, av\n",
      "Epoch 5:  90%|▉| 72/80 [00:01<00:00, 36.08it/s, loss=0.0137, val_loss=0.0185, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.61it/s, loss=0.0137, val_loss=0.0154, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.0123, val_loss=0.0154, av\u001b[A\n",
      "Epoch 6:  68%|▋| 54/80 [00:01<00:00, 28.43it/s, loss=0.0123, val_loss=0.0154, av\n",
      "Epoch 6:  90%|▉| 72/80 [00:02<00:00, 35.72it/s, loss=0.0123, val_loss=0.0154, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.0123, val_loss=0.0133, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.0113, val_loss=0.0133, av\u001b[A\n",
      "Epoch 7:  68%|▋| 54/80 [00:01<00:00, 28.60it/s, loss=0.0113, val_loss=0.0133, av\n",
      "Epoch 7:  90%|▉| 72/80 [00:02<00:00, 35.94it/s, loss=0.0113, val_loss=0.0133, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.0113, val_loss=0.0118, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.0105, val_loss=0.0118, av\u001b[A\n",
      "Epoch 8:  68%|▋| 54/80 [00:01<00:00, 28.55it/s, loss=0.0105, val_loss=0.0118, av\n",
      "Epoch 8:  90%|▉| 72/80 [00:02<00:00, 35.85it/s, loss=0.0105, val_loss=0.0118, av\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.0105, val_loss=0.0108, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00977, val_loss=0.0108, a\u001b[A\n",
      "Epoch 9:  68%|▋| 54/80 [00:01<00:00, 28.56it/s, loss=0.00977, val_loss=0.0108, a\n",
      "Epoch 9:  90%|▉| 72/80 [00:02<00:00, 35.88it/s, loss=0.00977, val_loss=0.0108, a\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00977, val_loss=0.00999, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00914, val_loss=0.00999,\u001b[A\n",
      "Epoch 10:  68%|▋| 54/80 [00:01<00:00, 28.44it/s, loss=0.00914, val_loss=0.00999,\n",
      "Epoch 10:  90%|▉| 72/80 [00:02<00:00, 35.74it/s, loss=0.00914, val_loss=0.00999,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00914, val_loss=0.00926,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.00859, val_loss=0.00926,\u001b[A\n",
      "Epoch 11:  68%|▋| 54/80 [00:01<00:00, 28.29it/s, loss=0.00859, val_loss=0.00926,\n",
      "Epoch 11:  90%|▉| 72/80 [00:02<00:00, 35.58it/s, loss=0.00859, val_loss=0.00926,\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00859, val_loss=0.0086, \u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00812, val_loss=0.0086, \u001b[A\n",
      "Epoch 12:  68%|▋| 54/80 [00:01<00:00, 28.57it/s, loss=0.00812, val_loss=0.0086, \n",
      "Epoch 12:  90%|▉| 72/80 [00:02<00:00, 35.89it/s, loss=0.00812, val_loss=0.0086, \u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00812, val_loss=0.00808,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00769, val_loss=0.00808,\u001b[A\n",
      "Epoch 13:  68%|▋| 54/80 [00:01<00:00, 28.58it/s, loss=0.00769, val_loss=0.00808,\n",
      "Epoch 13:  90%|▉| 72/80 [00:02<00:00, 35.91it/s, loss=0.00769, val_loss=0.00808,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00769, val_loss=0.00764,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 22.02it/s, loss=0.0073, val_loss=0.00764, \u001b[A\n",
      "Epoch 14:  68%|▋| 54/80 [00:01<00:00, 28.64it/s, loss=0.0073, val_loss=0.00764, \n",
      "Epoch 14:  90%|▉| 72/80 [00:02<00:00, 35.98it/s, loss=0.0073, val_loss=0.00764, \u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.0073, val_loss=0.00723, \u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.00694, val_loss=0.00723,\u001b[A\n",
      "Epoch 15:  68%|▋| 54/80 [00:01<00:00, 28.68it/s, loss=0.00694, val_loss=0.00723,\n",
      "Epoch 15:  90%|▉| 72/80 [00:01<00:00, 36.02it/s, loss=0.00694, val_loss=0.00723,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.56it/s, loss=0.00694, val_loss=0.0068, \u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00665, val_loss=0.0068, \u001b[A\n",
      "Epoch 16:  68%|▋| 54/80 [00:01<00:00, 28.19it/s, loss=0.00665, val_loss=0.0068, \n",
      "Epoch 16:  90%|▉| 72/80 [00:02<00:00, 35.44it/s, loss=0.00665, val_loss=0.0068, \u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00665, val_loss=0.00651,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00641, val_loss=0.00651,\u001b[A\n",
      "Epoch 17:  68%|▋| 54/80 [00:01<00:00, 28.30it/s, loss=0.00641, val_loss=0.00651,\n",
      "Epoch 17:  90%|▉| 72/80 [00:02<00:00, 35.56it/s, loss=0.00641, val_loss=0.00651,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.09it/s, loss=0.00641, val_loss=0.00636,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.00619, val_loss=0.00636,\u001b[A\n",
      "Epoch 18:  68%|▋| 54/80 [00:01<00:00, 28.35it/s, loss=0.00619, val_loss=0.00636,\n",
      "Epoch 18:  90%|▉| 72/80 [00:02<00:00, 35.63it/s, loss=0.00619, val_loss=0.00636,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00619, val_loss=0.00625,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 22.02it/s, loss=0.00596, val_loss=0.00625,\u001b[A\n",
      "Epoch 19:  68%|▋| 54/80 [00:01<00:00, 28.64it/s, loss=0.00596, val_loss=0.00625,\n",
      "Epoch 19:  90%|▉| 72/80 [00:02<00:00, 35.96it/s, loss=0.00596, val_loss=0.00625,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.51it/s, loss=0.00596, val_loss=0.00612,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 22.11it/s, loss=0.00576, val_loss=0.00612,\u001b[A\n",
      "Epoch 20:  68%|▋| 54/80 [00:01<00:00, 28.76it/s, loss=0.00576, val_loss=0.00612,\n",
      "Epoch 20:  90%|▉| 72/80 [00:01<00:00, 36.11it/s, loss=0.00576, val_loss=0.00612,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.65it/s, loss=0.00576, val_loss=0.00584,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.0056, val_loss=0.00584, \u001b[A\n",
      "Epoch 21:  68%|▋| 54/80 [00:01<00:00, 28.61it/s, loss=0.0056, val_loss=0.00584, \n",
      "Epoch 21:  90%|▉| 72/80 [00:02<00:00, 35.94it/s, loss=0.0056, val_loss=0.00584, \u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.0056, val_loss=0.0055, a\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00548, val_loss=0.0055, \u001b[A\n",
      "Epoch 22:  68%|▋| 54/80 [00:01<00:00, 28.58it/s, loss=0.00548, val_loss=0.0055, \n",
      "Epoch 22:  90%|▉| 72/80 [00:02<00:00, 35.90it/s, loss=0.00548, val_loss=0.0055, \u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00548, val_loss=0.00525,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.00539, val_loss=0.00525,\u001b[A\n",
      "Epoch 23:  68%|▋| 54/80 [00:01<00:00, 28.67it/s, loss=0.00539, val_loss=0.00525,\n",
      "Epoch 23:  90%|▉| 72/80 [00:01<00:00, 36.02it/s, loss=0.00539, val_loss=0.00525,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.53it/s, loss=0.00539, val_loss=0.00507,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00525, val_loss=0.00507,\u001b[A\n",
      "Epoch 24:  68%|▋| 54/80 [00:01<00:00, 28.59it/s, loss=0.00525, val_loss=0.00507,\n",
      "Epoch 24:  90%|▉| 72/80 [00:02<00:00, 35.92it/s, loss=0.00525, val_loss=0.00507,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00525, val_loss=0.00506,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00512, val_loss=0.00506,\u001b[A\n",
      "Epoch 25:  68%|▋| 54/80 [00:01<00:00, 28.60it/s, loss=0.00512, val_loss=0.00506,\n",
      "Epoch 25:  90%|▉| 72/80 [00:02<00:00, 35.91it/s, loss=0.00512, val_loss=0.00506,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00512, val_loss=0.00496,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00503, val_loss=0.00496,\u001b[A\n",
      "Epoch 26:  68%|▋| 54/80 [00:01<00:00, 28.62it/s, loss=0.00503, val_loss=0.00496,\n",
      "Epoch 26:  90%|▉| 72/80 [00:02<00:00, 35.94it/s, loss=0.00503, val_loss=0.00496,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.00503, val_loss=0.00495,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00494, val_loss=0.00495,\u001b[A\n",
      "Epoch 27:  68%|▋| 54/80 [00:01<00:00, 28.39it/s, loss=0.00494, val_loss=0.00495,\n",
      "Epoch 27:  90%|▉| 72/80 [00:02<00:00, 35.68it/s, loss=0.00494, val_loss=0.00495,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.00494, val_loss=0.00486,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00487, val_loss=0.00486,\u001b[A\n",
      "Epoch 28:  68%|▋| 54/80 [00:01<00:00, 28.17it/s, loss=0.00487, val_loss=0.00486,\n",
      "Epoch 28:  90%|▉| 72/80 [00:02<00:00, 35.42it/s, loss=0.00487, val_loss=0.00486,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 37.94it/s, loss=0.00487, val_loss=0.00461,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00477, val_loss=0.00461,\u001b[A\n",
      "Epoch 29:  68%|▋| 54/80 [00:01<00:00, 28.20it/s, loss=0.00477, val_loss=0.00461,\n",
      "Epoch 29:  90%|▉| 72/80 [00:02<00:00, 35.45it/s, loss=0.00477, val_loss=0.00461,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.00477, val_loss=0.00446,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.00467, val_loss=0.00446,\u001b[A\n",
      "Epoch 30:  68%|▋| 54/80 [00:01<00:00, 28.68it/s, loss=0.00467, val_loss=0.00446,\n",
      "Epoch 30:  90%|▉| 72/80 [00:02<00:00, 35.98it/s, loss=0.00467, val_loss=0.00446,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.55it/s, loss=0.00467, val_loss=0.00438,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00459, val_loss=0.00438,\u001b[A\n",
      "Epoch 31:  68%|▋| 54/80 [00:01<00:00, 28.60it/s, loss=0.00459, val_loss=0.00438,\n",
      "Epoch 31:  90%|▉| 72/80 [00:02<00:00, 35.91it/s, loss=0.00459, val_loss=0.00438,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.00459, val_loss=0.0043, \u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00453, val_loss=0.0043, \u001b[A\n",
      "Epoch 32:  68%|▋| 54/80 [00:01<00:00, 28.52it/s, loss=0.00453, val_loss=0.0043, \n",
      "Epoch 32:  90%|▉| 72/80 [00:02<00:00, 35.82it/s, loss=0.00453, val_loss=0.0043, \u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00453, val_loss=0.00432,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00446, val_loss=0.00432,\u001b[A\n",
      "Epoch 33:  68%|▋| 54/80 [00:01<00:00, 28.22it/s, loss=0.00446, val_loss=0.00432,\n",
      "Epoch 33:  90%|▉| 72/80 [00:02<00:00, 35.48it/s, loss=0.00446, val_loss=0.00432,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.00446, val_loss=0.00441,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00439, val_loss=0.00441,\u001b[A\n",
      "Epoch 34:  68%|▋| 54/80 [00:01<00:00, 28.18it/s, loss=0.00439, val_loss=0.00441,\n",
      "Epoch 34:  90%|▉| 72/80 [00:02<00:00, 35.43it/s, loss=0.00439, val_loss=0.00441,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00439, val_loss=0.00442,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00433, val_loss=0.00442,\u001b[A\n",
      "Epoch 35:  68%|▋| 54/80 [00:01<00:00, 28.19it/s, loss=0.00433, val_loss=0.00442,\n",
      "Epoch 35:  90%|▉| 72/80 [00:02<00:00, 35.47it/s, loss=0.00433, val_loss=0.00442,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00433, val_loss=0.00445,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00426, val_loss=0.00445,\u001b[A\n",
      "Epoch 36:  68%|▋| 54/80 [00:01<00:00, 28.55it/s, loss=0.00426, val_loss=0.00445,\n",
      "Epoch 36:  90%|▉| 72/80 [00:02<00:00, 35.84it/s, loss=0.00426, val_loss=0.00445,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00426, val_loss=0.0044, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00419, val_loss=0.0044, \u001b[A\n",
      "Epoch 37:  68%|▋| 54/80 [00:01<00:00, 28.58it/s, loss=0.00419, val_loss=0.0044, \n",
      "Epoch 37:  90%|▉| 72/80 [00:02<00:00, 35.93it/s, loss=0.00419, val_loss=0.0044, \u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00419, val_loss=0.00429,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00416, val_loss=0.00429,\u001b[A\n",
      "Epoch 38:  68%|▋| 54/80 [00:01<00:00, 28.57it/s, loss=0.00416, val_loss=0.00429,\n",
      "Epoch 38:  90%|▉| 72/80 [00:02<00:00, 35.89it/s, loss=0.00416, val_loss=0.00429,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00416, val_loss=0.00439,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00418, val_loss=0.00439,\u001b[A\n",
      "Epoch 39:  68%|▋| 54/80 [00:01<00:00, 28.48it/s, loss=0.00418, val_loss=0.00439,\n",
      "Epoch 39:  90%|▉| 72/80 [00:02<00:00, 35.80it/s, loss=0.00418, val_loss=0.00439,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.33it/s, loss=0.00418, val_loss=0.00416,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00418, val_loss=0.00416,\u001b[A\n",
      "Sizes of clusters: 230, 578, 641, 377, 174\n",
      "\n",
      "preds: [4 2 3 2 3 2 2 3 2 4 0 1 2 2 3 2 3 1 1 2 1 2 3 0 2 2 2 1 1 3 3 2 0 0 0 1 1\n",
      " 2 3 2 1 2 1 2 2 3 2 2 1 3 3 2 2 2 1 0 0 1 0 4 2 1 1 1 1 2 2 1 1 4 3 2 2 2\n",
      " 2 4 0 3 4 1 2 3 1 0 1 1 3 3 2 1 2 3 0 3 4 3 2 2 2 3 1 1 3 2 0 3 2 4 1 3 2\n",
      " 3 0 0 1 2 1 2 1 1 1 3 1 2 1 1 2 2 1 3 1 2 2 2 2 4 4 1 3 2 3 4 1 3 1 2 4 1\n",
      " 0 2 2 3 2 2 3 2 2 3 2 1 3 3 3 1 0 1 1 3 2 2 2 3 2 1 3 0 1 4 2 0 1 1 1 4 2\n",
      " 3 3 3 3 1 2 0 2 3 3 1 3 1 2 1 2 1 4 2 3 4 4 2 1 1 2 1 2 1 1 3 2 0 2 3 4 4\n",
      " 1 0 3 2 1 2 1 2 1 1 3 4 2 3 1 3 2 3 4 1 1 4 1 0 1 4 2 1 1 1 1 1 1 2 4 3 2\n",
      " 1 4 0 0 4 1 2 1 0 3 3 1 0 1 0 3 1 2 2 2 3 1 4 3 3 4 1 1 3 2 1 2 3 0 1 2 4\n",
      " 1 1 1 1 2 2 4 1 2 0 3 2 2 4 3 1 3 3 1 2 0 2 1 2 1 3 2 2 1 3 2 3 2 4 1 2 2\n",
      " 4 1 3 1 1 1 0 3 2 3 1 4 2 1 4 3 2 3 4 2 2 3 3 3 1 1 3 1 2 0 2 0 0 2 1 4 3\n",
      " 2 0 2 1 1 1 3 1 2 4 2 2 2 1 1 2 0 1 1 4 2 3 3 4 1 2 3 4 1 3 3 3 2 4 1 3 3\n",
      " 4 4 1 3 2 2 4 2 1 3 2 1 1 3 1 3 2 1 4 3 3 2 4 4 1 3 4 4 3 1 4 3 1 2 1 2 4\n",
      " 2 1 1 4 4 2 4 2 2 1 3 1 3 2 0 3 1 1 1 3 2 3 4 2 2 3 3 3 2 3 3 4 3 1 0 1 3\n",
      " 4 1 1 1 3 1 1 3 3 1 2 0 2 1 0 2 4 2 4 4 3 3 3 3 2 2 2 4 2 4 2 2 1 1 4 3 2\n",
      " 4 1 3 4 1 3 3 4 1 1 1 2 1 3 2 4 2 0 1 0 1 3 1 1 2 1 1 2 4 3 1 2 1 0 1 2 4\n",
      " 3 2 2 1 1 1 1 3 1 1 3 3 3 2 1 2 1 3 2 2 1 3 0 1 2 3 2 3 1 1 1 2 3 2 1 2 2\n",
      " 3 2 1 1 3 2 2 2 1 1 0 2 3 1 1 1 2 1 4 2 0 2 1 4 1 3 3 3 4 2 1 2 4 4 3 4 2\n",
      " 3 2 4 2 2 2 2 3 1 1 1 2 2 1 4 1 2 3 1 1 4 3 3 1 1 1 1 2 2 1 3 1 3 1 2 2 1\n",
      " 3 3 1 4 4 2 2 4 3 2 3 2 2 4 1 0 4 3 1 2 3 2 3 3 1 4 1 3 4 1 4 3 4 3 3 2 3\n",
      " 1 2 3 4 2 3 3 3 2 1 3 3 2 3 1 0 1 3 1 0 3 1 0 2 2 1 1 3 1 2 3 2 3 3 3 3 3\n",
      " 1 2 1 2 3 4 2 3 2 3 3 2 1 2 4 1 0 1 2 4 4 1 3 4 4 4 2 1 1 2 1 3 4 2 4 2 4\n",
      " 1 3 1 3 1 3 1 2 4 3 1 3 3 2 3 2 1 1 1 1 1 2 3 1 2 2 0 1 2 2 1 1 1 2 2 1 2\n",
      " 2 2 2 2 4 2 1 2 2 2 1 1 2 3 4 2 1 0 3 2 2 2 2 2 2 0 1 2 2 1 0 0 2 2 0 2 3\n",
      " 2 1 0 0 0 1 0 1 0 0 2 1 1 2 1 2 2 0 1 0 2 0 0 2 0 0 2 2 0 1 2 3 0 2 2 2 2\n",
      " 2 2 1 2 2 3 1 1 1 2 0 0 0 1 2 0 0 2 0 2 2 0 0 1 0 0 0 1 2 1 1 1 1 0 1 0 2\n",
      " 2 2 2 2 2 2 0 2 2 2 2 0 3 1 2 3 2 2 2 3 1 2 2 2 2 0 1 0 2 2 2 2 2 0 2 2 2\n",
      " 0 2 3 3 1 0 1 2 1 2 2 2 1 4 2 1 1 1 2 1 2 1 2 2 2 1 3 0 2 2 0 2 2 3 0 1 2\n",
      " 1 1 1 0 1 2 2 2 3 2 1 0 0 0 1 1 0 2 1 2 2 1 2 0 0 0 0 1 2 2 2 0 0 1 0 0 2\n",
      " 3 1 0 2 1 2 3 2 0 0 1 1 2 2 1 0 1 1 2 1 2 0 0 3 2 0 2 1 0 3 1 2 1 2 3 0 0\n",
      " 2 2 0 1 2 2 1 1 2 2 0 2 0 1 1 0 1 2 2 1 1 0 1 2 1 2 2 0 2 2 1 3 0 0 1 0 2\n",
      " 0 2 0 2 2 2 0 2 2 0 2 2 2 2 1 2 2 1 0 3 1 2 2 0 2 2 2 2 1 1 0 1 0 2 2 2 0\n",
      " 1 1 2 0 2 3 1 3 2 2 1 2 1 2 2 2 1 0 3 1 2 0 1 2 1 2 2 1 0 2 3 2 0 0 2 0 1\n",
      " 2 1 0 1 3 2 0 2 2 1 0 2 1 0 2 1 2 2 1 3 2 2 1 4 1 3 1 0 4 1 2 1 3 2 0 0 1\n",
      " 1 2 3 4 1 2 0 0 4 4 3 4 4 2 1 0 4 3 1 2 3 3 3 2 2 2 0 3 2 1 1 1 1 3 3 3 3\n",
      " 1 4 2 2 3 1 3 3 3 3 0 0 4 2 1 2 0 2 2 4 3 2 1 2 2 3 1 2 2 4 2 2 2 2 4 0 1\n",
      " 2 2 1 2 3 1 1 1 1 1 1 4 0 2 2 3 1 3 3 4 2 1 2 1 2 3 3 3 2 0 2 0 4 2 2 0 3\n",
      " 3 2 3 1 1 1 3 2 1 1 3 1 3 1 2 4 2 4 2 3 4 3 1 1 3 1 1 1 1 2 3 0 1 3 1 2 2\n",
      " 2 2 1 2 1 3 1 3 2 2 2 3 2 0 0 2 0 2 2 0 3 0 2 2 3 2 4 1 1 0 1 1 1 0 3 2 3\n",
      " 2 3 3 0 2 0 0 2 1 1 0 0 3 0 3 1 3 2 2 2 2 1 3 1 0 3 0 0 2 4 1 1 1 0 4 3 2\n",
      " 2 1 1 4 3 2 4 2 2 1 2 1 2 2 1 4 4 1 3 1 2 3 1 2 4 1 3 2 1 2 2 0 1 2 4 4 0\n",
      " 1 3 2 2 2 0 3 2 2 4 2 2 0 0 1 2 1 1 4 2 4 4 3 1 2 1 0 2 3 2 3 1 2 4 3 2 3\n",
      " 3 2 1 1 2 2 1 0 0 0 0 2 3 1 2 0 1 1 1 0 2 2 2 2 2 4 1 2 3 1 2 2 2 4 1 2 2\n",
      " 0 3 3 3 1 2 1 1 3 3 1 1 0 1 1 1 1 1 1 2 0 1 3 1 4 3 2 3 2 2 3 2 3 3 1 0 2\n",
      " 2 2 3 0 2 2 2 3 3 4 2 1 3 1 1 1 4 4 1 3 2 0 2 4 1 3 2 3 3 2 2 4 2 3 2 3 1\n",
      " 2 1 2 2 2 3 2 0 4 2 2 1 1 3 2 2 2 0 1 0 3 3 3 2 2 2 1 4 4 2 4 2 1 2 1 2 4\n",
      " 3 0 1 1 0 3 1 4 0 1 3 1 0 1 2 2 1 3 2 3 1 2 2 3 0 3 4 1 1 1 1 2 2 1 1 1 1\n",
      " 1 4 3 3 1 1 4 1 0 2 1 2 2 1 1 3 0 2 3 1 3 2 3 0 2 3 3 1 1 1 2 3 1 2 1 1 2\n",
      " 4 2 2 1 2 3 1 1 2 2 1 1 1 2 0 2 2 3 2 2 3 1 3 1 0 4 1 2 0 1 1 1 1 1 3 3 1\n",
      " 3 3 4 3 1 2 3 2 1 2 4 1 3 3 2 2 1 1 0 2 2 1 2 1 1 2 3 4 1 4 2 3 1 2 0 0 2\n",
      " 1 1 3 1 2 1 1 1 1 2 3 4 1 2 1 0 2 1 4 1 3 3 2 3 1 2 3 3 2 2 1 0 2 2 2 3 3\n",
      " 2 1 1 2 1 2 2 3 1 2 1 3 3 2 3 1 3 1 3 1 2 1 2 1 1 4 3 2 2 3 2 0 3 1 2 1 1\n",
      " 0 0 2 3 1 0 1 4 0 1 1 3 3 2 1 1 1 3 2 4 3 0 2 1 1 1 2 2 1 1 1 3 3 2 2 1 1\n",
      " 1 0 3 1 2 1 1 3 1 3 1 1 2 2 1 3 2 4 2 4 2 2 3 3 1 3 2 1 1 1 3 2 2 0 0 3 3\n",
      " 2 1 2 1 2 2 1 1 2 0 1 3 4 4 1 4 1 3 2 1 4 0 1 1 0 4 2 1 0 4 2 2 1 2 2 1 0\n",
      " 4 2]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.2855\n",
      "============= RUN 2 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 20.39it/s, loss=0.916, val_loss=0.0844, avg\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  74%|▋| 59/80 [00:02<00:00, 28.58it/s, loss=0.916, val_loss=0.0844, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 36.00it/s, loss=0.916, val_loss=0.172, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.044, val_loss=0.172, avg_\u001b[A\n",
      "Epoch 1:  71%|▋| 57/80 [00:01<00:00, 29.59it/s, loss=0.044, val_loss=0.172, avg_\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.66it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.044, val_loss=0.0401, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.02, val_loss=0.0401, avg_\u001b[A\n",
      "Epoch 2:  71%|▋| 57/80 [00:01<00:00, 29.74it/s, loss=0.02, val_loss=0.0401, avg_\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.47it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.02, val_loss=0.0239, avg_\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.0151, val_loss=0.0239, av\u001b[A\n",
      "Epoch 3:  71%|▋| 57/80 [00:01<00:00, 29.67it/s, loss=0.0151, val_loss=0.0239, av\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.92it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.0151, val_loss=0.0177, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.0126, val_loss=0.0177, av\u001b[A\n",
      "Epoch 4:  71%|▋| 57/80 [00:01<00:00, 29.75it/s, loss=0.0126, val_loss=0.0177, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.78it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.0126, val_loss=0.0142, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.10it/s, loss=0.0111, val_loss=0.0142, av\u001b[A\n",
      "Epoch 5:  71%|▋| 57/80 [00:01<00:00, 30.03it/s, loss=0.0111, val_loss=0.0142, av\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 180.03it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.64it/s, loss=0.0111, val_loss=0.0119, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00996, val_loss=0.0119, a\u001b[A\n",
      "Epoch 6:  71%|▋| 57/80 [00:01<00:00, 29.56it/s, loss=0.00996, val_loss=0.0119, a\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.70it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.00996, val_loss=0.0105, a\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00914, val_loss=0.0105, a\u001b[A\n",
      "Epoch 7:  71%|▋| 57/80 [00:01<00:00, 29.73it/s, loss=0.00914, val_loss=0.0105, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.42it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.00914, val_loss=0.00953, \u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00849, val_loss=0.00953, \u001b[A\n",
      "Epoch 8:  71%|▋| 57/80 [00:01<00:00, 29.85it/s, loss=0.00849, val_loss=0.00953, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 176.29it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00849, val_loss=0.00889, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00798, val_loss=0.00889, \u001b[A\n",
      "Epoch 9:  71%|▋| 57/80 [00:01<00:00, 29.79it/s, loss=0.00798, val_loss=0.00889, \n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.27it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00798, val_loss=0.00847, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.00756, val_loss=0.00847,\u001b[A\n",
      "Epoch 10:  71%|▋| 57/80 [00:01<00:00, 29.79it/s, loss=0.00756, val_loss=0.00847,\n",
      "Epoch 10:  95%|▉| 76/80 [00:02<00:00, 37.32it/s, loss=0.00756, val_loss=0.00847,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00756, val_loss=0.00813,\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00722, val_loss=0.00813,\u001b[A\n",
      "Epoch 11:  71%|▋| 57/80 [00:01<00:00, 29.80it/s, loss=0.00722, val_loss=0.00813,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.36it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.00722, val_loss=0.00787,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00693, val_loss=0.00787,\u001b[A\n",
      "Epoch 12:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00693, val_loss=0.00787,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 178.71it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00693, val_loss=0.00764,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00669, val_loss=0.00764,\u001b[A\n",
      "Epoch 13:  71%|▋| 57/80 [00:01<00:00, 29.76it/s, loss=0.00669, val_loss=0.00764,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.72it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00669, val_loss=0.00757,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00649, val_loss=0.00757,\u001b[A\n",
      "Epoch 14:  71%|▋| 57/80 [00:01<00:00, 29.88it/s, loss=0.00649, val_loss=0.00757,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.57it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.00649, val_loss=0.00751,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 22.10it/s, loss=0.00632, val_loss=0.00751,\u001b[A\n",
      "Epoch 15:  71%|▋| 57/80 [00:01<00:00, 30.02it/s, loss=0.00632, val_loss=0.00751,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.70it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.64it/s, loss=0.00632, val_loss=0.00737,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00616, val_loss=0.00737,\u001b[A\n",
      "Epoch 16:  71%|▋| 57/80 [00:01<00:00, 29.75it/s, loss=0.00616, val_loss=0.00737,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.86it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00616, val_loss=0.00735,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00603, val_loss=0.00735,\u001b[A\n",
      "Epoch 17:  71%|▋| 57/80 [00:01<00:00, 29.67it/s, loss=0.00603, val_loss=0.00735,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.90it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.00603, val_loss=0.00733,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00591, val_loss=0.00733,\u001b[A\n",
      "Epoch 18:  71%|▋| 57/80 [00:01<00:00, 29.80it/s, loss=0.00591, val_loss=0.00733,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.07it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00591, val_loss=0.00744,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00579, val_loss=0.00744,\u001b[A\n",
      "Epoch 19:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.00579, val_loss=0.00744,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.38it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00579, val_loss=0.00745,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.00569, val_loss=0.00745,\u001b[A\n",
      "Epoch 20:  71%|▋| 57/80 [00:01<00:00, 29.96it/s, loss=0.00569, val_loss=0.00745,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.29it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.57it/s, loss=0.00569, val_loss=0.00755,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00559, val_loss=0.00755,\u001b[A\n",
      "Epoch 21:  71%|▋| 57/80 [00:01<00:00, 29.86it/s, loss=0.00559, val_loss=0.00755,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.90it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00559, val_loss=0.0076, \u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00551, val_loss=0.0076, \u001b[A\n",
      "Epoch 22:  71%|▋| 57/80 [00:01<00:00, 29.84it/s, loss=0.00551, val_loss=0.0076, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.31it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00551, val_loss=0.00771,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.78it/s, loss=0.00542, val_loss=0.00771,\u001b[A\n",
      "Epoch 23:  71%|▋| 57/80 [00:01<00:00, 29.58it/s, loss=0.00542, val_loss=0.00771,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 175.91it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.12it/s, loss=0.00542, val_loss=0.00784,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00534, val_loss=0.00784,\u001b[A\n",
      "Epoch 24:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.00534, val_loss=0.00784,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 177.21it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.00534, val_loss=0.008, a\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.00526, val_loss=0.008, a\u001b[A\n",
      "Epoch 25:  71%|▋| 57/80 [00:01<00:00, 30.00it/s, loss=0.00526, val_loss=0.008, a\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.80it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.61it/s, loss=0.00526, val_loss=0.00816,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00518, val_loss=0.00816,\u001b[A\n",
      "Epoch 26:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.00518, val_loss=0.00816,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 176.80it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00518, val_loss=0.00832,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00511, val_loss=0.00832,\u001b[A\n",
      "Epoch 27:  71%|▋| 57/80 [00:01<00:00, 29.71it/s, loss=0.00511, val_loss=0.00832,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 176.28it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.27it/s, loss=0.00511, val_loss=0.00845,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.00505, val_loss=0.00845,\u001b[A\n",
      "Epoch 28:  71%|▋| 57/80 [00:01<00:00, 29.91it/s, loss=0.00505, val_loss=0.00845,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.12it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.00505, val_loss=0.00857,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00498, val_loss=0.00857,\u001b[A\n",
      "Epoch 29:  71%|▋| 57/80 [00:01<00:00, 29.89it/s, loss=0.00498, val_loss=0.00857,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.82it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.00498, val_loss=0.00869,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.00491, val_loss=0.00869,\u001b[A\n",
      "Epoch 30:  71%|▋| 57/80 [00:01<00:00, 29.95it/s, loss=0.00491, val_loss=0.00869,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.82it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.57it/s, loss=0.00491, val_loss=0.00881,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00486, val_loss=0.00881,\u001b[A\n",
      "Epoch 31:  71%|▋| 57/80 [00:01<00:00, 29.86it/s, loss=0.00486, val_loss=0.00881,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.88it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00486, val_loss=0.00895,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.0048, val_loss=0.00895, \u001b[A\n",
      "Epoch 32:  71%|▋| 57/80 [00:01<00:00, 29.81it/s, loss=0.0048, val_loss=0.00895, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.71it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.0048, val_loss=0.0091, a\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00475, val_loss=0.0091, \u001b[A\n",
      "Epoch 33:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.00475, val_loss=0.0091, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 175.97it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.00475, val_loss=0.00927,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.0047, val_loss=0.00927, \u001b[A\n",
      "Epoch 34:  71%|▋| 57/80 [00:01<00:00, 29.91it/s, loss=0.0047, val_loss=0.00927, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.20it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.50it/s, loss=0.0047, val_loss=0.00944, \u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.00465, val_loss=0.00944,\u001b[A\n",
      "Epoch 35:  71%|▋| 57/80 [00:01<00:00, 29.98it/s, loss=0.00465, val_loss=0.00944,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.95it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.61it/s, loss=0.00465, val_loss=0.00959,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0046, val_loss=0.00959, \u001b[A\n",
      "Epoch 36:  71%|▋| 57/80 [00:01<00:00, 29.87it/s, loss=0.0046, val_loss=0.00959, \n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 178.05it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.45it/s, loss=0.0046, val_loss=0.00973, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00456, val_loss=0.00973,\u001b[A\n",
      "Epoch 37:  71%|▋| 57/80 [00:01<00:00, 29.74it/s, loss=0.00456, val_loss=0.00973,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 177.09it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.00456, val_loss=0.00989,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00451, val_loss=0.00989,\u001b[A\n",
      "Epoch 38:  71%|▋| 57/80 [00:01<00:00, 29.73it/s, loss=0.00451, val_loss=0.00989,\n",
      "Validating:  45%|█████████████▌                | 18/40 [00:00<00:00, 179.70it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00451, val_loss=0.00999,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00447, val_loss=0.00999,\u001b[A\n",
      "Epoch 39:  71%|▋| 57/80 [00:01<00:00, 29.77it/s, loss=0.00447, val_loss=0.00999,\n",
      "Validating:  48%|██████████████▎               | 19/40 [00:00<00:00, 179.76it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00447, val_loss=0.0101, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.16it/s, loss=0.00447, val_loss=0.0101, \u001b[A\n",
      "Sizes of clusters: 565, 497, 302, 363, 273\n",
      "\n",
      "preds: [3 4 3 0 3 3 1 4 4 3 4 3 1 4 4 1 3 4 0 1 3 1 3 1 0 4 0 0 1 1 1 0 4 1 0 1 4\n",
      " 1 3 1 0 1 0 1 1 4 0 4 3 3 3 3 1 1 4 0 4 3 4 4 0 3 4 0 4 3 1 4 4 3 3 4 0 1\n",
      " 4 4 4 1 3 4 4 3 1 4 3 1 4 4 0 0 1 3 1 1 3 3 1 4 3 3 3 0 1 1 0 3 3 3 0 3 1\n",
      " 3 1 1 4 1 1 1 4 0 0 3 1 0 3 0 0 1 0 4 4 0 1 4 1 3 3 3 3 0 4 3 4 3 3 1 2 1\n",
      " 4 3 1 3 1 0 4 1 1 3 1 3 3 3 2 1 1 0 1 4 1 0 1 4 1 3 4 1 1 3 0 0 3 4 0 4 0\n",
      " 3 3 3 1 0 1 1 1 3 4 4 3 3 0 4 1 3 4 1 4 2 3 4 4 0 1 3 0 4 3 3 1 4 4 4 3 3\n",
      " 3 1 4 0 4 0 1 1 1 0 1 3 1 4 4 1 0 3 3 2 4 4 4 1 0 3 4 3 4 1 4 3 1 1 2 2 3\n",
      " 3 3 4 1 3 0 4 0 1 3 3 0 1 2 1 3 3 0 0 0 3 0 3 4 3 3 3 3 3 1 3 4 3 4 4 0 3\n",
      " 0 0 1 3 3 4 3 3 0 1 3 3 0 3 0 3 4 4 1 1 0 4 3 4 3 4 1 4 3 3 0 3 4 3 1 1 0\n",
      " 3 4 4 1 1 3 0 3 0 2 0 4 0 1 4 4 1 3 4 1 1 3 1 4 1 4 1 1 3 1 4 0 0 4 3 3 4\n",
      " 1 4 4 3 4 3 4 0 1 3 1 0 4 0 3 0 1 0 4 3 4 3 3 3 1 0 3 3 1 3 4 4 1 3 1 2 2\n",
      " 3 2 3 3 1 4 3 1 1 2 4 4 0 2 4 0 1 0 3 0 2 0 3 2 0 0 0 3 2 0 3 0 0 3 4 1 0\n",
      " 1 2 3 2 3 4 2 1 1 4 3 1 2 1 0 3 4 3 0 0 2 3 3 0 0 2 0 3 0 3 1 3 3 1 1 2 3\n",
      " 2 0 1 1 3 2 2 2 4 0 1 4 0 0 1 1 2 1 3 2 1 2 2 2 4 4 1 3 2 3 1 1 2 1 0 3 0\n",
      " 2 1 2 2 0 2 0 2 0 4 0 1 1 0 0 2 1 0 0 1 3 4 4 2 4 2 2 0 2 0 0 1 3 1 2 1 3\n",
      " 1 1 1 4 0 0 0 3 0 4 4 3 0 0 0 0 0 3 1 1 3 4 1 1 1 0 0 3 2 1 0 0 0 0 2 4 1\n",
      " 3 1 0 1 0 0 4 1 2 1 0 1 2 2 2 3 1 1 3 1 2 4 1 3 2 3 3 3 0 0 0 0 3 2 0 2 4\n",
      " 3 1 2 4 1 1 1 1 1 4 0 3 1 0 3 4 0 1 0 2 0 0 1 1 3 4 3 4 1 2 3 1 3 4 0 1 1\n",
      " 2 2 2 3 3 1 2 2 0 1 3 0 0 2 0 4 2 2 0 0 1 1 2 2 0 3 0 3 3 0 2 0 3 0 3 3 3\n",
      " 1 1 0 2 0 2 0 3 1 0 2 3 1 0 2 1 1 0 0 1 0 0 1 1 2 3 4 2 1 0 2 1 3 3 1 2 0\n",
      " 1 1 1 1 3 0 4 3 0 0 2 2 1 4 3 0 0 3 1 2 2 2 0 4 0 0 1 3 4 1 0 3 3 0 0 1 0\n",
      " 2 3 3 3 1 0 3 1 0 2 4 3 2 0 0 0 1 1 0 1 4 1 3 1 4 1 1 1 1 1 4 1 4 1 0 3 1\n",
      " 1 4 4 1 3 2 0 0 1 4 4 0 1 4 4 0 4 1 4 1 1 0 1 4 1 1 4 1 4 1 1 1 0 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 4 3 0 1 1 1 1 0 0 0 4 1 1 4 0 4 4 4 0 0 1 3 1 0 4 4 1\n",
      " 1 1 0 1 1 1 0 1 3 1 1 1 1 4 4 4 1 1 1 1 4 2 0 0 0 0 1 3 0 1 4 3 4 1 3 1 4\n",
      " 4 0 1 0 4 1 4 0 0 1 4 1 0 4 0 1 0 0 4 1 4 1 1 4 4 4 3 0 1 4 1 1 1 0 1 1 1\n",
      " 1 1 3 3 4 1 1 4 1 0 4 1 2 3 1 4 4 3 1 4 0 1 1 1 4 4 4 0 0 0 1 1 0 0 1 1 0\n",
      " 0 1 1 1 3 1 0 4 4 1 1 1 4 1 3 4 1 4 1 1 1 3 0 1 1 1 1 0 1 1 4 1 1 3 0 1 1\n",
      " 3 4 1 0 0 1 4 0 1 0 0 1 0 1 1 1 0 0 1 2 4 1 0 3 1 4 1 0 1 4 3 0 3 1 3 1 1\n",
      " 0 0 1 3 1 0 1 4 4 1 1 4 0 3 1 1 1 1 1 3 3 1 1 1 3 1 0 1 1 1 4 0 0 1 1 1 1\n",
      " 0 1 0 1 1 1 1 4 4 4 1 1 0 3 4 4 4 4 1 1 4 1 4 1 4 1 0 1 0 1 4 3 0 0 1 0 0\n",
      " 4 3 4 1 4 1 4 4 0 1 1 4 3 4 1 4 3 1 3 1 3 1 1 1 4 4 4 4 1 4 4 0 4 1 1 1 3\n",
      " 1 0 0 0 4 0 4 0 1 1 0 0 3 0 1 3 2 2 1 3 0 0 2 3 2 0 3 0 3 0 0 0 2 0 0 1 0\n",
      " 3 0 0 3 2 0 0 0 3 3 0 2 2 0 0 1 3 0 0 1 4 3 3 2 3 0 1 0 0 0 1 2 3 3 3 3 3\n",
      " 3 3 2 3 3 0 2 3 0 0 0 0 3 4 2 3 1 0 0 2 3 1 4 4 1 3 3 0 4 2 0 0 1 0 2 2 2\n",
      " 1 0 4 0 2 0 0 2 2 2 0 3 0 1 0 3 4 0 2 3 0 0 0 0 0 2 3 0 0 0 0 0 3 0 0 1 2\n",
      " 3 0 3 0 2 0 0 0 3 0 2 1 4 1 1 3 4 2 2 3 3 0 0 0 3 1 3 0 0 3 0 2 0 3 2 1 0\n",
      " 0 2 2 0 0 3 4 3 0 1 0 2 0 0 0 1 1 0 2 0 0 1 1 1 0 0 3 2 3 0 2 2 4 0 0 0 0\n",
      " 0 3 2 1 2 0 1 0 3 0 2 1 3 1 3 0 0 1 1 1 0 2 2 3 0 0 4 0 2 2 0 3 2 0 3 3 0\n",
      " 4 2 2 4 2 1 0 0 0 0 1 2 0 2 0 3 3 0 0 0 0 1 1 3 3 3 3 1 0 0 0 1 0 3 2 3 0\n",
      " 1 3 0 2 1 0 2 3 0 0 0 1 0 1 3 1 2 3 3 4 3 2 3 2 2 2 0 1 0 0 3 2 2 3 2 0 0\n",
      " 3 0 2 2 0 1 3 0 2 0 2 0 3 0 1 0 0 2 0 1 0 3 0 1 3 1 2 0 0 0 0 1 0 3 2 2 0\n",
      " 0 0 3 2 2 1 2 0 2 4 3 3 1 2 0 2 3 0 2 0 2 3 2 1 3 3 1 3 1 1 4 0 2 3 0 2 1\n",
      " 1 3 3 1 0 0 0 3 3 2 0 0 3 0 0 2 2 2 0 0 0 0 0 2 1 1 2 0 2 0 1 2 2 3 4 2 0\n",
      " 2 2 0 0 2 0 2 1 2 0 2 0 0 0 1 0 1 0 0 2 2 0 2 3 1 1 0 2 2 0 2 2 4 2 2 0 2\n",
      " 2 0 1 0 1 3 4 2 4 2 0 0 0 2 4 2 0 2 0 3 4 0 1 1 2 2 3 2 2 4 3 1 4 2 0 1 0\n",
      " 2 0 0 3 0 0 2 2 2 2 0 2 0 0 0 0 2 1 2 1 2 1 2 0 0 0 2 3 2 2 0 4 2 0 4 0 2\n",
      " 2 0 0 0 0 2 3 2 1 0 2 0 1 0 2 2 1 2 0 0 2 3 0 2 4 0 2 4 0 0 2 3 0 0 0 0 0\n",
      " 4 0 2 0 3 1 3 0 2 1 2 2 3 0 0 1 0 3 0 0 2 0 0 2 1 0 2 3 2 2 2 1 2 4 2 1 1\n",
      " 0 3 2 2 4 3 4 2 0 2 3 0 2 1 0 1 0 0 2 1 2 2 0 3 4 4 0 2 0 1 2 0 1 0 0 2 3\n",
      " 1 3 0 2 0 0 0 2 0 2 2 0 3 1 1 2 0 0 0 0 1 2 1 2 4 3 3 0 0 2 2 1 0 3 2 0 0\n",
      " 0 0 0 0 2 0 2 0 1 0 1 2 2 1 1 3 0 0 1 0 4 0 2 2 2 2 1 0 2 3 0 3 2 2 0 0 3\n",
      " 2 2 3 2 1 0 2 2 0 2 4 2 0 2 2 2 0 3 0 3 0 0 2 2 0 2 2 0 2 1 4 0 1 4 0 2 1\n",
      " 1 3 0 2 0 0 2 0 1 1 0 0 2 4 0 3 1 2 1 2 2 1 0 0 1 4 0 0 1 0 2 4 0 0 0 2 1\n",
      " 2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3435\n",
      "============= RUN 3 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.845, val_loss=0.0887, avg\n",
      "Epoch 0:  55%|▌| 44/80 [00:01<00:01, 23.99it/s, loss=0.845, val_loss=0.0887, avg\n",
      "Epoch 0:  76%|▊| 61/80 [00:01<00:00, 31.48it/s, loss=0.845, val_loss=0.0887, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.845, val_loss=0.104, avg_\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.044, val_loss=0.104, avg_\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:01<00:01, 27.16it/s, loss=0.044, val_loss=0.104, avg_\n",
      "Epoch 1:  85%|▊| 68/80 [00:01<00:00, 34.22it/s, loss=0.044, val_loss=0.104, avg_\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.044, val_loss=0.0425, avg\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.0218, val_loss=0.0425, av\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 27.16it/s, loss=0.0218, val_loss=0.0425, av\n",
      "Epoch 2:  85%|▊| 68/80 [00:01<00:00, 34.23it/s, loss=0.0218, val_loss=0.0425, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.0218, val_loss=0.0265, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.0172, val_loss=0.0265, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.0172, val_loss=0.0265, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:01<00:00, 34.17it/s, loss=0.0172, val_loss=0.0265, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.0172, val_loss=0.0197, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.0146, val_loss=0.0197, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 27.21it/s, loss=0.0146, val_loss=0.0197, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:01<00:00, 34.29it/s, loss=0.0146, val_loss=0.0197, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.0146, val_loss=0.0159, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.05it/s, loss=0.0126, val_loss=0.0159, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 27.37it/s, loss=0.0126, val_loss=0.0159, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:01<00:00, 34.43it/s, loss=0.0126, val_loss=0.0159, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.57it/s, loss=0.0126, val_loss=0.0135, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.73it/s, loss=0.0111, val_loss=0.0135, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 26.98it/s, loss=0.0111, val_loss=0.0135, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:01<00:00, 34.01it/s, loss=0.0111, val_loss=0.0135, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.0111, val_loss=0.0117, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00991, val_loss=0.0117, a\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 27.16it/s, loss=0.00991, val_loss=0.0117, a\n",
      "Epoch 7:  85%|▊| 68/80 [00:01<00:00, 34.22it/s, loss=0.00991, val_loss=0.0117, a\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.00991, val_loss=0.0103, a\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.79it/s, loss=0.00892, val_loss=0.0103, a\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 27.03it/s, loss=0.00892, val_loss=0.0103, a\n",
      "Epoch 8:  85%|▊| 68/80 [00:01<00:00, 34.06it/s, loss=0.00892, val_loss=0.0103, a\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.15it/s, loss=0.00892, val_loss=0.00913, \u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.00812, val_loss=0.00913, \u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:01<00:01, 27.20it/s, loss=0.00812, val_loss=0.00913, \n",
      "Epoch 9:  85%|▊| 68/80 [00:01<00:00, 34.26it/s, loss=0.00812, val_loss=0.00913, \u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00812, val_loss=0.00822, \u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00748, val_loss=0.00822,\u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 27.30it/s, loss=0.00748, val_loss=0.00822,\n",
      "Epoch 10:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00748, val_loss=0.00822,\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00748, val_loss=0.0075, \u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00697, val_loss=0.0075, \u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 27.26it/s, loss=0.00697, val_loss=0.0075, \n",
      "Epoch 11:  85%|▊| 68/80 [00:01<00:00, 34.34it/s, loss=0.00697, val_loss=0.0075, \u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.42it/s, loss=0.00697, val_loss=0.00693,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00657, val_loss=0.00693,\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 27.13it/s, loss=0.00657, val_loss=0.00693,\n",
      "Epoch 12:  85%|▊| 68/80 [00:01<00:00, 34.19it/s, loss=0.00657, val_loss=0.00693,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.28it/s, loss=0.00657, val_loss=0.00649,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.56it/s, loss=0.00627, val_loss=0.00649,\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 26.76it/s, loss=0.00627, val_loss=0.00649,\n",
      "Epoch 13:  85%|▊| 68/80 [00:02<00:00, 33.74it/s, loss=0.00627, val_loss=0.00649,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 37.80it/s, loss=0.00627, val_loss=0.00618,\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00603, val_loss=0.00618,\u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 26.85it/s, loss=0.00603, val_loss=0.00618,\n",
      "Epoch 14:  85%|▊| 68/80 [00:02<00:00, 33.87it/s, loss=0.00603, val_loss=0.00618,\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.00603, val_loss=0.00596,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.54it/s, loss=0.00584, val_loss=0.00596,\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 26.73it/s, loss=0.00584, val_loss=0.00596,\n",
      "Epoch 15:  85%|▊| 68/80 [00:02<00:00, 33.71it/s, loss=0.00584, val_loss=0.00596,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 37.75it/s, loss=0.00584, val_loss=0.00582,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.00569, val_loss=0.00582,\u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:01<00:01, 26.91it/s, loss=0.00569, val_loss=0.00582,\n",
      "Epoch 16:  85%|▊| 68/80 [00:02<00:00, 33.74it/s, loss=0.00569, val_loss=0.00582,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 37.91it/s, loss=0.00569, val_loss=0.00574,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.50it/s, loss=0.00556, val_loss=0.00574,\u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:01<00:01, 26.67it/s, loss=0.00556, val_loss=0.00574,\n",
      "Epoch 17:  85%|▊| 68/80 [00:02<00:00, 33.64it/s, loss=0.00556, val_loss=0.00574,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00556, val_loss=0.00563,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.58it/s, loss=0.00545, val_loss=0.00563,\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:01<00:01, 26.79it/s, loss=0.00545, val_loss=0.00563,\n",
      "Epoch 18:  85%|▊| 68/80 [00:02<00:00, 33.77it/s, loss=0.00545, val_loss=0.00563,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 37.84it/s, loss=0.00545, val_loss=0.00553,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.20it/s, loss=0.00535, val_loss=0.00553,\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:01<00:01, 26.30it/s, loss=0.00535, val_loss=0.00553,\n",
      "Epoch 19:  85%|▊| 68/80 [00:02<00:00, 33.21it/s, loss=0.00535, val_loss=0.00553,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 37.24it/s, loss=0.00535, val_loss=0.00549,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.76it/s, loss=0.00526, val_loss=0.00549,\u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:01<00:01, 26.97it/s, loss=0.00526, val_loss=0.00549,\n",
      "Epoch 20:  85%|▊| 68/80 [00:01<00:00, 34.01it/s, loss=0.00526, val_loss=0.00549,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.08it/s, loss=0.00526, val_loss=0.00546,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.00517, val_loss=0.00546,\u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:01<00:01, 26.89it/s, loss=0.00517, val_loss=0.00546,\n",
      "Epoch 21:  85%|▊| 68/80 [00:02<00:00, 33.92it/s, loss=0.00517, val_loss=0.00546,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 37.97it/s, loss=0.00517, val_loss=0.00538,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.92it/s, loss=0.00509, val_loss=0.00538,\u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:01<00:01, 27.21it/s, loss=0.00509, val_loss=0.00538,\n",
      "Epoch 22:  85%|▊| 68/80 [00:01<00:00, 34.28it/s, loss=0.00509, val_loss=0.00538,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00509, val_loss=0.0053, \u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00502, val_loss=0.0053, \u001b[A\n",
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 27.15it/s, loss=0.00502, val_loss=0.0053, \n",
      "Epoch 23:  85%|▊| 68/80 [00:01<00:00, 34.20it/s, loss=0.00502, val_loss=0.0053, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.29it/s, loss=0.00502, val_loss=0.00523,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.81it/s, loss=0.00495, val_loss=0.00523,\u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 27.05it/s, loss=0.00495, val_loss=0.00523,\n",
      "Epoch 24:  85%|▊| 68/80 [00:01<00:00, 34.12it/s, loss=0.00495, val_loss=0.00523,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.20it/s, loss=0.00495, val_loss=0.00517,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.00488, val_loss=0.00517,\u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:01<00:01, 27.32it/s, loss=0.00488, val_loss=0.00517,\n",
      "Epoch 25:  85%|▊| 68/80 [00:01<00:00, 34.42it/s, loss=0.00488, val_loss=0.00517,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.54it/s, loss=0.00488, val_loss=0.00513,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.00482, val_loss=0.00513,\u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00482, val_loss=0.00513,\n",
      "Epoch 26:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00482, val_loss=0.00513,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00482, val_loss=0.00505,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00475, val_loss=0.00505,\u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:01<00:01, 27.30it/s, loss=0.00475, val_loss=0.00505,\n",
      "Epoch 27:  85%|▊| 68/80 [00:01<00:00, 34.39it/s, loss=0.00475, val_loss=0.00505,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.00475, val_loss=0.00499,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.00468, val_loss=0.00499,\u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:01<00:01, 27.20it/s, loss=0.00468, val_loss=0.00499,\n",
      "Epoch 28:  85%|▊| 68/80 [00:01<00:00, 34.27it/s, loss=0.00468, val_loss=0.00499,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00468, val_loss=0.00491,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.00462, val_loss=0.00491,\u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:01<00:01, 27.21it/s, loss=0.00462, val_loss=0.00491,\n",
      "Epoch 29:  85%|▊| 68/80 [00:01<00:00, 34.27it/s, loss=0.00462, val_loss=0.00491,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.37it/s, loss=0.00462, val_loss=0.00485,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 22.10it/s, loss=0.00456, val_loss=0.00485,\u001b[A\n",
      "Epoch 30:  64%|▋| 51/80 [00:01<00:01, 27.41it/s, loss=0.00456, val_loss=0.00485,\n",
      "Epoch 30:  85%|▊| 68/80 [00:01<00:00, 34.53it/s, loss=0.00456, val_loss=0.00485,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.64it/s, loss=0.00456, val_loss=0.00483,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.67it/s, loss=0.0045, val_loss=0.00483, \u001b[A\n",
      "Epoch 31:  64%|▋| 51/80 [00:01<00:01, 26.90it/s, loss=0.0045, val_loss=0.00483, \n",
      "Epoch 31:  85%|▊| 68/80 [00:02<00:00, 33.92it/s, loss=0.0045, val_loss=0.00483, \u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 37.98it/s, loss=0.0045, val_loss=0.00482, \u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00443, val_loss=0.00482,\u001b[A\n",
      "Epoch 32:  64%|▋| 51/80 [00:01<00:01, 27.08it/s, loss=0.00443, val_loss=0.00482,\n",
      "Epoch 32:  85%|▊| 68/80 [00:01<00:00, 34.13it/s, loss=0.00443, val_loss=0.00482,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.00443, val_loss=0.00477,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.00437, val_loss=0.00477,\u001b[A\n",
      "Epoch 33:  64%|▋| 51/80 [00:01<00:01, 27.17it/s, loss=0.00437, val_loss=0.00477,\n",
      "Epoch 33:  85%|▊| 68/80 [00:01<00:00, 34.24it/s, loss=0.00437, val_loss=0.00477,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.00437, val_loss=0.00473,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.00432, val_loss=0.00473,\u001b[A\n",
      "Epoch 34:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00432, val_loss=0.00473,\n",
      "Epoch 34:  85%|▊| 68/80 [00:01<00:00, 34.35it/s, loss=0.00432, val_loss=0.00473,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00432, val_loss=0.00474,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.00426, val_loss=0.00474,\u001b[A\n",
      "Epoch 35:  64%|▋| 51/80 [00:01<00:01, 27.33it/s, loss=0.00426, val_loss=0.00474,\n",
      "Epoch 35:  85%|▊| 68/80 [00:01<00:00, 34.43it/s, loss=0.00426, val_loss=0.00474,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.53it/s, loss=0.00426, val_loss=0.00478,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0042, val_loss=0.00478, \u001b[A\n",
      "Epoch 36:  64%|▋| 51/80 [00:01<00:01, 27.26it/s, loss=0.0042, val_loss=0.00478, \n",
      "Epoch 36:  85%|▊| 68/80 [00:01<00:00, 34.35it/s, loss=0.0042, val_loss=0.00478, \u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.0042, val_loss=0.00481, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.00413, val_loss=0.00481,\u001b[A\n",
      "Epoch 37:  64%|▋| 51/80 [00:01<00:01, 27.00it/s, loss=0.00413, val_loss=0.00481,\n",
      "Epoch 37:  85%|▊| 68/80 [00:01<00:00, 34.03it/s, loss=0.00413, val_loss=0.00481,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.11it/s, loss=0.00413, val_loss=0.00468,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00406, val_loss=0.00468,\u001b[A\n",
      "Epoch 38:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.00406, val_loss=0.00468,\n",
      "Epoch 38:  85%|▊| 68/80 [00:01<00:00, 34.30it/s, loss=0.00406, val_loss=0.00468,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00406, val_loss=0.00464,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.004, val_loss=0.00464, a\u001b[A\n",
      "Epoch 39:  64%|▋| 51/80 [00:01<00:01, 27.19it/s, loss=0.004, val_loss=0.00464, a\n",
      "Epoch 39:  85%|▊| 68/80 [00:01<00:00, 34.26it/s, loss=0.004, val_loss=0.00464, a\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.004, val_loss=0.00465, a\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 38.14it/s, loss=0.004, val_loss=0.00465, a\u001b[A\n",
      "Sizes of clusters: 414, 438, 362, 557, 229\n",
      "\n",
      "preds: [4 2 1 3 4 2 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 2 4 2 1 2 0 3 2 2 2 0 3 4 0 3 3\n",
      " 3 3 3 3 2 3 3 2 3 4 3 1 1 4 2 2 2 4 3 4 2 3 4 3 1 3 1 3 1 2 2 2 3 1 3 0 2\n",
      " 2 4 2 2 3 2 2 1 3 2 3 3 3 2 2 1 3 4 4 4 4 3 2 4 2 3 3 2 4 2 0 1 2 4 0 4 3\n",
      " 3 3 2 3 2 2 2 3 1 1 1 2 0 3 0 1 3 1 3 3 3 2 3 2 4 4 1 4 0 2 1 2 1 3 3 1 3\n",
      " 3 1 4 4 3 0 2 2 3 3 3 3 1 1 1 3 4 1 3 3 2 3 2 3 2 3 3 3 3 4 0 2 1 4 0 4 1\n",
      " 4 3 1 3 0 3 4 3 4 2 2 0 3 1 3 2 3 4 2 4 0 4 2 3 3 2 3 3 3 3 1 3 2 2 4 4 4\n",
      " 1 2 3 1 4 0 2 3 3 1 3 4 2 2 3 3 0 4 4 0 3 4 3 4 0 4 3 3 3 3 3 3 2 2 1 1 1\n",
      " 2 3 4 3 3 3 3 1 3 4 4 0 4 0 3 3 1 0 1 1 0 1 4 3 4 4 2 3 0 2 4 2 1 2 3 1 3\n",
      " 1 1 3 4 3 2 4 3 1 2 0 2 1 4 3 3 3 3 3 2 2 3 1 3 4 2 2 2 1 4 0 2 3 1 2 2 1\n",
      " 4 4 3 3 2 4 0 1 0 1 1 3 0 3 4 3 2 1 4 2 3 1 2 3 2 4 2 2 0 3 2 4 0 2 4 4 3\n",
      " 2 2 4 3 3 4 4 3 3 3 4 3 3 1 1 1 2 1 3 4 2 4 4 4 3 3 2 4 2 0 3 3 3 1 2 0 0\n",
      " 2 1 3 1 2 3 1 2 2 1 4 2 1 0 3 0 3 0 1 3 1 3 4 0 1 0 0 4 0 3 1 3 0 1 3 3 0\n",
      " 3 0 1 0 4 3 1 3 3 3 3 2 0 2 0 3 2 3 0 1 0 4 1 3 0 0 0 3 0 3 2 0 3 2 2 0 0\n",
      " 1 1 2 3 3 0 0 0 2 0 2 3 0 0 3 2 0 2 3 0 3 0 0 0 2 3 2 1 0 3 2 2 0 2 0 3 3\n",
      " 0 2 0 0 1 0 0 0 0 4 1 2 2 0 3 1 3 0 1 3 3 3 3 0 3 0 0 0 1 1 3 2 1 2 0 3 1\n",
      " 2 2 2 2 1 1 0 3 0 3 4 3 0 3 0 0 0 3 2 2 2 3 4 2 2 3 0 3 1 2 0 0 0 2 0 3 2\n",
      " 1 3 1 2 0 1 3 3 1 3 3 2 1 0 0 3 3 3 0 2 0 2 2 3 0 4 0 3 0 0 0 0 1 0 4 1 3\n",
      " 1 3 1 2 2 3 3 2 3 3 3 3 2 1 1 3 0 3 0 0 0 0 4 3 3 2 3 2 2 1 3 2 3 3 0 2 2\n",
      " 0 0 0 1 3 3 1 0 1 4 0 0 0 1 0 2 1 1 0 3 2 3 1 1 0 3 0 1 2 0 0 1 1 1 3 1 3\n",
      " 2 3 0 1 3 0 0 1 2 1 0 3 2 0 1 2 3 1 0 2 0 0 2 2 0 3 3 0 3 0 0 2 3 3 2 0 0\n",
      " 2 2 3 3 3 1 3 3 3 0 0 0 3 2 1 0 2 2 2 0 1 0 0 4 2 0 3 3 4 2 1 4 3 0 0 3 0\n",
      " 0 3 0 3 2 0 2 3 0 0 4 1 1 0 0 0 2 3 1 2 2 3 1 3 2 2 4 3 2 3 2 2 3 2 0 3 2\n",
      " 3 2 3 3 4 0 0 3 3 4 2 1 2 4 4 0 3 2 3 2 3 2 4 3 3 3 2 3 2 2 2 3 1 3 2 3 3\n",
      " 2 2 1 3 3 1 2 3 2 1 2 1 1 4 3 3 2 2 1 1 3 2 2 2 1 2 2 3 3 1 3 3 4 1 4 4 4\n",
      " 4 3 3 3 3 3 1 3 2 3 4 2 4 3 2 2 3 2 4 2 2 0 3 1 3 1 3 4 0 3 3 3 2 3 1 2 3\n",
      " 3 1 3 1 3 2 2 3 1 3 2 2 0 3 3 4 4 0 2 3 3 4 2 3 2 2 1 2 2 3 2 2 3 1 3 3 3\n",
      " 2 2 2 1 3 2 2 2 3 4 2 3 1 1 2 4 4 3 3 3 0 3 3 2 3 3 3 1 0 1 2 2 3 0 4 3 1\n",
      " 3 3 3 3 1 3 1 3 3 3 2 3 3 4 4 3 4 3 3 3 3 2 0 3 2 2 2 1 3 2 3 2 3 3 1 4 2\n",
      " 1 3 2 0 3 3 3 3 3 0 1 3 4 2 2 3 0 1 2 1 3 4 1 1 2 2 4 1 4 3 3 4 1 3 3 2 3\n",
      " 2 1 2 3 4 0 3 3 3 3 2 2 2 4 3 4 3 4 3 3 1 2 3 2 4 2 2 3 4 3 3 1 3 4 2 4 2\n",
      " 0 2 2 3 3 2 4 3 3 4 2 3 0 1 3 3 3 4 4 4 3 3 3 2 3 2 4 1 0 3 3 3 1 0 3 4 1\n",
      " 2 4 2 3 3 3 3 3 2 4 4 2 3 4 2 2 3 2 3 3 2 2 3 2 3 2 2 3 2 2 2 0 4 2 4 2 3\n",
      " 2 1 0 1 3 4 2 4 3 3 2 1 3 3 3 3 1 1 3 0 0 0 0 4 0 1 1 1 4 2 1 4 0 1 3 3 1\n",
      " 3 0 0 3 1 1 1 1 2 4 0 1 0 3 1 2 1 1 0 4 3 1 0 1 1 4 2 1 3 0 2 0 1 1 4 4 4\n",
      " 3 4 1 2 4 1 1 4 1 0 1 3 4 3 1 1 3 1 1 4 3 3 3 3 3 4 1 1 2 0 1 0 2 1 4 0 0\n",
      " 4 1 3 1 1 0 0 0 1 1 1 4 0 3 1 1 2 0 1 1 1 0 1 1 3 1 1 0 1 3 3 0 4 0 1 2 1\n",
      " 1 1 3 3 1 4 1 1 3 1 1 3 3 3 3 4 3 1 1 4 4 1 0 0 0 3 4 3 1 1 1 0 1 4 0 2 1\n",
      " 3 1 0 1 4 3 3 1 1 3 1 1 4 1 0 2 2 0 1 1 0 3 2 2 1 1 4 1 4 0 1 1 3 1 1 0 0\n",
      " 4 4 0 2 1 0 4 4 0 0 0 4 1 2 3 3 1 2 2 3 1 1 1 1 0 0 2 1 0 1 0 4 0 2 4 4 1\n",
      " 2 1 1 4 1 2 1 0 4 0 2 0 0 0 1 3 4 1 1 1 1 3 4 4 4 1 1 2 1 0 3 3 0 2 1 1 0\n",
      " 3 3 0 0 2 3 0 1 0 1 1 3 3 3 3 3 1 1 1 2 4 1 0 0 0 0 3 2 1 1 3 1 1 1 0 3 0\n",
      " 1 1 1 0 0 4 4 0 0 3 0 1 4 0 4 4 0 1 0 3 1 1 1 3 1 2 1 1 1 1 4 3 0 4 0 0 0\n",
      " 1 0 3 1 0 3 1 4 0 3 4 3 3 0 0 0 1 1 0 1 0 4 1 3 4 1 3 2 3 3 4 4 1 1 0 0 3\n",
      " 2 1 1 3 0 1 1 3 3 1 0 0 1 2 3 0 0 1 2 3 1 1 1 0 2 3 0 0 1 0 2 1 0 3 3 1 0\n",
      " 0 0 1 3 1 1 1 2 1 0 1 0 3 0 3 1 2 1 2 0 0 1 1 1 3 3 1 1 0 1 1 0 3 0 1 0 1\n",
      " 0 4 3 0 2 4 3 1 4 0 1 0 0 0 3 1 4 0 0 3 3 1 3 2 1 0 1 1 1 3 4 4 3 0 0 4 1\n",
      " 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 2 0 3 0 2 0 4 0 0 0 2 0 0 0 3 0 1 4 1 1\n",
      " 1 1 1 1 0 4 3 0 2 0 0 3 3 0 1 1 2 0 1 1 1 1 0 1 3 0 1 3 2 0 0 3 1 3 0 3 0\n",
      " 3 0 1 0 0 4 3 2 0 4 1 0 3 0 3 2 3 3 2 0 1 2 2 0 3 0 0 1 0 4 0 2 1 2 1 3 4\n",
      " 0 2 1 1 2 3 4 1 1 0 1 0 0 4 0 3 0 1 0 3 0 1 1 3 3 3 0 0 4 3 1 0 2 4 0 0 3\n",
      " 2 3 1 1 0 0 1 0 0 0 0 0 0 2 3 1 2 3 1 0 3 0 3 0 3 1 3 1 0 1 1 3 0 1 0 4 2\n",
      " 0 0 0 3 1 0 0 1 2 3 2 0 0 3 2 3 0 0 2 1 3 3 0 1 0 1 2 2 0 1 0 1 0 0 1 3 3\n",
      " 0 0 3 0 2 4 1 1 0 1 3 0 1 0 1 0 1 1 0 3 0 1 1 1 1 1 0 1 0 3 3 4 2 3 0 1 2\n",
      " 3 3 0 0 0 2 1 1 2 4 0 4 0 4 1 1 2 0 2 1 0 2 0 0 3 4 4 0 2 1 1 2 0 0 0 0 4\n",
      " 1 3]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3185\n",
      "============= RUN 4 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.902, val_loss=0.0652, avg\n",
      "Epoch 0:  55%|▌| 44/80 [00:01<00:01, 23.99it/s, loss=0.902, val_loss=0.0652, avg\n",
      "Epoch 0:  76%|▊| 61/80 [00:01<00:00, 31.51it/s, loss=0.902, val_loss=0.0652, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.902, val_loss=0.0987, avg\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0705, val_loss=0.0987, av\u001b[A\n",
      "Epoch 1:  64%|▋| 51/80 [00:01<00:01, 27.31it/s, loss=0.0705, val_loss=0.0987, av\n",
      "Epoch 1:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.0705, val_loss=0.0987, av\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.50it/s, loss=0.0705, val_loss=0.0594, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.47it/s, loss=0.0384, val_loss=0.0594, av\u001b[A\n",
      "Epoch 2:  64%|▋| 51/80 [00:01<00:01, 26.64it/s, loss=0.0384, val_loss=0.0594, av\n",
      "Epoch 2:  85%|▊| 68/80 [00:02<00:00, 33.59it/s, loss=0.0384, val_loss=0.0594, av\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 37.65it/s, loss=0.0384, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.0284, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3:  64%|▋| 51/80 [00:01<00:01, 27.23it/s, loss=0.0284, val_loss=0.0411, av\n",
      "Epoch 3:  85%|▊| 68/80 [00:01<00:00, 34.31it/s, loss=0.0284, val_loss=0.0411, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.0284, val_loss=0.0314, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.0231, val_loss=0.0314, av\u001b[A\n",
      "Epoch 4:  64%|▋| 51/80 [00:01<00:01, 27.25it/s, loss=0.0231, val_loss=0.0314, av\n",
      "Epoch 4:  85%|▊| 68/80 [00:01<00:00, 34.32it/s, loss=0.0231, val_loss=0.0314, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.0231, val_loss=0.0259, av\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.0199, val_loss=0.0259, av\u001b[A\n",
      "Epoch 5:  64%|▋| 51/80 [00:01<00:01, 27.36it/s, loss=0.0199, val_loss=0.0259, av\n",
      "Epoch 5:  85%|▊| 68/80 [00:01<00:00, 34.46it/s, loss=0.0199, val_loss=0.0259, av\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.55it/s, loss=0.0199, val_loss=0.0226, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.0179, val_loss=0.0226, av\u001b[A\n",
      "Epoch 6:  64%|▋| 51/80 [00:01<00:01, 26.96it/s, loss=0.0179, val_loss=0.0226, av\n",
      "Epoch 6:  85%|▊| 68/80 [00:02<00:00, 34.00it/s, loss=0.0179, val_loss=0.0226, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.0179, val_loss=0.0202, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.0165, val_loss=0.0202, av\u001b[A\n",
      "Epoch 7:  64%|▋| 51/80 [00:01<00:01, 27.24it/s, loss=0.0165, val_loss=0.0202, av\n",
      "Epoch 7:  85%|▊| 68/80 [00:01<00:00, 34.31it/s, loss=0.0165, val_loss=0.0202, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.0165, val_loss=0.0185, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.0155, val_loss=0.0185, av\u001b[A\n",
      "Epoch 8:  64%|▋| 51/80 [00:01<00:01, 27.12it/s, loss=0.0155, val_loss=0.0185, av\n",
      "Epoch 8:  85%|▊| 68/80 [00:01<00:00, 34.18it/s, loss=0.0155, val_loss=0.0185, av\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.25it/s, loss=0.0155, val_loss=0.0171, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0146, val_loss=0.0171, av\u001b[A\n",
      "Epoch 9:  64%|▋| 51/80 [00:01<00:01, 27.26it/s, loss=0.0146, val_loss=0.0171, av\n",
      "Epoch 9:  85%|▊| 68/80 [00:01<00:00, 34.36it/s, loss=0.0146, val_loss=0.0171, av\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.0146, val_loss=0.016, avg\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.014, val_loss=0.016, avg\u001b[A\n",
      "Epoch 10:  64%|▋| 51/80 [00:01<00:01, 27.35it/s, loss=0.014, val_loss=0.016, avg\n",
      "Epoch 10:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.014, val_loss=0.016, avg\u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.014, val_loss=0.0151, av\u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.89it/s, loss=0.0134, val_loss=0.0151, a\u001b[A\n",
      "Epoch 11:  64%|▋| 51/80 [00:01<00:01, 27.17it/s, loss=0.0134, val_loss=0.0151, a\n",
      "Epoch 11:  85%|▊| 68/80 [00:01<00:00, 34.24it/s, loss=0.0134, val_loss=0.0151, a\u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 38.32it/s, loss=0.0134, val_loss=0.0143, a\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0129, val_loss=0.0143, a\u001b[A\n",
      "Epoch 12:  64%|▋| 51/80 [00:01<00:01, 27.31it/s, loss=0.0129, val_loss=0.0143, a\n",
      "Epoch 12:  85%|▊| 68/80 [00:01<00:00, 34.40it/s, loss=0.0129, val_loss=0.0143, a\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 38.50it/s, loss=0.0129, val_loss=0.0137, a\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0124, val_loss=0.0137, a\u001b[A\n",
      "Epoch 13:  64%|▋| 51/80 [00:01<00:01, 27.32it/s, loss=0.0124, val_loss=0.0137, a\n",
      "Epoch 13:  85%|▊| 68/80 [00:01<00:00, 34.41it/s, loss=0.0124, val_loss=0.0137, a\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.50it/s, loss=0.0124, val_loss=0.0132, a\u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.012, val_loss=0.0132, av\u001b[A\n",
      "Epoch 14:  64%|▋| 51/80 [00:01<00:01, 26.52it/s, loss=0.012, val_loss=0.0132, av\n",
      "Epoch 14:  85%|▊| 68/80 [00:02<00:00, 33.50it/s, loss=0.012, val_loss=0.0132, av\u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 37.54it/s, loss=0.012, val_loss=0.0127, av\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.0117, val_loss=0.0127, a\u001b[A\n",
      "Epoch 15:  64%|▋| 51/80 [00:01<00:01, 27.11it/s, loss=0.0117, val_loss=0.0127, a\n",
      "Epoch 15:  85%|▊| 68/80 [00:01<00:00, 34.16it/s, loss=0.0117, val_loss=0.0127, a\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.0117, val_loss=0.0123, a\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.0113, val_loss=0.0123, a\u001b[A\n",
      "Epoch 16:  64%|▋| 51/80 [00:01<00:01, 26.97it/s, loss=0.0113, val_loss=0.0123, a\n",
      "Epoch 16:  85%|▊| 68/80 [00:01<00:00, 34.01it/s, loss=0.0113, val_loss=0.0123, a\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.07it/s, loss=0.0113, val_loss=0.0119, a\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.82it/s, loss=0.011, val_loss=0.0119, av\u001b[A\n",
      "Epoch 17:  64%|▋| 51/80 [00:01<00:01, 27.08it/s, loss=0.011, val_loss=0.0119, av\n",
      "Epoch 17:  85%|▊| 68/80 [00:01<00:00, 34.13it/s, loss=0.011, val_loss=0.0119, av\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.011, val_loss=0.0116, av\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.0108, val_loss=0.0116, a\u001b[A\n",
      "Epoch 18:  64%|▋| 51/80 [00:01<00:01, 27.12it/s, loss=0.0108, val_loss=0.0116, a\n",
      "Epoch 18:  85%|▊| 68/80 [00:01<00:00, 34.17it/s, loss=0.0108, val_loss=0.0116, a\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.0108, val_loss=0.0113, a\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.71it/s, loss=0.0105, val_loss=0.0113, a\u001b[A\n",
      "Epoch 19:  64%|▋| 51/80 [00:01<00:01, 26.92it/s, loss=0.0105, val_loss=0.0113, a\n",
      "Epoch 19:  85%|▊| 68/80 [00:02<00:00, 33.94it/s, loss=0.0105, val_loss=0.0113, a\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.0105, val_loss=0.011, av\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.0103, val_loss=0.011, av\u001b[A\n",
      "Epoch 20:  64%|▋| 51/80 [00:01<00:01, 27.09it/s, loss=0.0103, val_loss=0.011, av\n",
      "Epoch 20:  85%|▊| 68/80 [00:01<00:00, 34.15it/s, loss=0.0103, val_loss=0.011, av\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.0103, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.75it/s, loss=0.0101, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21:  64%|▋| 51/80 [00:01<00:01, 26.99it/s, loss=0.0101, val_loss=0.0107, a\n",
      "Epoch 21:  85%|▊| 68/80 [00:01<00:00, 34.02it/s, loss=0.0101, val_loss=0.0107, a\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.0101, val_loss=0.0105, a\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.39it/s, loss=0.0099, val_loss=0.0105, a\u001b[A\n",
      "Epoch 22:  64%|▋| 51/80 [00:01<00:01, 26.55it/s, loss=0.0099, val_loss=0.0105, a\n",
      "Epoch 22:  85%|▊| 68/80 [00:02<00:00, 33.48it/s, loss=0.0099, val_loss=0.0105, a\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.49it/s, loss=0.0099, val_loss=0.0102, a\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.63it/s, loss=0.00972, val_loss=0.0102, \u001b[A\n",
      "Epoch 23:  64%|▋| 51/80 [00:01<00:01, 26.83it/s, loss=0.00972, val_loss=0.0102, \n",
      "Epoch 23:  85%|▊| 68/80 [00:02<00:00, 33.84it/s, loss=0.00972, val_loss=0.0102, \u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 37.90it/s, loss=0.00972, val_loss=0.01, av\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.24it/s, loss=0.00954, val_loss=0.01, av\u001b[A\n",
      "Epoch 24:  64%|▋| 51/80 [00:01<00:01, 26.37it/s, loss=0.00954, val_loss=0.01, av\n",
      "Epoch 24:  85%|▊| 68/80 [00:02<00:00, 33.27it/s, loss=0.00954, val_loss=0.01, av\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 37.30it/s, loss=0.00954, val_loss=0.0098, \u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00937, val_loss=0.0098, \u001b[A\n",
      "Epoch 25:  64%|▋| 51/80 [00:01<00:01, 27.07it/s, loss=0.00937, val_loss=0.0098, \n",
      "Epoch 25:  85%|▊| 68/80 [00:01<00:00, 34.09it/s, loss=0.00937, val_loss=0.0098, \u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.21it/s, loss=0.00937, val_loss=0.00961,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.27it/s, loss=0.0092, val_loss=0.00961, \u001b[A\n",
      "Epoch 26:  64%|▋| 51/80 [00:01<00:01, 26.39it/s, loss=0.0092, val_loss=0.00961, \n",
      "Epoch 26:  85%|▊| 68/80 [00:02<00:00, 33.32it/s, loss=0.0092, val_loss=0.00961, \u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 37.36it/s, loss=0.0092, val_loss=0.00943, \u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.68it/s, loss=0.00904, val_loss=0.00943,\u001b[A\n",
      "Epoch 27:  64%|▋| 51/80 [00:01<00:01, 26.89it/s, loss=0.00904, val_loss=0.00943,\n",
      "Epoch 27:  85%|▊| 68/80 [00:02<00:00, 33.91it/s, loss=0.00904, val_loss=0.00943,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 37.99it/s, loss=0.00904, val_loss=0.00926,\u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.69it/s, loss=0.00889, val_loss=0.00926,\u001b[A\n",
      "Epoch 28:  64%|▋| 51/80 [00:01<00:01, 26.92it/s, loss=0.00889, val_loss=0.00926,\n",
      "Epoch 28:  85%|▊| 68/80 [00:02<00:00, 33.92it/s, loss=0.00889, val_loss=0.00926,\u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.00it/s, loss=0.00889, val_loss=0.00909,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.74it/s, loss=0.00874, val_loss=0.00909,\u001b[A\n",
      "Epoch 29:  64%|▋| 51/80 [00:01<00:01, 26.94it/s, loss=0.00874, val_loss=0.00909,\n",
      "Epoch 29:  85%|▊| 68/80 [00:01<00:00, 34.00it/s, loss=0.00874, val_loss=0.00909,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 37.88it/s, loss=0.00874, val_loss=0.00893,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.56it/s, loss=0.00859, val_loss=0.00893,\u001b[A\n",
      "Epoch 30:  64%|▋| 51/80 [00:01<00:01, 26.76it/s, loss=0.00859, val_loss=0.00893,\n",
      "Epoch 30:  85%|▊| 68/80 [00:02<00:00, 33.74it/s, loss=0.00859, val_loss=0.00893,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 37.75it/s, loss=0.00859, val_loss=0.00878,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00845, val_loss=0.00878,\u001b[A\n",
      "Epoch 31:  64%|▋| 51/80 [00:01<00:01, 27.28it/s, loss=0.00845, val_loss=0.00878,\n",
      "Epoch 31:  85%|▊| 68/80 [00:01<00:00, 34.36it/s, loss=0.00845, val_loss=0.00878,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00845, val_loss=0.00863,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00831, val_loss=0.00863,\u001b[A\n",
      "Epoch 32:  64%|▋| 51/80 [00:01<00:01, 27.30it/s, loss=0.00831, val_loss=0.00863,\n",
      "Epoch 32:  85%|▊| 68/80 [00:01<00:00, 34.38it/s, loss=0.00831, val_loss=0.00863,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.00831, val_loss=0.00848,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.34it/s, loss=0.00817, val_loss=0.00848,\u001b[A\n",
      "Epoch 33:  64%|▋| 51/80 [00:01<00:01, 26.45it/s, loss=0.00817, val_loss=0.00848,\n",
      "Epoch 33:  85%|▊| 68/80 [00:02<00:00, 33.41it/s, loss=0.00817, val_loss=0.00848,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 37.44it/s, loss=0.00817, val_loss=0.00833,\u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 20.98it/s, loss=0.00803, val_loss=0.00833,\u001b[A\n",
      "Epoch 34:  64%|▋| 51/80 [00:01<00:01, 26.02it/s, loss=0.00803, val_loss=0.00833,\n",
      "Epoch 34:  85%|▊| 68/80 [00:02<00:00, 32.86it/s, loss=0.00803, val_loss=0.00833,\u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 36.85it/s, loss=0.00803, val_loss=0.00819,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00789, val_loss=0.00819,\u001b[A\n",
      "Epoch 35:  64%|▋| 51/80 [00:01<00:01, 27.10it/s, loss=0.00789, val_loss=0.00819,\n",
      "Epoch 35:  85%|▊| 68/80 [00:01<00:00, 34.17it/s, loss=0.00789, val_loss=0.00819,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.22it/s, loss=0.00789, val_loss=0.00804,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.15it/s, loss=0.00775, val_loss=0.00804,\u001b[A\n",
      "Epoch 36:  64%|▋| 51/80 [00:01<00:01, 26.25it/s, loss=0.00775, val_loss=0.00804,\n",
      "Epoch 36:  85%|▊| 68/80 [00:02<00:00, 33.14it/s, loss=0.00775, val_loss=0.00804,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 37.14it/s, loss=0.00775, val_loss=0.0079, \u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00761, val_loss=0.0079, \u001b[A\n",
      "Epoch 37:  64%|▋| 51/80 [00:01<00:01, 26.95it/s, loss=0.00761, val_loss=0.0079, \n",
      "Epoch 37:  85%|▊| 68/80 [00:02<00:00, 33.97it/s, loss=0.00761, val_loss=0.0079, \u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 38.03it/s, loss=0.00761, val_loss=0.00777,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.53it/s, loss=0.00748, val_loss=0.00777,\u001b[A\n",
      "Epoch 38:  64%|▋| 51/80 [00:01<00:01, 26.73it/s, loss=0.00748, val_loss=0.00777,\n",
      "Epoch 38:  85%|▊| 68/80 [00:02<00:00, 33.55it/s, loss=0.00748, val_loss=0.00777,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00748, val_loss=0.00763,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.45it/s, loss=0.00734, val_loss=0.00763,\u001b[A\n",
      "Epoch 39:  64%|▋| 51/80 [00:01<00:01, 26.62it/s, loss=0.00734, val_loss=0.00763,\n",
      "Epoch 39:  85%|▊| 68/80 [00:02<00:00, 33.58it/s, loss=0.00734, val_loss=0.00763,\u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.61it/s, loss=0.00734, val_loss=0.0075, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.38it/s, loss=0.00734, val_loss=0.0075, \u001b[A\n",
      "Sizes of clusters: 618, 581, 108, 275, 418\n",
      "\n",
      "preds: [2 0 4 1 0 4 1 4 0 0 1 0 1 0 0 0 4 4 0 4 0 0 2 1 0 0 0 0 1 0 4 0 0 0 1 4 4\n",
      " 1 4 3 0 1 0 0 1 4 0 0 4 4 2 4 1 3 2 1 0 0 1 4 1 4 4 0 4 0 1 4 0 4 4 0 1 1\n",
      " 4 2 1 4 0 0 4 2 0 0 4 0 0 4 1 4 1 2 0 4 2 0 1 0 4 0 0 1 4 1 3 4 4 2 1 4 1\n",
      " 0 1 0 0 1 3 0 0 0 4 4 1 0 0 0 1 1 0 4 4 0 0 0 1 2 2 0 4 0 4 2 4 2 4 1 4 3\n",
      " 3 0 1 2 1 1 4 0 1 2 1 4 4 2 4 0 3 0 4 4 0 1 0 2 1 0 4 0 0 2 1 1 1 2 2 2 0\n",
      " 4 0 4 1 0 1 0 1 2 1 0 0 4 0 2 0 4 2 4 2 2 2 4 4 0 4 2 1 4 2 4 1 0 0 2 2 2\n",
      " 4 1 4 1 0 1 0 1 0 4 1 2 4 4 4 1 3 2 2 1 4 2 4 1 0 2 0 4 4 0 4 0 1 0 4 0 0\n",
      " 0 4 1 1 4 1 0 4 1 4 0 0 1 4 1 2 4 0 1 1 0 0 2 4 4 2 0 4 4 0 4 4 4 1 4 0 2\n",
      " 4 0 1 2 2 4 2 4 3 1 0 4 0 2 1 4 0 4 1 3 1 0 1 4 4 4 1 0 4 2 1 4 4 2 3 0 1\n",
      " 2 4 4 0 1 4 1 4 1 4 4 2 4 0 2 4 4 2 2 1 0 4 0 4 3 4 0 1 4 1 4 3 3 0 4 2 4\n",
      " 0 1 0 4 4 4 0 0 1 4 4 0 0 4 0 1 3 0 0 2 0 4 0 2 0 1 0 2 0 1 4 2 1 4 1 3 1\n",
      " 0 4 0 4 3 3 2 0 0 3 1 0 1 3 1 3 1 1 4 1 1 1 4 1 3 3 3 4 3 0 4 1 3 4 0 0 3\n",
      " 0 3 0 4 2 0 1 3 1 4 0 0 3 0 3 4 0 4 3 0 1 4 4 1 0 1 1 0 3 4 0 4 0 1 1 3 1\n",
      " 4 4 1 4 0 1 3 3 4 1 0 1 0 1 1 4 3 1 4 1 1 3 3 3 4 0 3 4 3 4 0 0 3 1 3 4 1\n",
      " 3 0 3 3 3 3 3 1 1 4 4 1 1 0 1 1 0 3 3 1 0 0 0 0 0 3 3 3 3 3 0 1 0 3 3 1 0\n",
      " 0 0 3 1 3 1 1 4 0 4 2 4 3 1 3 1 3 4 3 1 0 4 1 3 1 1 1 0 0 4 1 3 3 1 3 0 0\n",
      " 4 1 1 0 3 1 1 1 0 1 3 1 1 3 3 4 0 4 1 4 3 0 0 0 3 0 4 0 3 0 4 0 2 3 1 4 1\n",
      " 4 0 0 4 1 1 0 3 0 4 0 0 0 0 2 4 1 1 1 1 0 1 4 0 4 0 4 4 0 0 4 0 0 0 3 1 1\n",
      " 1 3 3 4 4 1 3 1 0 0 0 1 3 3 0 1 1 4 3 1 1 3 4 3 1 4 1 4 0 1 3 0 0 4 0 0 0\n",
      " 1 0 3 0 1 3 3 4 1 1 3 4 3 3 1 3 4 3 1 0 3 1 3 0 3 0 0 1 0 0 3 0 0 0 4 3 3\n",
      " 0 0 0 1 4 0 0 1 0 0 3 0 0 3 2 3 1 0 0 3 1 3 3 4 3 3 1 0 4 0 3 2 4 1 1 0 0\n",
      " 3 0 4 0 0 3 0 1 3 3 4 4 4 1 3 0 3 3 0 1 0 1 4 4 0 0 1 0 0 1 4 1 4 3 1 0 0\n",
      " 1 0 1 1 2 3 0 0 1 4 1 0 0 0 2 1 4 1 1 1 3 1 0 0 1 1 0 1 4 1 1 1 1 0 0 0 1\n",
      " 1 3 3 3 3 1 1 0 3 1 4 1 1 1 0 1 0 1 4 1 4 1 0 4 3 1 4 0 1 0 1 0 1 4 0 0 0\n",
      " 0 1 0 1 1 1 0 4 0 1 3 0 3 4 4 1 1 0 1 1 0 1 3 0 1 1 1 2 3 0 4 0 0 1 4 3 0\n",
      " 0 1 1 1 1 0 1 0 1 0 4 1 0 0 0 4 1 1 0 1 0 3 1 0 0 1 1 1 3 0 1 0 1 3 1 0 1\n",
      " 1 0 0 4 4 1 1 1 0 1 4 0 0 4 0 0 4 4 1 4 1 0 3 1 0 4 4 3 1 3 1 1 1 4 1 0 0\n",
      " 0 0 4 1 0 1 4 0 4 1 0 1 1 1 4 0 3 0 1 0 4 0 0 1 1 1 1 1 1 4 0 3 1 4 3 3 0\n",
      " 4 3 1 1 0 1 0 0 3 1 0 0 1 1 0 1 3 3 1 0 4 3 1 4 0 1 0 3 3 4 0 1 1 0 0 0 1\n",
      " 1 0 3 4 0 0 1 4 0 1 3 0 1 4 4 3 0 1 0 4 1 1 4 1 4 0 1 1 4 1 4 1 3 0 1 3 0\n",
      " 1 0 1 4 1 1 1 4 4 3 0 0 3 0 4 4 0 0 1 4 0 3 0 1 0 3 0 0 1 1 1 4 3 0 4 1 1\n",
      " 1 4 0 1 4 1 4 2 3 3 4 0 4 4 4 0 4 3 4 4 4 1 0 4 1 1 0 4 0 0 4 1 1 1 0 0 4\n",
      " 0 1 3 1 2 3 1 0 4 4 1 1 0 3 1 4 3 0 0 1 3 3 0 4 1 4 4 0 4 1 1 0 4 1 3 1 3\n",
      " 0 1 4 4 0 1 3 1 0 2 0 4 0 1 4 3 2 0 0 1 4 4 0 0 4 1 1 0 1 0 0 1 4 4 4 2 4\n",
      " 4 2 1 4 2 0 0 4 4 1 1 1 4 0 0 4 3 4 1 4 2 1 0 0 0 2 1 0 0 4 1 3 1 1 4 0 3\n",
      " 1 3 4 0 4 1 0 3 1 0 0 2 1 1 0 4 0 0 0 2 1 4 1 1 1 1 4 1 1 3 1 0 2 1 0 1 4\n",
      " 2 1 4 0 4 0 0 0 0 0 0 1 4 4 1 2 1 0 0 2 2 4 1 3 0 0 0 0 1 4 1 3 4 2 1 0 1\n",
      " 4 1 1 1 0 2 4 2 0 1 1 0 0 0 3 1 4 1 0 1 3 0 0 3 0 1 4 0 4 3 0 4 4 0 4 0 0\n",
      " 0 2 4 1 0 1 3 1 0 1 3 1 2 1 2 0 4 0 0 0 0 4 4 1 3 0 1 3 1 4 1 0 3 1 2 4 0\n",
      " 0 4 0 2 4 1 4 0 1 1 0 4 0 0 0 4 2 0 0 0 0 1 0 4 2 0 4 0 0 4 0 3 4 4 4 2 1\n",
      " 0 0 1 3 0 3 4 0 1 0 1 0 3 1 0 0 0 1 4 0 2 4 0 4 0 1 1 0 0 3 0 0 3 0 4 1 0\n",
      " 2 0 0 1 0 0 4 1 3 1 0 0 4 1 0 1 0 4 3 1 1 4 3 0 4 1 0 1 4 1 1 3 1 2 0 3 0\n",
      " 3 0 4 4 0 0 0 0 1 4 2 4 1 1 3 1 0 4 1 0 3 4 0 4 4 4 1 4 1 0 4 0 1 2 1 1 1\n",
      " 1 0 0 1 1 0 1 4 2 0 4 0 4 1 0 1 4 1 1 1 1 3 1 4 1 1 3 1 1 0 0 1 0 4 0 3 1\n",
      " 0 3 4 1 0 0 0 0 4 0 1 3 4 4 0 3 0 1 1 3 3 4 1 0 3 0 0 0 0 3 0 1 0 3 1 4 0\n",
      " 3 3 4 1 3 4 4 4 1 3 4 0 1 3 0 1 1 1 1 2 4 3 0 1 1 3 4 0 1 0 2 1 1 1 1 0 1\n",
      " 1 0 0 4 4 1 0 3 1 3 0 0 0 1 0 1 3 0 3 1 3 1 1 1 4 0 1 0 1 3 1 4 3 3 2 0 3\n",
      " 4 0 1 4 4 4 4 3 0 4 0 4 3 0 1 1 0 1 1 4 0 4 0 3 1 1 1 0 1 0 1 4 4 0 4 1 1\n",
      " 4 0 2 1 4 0 0 1 1 1 2 3 2 1 1 0 0 4 3 0 1 1 1 1 0 0 3 4 3 1 3 0 1 4 0 1 0\n",
      " 0 0 1 1 0 0 4 0 1 0 4 1 1 0 3 1 3 0 4 0 0 4 3 0 4 0 3 4 3 0 3 1 3 1 3 0 0\n",
      " 1 0 3 1 4 3 1 0 0 1 1 4 0 1 1 1 4 4 4 0 0 3 3 1 4 0 4 1 1 0 3 0 1 0 3 0 1\n",
      " 3 3 0 1 3 3 3 3 1 0 3 1 1 0 3 0 3 0 0 0 4 1 3 3 3 1 1 1 4 4 0 4 3 1 1 0 4\n",
      " 0 3 0 3 0 0 3 4 3 1 4 1 3 0 0 0 4 0 1 0 1 1 1 1 1 1 3 1 1 0 4 0 4 0 1 1 0\n",
      " 1 4 0 1 1 0 1 0 0 1 4 1 1 2 0 0 1 1 0 1 1 1 3 3 3 2 0 1 1 1 0 1 0 0 4 0 3\n",
      " 1 0]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.2815\n",
      "============= RUN 5 ===============\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 534 K \n",
      "1 | decoder | Sequential | 534 K \n",
      "---------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0:  50%|▌| 40/80 [00:01<00:01, 21.83it/s, loss=0.747, val_loss=0.0717, avg\n",
      "Epoch 0:  65%|▋| 52/80 [00:01<00:01, 27.55it/s, loss=0.747, val_loss=0.0717, avg\n",
      "Epoch 0:  85%|▊| 68/80 [00:01<00:00, 34.16it/s, loss=0.747, val_loss=0.0717, avg\u001b[A\n",
      "Epoch 0: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.747, val_loss=0.114, avg_\u001b[A\n",
      "Epoch 1:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.0493, val_loss=0.114, avg\u001b[A\n",
      "Epoch 1:  60%|▌| 48/80 [00:01<00:01, 25.69it/s, loss=0.0493, val_loss=0.114, avg\n",
      "Epoch 1:  80%|▊| 64/80 [00:01<00:00, 32.31it/s, loss=0.0493, val_loss=0.114, avg\u001b[A\n",
      "Epoch 1: 100%|█| 80/80 [00:02<00:00, 38.10it/s, loss=0.0493, val_loss=0.0414, av\u001b[A\n",
      "Epoch 2:  50%|▌| 40/80 [00:01<00:01, 21.93it/s, loss=0.028, val_loss=0.0414, avg\u001b[A\n",
      "Epoch 2:  60%|▌| 48/80 [00:01<00:01, 25.87it/s, loss=0.028, val_loss=0.0414, avg\n",
      "Epoch 2:  80%|▊| 64/80 [00:01<00:00, 32.70it/s, loss=0.028, val_loss=0.0414, avg\u001b[A\n",
      "Epoch 2: 100%|█| 80/80 [00:02<00:00, 38.38it/s, loss=0.028, val_loss=0.0299, avg\u001b[A\n",
      "Epoch 3:  50%|▌| 40/80 [00:01<00:01, 21.70it/s, loss=0.0226, val_loss=0.0299, av\u001b[A\n",
      "Epoch 3:  60%|▌| 48/80 [00:01<00:01, 25.60it/s, loss=0.0226, val_loss=0.0299, av\n",
      "Epoch 3:  80%|▊| 64/80 [00:01<00:00, 32.37it/s, loss=0.0226, val_loss=0.0299, av\u001b[A\n",
      "Epoch 3: 100%|█| 80/80 [00:02<00:00, 38.01it/s, loss=0.0226, val_loss=0.0246, av\u001b[A\n",
      "Epoch 4:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.0191, val_loss=0.0246, av\u001b[A\n",
      "Epoch 4:  60%|▌| 48/80 [00:01<00:01, 25.96it/s, loss=0.0191, val_loss=0.0246, av\n",
      "Epoch 4:  80%|▊| 64/80 [00:01<00:00, 32.78it/s, loss=0.0191, val_loss=0.0246, av\u001b[A\n",
      "Epoch 4: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.0191, val_loss=0.021, avg\u001b[A\n",
      "Epoch 5:  50%|▌| 40/80 [00:01<00:01, 22.06it/s, loss=0.0164, val_loss=0.021, avg\u001b[A\n",
      "Epoch 5:  60%|▌| 48/80 [00:01<00:01, 26.03it/s, loss=0.0164, val_loss=0.021, avg\n",
      "Epoch 5:  80%|▊| 64/80 [00:01<00:00, 32.89it/s, loss=0.0164, val_loss=0.021, avg\u001b[A\n",
      "Epoch 5: 100%|█| 80/80 [00:02<00:00, 38.57it/s, loss=0.0164, val_loss=0.0179, av\u001b[A\n",
      "Epoch 6:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.0142, val_loss=0.0179, av\u001b[A\n",
      "Epoch 6:  60%|▌| 48/80 [00:01<00:01, 25.95it/s, loss=0.0142, val_loss=0.0179, av\n",
      "Epoch 6:  80%|▊| 64/80 [00:01<00:00, 32.79it/s, loss=0.0142, val_loss=0.0179, av\u001b[A\n",
      "Epoch 6: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.0142, val_loss=0.0154, av\u001b[A\n",
      "Epoch 7:  50%|▌| 40/80 [00:01<00:01, 21.77it/s, loss=0.0125, val_loss=0.0154, av\u001b[A\n",
      "Epoch 7:  60%|▌| 48/80 [00:01<00:01, 25.70it/s, loss=0.0125, val_loss=0.0154, av\n",
      "Epoch 7:  80%|▊| 64/80 [00:01<00:00, 32.47it/s, loss=0.0125, val_loss=0.0154, av\u001b[A\n",
      "Epoch 7: 100%|█| 80/80 [00:02<00:00, 38.13it/s, loss=0.0125, val_loss=0.0133, av\u001b[A\n",
      "Epoch 8:  50%|▌| 40/80 [00:01<00:01, 21.97it/s, loss=0.0112, val_loss=0.0133, av\u001b[A\n",
      "Epoch 8:  60%|▌| 48/80 [00:01<00:01, 25.94it/s, loss=0.0112, val_loss=0.0133, av\n",
      "Epoch 8:  80%|▊| 64/80 [00:01<00:00, 32.76it/s, loss=0.0112, val_loss=0.0133, av\u001b[A\n",
      "Epoch 8: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.0112, val_loss=0.0118, av\u001b[A\n",
      "Epoch 9:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.0102, val_loss=0.0118, av\u001b[A\n",
      "Epoch 9:  60%|▌| 48/80 [00:01<00:01, 25.84it/s, loss=0.0102, val_loss=0.0118, av\n",
      "Epoch 9:  80%|▊| 64/80 [00:01<00:00, 32.63it/s, loss=0.0102, val_loss=0.0118, av\u001b[A\n",
      "Epoch 9: 100%|█| 80/80 [00:02<00:00, 38.31it/s, loss=0.0102, val_loss=0.0106, av\u001b[A\n",
      "Epoch 10:  50%|▌| 40/80 [00:01<00:01, 22.04it/s, loss=0.00933, val_loss=0.0106, \u001b[A\n",
      "Epoch 10:  60%|▌| 48/80 [00:01<00:01, 26.02it/s, loss=0.00933, val_loss=0.0106, \n",
      "Epoch 10:  80%|▊| 64/80 [00:01<00:00, 32.86it/s, loss=0.00933, val_loss=0.0106, \u001b[A\n",
      "Epoch 10: 100%|█| 80/80 [00:02<00:00, 38.56it/s, loss=0.00933, val_loss=0.0093, \u001b[A\n",
      "Epoch 11:  50%|▌| 40/80 [00:01<00:01, 21.52it/s, loss=0.00868, val_loss=0.0093, \u001b[A\n",
      "Epoch 11:  60%|▌| 48/80 [00:01<00:01, 25.38it/s, loss=0.00868, val_loss=0.0093, \n",
      "Epoch 11:  80%|▊| 64/80 [00:01<00:00, 32.10it/s, loss=0.00868, val_loss=0.0093, \u001b[A\n",
      "Epoch 11: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00868, val_loss=0.00837,\u001b[A\n",
      "Epoch 12:  50%|▌| 40/80 [00:01<00:01, 21.49it/s, loss=0.00826, val_loss=0.00837,\u001b[A\n",
      "Epoch 12:  60%|▌| 48/80 [00:01<00:01, 25.35it/s, loss=0.00826, val_loss=0.00837,\n",
      "Epoch 12:  80%|▊| 64/80 [00:01<00:00, 32.07it/s, loss=0.00826, val_loss=0.00837,\u001b[A\n",
      "Epoch 12: 100%|█| 80/80 [00:02<00:00, 37.70it/s, loss=0.00826, val_loss=0.00786,\u001b[A\n",
      "Epoch 13:  50%|▌| 40/80 [00:01<00:01, 21.88it/s, loss=0.00791, val_loss=0.00786,\u001b[A\n",
      "Epoch 13:  60%|▌| 48/80 [00:01<00:01, 25.82it/s, loss=0.00791, val_loss=0.00786,\n",
      "Epoch 13:  80%|▊| 64/80 [00:01<00:00, 32.63it/s, loss=0.00791, val_loss=0.00786,\u001b[A\n",
      "Epoch 13: 100%|█| 80/80 [00:02<00:00, 38.30it/s, loss=0.00791, val_loss=0.0076, \u001b[A\n",
      "Epoch 14:  50%|▌| 40/80 [00:01<00:01, 21.84it/s, loss=0.00753, val_loss=0.0076, \u001b[A\n",
      "Epoch 14:  60%|▌| 48/80 [00:01<00:01, 25.77it/s, loss=0.00753, val_loss=0.0076, \n",
      "Epoch 14:  80%|▊| 64/80 [00:01<00:00, 32.57it/s, loss=0.00753, val_loss=0.0076, \u001b[A\n",
      "Epoch 14: 100%|█| 80/80 [00:02<00:00, 38.23it/s, loss=0.00753, val_loss=0.00705,\u001b[A\n",
      "Epoch 15:  50%|▌| 40/80 [00:01<00:01, 22.01it/s, loss=0.00711, val_loss=0.00705,\u001b[A\n",
      "Epoch 15:  60%|▌| 48/80 [00:01<00:01, 25.95it/s, loss=0.00711, val_loss=0.00705,\n",
      "Epoch 15:  80%|▊| 64/80 [00:01<00:00, 32.76it/s, loss=0.00711, val_loss=0.00705,\u001b[A\n",
      "Epoch 15: 100%|█| 80/80 [00:02<00:00, 38.48it/s, loss=0.00711, val_loss=0.00659,\u001b[A\n",
      "Epoch 16:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00685, val_loss=0.00659,\u001b[A\n",
      "Epoch 16:  60%|▌| 48/80 [00:01<00:01, 25.96it/s, loss=0.00685, val_loss=0.00659,\n",
      "Epoch 16:  80%|▊| 64/80 [00:01<00:00, 32.78it/s, loss=0.00685, val_loss=0.00659,\u001b[A\n",
      "Epoch 16: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00685, val_loss=0.00654,\u001b[A\n",
      "Epoch 17:  50%|▌| 40/80 [00:01<00:01, 21.87it/s, loss=0.00669, val_loss=0.00654,\u001b[A\n",
      "Epoch 17:  60%|▌| 48/80 [00:01<00:01, 25.81it/s, loss=0.00669, val_loss=0.00654,\n",
      "Epoch 17:  80%|▊| 64/80 [00:01<00:00, 32.62it/s, loss=0.00669, val_loss=0.00654,\u001b[A\n",
      "Epoch 17: 100%|█| 80/80 [00:02<00:00, 38.02it/s, loss=0.00669, val_loss=0.00655,\u001b[A\n",
      "Epoch 18:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00652, val_loss=0.00655,\u001b[A\n",
      "Epoch 18:  60%|▌| 48/80 [00:01<00:01, 25.90it/s, loss=0.00652, val_loss=0.00655,\n",
      "Epoch 18:  80%|▊| 64/80 [00:01<00:00, 32.75it/s, loss=0.00652, val_loss=0.00655,\u001b[A\n",
      "Epoch 18: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00652, val_loss=0.00634,\u001b[A\n",
      "Epoch 19:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00633, val_loss=0.00634,\u001b[A\n",
      "Epoch 19:  60%|▌| 48/80 [00:01<00:01, 25.90it/s, loss=0.00633, val_loss=0.00634,\n",
      "Epoch 19:  80%|▊| 64/80 [00:01<00:00, 32.72it/s, loss=0.00633, val_loss=0.00634,\u001b[A\n",
      "Epoch 19: 100%|█| 80/80 [00:02<00:00, 38.41it/s, loss=0.00633, val_loss=0.00615,\u001b[A\n",
      "Epoch 20:  50%|▌| 40/80 [00:01<00:01, 22.08it/s, loss=0.00619, val_loss=0.00615,\u001b[A\n",
      "Epoch 20:  60%|▌| 48/80 [00:01<00:01, 26.04it/s, loss=0.00619, val_loss=0.00615,\n",
      "Epoch 20:  80%|▊| 64/80 [00:01<00:00, 32.91it/s, loss=0.00619, val_loss=0.00615,\u001b[A\n",
      "Epoch 20: 100%|█| 80/80 [00:02<00:00, 38.61it/s, loss=0.00619, val_loss=0.00604,\u001b[A\n",
      "Epoch 21:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00614, val_loss=0.00604,\u001b[A\n",
      "Epoch 21:  60%|▌| 48/80 [00:01<00:01, 25.61it/s, loss=0.00614, val_loss=0.00604,\n",
      "Epoch 21:  80%|▊| 64/80 [00:01<00:00, 32.40it/s, loss=0.00614, val_loss=0.00604,\u001b[A\n",
      "Epoch 21: 100%|█| 80/80 [00:02<00:00, 38.04it/s, loss=0.00614, val_loss=0.00595,\u001b[A\n",
      "Epoch 22:  50%|▌| 40/80 [00:01<00:01, 21.51it/s, loss=0.00619, val_loss=0.00595,\u001b[A\n",
      "Epoch 22:  60%|▌| 48/80 [00:01<00:01, 25.34it/s, loss=0.00619, val_loss=0.00595,\n",
      "Epoch 22:  80%|▊| 64/80 [00:02<00:00, 31.90it/s, loss=0.00619, val_loss=0.00595,\u001b[A\n",
      "Epoch 22: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.00619, val_loss=0.00587,\u001b[A\n",
      "Epoch 23:  50%|▌| 40/80 [00:01<00:01, 21.96it/s, loss=0.00629, val_loss=0.00587,\u001b[A\n",
      "Epoch 23:  60%|▌| 48/80 [00:01<00:01, 25.92it/s, loss=0.00629, val_loss=0.00587,\n",
      "Epoch 23:  80%|▊| 64/80 [00:01<00:00, 32.72it/s, loss=0.00629, val_loss=0.00587,\u001b[A\n",
      "Epoch 23: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00629, val_loss=0.00566,\u001b[A\n",
      "Epoch 24:  50%|▌| 40/80 [00:01<00:01, 21.90it/s, loss=0.00642, val_loss=0.00566,\u001b[A\n",
      "Epoch 24:  60%|▌| 48/80 [00:01<00:01, 25.85it/s, loss=0.00642, val_loss=0.00566,\n",
      "Epoch 24:  80%|▊| 64/80 [00:01<00:00, 32.66it/s, loss=0.00642, val_loss=0.00566,\u001b[A\n",
      "Epoch 24: 100%|█| 80/80 [00:02<00:00, 38.34it/s, loss=0.00642, val_loss=0.00542,\u001b[A\n",
      "Epoch 25:  50%|▌| 40/80 [00:01<00:01, 22.07it/s, loss=0.00645, val_loss=0.00542,\u001b[A\n",
      "Epoch 25:  60%|▌| 48/80 [00:01<00:01, 26.05it/s, loss=0.00645, val_loss=0.00542,\n",
      "Epoch 25:  80%|▊| 64/80 [00:01<00:00, 32.89it/s, loss=0.00645, val_loss=0.00542,\u001b[A\n",
      "Epoch 25: 100%|█| 80/80 [00:02<00:00, 38.59it/s, loss=0.00645, val_loss=0.00575,\u001b[A\n",
      "Epoch 26:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00622, val_loss=0.00575,\u001b[A\n",
      "Epoch 26:  60%|▌| 48/80 [00:01<00:01, 25.91it/s, loss=0.00622, val_loss=0.00575,\n",
      "Epoch 26:  80%|▊| 64/80 [00:01<00:00, 32.73it/s, loss=0.00622, val_loss=0.00575,\u001b[A\n",
      "Epoch 26: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.00622, val_loss=0.00636,\u001b[A\n",
      "Epoch 27:  50%|▌| 40/80 [00:01<00:01, 21.91it/s, loss=0.00593, val_loss=0.00636,\u001b[A\n",
      "Epoch 27:  60%|▌| 48/80 [00:01<00:01, 25.87it/s, loss=0.00593, val_loss=0.00636,\n",
      "Epoch 27:  80%|▊| 64/80 [00:01<00:00, 32.67it/s, loss=0.00593, val_loss=0.00636,\u001b[A\n",
      "Epoch 27: 100%|█| 80/80 [00:02<00:00, 38.35it/s, loss=0.00593, val_loss=0.0062, \u001b[A\n",
      "Epoch 28:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00591, val_loss=0.0062, \u001b[A\n",
      "Epoch 28:  60%|▌| 48/80 [00:01<00:01, 25.90it/s, loss=0.00591, val_loss=0.0062, \n",
      "Epoch 28:  80%|▊| 64/80 [00:01<00:00, 32.74it/s, loss=0.00591, val_loss=0.0062, \u001b[A\n",
      "Epoch 28: 100%|█| 80/80 [00:02<00:00, 38.43it/s, loss=0.00591, val_loss=0.00595,\u001b[A\n",
      "Epoch 29:  50%|▌| 40/80 [00:01<00:01, 21.95it/s, loss=0.00607, val_loss=0.00595,\u001b[A\n",
      "Epoch 29:  60%|▌| 48/80 [00:01<00:01, 25.91it/s, loss=0.00607, val_loss=0.00595,\n",
      "Epoch 29:  80%|▊| 64/80 [00:01<00:00, 32.70it/s, loss=0.00607, val_loss=0.00595,\u001b[A\n",
      "Epoch 29: 100%|█| 80/80 [00:02<00:00, 38.40it/s, loss=0.00607, val_loss=0.00562,\u001b[A\n",
      "Epoch 30:  50%|▌| 40/80 [00:01<00:01, 21.85it/s, loss=0.00631, val_loss=0.00562,\u001b[A\n",
      "Epoch 30:  60%|▌| 48/80 [00:01<00:01, 25.79it/s, loss=0.00631, val_loss=0.00562,\n",
      "Epoch 30:  80%|▊| 64/80 [00:01<00:00, 32.59it/s, loss=0.00631, val_loss=0.00562,\u001b[A\n",
      "Epoch 30: 100%|█| 80/80 [00:02<00:00, 38.24it/s, loss=0.00631, val_loss=0.00517,\u001b[A\n",
      "Epoch 31:  50%|▌| 40/80 [00:01<00:01, 21.98it/s, loss=0.00637, val_loss=0.00517,\u001b[A\n",
      "Epoch 31:  60%|▌| 48/80 [00:01<00:01, 25.94it/s, loss=0.00637, val_loss=0.00517,\n",
      "Epoch 31:  80%|▊| 64/80 [00:01<00:00, 32.77it/s, loss=0.00637, val_loss=0.00517,\u001b[A\n",
      "Epoch 31: 100%|█| 80/80 [00:02<00:00, 38.46it/s, loss=0.00637, val_loss=0.00526,\u001b[A\n",
      "Epoch 32:  50%|▌| 40/80 [00:01<00:01, 21.94it/s, loss=0.00601, val_loss=0.00526,\u001b[A\n",
      "Epoch 32:  60%|▌| 48/80 [00:01<00:01, 25.89it/s, loss=0.00601, val_loss=0.00526,\n",
      "Epoch 32:  80%|▊| 64/80 [00:01<00:00, 32.72it/s, loss=0.00601, val_loss=0.00526,\u001b[A\n",
      "Epoch 32: 100%|█| 80/80 [00:02<00:00, 38.39it/s, loss=0.00601, val_loss=0.00608,\u001b[A\n",
      "Epoch 33:  50%|▌| 40/80 [00:01<00:01, 21.99it/s, loss=0.00553, val_loss=0.00608,\u001b[A\n",
      "Epoch 33:  60%|▌| 48/80 [00:01<00:01, 25.96it/s, loss=0.00553, val_loss=0.00608,\n",
      "Epoch 33:  80%|▊| 64/80 [00:01<00:00, 32.78it/s, loss=0.00553, val_loss=0.00608,\u001b[A\n",
      "Epoch 33: 100%|█| 80/80 [00:02<00:00, 38.44it/s, loss=0.00553, val_loss=0.0063, \u001b[A\n",
      "Epoch 34:  50%|▌| 40/80 [00:01<00:01, 22.00it/s, loss=0.00537, val_loss=0.0063, \u001b[A\n",
      "Epoch 34:  60%|▌| 48/80 [00:01<00:01, 25.96it/s, loss=0.00537, val_loss=0.0063, \n",
      "Epoch 34:  80%|▊| 64/80 [00:01<00:00, 32.79it/s, loss=0.00537, val_loss=0.0063, \u001b[A\n",
      "Epoch 34: 100%|█| 80/80 [00:02<00:00, 38.47it/s, loss=0.00537, val_loss=0.00638,\u001b[A\n",
      "Epoch 35:  50%|▌| 40/80 [00:01<00:01, 21.86it/s, loss=0.00543, val_loss=0.00638,\u001b[A\n",
      "Epoch 35:  60%|▌| 48/80 [00:01<00:01, 25.78it/s, loss=0.00543, val_loss=0.00638,\n",
      "Epoch 35:  80%|▊| 64/80 [00:01<00:00, 32.59it/s, loss=0.00543, val_loss=0.00638,\u001b[A\n",
      "Epoch 35: 100%|█| 80/80 [00:02<00:00, 38.26it/s, loss=0.00543, val_loss=0.00647,\u001b[A\n",
      "Epoch 36:  50%|▌| 40/80 [00:01<00:01, 21.48it/s, loss=0.00558, val_loss=0.00647,\u001b[A\n",
      "Epoch 36:  60%|▌| 48/80 [00:01<00:01, 25.34it/s, loss=0.00558, val_loss=0.00647,\n",
      "Epoch 36:  80%|▊| 64/80 [00:01<00:00, 32.07it/s, loss=0.00558, val_loss=0.00647,\u001b[A\n",
      "Epoch 36: 100%|█| 80/80 [00:02<00:00, 37.68it/s, loss=0.00558, val_loss=0.00617,\u001b[A\n",
      "Epoch 37:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.00563, val_loss=0.00617,\u001b[A\n",
      "Epoch 37:  60%|▌| 48/80 [00:01<00:01, 25.58it/s, loss=0.00563, val_loss=0.00617,\n",
      "Epoch 37:  80%|▊| 64/80 [00:01<00:00, 32.34it/s, loss=0.00563, val_loss=0.00617,\u001b[A\n",
      "Epoch 37: 100%|█| 80/80 [00:02<00:00, 37.96it/s, loss=0.00563, val_loss=0.00541,\u001b[A\n",
      "Epoch 38:  50%|▌| 40/80 [00:01<00:01, 21.72it/s, loss=0.00542, val_loss=0.00541,\u001b[A\n",
      "Epoch 38:  60%|▌| 48/80 [00:01<00:01, 25.65it/s, loss=0.00542, val_loss=0.00541,\n",
      "Epoch 38:  80%|▊| 64/80 [00:01<00:00, 32.42it/s, loss=0.00542, val_loss=0.00541,\u001b[A\n",
      "Epoch 38: 100%|█| 80/80 [00:02<00:00, 38.05it/s, loss=0.00542, val_loss=0.00521,\u001b[A\n",
      "Epoch 39:  50%|▌| 40/80 [00:01<00:01, 21.66it/s, loss=0.0051, val_loss=0.00521, \u001b[A\n",
      "Epoch 39:  60%|▌| 48/80 [00:01<00:01, 25.56it/s, loss=0.0051, val_loss=0.00521, \n",
      "Epoch 39:  80%|▊| 64/80 [00:01<00:00, 32.31it/s, loss=0.0051, val_loss=0.00521, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.95it/s, loss=0.0051, val_loss=0.00547, \u001b[A\n",
      "Epoch 39: 100%|█| 80/80 [00:02<00:00, 37.72it/s, loss=0.0051, val_loss=0.00547, \u001b[A\n",
      "Sizes of clusters: 549, 251, 357, 444, 399\n",
      "\n",
      "preds: [1 4 1 0 3 0 4 3 4 1 4 0 4 4 3 4 3 4 3 4 3 4 1 2 0 4 0 3 4 3 3 0 4 2 2 3 4\n",
      " 4 3 2 3 2 3 4 4 3 0 4 3 1 1 0 2 2 3 2 4 0 4 1 0 3 4 0 4 0 2 3 4 1 3 4 2 2\n",
      " 4 1 2 3 3 4 4 1 3 2 3 3 3 3 2 0 2 1 2 3 1 3 4 4 0 3 3 4 3 2 2 1 0 1 0 1 2\n",
      " 3 2 2 4 2 4 4 4 0 3 3 4 0 3 0 0 4 0 3 4 0 4 4 2 1 1 3 1 0 3 1 3 1 3 2 1 4\n",
      " 2 0 0 1 4 4 3 4 4 1 4 3 3 1 1 3 2 0 3 3 4 0 4 3 2 3 3 2 3 1 0 2 0 3 3 1 0\n",
      " 3 3 1 3 0 4 2 0 1 3 4 3 3 0 4 4 3 1 4 1 1 1 4 3 3 4 3 0 3 3 1 4 2 4 1 1 1\n",
      " 3 2 3 2 4 2 4 2 3 3 3 1 4 3 3 3 2 1 1 0 3 1 3 2 0 1 4 3 4 3 4 3 4 2 1 1 0\n",
      " 0 1 2 2 1 3 4 3 2 3 3 0 2 0 2 1 3 0 0 0 3 0 1 3 1 1 0 3 3 4 3 4 3 2 3 0 1\n",
      " 3 0 4 3 3 4 1 3 2 2 3 0 0 1 3 3 3 3 4 2 2 4 0 4 3 3 2 4 3 1 4 3 4 1 2 4 0\n",
      " 1 3 3 3 4 1 2 1 4 1 3 1 0 4 1 3 4 1 1 2 4 3 3 3 4 3 3 4 0 2 4 2 2 4 3 1 1\n",
      " 2 2 4 3 4 3 3 3 4 1 4 0 4 3 3 0 2 0 4 1 4 1 3 1 3 0 3 1 4 3 3 3 4 1 0 0 3\n",
      " 1 1 3 3 2 4 1 4 4 0 4 4 0 0 4 0 4 0 1 3 0 0 1 1 0 0 3 1 0 3 1 3 2 0 3 4 1\n",
      " 4 0 0 1 1 4 1 2 4 3 3 4 0 4 2 3 4 3 2 3 0 3 1 0 0 0 3 3 2 3 3 1 3 4 2 0 3\n",
      " 1 3 4 3 3 0 0 0 3 0 4 2 0 0 2 4 3 2 1 1 3 0 0 0 4 4 2 1 2 1 4 4 0 4 3 3 2\n",
      " 3 4 0 3 0 0 0 1 0 3 3 2 0 3 0 1 0 2 0 2 3 4 3 0 4 0 0 2 3 0 3 2 3 2 0 4 1\n",
      " 3 4 2 4 0 0 0 3 0 4 3 3 3 0 0 2 0 3 2 4 0 3 2 4 2 3 0 3 0 3 0 2 0 2 0 4 4\n",
      " 1 4 0 4 4 0 4 4 0 3 2 2 0 0 0 3 4 3 3 4 2 4 4 3 0 3 3 3 3 0 0 0 1 3 3 1 4\n",
      " 1 0 1 4 4 4 0 4 3 4 3 0 2 0 1 4 4 3 0 0 1 3 3 3 3 4 3 4 4 0 3 4 3 3 2 2 4\n",
      " 3 0 0 1 1 4 0 1 3 0 3 2 2 3 0 2 1 1 0 0 3 2 1 0 0 1 0 1 1 0 3 3 1 3 3 0 3\n",
      " 4 4 0 1 0 0 4 3 2 0 0 3 2 0 0 2 3 0 0 2 0 0 2 4 2 3 4 0 3 0 0 4 3 3 3 0 0\n",
      " 4 4 3 4 3 1 4 3 0 3 0 0 3 4 1 0 2 0 4 3 1 0 0 1 4 3 4 3 3 2 0 1 1 2 3 4 1\n",
      " 0 3 3 3 4 0 0 4 3 0 3 1 1 4 0 0 2 4 0 4 4 4 1 3 4 4 2 4 4 4 4 0 4 2 2 3 4\n",
      " 2 4 4 4 1 2 0 0 4 4 4 0 2 3 1 0 4 2 4 4 2 2 0 4 4 2 4 4 4 4 2 2 0 4 2 4 3\n",
      " 4 4 2 2 2 0 2 3 2 2 4 0 0 4 4 4 4 2 3 2 4 2 2 4 2 2 4 4 2 0 2 3 2 0 4 4 4\n",
      " 0 2 3 4 4 3 0 4 0 4 2 2 2 4 4 2 2 4 2 2 4 2 2 0 2 2 2 3 2 3 4 3 4 2 3 2 4\n",
      " 4 0 2 0 4 4 2 0 0 0 4 2 3 4 0 3 0 2 4 3 3 2 2 4 4 2 0 2 2 4 4 4 4 2 2 4 2\n",
      " 2 2 3 3 3 2 4 4 3 0 4 4 0 1 4 3 3 3 4 4 4 3 2 2 4 4 3 2 2 0 2 4 0 3 2 3 0\n",
      " 3 4 3 2 0 2 0 4 3 4 4 2 4 2 3 4 2 4 4 4 4 0 0 2 2 2 2 0 4 4 4 2 2 3 2 2 2\n",
      " 3 4 2 2 3 4 3 0 2 2 0 4 0 2 4 2 0 0 4 0 4 2 2 3 4 2 0 0 2 3 3 0 0 4 3 2 2\n",
      " 2 0 2 3 4 0 4 4 4 4 2 4 2 3 3 2 3 4 4 3 0 2 3 2 3 4 2 2 0 4 3 3 2 2 4 2 4\n",
      " 2 4 2 4 4 2 2 4 4 2 4 0 2 0 3 4 4 3 2 3 4 2 4 2 4 2 0 2 0 4 2 3 2 4 3 0 2\n",
      " 4 3 4 2 4 3 3 3 2 2 3 4 3 3 4 4 3 2 3 3 0 2 3 4 4 4 4 3 2 4 3 4 2 2 0 2 3\n",
      " 4 0 2 0 3 0 2 0 4 3 2 0 3 2 2 3 0 0 4 3 2 2 0 1 0 1 3 2 1 4 0 0 1 0 2 2 0\n",
      " 3 4 3 1 0 2 2 2 1 1 3 1 1 0 3 2 1 3 0 0 3 3 3 0 0 0 2 3 2 0 4 0 3 1 1 1 1\n",
      " 3 1 0 0 1 0 1 1 1 3 0 2 1 4 0 0 2 0 0 1 1 4 4 4 4 1 0 0 4 1 0 2 2 0 1 0 0\n",
      " 2 2 4 0 1 0 0 0 0 0 0 1 2 4 0 3 4 3 1 1 0 3 2 0 0 0 1 3 2 2 0 2 1 0 0 2 1\n",
      " 1 0 3 3 0 0 1 0 3 0 0 4 3 3 4 1 4 1 0 1 1 1 0 2 3 3 0 3 0 0 3 2 3 1 0 4 0\n",
      " 0 0 0 0 0 1 4 1 0 4 0 1 0 0 2 2 2 0 0 2 0 2 4 2 3 0 1 0 3 2 0 0 4 2 1 0 3\n",
      " 0 1 1 2 0 2 2 0 0 0 2 2 1 2 1 3 1 4 4 0 0 0 1 0 2 3 4 2 0 1 0 3 0 2 1 1 0\n",
      " 4 0 0 1 1 2 1 0 0 0 4 0 0 0 0 1 1 0 1 0 0 3 3 0 1 0 1 4 0 0 0 2 0 0 1 1 2\n",
      " 3 3 0 2 4 2 1 0 2 1 0 0 2 2 3 4 0 0 1 4 1 1 3 0 0 0 2 4 3 2 3 0 0 1 0 0 3\n",
      " 1 0 0 0 0 0 3 2 2 2 0 0 3 0 0 2 0 0 0 2 0 0 0 4 0 3 0 0 3 0 0 2 0 1 0 0 0\n",
      " 2 3 3 1 0 4 0 0 0 3 1 3 2 0 0 0 3 0 0 0 2 3 1 3 1 1 4 3 4 0 3 0 1 1 0 2 2\n",
      " 2 0 3 2 4 0 0 3 1 1 0 3 3 4 3 0 1 1 4 3 0 2 0 1 4 3 2 3 0 0 4 1 0 3 4 0 0\n",
      " 0 0 0 0 0 1 0 2 1 0 0 0 3 3 4 2 4 2 4 2 0 3 1 0 4 4 0 1 1 2 1 0 4 2 0 4 1\n",
      " 0 2 3 3 2 1 3 1 2 0 1 0 2 0 4 0 0 0 4 3 4 2 0 3 2 0 1 0 0 4 3 4 4 0 0 3 0\n",
      " 0 1 3 1 3 0 1 0 2 0 3 0 0 0 0 3 2 4 0 4 0 2 0 2 0 3 0 0 0 0 4 3 0 2 3 0 0\n",
      " 1 0 0 3 4 1 3 0 4 0 0 3 4 0 2 0 4 0 0 0 1 3 3 0 2 3 0 4 2 4 0 3 3 3 3 3 0\n",
      " 3 3 1 3 3 0 3 2 0 4 1 0 1 3 2 4 3 3 2 4 0 4 2 0 3 4 0 1 0 1 2 3 0 4 2 2 0\n",
      " 0 0 0 0 4 3 3 0 0 0 1 3 0 4 4 2 2 0 1 3 0 1 2 3 4 4 0 1 0 0 0 2 2 0 2 0 3\n",
      " 4 3 0 0 3 0 0 3 0 0 0 3 3 4 3 0 3 3 3 0 4 0 2 0 4 1 3 0 4 1 0 2 3 0 2 3 4\n",
      " 2 2 0 3 0 2 0 1 2 3 4 3 3 4 4 3 0 3 4 1 3 2 2 0 0 0 2 2 3 3 0 1 0 0 0 3 3\n",
      " 0 2 3 0 4 3 0 1 0 1 3 0 2 0 0 3 0 1 2 1 0 0 0 3 0 0 2 0 0 3 3 0 4 4 2 0 3\n",
      " 2 3 0 0 0 4 0 0 4 2 3 3 1 1 0 1 4 0 4 0 1 2 0 0 2 1 0 0 2 1 0 4 3 0 0 0 2\n",
      " 1 4]\n",
      "reals: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "\n",
      "Purity: 0.3145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Consistency: 0.2770\r\n",
      "Purity: 0.30870000000000003+-0.022885803459787007\r\n"
     ]
    }
   ],
   "source": [
    "!$sys.executable -m src.CAE.main \\\n",
    "    --data_dir 'data/simulated_Hawkes/tmp_trunc_K5_C5' \\\n",
    "    --verbose \\\n",
    "    --epochs 40 \\\n",
    "    --nruns 5 \\\n",
    "    --ext csv \\\n",
    "    --batch 50 \\\n",
    "    --n 8 \\\n",
    "    --N 10 \\\n",
    "    --nmb_cluster 5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AE_work_check.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00935d36cbe2450bb339073e50b5de39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0108dc4b44f54562a04ceb1e20e362ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_959140f0bd0e4aed988cbc945ab3dbab",
       "IPY_MODEL_6244cbed92d34f91a880028b60f1c15b"
      ],
      "layout": "IPY_MODEL_855186d2909c4d83b2df1a0333807103"
     }
    },
    "01451982d3454d60be9dcaffbbf7c130": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c51ac704be14ac1b1c9a32e45be6b65",
       "IPY_MODEL_954f4a096ebe490d8a380a9a640cc699"
      ],
      "layout": "IPY_MODEL_0e6ddc624dbc45b6b1cfa1cda9c0bdcf"
     }
    },
    "01685942f2734ccca2feafe3fade41b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02491e421bd445b8856f97c91ce6d07b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02b116a4544c4ce7beba7470ba52a0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "02f3fb0aef584ab5aa119bec8caccfeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ba531eb138c4493981a0e0233441efe",
       "IPY_MODEL_aa20c0119e0e4fc4a04e24c31efee353"
      ],
      "layout": "IPY_MODEL_e7feb148ae0d4d4c8afbd053742e9a7a"
     }
    },
    "0314ba08ed154cd2bce5dd1377a74414": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bef3ccd1393741288d9202a31cc5b103",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb714ee7a75c4ceca049fc6435981637",
      "value": 1
     }
    },
    "036608499bf541339cb2ec71dabb2dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "038d937ffd514d908b74622087e7e8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "03f2399c1a8b4faf82a7083054d25d78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0460602ee1314b14b07815efb8edd6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "04b0cc785562407ea8868351506963e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf908ffbc1764e7482ac02723be721d1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0552ab14b37341d1ae6303d8a38a1fd4",
      "value": 1
     }
    },
    "0552ab14b37341d1ae6303d8a38a1fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "065a9f9915014b97b19af23cecfbc115": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "066f02588e9c4f69a6741511ca58fe86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0729226619fb462a91d53afc4548ebdc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "076422f4d74d48dd8463a716f61b57a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9f5ce2ab98442f8b248deba980a6165",
      "placeholder": "​",
      "style": "IPY_MODEL_be86b11d15ff4c87ba48454db2a85832",
      "value": " 20/20 [00:00&lt;00:00, 89.75it/s]"
     }
    },
    "08381fa654224284ab7e13312749cb79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c76b7d4285a49b6b585b6ca70ae6313",
       "IPY_MODEL_e2c1b889f0754d549b4fc8759203cef7"
      ],
      "layout": "IPY_MODEL_94c5bdefed124d47a8959508dc1ec642"
     }
    },
    "086e0e7ba93a46bfbebb1024bb18532e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "09e6cb7ea45f415e99f6218bfe1d2c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd0b0f2e2bbf46dd9237b58d7be6fc9b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1b60f6fbaa64f30864bce855d419ef1",
      "value": 1
     }
    },
    "0a31ab3185094743bf57127cf30eac62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0a3248d246d5444d803f82dd5f0e4686": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a4c0e660fc64c1d82b346fb3aa2b0db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de52247d72e648aa8e6678535cbd5627",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4be8021c570f4221982030a58646071c",
      "value": 1
     }
    },
    "0be30989e3294545b8df622f4eca5c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbe227e7f07441c59118895e03b58c38",
      "placeholder": "​",
      "style": "IPY_MODEL_02491e421bd445b8856f97c91ce6d07b",
      "value": " 20/20 [00:00&lt;00:00, 116.17it/s]"
     }
    },
    "0c51ac704be14ac1b1c9a32e45be6b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4f2536bdf234406ba378665799dc83d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e79bd0abb42407290b42091df8286e2",
      "value": 1
     }
    },
    "0e6ddc624dbc45b6b1cfa1cda9c0bdcf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0e79bd0abb42407290b42091df8286e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0f1c9e098a834cc5b041bd2ee7fb2f67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "0f3fb7dc8f64420c95d8fc575be2a124": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9e9f04cb07e40e0992076538fd977ce",
      "placeholder": "​",
      "style": "IPY_MODEL_61b16571ee0848c3b8072ed68adc8a5a",
      "value": " 40/40 [00:01&lt;00:00, 36.23it/s, loss=0.00658, v_num=7, val_loss=0.00655, avg_val_loss=0.00655, avg_train_loss=0.00664]"
     }
    },
    "0f8794d7fde1477c8242251b884ffd62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ee4de039ad43f0870fcecf530715fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "12a3199a272f44588b8b99682c0fe01e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "12f6d7f0141641b1b9d249e37b1d3f70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47271ab19efe453fa173267d6f74637b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d460d17a1fc043c19d86fc4a8628ed7a",
      "value": 1
     }
    },
    "130d5cab186440bda9e727cfde740821": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "13763cd085ae49418871d2a10306137f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "13a4236c26da40629fed0f42dbe8fa5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15aa41a7250346768c6edafcf6cbb431": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "182039cd653441f48f11066410046cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1970c7190db140ccb953223f5fa82dae",
       "IPY_MODEL_3418fe31eef24ad2afc7da55819c841d"
      ],
      "layout": "IPY_MODEL_12a3199a272f44588b8b99682c0fe01e"
     }
    },
    "189302ae94a046e88f50d550501f1880": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18daaf64e3d848fd9b1b9d854a58fb84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1970c7190db140ccb953223f5fa82dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4775ad7a2f54e479ed8fb3f8a9c887d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac8497044fbb4d6a950411a8c67fad80",
      "value": 1
     }
    },
    "1992fe905ff5458cae9225b83d75f28e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a65b3fe4aec432a9cdea30567f1567e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a758f0047cf4bbbaad96b5dc3c74844": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30052827cc25461bb8b54391a16d20f2",
       "IPY_MODEL_46bc013d5e264307a7ea61332707b4b5"
      ],
      "layout": "IPY_MODEL_7755e2601894426c95674fd6bb33aed6"
     }
    },
    "1a797ee4de5749ca91e10053e6f00f44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1b931eecc71c443d94b27150593da60f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd97ec9ce2cc45bab0adfaaad9f076a1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00935d36cbe2450bb339073e50b5de39",
      "value": 1
     }
    },
    "1c44cc801b6c47febb227d0a07ebeae2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cc53ad90ac3472b914d646d6e35d42c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d18afbd32d644b0a707086478ae182d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1fc8e93566a44141a7b54b073e0a03b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71fe1fb4b9124a668f9912e2de27ede5",
      "placeholder": "​",
      "style": "IPY_MODEL_64a13e5087f04e71ae8e8cbe24537b64",
      "value": " 20/20 [00:00&lt;00:00, 119.43it/s]"
     }
    },
    "1ff10c0544a740c698cf2ca9851ac748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff88198fa5f4edab31f13aed80d656e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b99ef0017c34476a9d8b5bc108df2c6",
       "IPY_MODEL_828dc249e4a14121ab6b0c4421e20b26"
      ],
      "layout": "IPY_MODEL_83a4d2c72ea24924960d7323e6f0a8eb"
     }
    },
    "20bffea1038c4767a939738094127d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04b0cc785562407ea8868351506963e1",
       "IPY_MODEL_c61df9e4d1fa4e879efcda20abfdf3f0"
      ],
      "layout": "IPY_MODEL_13763cd085ae49418871d2a10306137f"
     }
    },
    "2180fd05050049a88344c036543467cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "22693c2a3ff246539ddc28f4e7bc1724": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22c344e037e145c78099ba838c3f81ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22e9d28be6fc44188bec37c359e73adf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a64d73a1cee84a3998d11e7cb4d999a6",
       "IPY_MODEL_a3711fe13ea749abb6fb6d280981311b"
      ],
      "layout": "IPY_MODEL_0f1c9e098a834cc5b041bd2ee7fb2f67"
     }
    },
    "22f6ef699cc241cd98820f7971ee5647": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9568a8e6e1fd4415afe1366f19fbfcdd",
      "placeholder": "​",
      "style": "IPY_MODEL_83c0fe00f1a6462b902e27cfd5495963",
      "value": " 20/20 [00:00&lt;00:00, 77.27it/s]"
     }
    },
    "244b7a2f44e74d6f9af6e6eba2af07a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24e84133686b4b9888f9be74594a72a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "252c400076f14669aa0b79561b790960": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_286b4317c21e495185cd46f08ff97252",
       "IPY_MODEL_733f604153674bce800aecdc3ec7188e"
      ],
      "layout": "IPY_MODEL_94ae06a3193440de9df45afb0a23e2f3"
     }
    },
    "27878bd1d1bc436384f5eb455a85c34a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c34923fd264fe288db6723c8b0d5b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286b4317c21e495185cd46f08ff97252": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5e9df6b808e4b97a192e7c890f05e22",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83e4ccf54f5f4f2b951ceb4f46244455",
      "value": 1
     }
    },
    "289d3a524ce2445aa2bf558bfbeddcfd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f55653ca484416a439098fe00b0da8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "290ad0658f474e4996741032146b458f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbcd6821c668470b8ac32c1c5e80ab76",
       "IPY_MODEL_eb52c4cf9cc644c5aaa14d753e50bc98"
      ],
      "layout": "IPY_MODEL_a21e5a24ce7642eaa1bca12a3c9a56d0"
     }
    },
    "2919241df6bf48798e66a1a720ee5cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_066f02588e9c4f69a6741511ca58fe86",
      "placeholder": "​",
      "style": "IPY_MODEL_24e84133686b4b9888f9be74594a72a3",
      "value": " 20/20 [00:00&lt;00:00, 112.69it/s]"
     }
    },
    "29612204b8084d5da6a69847b8acb3fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e1540f7845c4094b9b5b6285324f547",
       "IPY_MODEL_f2d40f6c3bcb48e3a2d4a3541cc8be0e"
      ],
      "layout": "IPY_MODEL_03f2399c1a8b4faf82a7083054d25d78"
     }
    },
    "2980517d76dd467fabced9483b9783a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "29c1acec829449aaa5e5414146acfbfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29eaddddf5264078be38680900b65895": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2a371a76905443db9361f76b36f29f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a6f667b916747408d83c06bbf758f1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c16a090e9134d19a9842ed20932ce71",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c998f2b45a740a7ba57897accac0222",
      "value": 1
     }
    },
    "2a913ccf5c894da0bb32e39d5a48bad7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b772a94569443ee88005e4dbe6791de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c0b5e36fd2b42b1ae2685bd72fe16b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0d2a32434a84f3cbcb50a78ed4943e1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02b116a4544c4ce7beba7470ba52a0dd",
      "value": 1
     }
    },
    "2c5e8fb1c6e540e3825c7476eb8ac52a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c6958b2cc474562b0290ce09eb3717b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27c34923fd264fe288db6723c8b0d5b1",
      "placeholder": "​",
      "style": "IPY_MODEL_edaabc8ea13d4f85904ca8cf57038692",
      "value": " 20/20 [00:00&lt;00:00, 60.82it/s]"
     }
    },
    "2d655cdf8ee6463dad7948faeaabc7fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2dc8c14573054c5d9cd766a6649f563b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d177b611e2df4d9c8e755b567babde40",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86d9dab4a08c49039e1fad5d1fe96f4b",
      "value": 1
     }
    },
    "2e012f55fbc6421cbf754db8c1db0908": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f8a114ee89941d28ec9e13d62d33b81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f8c729358c84d058470885257044e26": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2fda134405fc403ea133f68f40723cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc67f25602084b9283aeb9fb00f35946",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30b412486bdc48b0be754ca20b5889e9",
      "value": 1
     }
    },
    "30052827cc25461bb8b54391a16d20f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5def36a6054b48f1a4b0d65b06a70731",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e74518fc9cbf4a68b37c447006dd6c8d",
      "value": 1
     }
    },
    "30b412486bdc48b0be754ca20b5889e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "30c3b4a58a7e4b5b81a63bb267eb53ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "333bcd2a31c742d58231e567865345a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdda5ac6283d4225a513b23549eac446",
      "placeholder": "​",
      "style": "IPY_MODEL_036608499bf541339cb2ec71dabb2dd1",
      "value": " 20/20 [00:00&lt;00:00, 114.34it/s]"
     }
    },
    "33d459f33faf4d70839e9582f621e13b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "3418fe31eef24ad2afc7da55819c841d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94e87c5e141c443ab228414a15ebc4be",
      "placeholder": "​",
      "style": "IPY_MODEL_a25e30c482984decbec4326b96609ecb",
      "value": " 20/20 [00:00&lt;00:00, 99.47it/s]"
     }
    },
    "353bfbdb6a0f4ffbb629da239cf77633": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validation sanity check: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef8be5ef0f554e479484f71919348946",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43b1b6c2db86428fb38274ce5669237e",
      "value": 1
     }
    },
    "3595eea2b16941c7869700a3c67f13f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35f5e1e8f0b64a79a0d0719d56e19266": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c59e8cd0c98347748b7b9b05d6ef6786",
       "IPY_MODEL_51c6a25b6e3241f38684d3e4c6c0a6f5"
      ],
      "layout": "IPY_MODEL_d2abaf09fe964c768cf31b1c355f1f45"
     }
    },
    "35fa356c28094ed3a1e80bede8480786": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953f3d22ea03479ead46cd2abe6c667b",
      "placeholder": "​",
      "style": "IPY_MODEL_675fd1bc77ae400fad6391fea298f69c",
      "value": " 20/20 [00:00&lt;00:00, 116.51it/s]"
     }
    },
    "377dea38082a4ab09f7f448bbbb79014": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "3889858b04e34de79788b1610da790d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a9fbcba6dc5401dadeda04731e64ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a65b3fe4aec432a9cdea30567f1567e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_130d5cab186440bda9e727cfde740821",
      "value": 1
     }
    },
    "3bdc767e92b14b81bd426241d4313172": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c64f117342c46559787318cb8f5e51b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f3353d1fc5c456e8ab6e12d68be14f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f9f5d6af3204492ad310e83de3bf86d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40277c055fcb4541a11576a7eeff2ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8f689ec2ece44aca7d28a48abd09f12",
      "placeholder": "​",
      "style": "IPY_MODEL_a64fee502bf74b3396107f3622931999",
      "value": " 20/20 [00:00&lt;00:00, 99.33it/s]"
     }
    },
    "413356af4b29409a842fd6680296e234": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43b1b6c2db86428fb38274ce5669237e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "43b5eadb19484093a4dc4165d6aa1092": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f8794d7fde1477c8242251b884ffd62",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2d084d711ce49db8edfc46482e51d80",
      "value": 1
     }
    },
    "43eb3f866fd1447fa38a2995b39b1694": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46bc013d5e264307a7ea61332707b4b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_698c31b2ffa34430a3463ab0696dc1ea",
      "placeholder": "​",
      "style": "IPY_MODEL_ffb9fcf4724c4b30ba4ab35fe8104b1d",
      "value": " 20/20 [00:00&lt;00:00, 107.16it/s]"
     }
    },
    "46cdbe194e0b403ea228af56184e6ccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a5fa2fda2ce4d86a81dae0ec3f3dda3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55998df4a1d740e581f9c19cdb275b7c",
      "value": 1
     }
    },
    "47029dda85cb4a01ae1d1f116beb4b49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "471ebe9f70ca434a92bc279c2addb382": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47271ab19efe453fa173267d6f74637b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "480f17c3aba44ac0bd6667a463ba6516": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "48357801b7da4cb4a82fdd03f5754ca0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 49: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0dc723c55a147898e7d3999b1590dcd",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e32b39f6c8914cc8bdafd3d6c6507eaa",
      "value": 40
     }
    },
    "49865dd3dde74259b1239c3780d7f39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2dc8c14573054c5d9cd766a6649f563b",
       "IPY_MODEL_708f9eb4c7384f9aa7c1fc044c58b39d"
      ],
      "layout": "IPY_MODEL_57d5e710e76a43eebfef1eab8934ea61"
     }
    },
    "49b32cbc84e2454ea0919cb699416237": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "49d20b1c160f42e89c41f83487d6b82b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55d6937b5bf6401fad1484cfbd103424",
      "placeholder": "​",
      "style": "IPY_MODEL_ca057552d8ac454d8e4b5a53ca5b1b0a",
      "value": " 20/20 [00:00&lt;00:00, 106.82it/s]"
     }
    },
    "4a20fd2521044cd98e850de9a085eecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_646ca335037e42ac826ffdc32aea9dc6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f830ebd3e5864149aba7d3d6eef6b206",
      "value": 1
     }
    },
    "4a40f3c12dfa4743a41b4e9018efcac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4adcb1dacede4ddb8d4559b80a0e70ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "4adfa84a68864c2fb4dd877b97610047": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b0721fbafb540cbba849eb1762b196c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6510a104b2b2495c8a1b9a093b1e5856",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83eef57fefe7434ba8289b202585d9d7",
      "value": 1
     }
    },
    "4be8021c570f4221982030a58646071c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4c16a090e9134d19a9842ed20932ce71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e01f6590ae542739c803fa98ffd7e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b89637321d49d09a68618be5df9b82",
      "placeholder": "​",
      "style": "IPY_MODEL_fa03149453f14415a10456e4ab73257b",
      "value": " 20/20 [00:00&lt;00:00, 104.94it/s]"
     }
    },
    "4e3ed59924284d75a40dfcbad4865ace": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f369743273749cc9a7d4275e256295f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c493993a3eaa4200b577f96dbe2d4320",
      "placeholder": "​",
      "style": "IPY_MODEL_7833464c609042b4bd8348579c5ebd85",
      "value": " 20/20 [00:00&lt;00:00, 107.67it/s]"
     }
    },
    "4f4e85d0063d475a8db28986bccb2dd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4f5cb67a85164a3a9d37151761e869e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddbaf6210e7f4da48e54eec9486a0e47",
       "IPY_MODEL_6266051236c3466dbfdcb2da32cb26db"
      ],
      "layout": "IPY_MODEL_69a46b6be5a34c01a10e5ec99d65f8b6"
     }
    },
    "50482d6ee10a425690d03d81c27f272e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51c6a25b6e3241f38684d3e4c6c0a6f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b81cf92968d14cd5a8f3afd1f0f3720c",
      "placeholder": "​",
      "style": "IPY_MODEL_d602dfe71e8a4446aaf20f145a8617c1",
      "value": " 20/20 [00:00&lt;00:00, 114.60it/s]"
     }
    },
    "51de63f8d44845c29c993ef5ebd446c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "532dcef49684429e85b37e7314e5197e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53b3aed4e19f4b91b8e1cee828712b32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae379c20771b48f7aa895e8f91e8c0b4",
       "IPY_MODEL_a592f99916ce4600841ce3ec8b2fc370"
      ],
      "layout": "IPY_MODEL_51de63f8d44845c29c993ef5ebd446c4"
     }
    },
    "53f3fa57efc940599eacda1985313421": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53ff834af6744c86822600c6f79beb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "547f98d4389143239ca13ddfc302dad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5518bdbd3d484b5596effff7795710d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22c344e037e145c78099ba838c3f81ac",
      "placeholder": "​",
      "style": "IPY_MODEL_a52c3a411ecd46679b7391226734db6f",
      "value": " 20/20 [00:00&lt;00:00, 105.71it/s]"
     }
    },
    "556b87cfcf3f4110a450e24ff1ff6650": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30c3b4a58a7e4b5b81a63bb267eb53ac",
      "placeholder": "​",
      "style": "IPY_MODEL_f9d8ef8d11cb487994c8fb343ed60864",
      "value": " 20/20 [00:00&lt;00:00, 104.97it/s]"
     }
    },
    "55998df4a1d740e581f9c19cdb275b7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "55b27384aae14222b303e15039e2cb74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b39ac04c54224ca8b663e5eb671ca132",
       "IPY_MODEL_0be30989e3294545b8df622f4eca5c5a"
      ],
      "layout": "IPY_MODEL_9f77b55406b6434ba2c2c9941c23a27e"
     }
    },
    "55d6937b5bf6401fad1484cfbd103424": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d5e710e76a43eebfef1eab8934ea61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "59fc15e3b05548de91a8b016d7148385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_244b7a2f44e74d6f9af6e6eba2af07a2",
      "placeholder": "​",
      "style": "IPY_MODEL_edf0b93163cf439eaa9595756e5cdac4",
      "value": " 20/20 [00:00&lt;00:00, 115.04it/s]"
     }
    },
    "5be5a1fbf26442d28b9c210e7e2b4625": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0314ba08ed154cd2bce5dd1377a74414",
       "IPY_MODEL_d24ad53e4bea48229d6e27a7711657dd"
      ],
      "layout": "IPY_MODEL_b8074f41923b42f0ba52cec32fbf383d"
     }
    },
    "5c330dffc6b44466a33bc0cc3aeb4f2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d1c4c7315024609865172be2a8d0349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d6824c7ca5a4f43aeb6564362690d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5def36a6054b48f1a4b0d65b06a70731": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e1540f7845c4094b9b5b6285324f547": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbb4007e74bf48c49ff959a7383a31f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc56f7ebe3274dc6af868f95071e368c",
      "value": 1
     }
    },
    "5e20d8c7a3ab467f83695447b60f5acf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e59ea00645f47d2962ae3e33fb59974": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f51e705323f402d9ef26e8358540e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bddffe509ead40dcab566556e072c607",
       "IPY_MODEL_4e01f6590ae542739c803fa98ffd7e4b"
      ],
      "layout": "IPY_MODEL_2f8c729358c84d058470885257044e26"
     }
    },
    "5fbda4462c2a458ea27a170de5b31d3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60498c8c4daa4b4e90f9f7c7cf8a2d10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c38bd15cb024b73b05c3046bcc009c1",
       "IPY_MODEL_891bf6542ec64fd092b407961c815062"
      ],
      "layout": "IPY_MODEL_29eaddddf5264078be38680900b65895"
     }
    },
    "60e358bca2d04cbea092993bf5aee905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_289d3a524ce2445aa2bf558bfbeddcfd",
      "placeholder": "​",
      "style": "IPY_MODEL_dc75014b67cf47bb8b45cf2bed894d5c",
      "value": " 20/20 [00:00&lt;00:00, 97.82it/s]"
     }
    },
    "60fac6e7c9354f90b0f2a61759ae1b56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef218d053bd94fa99b70914be1582ce4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b265b9aba74145ecbe3918f67147bfc1",
      "value": 1
     }
    },
    "6108f118667c48d89097c493052cb739": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "61b16571ee0848c3b8072ed68adc8a5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6244cbed92d34f91a880028b60f1c15b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_413356af4b29409a842fd6680296e234",
      "placeholder": "​",
      "style": "IPY_MODEL_b4d219f5a03c4581b4153fb9d258799f",
      "value": " 20/20 [00:00&lt;00:00, 119.27it/s]"
     }
    },
    "6266051236c3466dbfdcb2da32cb26db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc0fe2bf88b34a93a416470a8a7afc2b",
      "placeholder": "​",
      "style": "IPY_MODEL_f685ec24b0b647c89a66781b0528a85d",
      "value": " 20/20 [00:00&lt;00:00, 117.52it/s]"
     }
    },
    "640f7ec74c7e4fb4a54b4f9ca22c0e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1b931eecc71c443d94b27150593da60f",
       "IPY_MODEL_b2425a1db89e4256b3135ca7bab8b220"
      ],
      "layout": "IPY_MODEL_086e0e7ba93a46bfbebb1024bb18532e"
     }
    },
    "6453e210c5274823bb35a3b9317add24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "646ca335037e42ac826ffdc32aea9dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6479c0fbb1d14504b81959d859cf24e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "64a13e5087f04e71ae8e8cbe24537b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64d30e7374f049939f104bfcf7861af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6510a104b2b2495c8a1b9a093b1e5856": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "653119329eb54d7daa70fd02eece2c0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6611dabf59404ecdbfd6e8746360346e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98b61935cfe7492c905d5f754b3ca210",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9fdb5eb3fdf74cbdba41f9ba091ac33c",
      "value": 1
     }
    },
    "66228a2c48c0407e93d134f3090a0ae5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66f9dbe6e0f14404b70e9ec58343ba85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "675fd1bc77ae400fad6391fea298f69c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67711b191b6e491cb9e813ca464a3f14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_353bfbdb6a0f4ffbb629da239cf77633",
       "IPY_MODEL_86cccc7243644d0faebe4e9e20726bbb"
      ],
      "layout": "IPY_MODEL_e45ce58113ba4f3db184667ca184e959"
     }
    },
    "67b3c765fe334f9b8181a7ad5dd82a5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6942e6b727db4765b1f70738c83d7ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dabc4d315d014d7f941cee2e6bb4ea32",
      "placeholder": "​",
      "style": "IPY_MODEL_4a40f3c12dfa4743a41b4e9018efcac6",
      "value": " 20/20 [00:00&lt;00:00, 118.41it/s]"
     }
    },
    "698c31b2ffa34430a3463ab0696dc1ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69a46b6be5a34c01a10e5ec99d65f8b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "6be30de2c4d14bb587bdd80f616210f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e6a006ae77d4375b21bb936400dbcca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe4d9d9223424e8a94c04d5162f041ed",
      "placeholder": "​",
      "style": "IPY_MODEL_8c7f6575be10492aaf519bfcf05f405a",
      "value": " 20/20 [00:00&lt;00:00, 120.66it/s]"
     }
    },
    "6ea9cef9893644b0af850e12634b21b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "7035ea47be1b4110b50acb28cbdfbc8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9905e86edb8473c85c46f9e1b6d1c5c",
       "IPY_MODEL_40277c055fcb4541a11576a7eeff2ac8"
      ],
      "layout": "IPY_MODEL_9d83433526264a6b9b2ac8c6e2d11f83"
     }
    },
    "708f9eb4c7384f9aa7c1fc044c58b39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba6bc799bb6845faa94b5d1098344041",
      "placeholder": "​",
      "style": "IPY_MODEL_ea9ed7f39a8248f393ca29f35b6cd110",
      "value": " 20/20 [00:00&lt;00:00, 120.61it/s]"
     }
    },
    "71fdc0af94614c93988fcea16b1baa87": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71fe1fb4b9124a668f9912e2de27ede5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "733f604153674bce800aecdc3ec7188e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b457390eaa7d42c3975ad513ae510ca7",
      "placeholder": "​",
      "style": "IPY_MODEL_3595eea2b16941c7869700a3c67f13f9",
      "value": " 20/20 [00:00&lt;00:00, 118.71it/s]"
     }
    },
    "73f40604416d46b2bb1fbe5b5ab64372": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7578cf0c94874c85b2ce237f2e08dc01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "757d0325a30441d786983ea4e5ac4818": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83cabe3c6161432ebe3b624009d7181d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7583b64f3bc14327b5a1eac6c1c03023",
      "value": 1
     }
    },
    "7583b64f3bc14327b5a1eac6c1c03023": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "77230f06ded2496ba6334a41d5e4fac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c44cc801b6c47febb227d0a07ebeae2",
      "placeholder": "​",
      "style": "IPY_MODEL_c4fd55a7497845a687b4bcf88724ade0",
      "value": " 20/20 [00:00&lt;00:00, 112.08it/s]"
     }
    },
    "7755e2601894426c95674fd6bb33aed6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "7833464c609042b4bd8348579c5ebd85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7931b051882a400baba1758c08a50a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f9f5d6af3204492ad310e83de3bf86d",
      "placeholder": "​",
      "style": "IPY_MODEL_15aa41a7250346768c6edafcf6cbb431",
      "value": " 20/20 [00:00&lt;00:00, 119.00it/s]"
     }
    },
    "7a4dc34d2ae7442c9cbde6ec8c2682a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b99ef0017c34476a9d8b5bc108df2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e20d8c7a3ab467f83695447b60f5acf",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_547f98d4389143239ca13ddfc302dad5",
      "value": 1
     }
    },
    "7ba531eb138c4493981a0e0233441efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3b49cf246564c93bdf18baf7d1dbc4e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0460602ee1314b14b07815efb8edd6e4",
      "value": 1
     }
    },
    "7bd5dd966a35440c90ca3688579d130d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdd7e31e5a1e4ad0bb6791910cddc9de",
      "placeholder": "​",
      "style": "IPY_MODEL_3c64f117342c46559787318cb8f5e51b",
      "value": " 20/20 [00:00&lt;00:00, 99.19it/s]"
     }
    },
    "7c06b162ad0f42499bb584b340ad4601": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "7c28178f5ff4434f84270c6474096cca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c76b7d4285a49b6b585b6ca70ae6313": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f8a114ee89941d28ec9e13d62d33b81",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10ee4de039ad43f0870fcecf530715fa",
      "value": 1
     }
    },
    "7e9006c933114db18b1cc6c11ef0352b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca89a24ed6a9403b88de44d29f70475b",
       "IPY_MODEL_2919241df6bf48798e66a1a720ee5cb0"
      ],
      "layout": "IPY_MODEL_f15e9b022d7c47f9ae608023d789fa21"
     }
    },
    "8119c2b5f97d4976ba44b5ae2da5bf72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fbda4462c2a458ea27a170de5b31d3b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a797ee4de5749ca91e10053e6f00f44",
      "value": 1
     }
    },
    "828dc249e4a14121ab6b0c4421e20b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c315ae4327e04f1dae7560ac9ae95d4e",
      "placeholder": "​",
      "style": "IPY_MODEL_b8c43f1d673746399924d8464ea2e8ee",
      "value": " 20/20 [00:00&lt;00:00, 88.24it/s]"
     }
    },
    "82c884bfcd9b4249a4262c5f9b228973": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b0721fbafb540cbba849eb1762b196c",
       "IPY_MODEL_d6c6b7d1bbac43c4b547af786ed8c036"
      ],
      "layout": "IPY_MODEL_e2a414ab0e2541a68035e283e69ddc44"
     }
    },
    "82e730ab744c44558699004797ac712e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "832b06b7f7dc4a04ac9acfe8ced21c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b577272e4a1e46db8be50117f425e59e",
      "placeholder": "​",
      "style": "IPY_MODEL_1ff10c0544a740c698cf2ca9851ac748",
      "value": " 20/20 [00:00&lt;00:00, 116.43it/s]"
     }
    },
    "834ff2370cb348858eb48be74c123c39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "837fed6a53104432bc1652296a09aaf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3315fcaca7044ae92f94b72f49db94e",
      "placeholder": "​",
      "style": "IPY_MODEL_53ff834af6744c86822600c6f79beb89",
      "value": " 20/20 [00:00&lt;00:00, 116.09it/s]"
     }
    },
    "83a4d2c72ea24924960d7323e6f0a8eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "83c0fe00f1a6462b902e27cfd5495963": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83cabe3c6161432ebe3b624009d7181d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83e4ccf54f5f4f2b951ceb4f46244455": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "83eef57fefe7434ba8289b202585d9d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "855186d2909c4d83b2df1a0333807103": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "86cccc7243644d0faebe4e9e20726bbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7e54c92ace64c47897536ab3205a51a",
      "placeholder": "​",
      "style": "IPY_MODEL_18daaf64e3d848fd9b1b9d854a58fb84",
      "value": " 2/2 [00:00&lt;00:00,  6.47it/s]"
     }
    },
    "86d9dab4a08c49039e1fad5d1fe96f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "891bf6542ec64fd092b407961c815062": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a3248d246d5444d803f82dd5f0e4686",
      "placeholder": "​",
      "style": "IPY_MODEL_e95952b66796443c93a8d908dd9880df",
      "value": " 20/20 [00:00&lt;00:00, 118.65it/s]"
     }
    },
    "891dee604875423fb69a034c0b5042bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d32abb5400ab428ebe0cb4d1d79bef72",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6793eaa029541539d83414a4e531294",
      "value": 1
     }
    },
    "8a1e9bd552594b4c8da61ac67cc7e951": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c0b5e36fd2b42b1ae2685bd72fe16b5",
       "IPY_MODEL_f9ba6371dc874d6185272fae4b27fe6a"
      ],
      "layout": "IPY_MODEL_6ea9cef9893644b0af850e12634b21b2"
     }
    },
    "8a5fa2fda2ce4d86a81dae0ec3f3dda3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b93ef2adbe34ca4b201fa0797209e37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bc0f140b2704250a3c0c64b1d57e3bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd7e5077aad7433484af71348d9f570f",
       "IPY_MODEL_832b06b7f7dc4a04ac9acfe8ced21c2c"
      ],
      "layout": "IPY_MODEL_7578cf0c94874c85b2ce237f2e08dc01"
     }
    },
    "8c7f6575be10492aaf519bfcf05f405a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92d0a0ce9a764511bcb1aeb4c8e49f45": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94ae06a3193440de9df45afb0a23e2f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "94c5bdefed124d47a8959508dc1ec642": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "94e87c5e141c443ab228414a15ebc4be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "953f3d22ea03479ead46cd2abe6c667b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954f4a096ebe490d8a380a9a640cc699": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a371a76905443db9361f76b36f29f5e",
      "placeholder": "​",
      "style": "IPY_MODEL_5e59ea00645f47d2962ae3e33fb59974",
      "value": " 20/20 [00:00&lt;00:00, 105.83it/s]"
     }
    },
    "9568a8e6e1fd4415afe1366f19fbfcdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "959140f0bd0e4aed988cbc945ab3dbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bdc767e92b14b81bd426241d4313172",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d1c4c7315024609865172be2a8d0349",
      "value": 1
     }
    },
    "97b67c9886d14621aee13ced8a9ca4e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c3eabfc412b41de89d28e10497e4a20",
      "placeholder": "​",
      "style": "IPY_MODEL_f531b36cb73d4e709e844557d267b063",
      "value": " 20/20 [00:00&lt;00:00, 115.13it/s]"
     }
    },
    "987b9401f0f14505ab7e2e49d699804a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "98b61935cfe7492c905d5f754b3ca210": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "990445afd1374533a7506e750a56238b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dac624fbeac342ebbe5553d83b683b79",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a31ab3185094743bf57127cf30eac62",
      "value": 1
     }
    },
    "995b2f954b54491b843917e1eabf1093": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "99b275574f7d4df0bd955f5993d2c7bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9a9f911d77c7420ead2f48bcf644b58a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9bc719992f2749d4af6bc9565044b333": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66228a2c48c0407e93d134f3090a0ae5",
      "placeholder": "​",
      "style": "IPY_MODEL_28f55653ca484416a439098fe00b0da8",
      "value": " 20/20 [00:00&lt;00:00, 117.43it/s]"
     }
    },
    "9c38bd15cb024b73b05c3046bcc009c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2aaf0b951dc4e2cac5077e9fb1b1116",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4b4e4140b6e460cb57bb7bcab98e9f4",
      "value": 1
     }
    },
    "9c3eabfc412b41de89d28e10497e4a20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c6251faf3f049c684c3781654f76540": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c998f2b45a740a7ba57897accac0222": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9d83433526264a6b9b2ac8c6e2d11f83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9dac5ef89ac44d4792e3c82856bead19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09e6cb7ea45f415e99f6218bfe1d2c50",
       "IPY_MODEL_9bc719992f2749d4af6bc9565044b333"
      ],
      "layout": "IPY_MODEL_6453e210c5274823bb35a3b9317add24"
     }
    },
    "9e25a085b1014df497bde74c907c98a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f95af6112ab7443788757f6166a8ddb2",
      "placeholder": "​",
      "style": "IPY_MODEL_9c6251faf3f049c684c3781654f76540",
      "value": " 20/20 [00:00&lt;00:00, 115.32it/s]"
     }
    },
    "9f77b55406b6434ba2c2c9941c23a27e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9fdb5eb3fdf74cbdba41f9ba091ac33c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a0c07667511549a2a5cf977ee5a0325d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0c19079b3df40f09dce39ddb9dd6e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aba8452fe55b446d98981eecdd2dfe57",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49b32cbc84e2454ea0919cb699416237",
      "value": 1
     }
    },
    "a0dc723c55a147898e7d3999b1590dcd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a21e5a24ce7642eaa1bca12a3c9a56d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "a25e30c482984decbec4326b96609ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3711fe13ea749abb6fb6d280981311b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0729226619fb462a91d53afc4548ebdc",
      "placeholder": "​",
      "style": "IPY_MODEL_a0c07667511549a2a5cf977ee5a0325d",
      "value": " 20/20 [00:00&lt;00:00, 117.10it/s]"
     }
    },
    "a3999601383e4d15b8ebe461c465bfc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73f40604416d46b2bb1fbe5b5ab64372",
      "placeholder": "​",
      "style": "IPY_MODEL_189302ae94a046e88f50d550501f1880",
      "value": " 20/20 [00:00&lt;00:00, 114.74it/s]"
     }
    },
    "a3b49cf246564c93bdf18baf7d1dbc4e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4561dcb30c242f6a986f3e3d9263218": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0c19079b3df40f09dce39ddb9dd6e20",
       "IPY_MODEL_4f369743273749cc9a7d4275e256295f"
      ],
      "layout": "IPY_MODEL_a68f8b42672b49938997c1dcd7c03bc8"
     }
    },
    "a4775ad7a2f54e479ed8fb3f8a9c887d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a52c3a411ecd46679b7391226734db6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a592f99916ce4600841ce3ec8b2fc370": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471ebe9f70ca434a92bc279c2addb382",
      "placeholder": "​",
      "style": "IPY_MODEL_6be30de2c4d14bb587bdd80f616210f3",
      "value": " 20/20 [00:00&lt;00:00, 109.01it/s]"
     }
    },
    "a5a35e92b82845ecaba4e1864dd63416": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed199103238c4b7ca5636b2a44a96c1d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66f9dbe6e0f14404b70e9ec58343ba85",
      "value": 1
     }
    },
    "a638f0d342fd41d897a25ccda418b6c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a64d73a1cee84a3998d11e7cb4d999a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27878bd1d1bc436384f5eb455a85c34a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6479c0fbb1d14504b81959d859cf24e9",
      "value": 1
     }
    },
    "a64fee502bf74b3396107f3622931999": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a68f8b42672b49938997c1dcd7c03bc8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "aa20c0119e0e4fc4a04e24c31efee353": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92d0a0ce9a764511bcb1aeb4c8e49f45",
      "placeholder": "​",
      "style": "IPY_MODEL_2e012f55fbc6421cbf754db8c1db0908",
      "value": " 20/20 [00:00&lt;00:00, 121.01it/s]"
     }
    },
    "aa84f8303d85425eab213d8096ad0170": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc7f5ef0038c4c79bb95b4bb0265d027",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_987b9401f0f14505ab7e2e49d699804a",
      "value": 1
     }
    },
    "aba8452fe55b446d98981eecdd2dfe57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac8497044fbb4d6a950411a8c67fad80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "acaaf7c81c7942a0a80878fc6f59ef3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a20fd2521044cd98e850de9a085eecd",
       "IPY_MODEL_556b87cfcf3f4110a450e24ff1ff6650"
      ],
      "layout": "IPY_MODEL_c148724c21c043889314bb8b0d4a17ce"
     }
    },
    "ade35fde974a4635a666414a2eb0ee3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fda134405fc403ea133f68f40723cdc",
       "IPY_MODEL_49d20b1c160f42e89c41f83487d6b82b"
      ],
      "layout": "IPY_MODEL_fb26bd75ad914bb398f302e3846c2bcb"
     }
    },
    "ae379c20771b48f7aa895e8f91e8c0b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c330dffc6b44466a33bc0cc3aeb4f2d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2980517d76dd467fabced9483b9783a2",
      "value": 1
     }
    },
    "af2fab836ea24b72b37407a0c35b6526": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43eb3f866fd1447fa38a2995b39b1694",
      "placeholder": "​",
      "style": "IPY_MODEL_532dcef49684429e85b37e7314e5197e",
      "value": " 20/20 [00:00&lt;00:00, 114.43it/s]"
     }
    },
    "afcbb516d10f4cfabae08bddf0f8bed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a4c0e660fc64c1d82b346fb3aa2b0db",
       "IPY_MODEL_6e6a006ae77d4375b21bb936400dbcca"
      ],
      "layout": "IPY_MODEL_f2d15e142f744484b86aeed8d044b666"
     }
    },
    "b0056a86f76f48e0adf14ab58173fd47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60fac6e7c9354f90b0f2a61759ae1b56",
       "IPY_MODEL_35fa356c28094ed3a1e80bede8480786"
      ],
      "layout": "IPY_MODEL_f4365c547eae4359a4304147042649e5"
     }
    },
    "b2425a1db89e4256b3135ca7bab8b220": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1992fe905ff5458cae9225b83d75f28e",
      "placeholder": "​",
      "style": "IPY_MODEL_4adfa84a68864c2fb4dd877b97610047",
      "value": " 20/20 [00:00&lt;00:00, 112.68it/s]"
     }
    },
    "b265b9aba74145ecbe3918f67147bfc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b39ac04c54224ca8b663e5eb671ca132": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3889858b04e34de79788b1610da790d8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0a6f63004a14f36ab798c5abeccc547",
      "value": 1
     }
    },
    "b444082f1a534eb88f7148f100891042": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b457390eaa7d42c3975ad513ae510ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4d219f5a03c4581b4153fb9d258799f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b577272e4a1e46db8be50117f425e59e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b72cab61e8144be5bccb2d1d8b5adc96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_beb4d84fed524fdeb17d47c3b6ee4e56",
       "IPY_MODEL_77230f06ded2496ba6334a41d5e4fac5"
      ],
      "layout": "IPY_MODEL_480f17c3aba44ac0bd6667a463ba6516"
     }
    },
    "b74ac848ccb243f0901e669b19f4344f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9ab2096b9c0447ebad38982d4467117",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_038d937ffd514d908b74622087e7e8b6",
      "value": 1
     }
    },
    "b8074f41923b42f0ba52cec32fbf383d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b81cf92968d14cd5a8f3afd1f0f3720c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b878af44359e461cb7ee85b46bc86315": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b8c43f1d673746399924d8464ea2e8ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8f689ec2ece44aca7d28a48abd09f12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f5ce2ab98442f8b248deba980a6165": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba6bc799bb6845faa94b5d1098344041": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb714ee7a75c4ceca049fc6435981637": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bb87c2950f4d4c63970c203cd46bbf06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbe227e7f07441c59118895e03b58c38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc197fd9659d457eba84e4366d33c280": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a9fbcba6dc5401dadeda04731e64ce2",
       "IPY_MODEL_7931b051882a400baba1758c08a50a79"
      ],
      "layout": "IPY_MODEL_4adcb1dacede4ddb8d4559b80a0e70ac"
     }
    },
    "bc56f7ebe3274dc6af868f95071e368c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bd0b0f2e2bbf46dd9237b58d7be6fc9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdd7e31e5a1e4ad0bb6791910cddc9de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bddffe509ead40dcab566556e072c607": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29c1acec829449aaa5e5414146acfbfa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7f1a6858e3e4a6bb7988fc1744b9614",
      "value": 1
     }
    },
    "be86b11d15ff4c87ba48454db2a85832": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "beb4d84fed524fdeb17d47c3b6ee4e56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71fdc0af94614c93988fcea16b1baa87",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c025120ce36242328e20aa30e3e3d082",
      "value": 1
     }
    },
    "bef3ccd1393741288d9202a31cc5b103": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfb2357a566a40e6b4f8c6bc3f309470": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e3ed59924284d75a40dfcbad4865ace",
      "placeholder": "​",
      "style": "IPY_MODEL_c469690573144ad09516f1e2f830c75e",
      "value": " 20/20 [00:00&lt;00:00, 111.19it/s]"
     }
    },
    "bfeb1a460fc24c0eabcdba8d6cc53b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebe02df0abe9433e954d62e330e896e5",
       "IPY_MODEL_6942e6b727db4765b1f70738c83d7ca2"
      ],
      "layout": "IPY_MODEL_feecd17c905340db837d7e698a1705a7"
     }
    },
    "c025120ce36242328e20aa30e3e3d082": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c0d2a32434a84f3cbcb50a78ed4943e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c148724c21c043889314bb8b0d4a17ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c315ae4327e04f1dae7560ac9ae95d4e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c469690573144ad09516f1e2f830c75e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c493993a3eaa4200b577f96dbe2d4320": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4fd55a7497845a687b4bcf88724ade0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4fdae9e786d45b887b80300fd71fc75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b772a94569443ee88005e4dbe6791de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d18afbd32d644b0a707086478ae182d",
      "value": 1
     }
    },
    "c59e8cd0c98347748b7b9b05d6ef6786": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50482d6ee10a425690d03d81c27f272e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f4e85d0063d475a8db28986bccb2dd9",
      "value": 1
     }
    },
    "c61df9e4d1fa4e879efcda20abfdf3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01685942f2734ccca2feafe3fade41b5",
      "placeholder": "​",
      "style": "IPY_MODEL_1cc53ad90ac3472b914d646d6e35d42c",
      "value": " 20/20 [00:00&lt;00:00, 94.46it/s]"
     }
    },
    "c637820d65d54d2292767453f84a1f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48357801b7da4cb4a82fdd03f5754ca0",
       "IPY_MODEL_0f3fb7dc8f64420c95d8fc575be2a124"
      ],
      "layout": "IPY_MODEL_2180fd05050049a88344c036543467cc"
     }
    },
    "c6997b2dfea747e2af968d5a899f72a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b74ac848ccb243f0901e669b19f4344f",
       "IPY_MODEL_9e25a085b1014df497bde74c907c98a8"
      ],
      "layout": "IPY_MODEL_82e730ab744c44558699004797ac712e"
     }
    },
    "c7d3a93f3d5f44619ac419180e07a354": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd5181a0d70248868934eb9dd7ce81e8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f388685404884d35a67dd947eb9bd787",
      "value": 1
     }
    },
    "c8382f6d65fc4f6f867159d3f10ba48f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c93d329ad81541eebc0ed2a0e929417b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_757d0325a30441d786983ea4e5ac4818",
       "IPY_MODEL_1fc8e93566a44141a7b54b073e0a03b8"
      ],
      "layout": "IPY_MODEL_065a9f9915014b97b19af23cecfbc115"
     }
    },
    "c98e202da2024d99ac6794dff592aa9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c9905e86edb8473c85c46f9e1b6d1c5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de696048bf1b480a95d3179af25cebf7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2d655cdf8ee6463dad7948faeaabc7fb",
      "value": 1
     }
    },
    "ca057552d8ac454d8e4b5a53ca5b1b0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca89a24ed6a9403b88de44d29f70475b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0ad02bc879f49c5a8ea563111e4c10b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8382f6d65fc4f6f867159d3f10ba48f",
      "value": 1
     }
    },
    "cc67f25602084b9283aeb9fb00f35946": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc7f5ef0038c4c79bb95b4bb0265d027": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd97ec9ce2cc45bab0adfaaad9f076a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdda5ac6283d4225a513b23549eac446": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf908ffbc1764e7482ac02723be721d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0a6f63004a14f36ab798c5abeccc547": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d0ad02bc879f49c5a8ea563111e4c10b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d177b611e2df4d9c8e755b567babde40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d208ae91fb844150bb2125d90c686296": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d24ad53e4bea48229d6e27a7711657dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53f3fa57efc940599eacda1985313421",
      "placeholder": "​",
      "style": "IPY_MODEL_7a4dc34d2ae7442c9cbde6ec8c2682a7",
      "value": " 20/20 [00:00&lt;00:00, 119.70it/s]"
     }
    },
    "d2abaf09fe964c768cf31b1c355f1f45": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "d312a1f5aea043a09bd240fa9b27af80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d32abb5400ab428ebe0cb4d1d79bef72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d460d17a1fc043c19d86fc4a8628ed7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d4af770cd4b04a1b9642df9fdcaae084": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4fdae9e786d45b887b80300fd71fc75",
       "IPY_MODEL_837fed6a53104432bc1652296a09aaf3"
      ],
      "layout": "IPY_MODEL_e1f2ab178370438489ee4318ab86c413"
     }
    },
    "d4b4e4140b6e460cb57bb7bcab98e9f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d5e6788b83884012a02abe0fbd53426b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa84f8303d85425eab213d8096ad0170",
       "IPY_MODEL_2c6958b2cc474562b0290ce09eb3717b"
      ],
      "layout": "IPY_MODEL_47029dda85cb4a01ae1d1f116beb4b49"
     }
    },
    "d5e9df6b808e4b97a192e7c890f05e22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d602dfe71e8a4446aaf20f145a8617c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d64b0a2cd28d434ba7469dce8ac63c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_990445afd1374533a7506e750a56238b",
       "IPY_MODEL_60e358bca2d04cbea092993bf5aee905"
      ],
      "layout": "IPY_MODEL_df2f16c0451c4090b4f295462326b5d2"
     }
    },
    "d6c6b7d1bbac43c4b547af786ed8c036": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb87c2950f4d4c63970c203cd46bbf06",
      "placeholder": "​",
      "style": "IPY_MODEL_d208ae91fb844150bb2125d90c686296",
      "value": " 20/20 [00:00&lt;00:00, 112.98it/s]"
     }
    },
    "d7c9ca3124fd481faabe97dfd1b66784": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f1a6858e3e4a6bb7988fc1744b9614": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d9e9f04cb07e40e0992076538fd977ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dab47226f6324ef3a9c47a2981d489c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "dabc4d315d014d7f941cee2e6bb4ea32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dac624fbeac342ebbe5553d83b683b79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbcd6821c668470b8ac32c1c5e80ab76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d312a1f5aea043a09bd240fa9b27af80",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64d30e7374f049939f104bfcf7861af9",
      "value": 1
     }
    },
    "dc0fe2bf88b34a93a416470a8a7afc2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc75014b67cf47bb8b45cf2bed894d5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd5181a0d70248868934eb9dd7ce81e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddbaf6210e7f4da48e54eec9486a0e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22693c2a3ff246539ddc28f4e7bc1724",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_653119329eb54d7daa70fd02eece2c0b",
      "value": 1
     }
    },
    "de52247d72e648aa8e6678535cbd5627": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de696048bf1b480a95d3179af25cebf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df2f16c0451c4090b4f295462326b5d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e0beaebbcc31475cbcdc4453833cc200": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a638f0d342fd41d897a25ccda418b6c3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b878af44359e461cb7ee85b46bc86315",
      "value": 1
     }
    },
    "e1f2ab178370438489ee4318ab86c413": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e2a414ab0e2541a68035e283e69ddc44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e2aaf0b951dc4e2cac5077e9fb1b1116": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c1b889f0754d549b4fc8759203cef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c28178f5ff4434f84270c6474096cca",
      "placeholder": "​",
      "style": "IPY_MODEL_834ff2370cb348858eb48be74c123c39",
      "value": " 20/20 [00:00&lt;00:00, 97.99it/s]"
     }
    },
    "e32b39f6c8914cc8bdafd3d6c6507eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e45ce58113ba4f3db184667ca184e959": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e4b89637321d49d09a68618be5df9b82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4f2536bdf234406ba378665799dc83d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5477dd576c2434a9ca099d4302fe634": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a6f667b916747408d83c06bbf758f1e",
       "IPY_MODEL_22f6ef699cc241cd98820f7971ee5647"
      ],
      "layout": "IPY_MODEL_dab47226f6324ef3a9c47a2981d489c5"
     }
    },
    "e54e67d6197d4d07b93f917788ca435d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e6793eaa029541539d83414a4e531294": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e6c328aa4d324cb08f7f217c64c0f373": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46cdbe194e0b403ea228af56184e6ccc",
       "IPY_MODEL_97b67c9886d14621aee13ced8a9ca4e5"
      ],
      "layout": "IPY_MODEL_99b275574f7d4df0bd955f5993d2c7bc"
     }
    },
    "e743eb9f3ed644589ea492797c0e1c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_891dee604875423fb69a034c0b5042bd",
       "IPY_MODEL_333bcd2a31c742d58231e567865345a6"
      ],
      "layout": "IPY_MODEL_6108f118667c48d89097c493052cb739"
     }
    },
    "e74518fc9cbf4a68b37c447006dd6c8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e7e54c92ace64c47897536ab3205a51a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7feb148ae0d4d4c8afbd053742e9a7a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e8c31b73bd8e4832a068b18c6a9a1d74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5a35e92b82845ecaba4e1864dd63416",
       "IPY_MODEL_59fc15e3b05548de91a8b016d7148385"
      ],
      "layout": "IPY_MODEL_c98e202da2024d99ac6794dff592aa9e"
     }
    },
    "e8d4a01e2f904fb192b2ae655975b3cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7d3a93f3d5f44619ac419180e07a354",
       "IPY_MODEL_076422f4d74d48dd8463a716f61b57a1"
      ],
      "layout": "IPY_MODEL_7c06b162ad0f42499bb584b340ad4601"
     }
    },
    "e95952b66796443c93a8d908dd9880df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9ab2096b9c0447ebad38982d4467117": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea8077bc212c4fc988e38913c5eaabaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0beaebbcc31475cbcdc4453833cc200",
       "IPY_MODEL_af2fab836ea24b72b37407a0c35b6526"
      ],
      "layout": "IPY_MODEL_9a9f911d77c7420ead2f48bcf644b58a"
     }
    },
    "ea9ed7f39a8248f393ca29f35b6cd110": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb52c4cf9cc644c5aaa14d753e50bc98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67b3c765fe334f9b8181a7ad5dd82a5c",
      "placeholder": "​",
      "style": "IPY_MODEL_3f3353d1fc5c456e8ab6e12d68be14f1",
      "value": " 20/20 [00:00&lt;00:00, 115.36it/s]"
     }
    },
    "ebe02df0abe9433e954d62e330e896e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13a4236c26da40629fed0f42dbe8fa5e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f950bb6e9825481082c35fad113e67c9",
      "value": 1
     }
    },
    "ed199103238c4b7ca5636b2a44a96c1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edaabc8ea13d4f85904ca8cf57038692": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edb9d96a9ee74a0e876590a3df7afc60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12f6d7f0141641b1b9d249e37b1d3f70",
       "IPY_MODEL_5518bdbd3d484b5596effff7795710d8"
      ],
      "layout": "IPY_MODEL_e54e67d6197d4d07b93f917788ca435d"
     }
    },
    "edf0b93163cf439eaa9595756e5cdac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef218d053bd94fa99b70914be1582ce4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef8be5ef0f554e479484f71919348946": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0b113817ccf4b26a06819cef7299edb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43b5eadb19484093a4dc4165d6aa1092",
       "IPY_MODEL_7bd5dd966a35440c90ca3688579d130d"
      ],
      "layout": "IPY_MODEL_377dea38082a4ab09f7f448bbbb79014"
     }
    },
    "f15e9b022d7c47f9ae608023d789fa21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f1b60f6fbaa64f30864bce855d419ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f2d084d711ce49db8edfc46482e51d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f2d15e142f744484b86aeed8d044b666": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f2d40f6c3bcb48e3a2d4a3541cc8be0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b93ef2adbe34ca4b201fa0797209e37",
      "placeholder": "​",
      "style": "IPY_MODEL_2a913ccf5c894da0bb32e39d5a48bad7",
      "value": " 20/20 [00:00&lt;00:00, 117.27it/s]"
     }
    },
    "f3315fcaca7044ae92f94b72f49db94e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f388685404884d35a67dd947eb9bd787": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f4365c547eae4359a4304147042649e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f531b36cb73d4e709e844557d267b063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f685ec24b0b647c89a66781b0528a85d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f830ebd3e5864149aba7d3d6eef6b206": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f8ee4947c1bc4bbfbdc9dbe1ced07e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6611dabf59404ecdbfd6e8746360346e",
       "IPY_MODEL_a3999601383e4d15b8ebe461c465bfc4"
      ],
      "layout": "IPY_MODEL_995b2f954b54491b843917e1eabf1093"
     }
    },
    "f950bb6e9825481082c35fad113e67c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f95af6112ab7443788757f6166a8ddb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9ba6371dc874d6185272fae4b27fe6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b444082f1a534eb88f7148f100891042",
      "placeholder": "​",
      "style": "IPY_MODEL_d7c9ca3124fd481faabe97dfd1b66784",
      "value": " 20/20 [00:00&lt;00:00, 104.29it/s]"
     }
    },
    "f9d8ef8d11cb487994c8fb343ed60864": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa03149453f14415a10456e4ab73257b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb26bd75ad914bb398f302e3846c2bcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "fbb4007e74bf48c49ff959a7383a31f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc72f9f9c94347f2b879d4e2a650a447": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8119c2b5f97d4976ba44b5ae2da5bf72",
       "IPY_MODEL_bfb2357a566a40e6b4f8c6bc3f309470"
      ],
      "layout": "IPY_MODEL_33d459f33faf4d70839e9582f621e13b"
     }
    },
    "fd7e5077aad7433484af71348d9f570f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c5e8fb1c6e540e3825c7476eb8ac52a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d6824c7ca5a4f43aeb6564362690d64",
      "value": 1
     }
    },
    "fe4d9d9223424e8a94c04d5162f041ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feecd17c905340db837d7e698a1705a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "ffb9fcf4724c4b30ba4ab35fe8104b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
