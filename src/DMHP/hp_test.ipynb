{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from HP import PointProcessStorage, DirichletMixtureModel, EM_clustering\n",
    "from metrics import consistency, purity\n",
    "from data_utils import load_data"
   ]
  },
  {
   "source": [
    "### IPTV Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'IPTV_Data')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=300, type='txt', datetime=True, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(49.3723), tensor(49.8660))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ss[0][-1, 0], Ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ss)):\n",
    "#     ss[i] = ss[i][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (2.*(k+1)**2) ) for k in range(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(class2idx)\n",
    "K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.65s/it]\u001b[A\n",
      "NLL / N: 537.3705\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:42, 34.08s/it]\u001b[A\n",
      "NLL / N: 596.5760\n",
      "\n",
      " 60%|██████    | 3/5 [01:36<01:07, 33.93s/it]\u001b[A\n",
      "NLL / N: 587.5982\n",
      "\n",
      " 80%|████████  | 4/5 [02:15<00:35, 35.21s/it]\u001b[A\n",
      "NLL / N: 601.1137\n",
      "\n",
      "100%|██████████| 5/5 [02:58<00:00, 35.79s/it]\n",
      "NLL / N: 645.3842\n",
      "\n",
      " 10%|█         | 1/10 [03:50<34:37, 230.82s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: nan\n",
      "\n",
      " 20%|██        | 1/5 [00:38<02:32, 38.19s/it]\u001b[A\n",
      "NLL / N: 522.6370\n",
      "\n",
      " 40%|████      | 2/5 [01:05<01:44, 34.94s/it]\u001b[A\n",
      "NLL / N: 516.6924\n",
      "\n",
      " 60%|██████    | 3/5 [01:42<01:11, 35.68s/it]\u001b[A\n",
      "NLL / N: 482.7739\n",
      "\n",
      " 80%|████████  | 4/5 [02:23<00:37, 37.17s/it]\u001b[A\n",
      "NLL / N: 487.5942\n",
      "\n",
      "100%|██████████| 5/5 [03:09<00:00, 37.82s/it]\n",
      "NLL / N: 559.7852\n",
      "\n",
      " 20%|██        | 2/10 [07:49<31:05, 233.22s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3361\n",
      "\n",
      " 20%|██        | 1/5 [00:38<02:33, 38.25s/it]\u001b[A\n",
      "NLL / N: 531.1342\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:43, 34.39s/it]\u001b[A\n",
      "NLL / N: 497.7358\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.75s/it]\u001b[A\n",
      "NLL / N: 443.5218\n",
      "\n",
      " 80%|████████  | 4/5 [02:19<00:36, 36.42s/it]\u001b[A\n",
      "NLL / N: 404.2956\n",
      "\n",
      "100%|██████████| 5/5 [03:08<00:00, 37.65s/it]\n",
      "NLL / N: 441.0808\n",
      "\n",
      " 30%|███       | 3/10 [11:47<27:21, 234.50s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.2927\n",
      "\n",
      " 20%|██        | 1/5 [00:36<02:26, 36.73s/it]\u001b[A\n",
      "NLL / N: 506.3757\n",
      "\n",
      " 40%|████      | 2/5 [01:02<01:40, 33.50s/it]\u001b[A\n",
      "NLL / N: 518.5385\n",
      "\n",
      " 60%|██████    | 3/5 [01:40<01:09, 34.88s/it]\u001b[A\n",
      "NLL / N: 527.1872\n",
      "\n",
      " 80%|████████  | 4/5 [02:22<00:36, 36.94s/it]\u001b[A\n",
      "NLL / N: 485.8402\n",
      "\n",
      "100%|██████████| 5/5 [03:09<00:00, 37.92s/it]\n",
      "NLL / N: 491.8597\n",
      "\n",
      " 40%|████      | 4/10 [15:46<23:35, 235.94s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.2970\n",
      "\n",
      " 20%|██        | 1/5 [00:39<02:36, 39.07s/it]\u001b[A\n",
      "NLL / N: 490.2220\n",
      "\n",
      " 40%|████      | 2/5 [01:07<01:47, 35.83s/it]\u001b[A\n",
      "NLL / N: 551.2139\n",
      "\n",
      " 60%|██████    | 3/5 [01:44<01:12, 36.33s/it]\u001b[A\n",
      "NLL / N: 573.0693\n",
      "\n",
      " 80%|████████  | 4/5 [02:27<00:38, 38.21s/it]\u001b[A\n",
      "NLL / N: 561.0652\n",
      "\n",
      "100%|██████████| 5/5 [03:15<00:00, 39.16s/it]\n",
      "NLL / N: 570.0848\n",
      "\n",
      " 50%|█████     | 5/10 [19:52<19:54, 238.86s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3131\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.56s/it]\u001b[A\n",
      "NLL / N: 505.1434\n",
      "\n",
      " 40%|████      | 2/5 [01:04<01:43, 34.35s/it]\u001b[A\n",
      "NLL / N: 511.3603\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.53s/it]\u001b[A\n",
      "NLL / N: 533.3947\n",
      "\n",
      " 80%|████████  | 4/5 [02:18<00:36, 36.02s/it]\u001b[A\n",
      "NLL / N: 576.7228\n",
      "\n",
      "100%|██████████| 5/5 [03:02<00:00, 36.55s/it]\n",
      "NLL / N: 595.7842\n",
      "\n",
      " 60%|██████    | 6/10 [23:42<15:44, 236.23s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3069\n",
      "\n",
      " 20%|██        | 1/5 [00:35<02:21, 35.48s/it]\u001b[A\n",
      "NLL / N: 501.6199\n",
      "\n",
      " 40%|████      | 2/5 [01:00<01:36, 32.20s/it]\u001b[A\n",
      "NLL / N: 517.6251\n",
      "\n",
      " 60%|██████    | 3/5 [01:34<01:05, 32.80s/it]\u001b[A\n",
      "NLL / N: 495.6169\n",
      "\n",
      " 80%|████████  | 4/5 [02:11<00:34, 34.25s/it]\u001b[A\n",
      "NLL / N: 488.3614\n",
      "\n",
      "100%|██████████| 5/5 [02:56<00:00, 35.21s/it]\n",
      "NLL / N: 507.6536\n",
      "\n",
      " 70%|███████   | 7/10 [27:29<11:40, 233.55s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3134\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.69s/it]\u001b[A\n",
      "NLL / N: 558.5164\n",
      "\n",
      " 40%|████      | 2/5 [01:02<01:41, 33.90s/it]\u001b[A\n",
      "NLL / N: 552.7010\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.69s/it]\u001b[A\n",
      "NLL / N: 545.7552\n",
      "\n",
      " 80%|████████  | 4/5 [02:21<00:36, 36.98s/it]\u001b[A\n",
      "NLL / N: 594.5211\n",
      "\n",
      "100%|██████████| 5/5 [03:06<00:00, 37.34s/it]\n",
      "NLL / N: 602.9580\n",
      "\n",
      " 80%|████████  | 8/10 [31:24<07:47, 233.99s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3095\n",
      "\n",
      " 20%|██        | 1/5 [00:36<02:24, 36.13s/it]\u001b[A\n",
      "NLL / N: 530.7309\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:40, 33.59s/it]\u001b[A\n",
      "NLL / N: 701.2354\n",
      "\n",
      " 60%|██████    | 3/5 [01:41<01:09, 34.92s/it]\u001b[A\n",
      "NLL / N: 702.4122\n",
      "\n",
      " 80%|████████  | 4/5 [02:24<00:37, 37.29s/it]\u001b[A\n",
      "NLL / N: 629.8088\n",
      "\n",
      "100%|██████████| 5/5 [03:12<00:00, 38.45s/it]\n",
      "NLL / N: 633.1060\n",
      "\n",
      " 90%|█████████ | 9/10 [35:26<03:56, 236.40s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3068\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:28, 37.02s/it]\u001b[A\n",
      "NLL / N: 555.6172\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:41, 33.99s/it]\u001b[A\n",
      "NLL / N: 565.5540\n",
      "\n",
      " 60%|██████    | 3/5 [01:40<01:09, 34.81s/it]\u001b[A\n",
      "NLL / N: 542.0080\n",
      "\n",
      " 80%|████████  | 4/5 [02:25<00:37, 37.89s/it]\u001b[A\n",
      "NLL / N: 548.4473\n",
      "\n",
      "100%|██████████| 5/5 [03:16<00:00, 39.20s/it]\n",
      "NLL / N: 524.2672\n",
      "\n",
      "100%|██████████| 10/10 [39:32<00:00, 237.26s/it]\n",
      "Consistency of clustering: 0.3033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 10\n",
    "niter = 5\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in trange(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    train_ids = np.sort(np.random.choice(np.arange(len(ss)), size=len(ss) // 2, replace=False))\n",
    "    train_fold = [ss[i] for i in range(len(ss)) if i in train_ids]\n",
    "    train_Ts = Ts[train_ids]\n",
    "    \n",
    "    # learn\n",
    "    hp = PointProcessStorage(train_fold, train_Ts, basis_fs)\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model, n_inner=5)\n",
    "\n",
    "    _, nll_history, _ = EM.learn_hp(niter=niter, ninner=[2,4,6,7,8])\n",
    "\n",
    "    # validate\n",
    "    EM.hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "    EM.N = len(ss)\n",
    "    EM.int_g = []\n",
    "    EM.g = []\n",
    "    r = EM.e_step()\n",
    "    \n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'\\nConsistency of clustering: {consistency(labels[:i+1]).item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.mean(0).numpy() / len(train_ids))\n",
    "# plt.fill_between(np.arange(niter)+1, (nlls.mean(0).numpy() - nlls.std(0).numpy()) / len(train_ids), (nlls.mean(0).numpy() + nlls.std(0).numpy()) / len(train_ids), alpha=0.2)\n",
    "# plt.title('Mixing DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Consistency of clustering: 0.3033\n"
     ]
    }
   ],
   "source": [
    "print(f'Consistency of clustering: {consistency(labels).item():.4f}')"
   ]
  },
  {
   "source": [
    "### Synthetic data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K5_C5')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=2000, maxlen=-1, type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([25.9637, 20.5132, 13.4076,  ...,  7.7114, 11.4030, 27.8628])"
      ]
     },
     "metadata": {},
     "execution_count": 256
    }
   ],
   "source": [
    "Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([50, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 257
    }
   ],
   "source": [
    "ss[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:55, 55.29s/it]\n",
      "NLL / N: 113.6334\n",
      "2it [01:07, 42.34s/it]\n",
      "NLL / N: 109.6858\n",
      "3it [01:23, 34.44s/it]\n",
      "NLL / N: 112.1539\n",
      "4it [01:39, 28.99s/it]\n",
      "NLL / N: 112.9830\n",
      "5it [02:00, 26.53s/it]\n",
      "NLL / N: 107.6991\n",
      "6it [02:21, 24.77s/it]\n",
      "NLL / N: 113.6205\n",
      "7it [02:45, 24.51s/it]\n",
      "NLL / N: 114.3848\n",
      "8it [03:05, 23.22s/it]\n",
      "NLL / N: 112.4740\n",
      "9it [03:29, 23.45s/it]\n",
      "NLL / N: 110.9315\n",
      "10it [03:56, 24.70s/it]\n",
      "NLL / N: 110.1535\n",
      "11it [04:29, 27.04s/it]\n",
      "NLL / N: 109.8683\n",
      "12it [05:01, 28.49s/it]\n",
      "NLL / N: 109.7370\n",
      "13it [05:38, 31.10s/it]\n",
      "NLL / N: 109.6369\n",
      "14it [06:15, 32.75s/it]\n",
      "NLL / N: 109.5524\n",
      "15it [06:51, 33.91s/it]\n",
      "NLL / N: 109.4811\n",
      "16it [07:28, 34.82s/it]\n",
      "NLL / N: 109.4183\n",
      "17it [08:06, 35.66s/it]\n",
      "NLL / N: 109.3717\n",
      "18it [08:42, 35.83s/it]\n",
      "NLL / N: 109.3340\n",
      "19it [09:18, 35.99s/it]\n",
      "NLL / N: 109.3059\n",
      "20it [09:55, 29.77s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.2871\n",
      "Purity: 0.6380\n",
      "1it [00:54, 54.32s/it]\n",
      "NLL / N: 111.1096\n",
      "2it [01:05, 41.51s/it]\n",
      "NLL / N: 118.6358\n",
      "3it [01:21, 33.75s/it]\n",
      "NLL / N: 120.2586\n",
      "4it [01:37, 28.34s/it]\n",
      "NLL / N: 117.3156\n",
      "5it [01:58, 26.22s/it]\n",
      "NLL / N: 110.5075\n",
      "6it [02:18, 24.48s/it]\n",
      "NLL / N: 112.4352\n",
      "7it [02:43, 24.58s/it]\n",
      "NLL / N: 112.3692\n",
      "8it [03:08, 24.70s/it]\n",
      "NLL / N: 109.8943\n",
      "9it [03:37, 25.95s/it]\n",
      "NLL / N: 108.2979\n",
      "10it [04:06, 26.81s/it]\n",
      "NLL / N: 108.0078\n",
      "11it [04:39, 28.58s/it]\n",
      "NLL / N: 107.9431\n",
      "12it [05:11, 29.85s/it]\n",
      "NLL / N: 107.8935\n",
      "13it [05:48, 31.86s/it]\n",
      "NLL / N: 107.9057\n",
      "14it [06:25, 33.28s/it]\n",
      "NLL / N: 108.3760\n",
      "15it [07:01, 34.18s/it]\n",
      "NLL / N: 109.0813\n",
      "16it [07:39, 35.45s/it]\n",
      "NLL / N: 109.3545\n",
      "17it [08:17, 36.06s/it]\n",
      "NLL / N: 109.4351\n",
      "18it [08:54, 36.44s/it]\n",
      "NLL / N: 109.4573\n",
      "19it [09:31, 36.59s/it]\n",
      "NLL / N: 109.4753\n",
      "20it [10:08, 30.45s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.4938\n",
      "Purity: 0.6300\n",
      "1it [00:54, 54.09s/it]\n",
      "NLL / N: 117.3077\n",
      "2it [01:05, 41.39s/it]\n",
      "NLL / N: 120.9852\n",
      "3it [01:22, 33.97s/it]\n",
      "NLL / N: 118.9885\n",
      "4it [01:38, 28.68s/it]\n",
      "NLL / N: 115.6046\n",
      "5it [01:59, 26.22s/it]\n",
      "NLL / N: 113.8595\n",
      "6it [02:19, 24.46s/it]\n",
      "NLL / N: 111.0919\n",
      "7it [02:44, 24.58s/it]\n",
      "NLL / N: 110.6735\n",
      "8it [03:09, 24.71s/it]\n",
      "NLL / N: 111.0245\n",
      "9it [03:38, 26.03s/it]\n",
      "NLL / N: 112.3814\n",
      "10it [04:07, 26.76s/it]\n",
      "NLL / N: 110.9709\n",
      "11it [04:39, 28.37s/it]\n",
      "NLL / N: 109.7576\n",
      "12it [05:11, 29.55s/it]\n",
      "NLL / N: 109.6388\n",
      "13it [05:48, 31.80s/it]\n",
      "NLL / N: 109.5602\n",
      "14it [06:25, 33.47s/it]\n",
      "NLL / N: 109.4811\n",
      "15it [07:04, 35.00s/it]\n",
      "NLL / N: 109.4090\n",
      "16it [07:41, 35.73s/it]\n",
      "NLL / N: 109.3520\n",
      "17it [08:19, 36.35s/it]\n",
      "NLL / N: 109.3142\n",
      "18it [08:56, 36.52s/it]\n",
      "NLL / N: 109.2957\n",
      "19it [09:33, 36.48s/it]\n",
      "NLL / N: 109.2862\n",
      "20it [10:09, 30.47s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.2787\n",
      "Purity: 0.6385\n",
      "1it [00:52, 52.75s/it]\n",
      "NLL / N: 110.2892\n",
      "2it [01:04, 40.36s/it]\n",
      "NLL / N: 105.6172\n",
      "3it [01:19, 32.87s/it]\n",
      "NLL / N: 102.5987\n",
      "4it [01:35, 27.65s/it]\n",
      "NLL / N: 103.8344\n",
      "5it [01:55, 25.38s/it]\n",
      "NLL / N: 103.6795\n",
      "6it [02:16, 24.06s/it]\n",
      "NLL / N: 104.6619\n",
      "7it [02:41, 24.35s/it]\n",
      "NLL / N: 108.8678\n",
      "8it [03:05, 24.25s/it]\n",
      "NLL / N: 112.0525\n",
      "9it [03:33, 25.55s/it]\n",
      "NLL / N: 108.7753\n",
      "10it [04:01, 26.32s/it]\n",
      "NLL / N: 108.4924\n",
      "11it [04:34, 28.17s/it]\n",
      "NLL / N: 108.5557\n",
      "12it [05:06, 29.41s/it]\n",
      "NLL / N: 108.5776\n",
      "13it [05:42, 31.48s/it]\n",
      "NLL / N: 108.5669\n",
      "14it [06:19, 32.85s/it]\n",
      "NLL / N: 108.5484\n",
      "15it [06:54, 33.63s/it]\n",
      "NLL / N: 108.5375\n",
      "16it [07:33, 35.16s/it]\n",
      "NLL / N: 108.5408\n",
      "17it [08:11, 35.96s/it]\n",
      "NLL / N: 108.5609\n",
      "18it [08:47, 36.22s/it]\n",
      "NLL / N: 108.5926\n",
      "19it [09:24, 36.28s/it]\n",
      "NLL / N: 108.6331\n",
      "20it [10:00, 30.05s/it]\n",
      "NLL / N: 108.6689\n",
      "Purity: 0.6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 4\n",
    "niter = 20\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,2,3,3,4,4,5,5,6,6,7,7] + (niter - 12)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.numpy() / len(ss))\n",
    "# plt.title('Mixing of DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.24850000000000003, 0.278, 0.314, 0.37400000000000005, 0.42700000000000005, 0.4555, 0.5265, 0.6135, 0.6325, 0.6280000000000001, 0.6335000000000001, 0.6380000000000001, 0.6380000000000001, 0.6460000000000001, 0.6540000000000001, 0.6585000000000001, 0.6635, 0.6675, 0.671, 0.6735]\n"
     ]
    }
   ],
   "source": [
    "print([purity(x, gt_ids) for x in r_history.argmax(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.6450+-0.0168\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.,  ..., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 268
    }
   ],
   "source": [
    "labels[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K4_C5')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=1600, maxlen=-1, type='csv')\n",
    "\n",
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()\n",
    "\n",
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:41, 41.60s/it]\n",
      "NLL / N: 110.8511\n",
      "2it [00:50, 31.70s/it]\n",
      "NLL / N: 115.4690\n",
      "3it [01:01, 25.71s/it]\n",
      "NLL / N: 118.5997\n",
      "4it [01:13, 21.46s/it]\n",
      "NLL / N: 116.3621\n",
      "5it [01:28, 19.44s/it]\n",
      "NLL / N: 114.8574\n",
      "6it [01:43, 18.13s/it]\n",
      "NLL / N: 114.7086\n",
      "7it [02:01, 18.23s/it]\n",
      "NLL / N: 114.4880\n",
      "8it [02:20, 18.24s/it]\n",
      "NLL / N: 114.1530\n",
      "9it [02:40, 18.93s/it]\n",
      "NLL / N: 113.8282\n",
      "10it [03:01, 19.67s/it]\n",
      "NLL / N: 113.5514\n",
      "11it [03:25, 20.93s/it]\n",
      "NLL / N: 113.3495\n",
      "12it [03:49, 21.83s/it]\n",
      "NLL / N: 113.1590\n",
      "13it [04:18, 23.88s/it]\n",
      "NLL / N: 112.9673\n",
      "14it [04:45, 24.71s/it]\n",
      "NLL / N: 112.8211\n",
      "15it [05:12, 25.53s/it]\n",
      "NLL / N: 112.7597\n",
      "16it [05:39, 26.00s/it]\n",
      "NLL / N: 112.6789\n",
      "17it [06:04, 25.71s/it]\n",
      "NLL / N: 112.6131\n",
      "18it [06:32, 26.42s/it]\n",
      "NLL / N: 112.5939\n",
      "19it [06:58, 26.28s/it]\n",
      "NLL / N: 112.5861\n",
      "20it [07:24, 22.20s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 112.5768\n",
      "Purity: 0.7444\n",
      "1it [00:38, 38.94s/it]\n",
      "NLL / N: 112.6540\n",
      "2it [00:47, 29.75s/it]\n",
      "NLL / N: 118.0835\n",
      "3it [00:58, 24.17s/it]\n",
      "NLL / N: 119.6325\n",
      "4it [01:09, 20.36s/it]\n",
      "NLL / N: 118.6087\n",
      "5it [01:23, 18.39s/it]\n",
      "NLL / N: 115.8191\n",
      "6it [01:37, 17.16s/it]\n",
      "NLL / N: 115.1439\n",
      "7it [01:54, 17.11s/it]\n",
      "NLL / N: 114.7446\n",
      "8it [02:11, 16.99s/it]\n",
      "NLL / N: 114.6208\n",
      "9it [02:31, 17.89s/it]\n",
      "NLL / N: 114.6157\n",
      "10it [02:51, 18.53s/it]\n",
      "NLL / N: 114.6318\n",
      "11it [03:14, 19.76s/it]\n",
      "NLL / N: 114.6405\n",
      "12it [03:36, 20.58s/it]\n",
      "NLL / N: 114.6415\n",
      "13it [04:02, 22.09s/it]\n",
      "NLL / N: 114.6384\n",
      "14it [04:29, 23.47s/it]\n",
      "NLL / N: 114.6359\n",
      "15it [04:53, 23.89s/it]\n",
      "NLL / N: 114.6358\n",
      "16it [05:18, 24.03s/it]\n",
      "NLL / N: 114.6351\n",
      "17it [05:43, 24.37s/it]\n",
      "NLL / N: 114.6330\n",
      "18it [06:07, 24.23s/it]\n",
      "NLL / N: 114.6324\n",
      "19it [06:30, 23.90s/it]\n",
      "NLL / N: 114.6314\n",
      "20it [06:54, 20.74s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 114.6303\n",
      "Purity: 0.8450\n",
      "1it [00:35, 35.09s/it]\n",
      "NLL / N: 112.4855\n",
      "2it [00:42, 26.84s/it]\n",
      "NLL / N: 113.1113\n",
      "3it [00:52, 21.71s/it]\n",
      "NLL / N: 115.2560\n",
      "4it [01:02, 18.24s/it]\n",
      "NLL / N: 112.9303\n",
      "5it [01:15, 16.66s/it]\n",
      "NLL / N: 113.0187\n",
      "6it [01:28, 15.55s/it]\n",
      "NLL / N: 113.4616\n",
      "7it [01:44, 15.70s/it]\n",
      "NLL / N: 112.9731\n",
      "8it [02:00, 15.75s/it]\n",
      "NLL / N: 112.1553\n",
      "9it [02:18, 16.57s/it]\n",
      "NLL / N: 112.0679\n",
      "10it [02:37, 17.12s/it]\n",
      "NLL / N: 112.0324\n",
      "11it [02:58, 18.28s/it]\n",
      "NLL / N: 112.0586\n",
      "12it [03:19, 19.04s/it]\n",
      "NLL / N: 112.0256\n",
      "13it [03:41, 19.99s/it]\n",
      "NLL / N: 111.9954\n",
      "14it [04:04, 20.95s/it]\n",
      "NLL / N: 111.9658\n",
      "15it [04:27, 21.69s/it]\n",
      "NLL / N: 111.9418\n",
      "16it [04:51, 22.15s/it]\n",
      "NLL / N: 111.9209\n",
      "17it [05:14, 22.55s/it]\n",
      "NLL / N: 111.9085\n",
      "18it [05:36, 22.43s/it]\n",
      "NLL / N: 111.9031\n",
      "19it [05:58, 22.31s/it]\n",
      "NLL / N: 111.8993\n",
      "20it [06:21, 19.09s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 111.8966\n",
      "Purity: 0.7462\n",
      "1it [00:33, 33.33s/it]\n",
      "NLL / N: 111.4514\n",
      "2it [00:40, 25.48s/it]\n",
      "NLL / N: 112.4884\n",
      "3it [00:50, 20.87s/it]\n",
      "NLL / N: 115.0192\n",
      "4it [01:00, 17.65s/it]\n",
      "NLL / N: 114.8973\n",
      "5it [01:13, 16.23s/it]\n",
      "NLL / N: 115.1195\n",
      "6it [01:26, 15.25s/it]\n",
      "NLL / N: 114.5431\n",
      "7it [01:42, 15.37s/it]\n",
      "NLL / N: 114.2997\n",
      "8it [01:57, 15.36s/it]\n",
      "NLL / N: 114.3398\n",
      "9it [02:15, 16.23s/it]\n",
      "NLL / N: 114.4227\n",
      "10it [02:34, 16.89s/it]\n",
      "NLL / N: 114.4811\n",
      "11it [02:51, 16.94s/it]\n",
      "NLL / N: 114.5063\n",
      "12it [03:06, 16.40s/it]\n",
      "NLL / N: 114.4934\n",
      "13it [03:23, 16.54s/it]\n",
      "NLL / N: 114.4660\n",
      "14it [03:40, 16.73s/it]\n",
      "NLL / N: 114.4279\n",
      "15it [03:57, 16.81s/it]\n",
      "NLL / N: 114.3855\n",
      "16it [04:14, 16.72s/it]\n",
      "NLL / N: 114.3376\n",
      "17it [04:30, 16.67s/it]\n",
      "NLL / N: 114.2909\n",
      "18it [04:47, 16.64s/it]\n",
      "NLL / N: 114.2449\n",
      "19it [05:03, 16.66s/it]\n",
      "NLL / N: 114.2050\n",
      "20it [05:20, 16.02s/it]\n",
      "NLL / N: 114.1695\n",
      "Purity: 0.7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 4\n",
    "\n",
    "ntrials = 4\n",
    "niter = 20\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,2,3,3,4,4,5,5,6,6,7,7] + (niter - 12)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.7639+-0.0480\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}