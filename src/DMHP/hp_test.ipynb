{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitf6c62337d7b54061b89e700f2be80f8a",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from HP import PointProcessStorage, DirichletMixtureModel, EM_clustering\n",
    "from metrics import consistency, purity\n",
    "from Cohortney.data_utils import load_data"
   ]
  },
  {
   "source": [
    "### IPTV Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'IPTV_Data')\n",
    "ss, Ts, class2idx, _ = load_data(path, ext='txt', datetime=True, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (2.*(k+1)**2) ) for k in range(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(class2idx)\n",
    "K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [01:18, 78.20s/it]\u001b[A\n",
      "NLL / N: 432.7707\n",
      "\n",
      "2it [01:48, 63.93s/it]\u001b[A\n",
      "NLL / N: 502.6920\n",
      "\n",
      "3it [02:36, 59.14s/it]\u001b[A\n",
      "NLL / N: 566.7167\n",
      "\n",
      "4it [03:38, 59.95s/it]\u001b[A\n",
      "NLL / N: 492.0925\n",
      "\n",
      "5it [04:52, 64.19s/it]\u001b[A\n",
      "NLL / N: 492.3028\n",
      "\n",
      "6it [06:12, 69.02s/it]\u001b[A\n",
      "NLL / N: 514.4466\n",
      "\n",
      "7it [07:41, 74.77s/it]\u001b[A\n",
      "NLL / N: 537.4928\n",
      "\n",
      "8it [08:47, 72.20s/it]\u001b[A\n",
      "NLL / N: 564.8536\n",
      "\n",
      "9it [09:44, 67.65s/it]\u001b[A\n",
      "NLL / N: 570.9984\n",
      "\n",
      "10it [10:59, 65.95s/it]\n",
      "NLL / N: 575.5531\n",
      "\n",
      " 10%|█         | 1/10 [12:22<1:51:18, 742.10s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: nan\n",
      "\n",
      "1it [01:14, 74.91s/it]\u001b[A\n",
      "NLL / N: 379.3969\n",
      "\n",
      "2it [01:53, 64.15s/it]\u001b[A\n",
      "NLL / N: 397.7283\n",
      "\n",
      "3it [02:44, 59.98s/it]\u001b[A\n",
      "NLL / N: 414.1325\n",
      "\n",
      "4it [03:37, 58.09s/it]\u001b[A\n",
      "NLL / N: 446.1228\n",
      "\n",
      "5it [04:48, 61.75s/it]\u001b[A\n",
      "NLL / N: 445.5093\n",
      "\n",
      "6it [06:08, 67.26s/it]\u001b[A\n",
      "NLL / N: 519.6938\n",
      "\n",
      "7it [07:35, 73.17s/it]\u001b[A\n",
      "NLL / N: 539.3990\n",
      "\n",
      "8it [09:01, 77.15s/it]\u001b[A\n",
      "NLL / N: 559.1468\n",
      "\n",
      "9it [10:00, 71.70s/it]\u001b[A\n",
      "NLL / N: 622.7192\n",
      "\n",
      "10it [10:51, 65.17s/it]\n",
      "NLL / N: 637.2678\n",
      "\n",
      " 20%|██        | 2/10 [24:31<1:38:26, 738.35s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.4002\n",
      "\n",
      "1it [01:12, 72.02s/it]\u001b[A\n",
      "NLL / N: 381.8168\n",
      "\n",
      "2it [01:53, 62.89s/it]\u001b[A\n",
      "NLL / N: 435.6650\n",
      "\n",
      "3it [02:45, 59.58s/it]\u001b[A\n",
      "NLL / N: 510.0789\n",
      "\n",
      "4it [03:50, 61.20s/it]\u001b[A\n",
      "NLL / N: 546.5104\n",
      "\n",
      "5it [05:08, 66.36s/it]\u001b[A\n",
      "NLL / N: 578.1712\n",
      "\n",
      "6it [06:39, 73.66s/it]\u001b[A\n",
      "NLL / N: 617.4498\n",
      "\n",
      "7it [08:10, 78.97s/it]\u001b[A\n",
      "NLL / N: 620.8245\n",
      "\n",
      "8it [09:43, 83.10s/it]\u001b[A\n",
      "NLL / N: 645.8772\n",
      "\n",
      "9it [10:54, 79.30s/it]\u001b[A\n",
      "NLL / N: 654.4037\n",
      "\n",
      "10it [12:25, 74.57s/it]\n",
      "NLL / N: 636.4960\n",
      "\n",
      " 30%|███       | 3/10 [38:32<1:29:43, 769.06s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3919\n",
      "\n",
      "1it [01:10, 70.57s/it]\u001b[A\n",
      "NLL / N: 448.8402\n",
      "\n",
      "2it [01:50, 61.31s/it]\u001b[A\n",
      "NLL / N: 466.2319\n",
      "\n",
      "3it [02:41, 58.42s/it]\u001b[A\n",
      "NLL / N: 457.0799\n",
      "\n",
      "4it [03:36, 57.39s/it]\u001b[A\n",
      "NLL / N: 434.3457\n",
      "\n",
      "5it [04:45, 60.72s/it]\u001b[A\n",
      "NLL / N: 464.7583\n",
      "\n",
      "6it [05:59, 64.87s/it]\u001b[A\n",
      "NLL / N: 504.5344\n",
      "\n",
      "7it [07:19, 69.25s/it]\u001b[A\n",
      "NLL / N: 548.9034\n",
      "\n",
      "8it [08:39, 72.64s/it]\u001b[A\n",
      "NLL / N: 595.8428\n",
      "\n",
      "9it [09:57, 74.23s/it]\u001b[A\n",
      "NLL / N: 641.2855\n",
      "\n",
      "10it [11:13, 67.35s/it]\n",
      "NLL / N: 643.8439\n",
      "\n",
      " 40%|████      | 4/10 [51:16<1:16:46, 767.69s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3692\n",
      "\n",
      "1it [01:01, 61.10s/it]\u001b[A\n",
      "NLL / N: 445.8101\n",
      "\n",
      "2it [01:36, 53.51s/it]\u001b[A\n",
      "NLL / N: 514.5603\n",
      "\n",
      "3it [02:22, 51.13s/it]\u001b[A\n",
      "NLL / N: 561.5418\n",
      "\n",
      "4it [03:06, 49.03s/it]\u001b[A\n",
      "NLL / N: 525.9064\n",
      "\n",
      "5it [04:06, 52.33s/it]\u001b[A\n",
      "NLL / N: 493.1955\n",
      "\n",
      "6it [05:17, 57.82s/it]\u001b[A\n",
      "NLL / N: 535.0579\n",
      "\n",
      "7it [06:38, 64.97s/it]\u001b[A\n",
      "NLL / N: 649.0688\n",
      "\n",
      "8it [08:07, 72.00s/it]\u001b[A\n",
      "NLL / N: 653.2850\n",
      "\n",
      "9it [09:36, 77.03s/it]\u001b[A\n",
      "NLL / N: 677.1686\n",
      "\n",
      "10it [11:01, 66.17s/it]\n",
      "NLL / N: 684.7900\n",
      "\n",
      " 50%|█████     | 5/10 [1:03:52<1:03:40, 764.10s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3697\n",
      "\n",
      "1it [00:59, 59.29s/it]\u001b[A\n",
      "NLL / N: 406.4718\n",
      "\n",
      "2it [01:36, 52.75s/it]\u001b[A\n",
      "NLL / N: 513.1257\n",
      "\n",
      "3it [02:27, 51.99s/it]\u001b[A\n",
      "NLL / N: 641.5285\n",
      "\n",
      "4it [03:28, 54.78s/it]\u001b[A\n",
      "NLL / N: 552.5520\n",
      "\n",
      "5it [04:37, 59.22s/it]\u001b[A\n",
      "NLL / N: 517.2814\n",
      "\n",
      "6it [05:57, 65.44s/it]\u001b[A\n",
      "NLL / N: 574.3993\n",
      "\n",
      "7it [07:48, 78.86s/it]\u001b[A\n",
      "NLL / N: 603.6507\n",
      "\n",
      "8it [09:14, 81.26s/it]\u001b[A\n",
      "NLL / N: 618.6624\n",
      "\n",
      "9it [11:01, 88.89s/it]\u001b[A\n",
      "NLL / N: 632.2145\n",
      "\n",
      "10it [13:06, 78.69s/it]\n",
      "NLL / N: 648.8344\n",
      "\n",
      " 60%|██████    | 6/10 [1:19:01<53:50, 807.61s/it]  \n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3824\n",
      "\n",
      "1it [01:36, 96.83s/it]\u001b[A\n",
      "NLL / N: 396.8306\n",
      "\n",
      "2it [02:36, 85.54s/it]\u001b[A\n",
      "NLL / N: 443.5219\n",
      "\n",
      "3it [03:49, 81.90s/it]\u001b[A\n",
      "NLL / N: 492.9916\n",
      "\n",
      "4it [05:16, 83.57s/it]\u001b[A\n",
      "NLL / N: 484.7494\n",
      "\n",
      "5it [07:02, 90.09s/it]\u001b[A\n",
      "NLL / N: 554.8740\n",
      "\n",
      "6it [08:59, 98.33s/it]\u001b[A\n",
      "NLL / N: 561.9768\n",
      "\n",
      "7it [11:12, 108.70s/it]\u001b[A\n",
      "NLL / N: 606.6703\n",
      "\n",
      "8it [13:22, 114.91s/it]\u001b[A\n",
      "NLL / N: 592.8202\n",
      "\n",
      "9it [15:27, 118.12s/it]\u001b[A\n",
      "NLL / N: 603.1785\n",
      "\n",
      "10it [17:36, 105.62s/it]\n",
      "NLL / N: 669.3150\n",
      "\n",
      " 70%|███████   | 7/10 [1:38:43<45:59, 919.95s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3646\n",
      "\n",
      "1it [01:32, 92.30s/it]\u001b[A\n",
      "NLL / N: 465.4481\n",
      "\n",
      "2it [02:28, 81.54s/it]\u001b[A\n",
      "NLL / N: 502.1417\n",
      "\n",
      "3it [03:38, 78.04s/it]\u001b[A\n",
      "NLL / N: 514.7236\n",
      "\n",
      "4it [05:05, 80.82s/it]\u001b[A\n",
      "NLL / N: 528.5328\n",
      "\n",
      "5it [06:41, 85.20s/it]\u001b[A\n",
      "NLL / N: 546.0627\n",
      "\n",
      "6it [08:26, 91.08s/it]\u001b[A\n",
      "NLL / N: 546.8936\n",
      "\n",
      "7it [09:41, 86.27s/it]\u001b[A\n",
      "NLL / N: 544.4812\n",
      "\n",
      "8it [10:53, 82.08s/it]\u001b[A\n",
      "NLL / N: 549.3354\n",
      "\n",
      "9it [12:06, 79.29s/it]\u001b[A\n",
      "NLL / N: 558.7448\n",
      "\n",
      "10it [13:20, 80.00s/it]\n",
      "NLL / N: 595.4750\n",
      "\n",
      " 80%|████████  | 8/10 [1:53:30<30:19, 909.86s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3572\n",
      "\n",
      "1it [00:59, 59.37s/it]\u001b[A\n",
      "NLL / N: 428.6947\n",
      "\n",
      "2it [01:34, 52.03s/it]\u001b[A\n",
      "NLL / N: 538.1657\n",
      "\n",
      "3it [02:23, 51.04s/it]\u001b[A\n",
      "NLL / N: 595.4649\n",
      "\n",
      "4it [03:17, 51.96s/it]\u001b[A\n",
      "NLL / N: 542.1173\n",
      "\n",
      "5it [04:18, 54.79s/it]\u001b[A\n",
      "NLL / N: 527.2848\n",
      "\n",
      "6it [05:29, 59.75s/it]\u001b[A\n",
      "NLL / N: 552.8353\n",
      "\n",
      "7it [06:47, 65.01s/it]\u001b[A\n",
      "NLL / N: 573.0167\n",
      "\n",
      "8it [08:01, 67.80s/it]\u001b[A\n",
      "NLL / N: 594.0663\n",
      "\n",
      "9it [09:15, 69.75s/it]\u001b[A\n",
      "NLL / N: 615.5855\n",
      "\n",
      "10it [10:28, 62.90s/it]\n",
      "NLL / N: 618.8629\n",
      "\n",
      " 90%|█████████ | 9/10 [2:05:20<14:10, 850.10s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3652\n",
      "\n",
      "1it [00:58, 58.60s/it]\u001b[A\n",
      "NLL / N: 446.2572\n",
      "\n",
      "2it [01:31, 50.90s/it]\u001b[A\n",
      "NLL / N: 459.8197\n",
      "\n",
      "3it [02:12, 47.89s/it]\u001b[A\n",
      "NLL / N: 475.0215\n",
      "\n",
      "4it [03:01, 48.15s/it]\u001b[A\n",
      "NLL / N: 480.4117\n",
      "\n",
      "5it [03:59, 51.11s/it]\u001b[A\n",
      "NLL / N: 469.8492\n",
      "\n",
      "6it [05:05, 55.70s/it]\u001b[A\n",
      "NLL / N: 457.4753\n",
      "\n",
      "7it [06:20, 61.59s/it]\u001b[A\n",
      "NLL / N: 499.6849\n",
      "\n",
      "8it [07:33, 64.80s/it]\u001b[A\n",
      "NLL / N: 544.6207\n",
      "\n",
      "9it [08:40, 65.65s/it]\u001b[A\n",
      "NLL / N: 596.4656\n",
      "\n",
      "10it [09:41, 58.12s/it]\n",
      "NLL / N: 607.2946\n",
      "\n",
      "100%|██████████| 10/10 [2:16:09<00:00, 816.95s/it]\n",
      "Consistency of clustering: 0.3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 10\n",
    "niter = 10\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in trange(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    train_ids = np.sort(np.random.choice(np.arange(len(ss)), size=len(ss) // 2, replace=False))\n",
    "    train_fold = [ss[i] for i in range(len(ss)) if i in train_ids]\n",
    "    train_Ts = Ts[train_ids]\n",
    "    \n",
    "    # learn\n",
    "    hp = PointProcessStorage(train_fold, train_Ts, basis_fs)\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model, n_inner=5)\n",
    "\n",
    "    _, nll_history, _ = EM.learn_hp(niter=niter, ninner=[2,3,4,5,6,7] + (niter-6)*[8])\n",
    "\n",
    "    # validate\n",
    "    EM.hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "    EM.N = len(ss)\n",
    "    EM.int_g = []\n",
    "    EM.g = []\n",
    "    r = EM.e_step()\n",
    "    \n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'\\nConsistency of clustering: {consistency(labels[:i+1]).item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.mean(0).numpy() / len(train_ids))\n",
    "# plt.fill_between(np.arange(niter)+1, (nlls.mean(0).numpy() - nlls.std(0).numpy()) / len(train_ids), (nlls.mean(0).numpy() + nlls.std(0).numpy()) / len(train_ids), alpha=0.2)\n",
    "# plt.title('Mixing DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Consistency of clustering: 0.3660\n"
     ]
    }
   ],
   "source": [
    "print(f'Consistency of clustering: {consistency(labels).item():.4f}')"
   ]
  },
  {
   "source": [
    "### Synthetic data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 5 cluster, 5 classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K5_C5')\n",
    "ss, Ts, class2idx, _ = load_data(path, maxlen=-1, ext='csv', datetime=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (2.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:50, 50.66s/it]\n",
      "NLL / N: 114.6237\n",
      "2it [01:04, 39.70s/it]\n",
      "NLL / N: 112.4859\n",
      "3it [01:22, 33.22s/it]\n",
      "NLL / N: 107.7913\n",
      "4it [01:44, 29.71s/it]\n",
      "NLL / N: 107.6673\n",
      "5it [02:09, 28.32s/it]\n",
      "NLL / N: 110.5551\n",
      "6it [02:38, 28.54s/it]\n",
      "NLL / N: 112.7791\n",
      "7it [03:11, 29.99s/it]\n",
      "NLL / N: 111.4655\n",
      "8it [03:43, 30.40s/it]\n",
      "NLL / N: 110.0676\n",
      "9it [04:16, 31.33s/it]\n",
      "NLL / N: 109.5276\n",
      "10it [04:48, 28.81s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.4583\n",
      "Purity: 0.6370\n",
      "1it [00:50, 50.08s/it]\n",
      "NLL / N: 110.6662\n",
      "2it [01:03, 38.95s/it]\n",
      "NLL / N: 110.4590\n",
      "3it [01:19, 32.21s/it]\n",
      "NLL / N: 109.8640\n",
      "4it [01:40, 28.86s/it]\n",
      "NLL / N: 106.5325\n",
      "5it [02:05, 27.67s/it]\n",
      "NLL / N: 112.3647\n",
      "6it [02:33, 27.83s/it]\n",
      "NLL / N: 110.9341\n",
      "7it [03:04, 28.84s/it]\n",
      "NLL / N: 109.2221\n",
      "8it [03:36, 29.55s/it]\n",
      "NLL / N: 108.0501\n",
      "9it [04:07, 30.13s/it]\n",
      "NLL / N: 107.5931\n",
      "10it [04:38, 27.84s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 107.3807\n",
      "Purity: 0.5150\n",
      "1it [00:51, 51.33s/it]\n",
      "NLL / N: 107.9458\n",
      "2it [01:05, 40.25s/it]\n",
      "NLL / N: 105.7468\n",
      "3it [01:24, 33.83s/it]\n",
      "NLL / N: 110.8504\n",
      "4it [01:46, 30.38s/it]\n",
      "NLL / N: 108.7665\n",
      "5it [02:12, 28.85s/it]\n",
      "NLL / N: 106.1326\n",
      "6it [02:39, 28.26s/it]\n",
      "NLL / N: 112.2810\n",
      "7it [03:10, 29.17s/it]\n",
      "NLL / N: 112.0350\n",
      "8it [03:43, 30.22s/it]\n",
      "NLL / N: 110.1052\n",
      "9it [04:14, 30.59s/it]\n",
      "NLL / N: 109.0417\n",
      "10it [04:45, 28.59s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 108.7643\n",
      "Purity: 0.6125\n",
      "1it [00:50, 50.56s/it]\n",
      "NLL / N: 113.1476\n",
      "2it [01:03, 39.32s/it]\n",
      "NLL / N: 111.6663\n",
      "3it [01:21, 32.85s/it]\n",
      "NLL / N: 108.3839\n",
      "4it [01:44, 29.82s/it]\n",
      "NLL / N: 106.0406\n",
      "5it [02:10, 28.86s/it]\n",
      "NLL / N: 111.4557\n",
      "6it [02:40, 29.06s/it]\n",
      "NLL / N: 111.2231\n",
      "7it [03:11, 29.66s/it]\n",
      "NLL / N: 109.1807\n",
      "8it [03:44, 30.67s/it]\n",
      "NLL / N: 108.3429\n",
      "9it [04:17, 31.26s/it]\n",
      "NLL / N: 108.6722\n",
      "10it [04:47, 28.76s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.0856\n",
      "Purity: 0.6510\n",
      "1it [00:49, 49.39s/it]\n",
      "NLL / N: 111.7035\n",
      "2it [01:03, 38.80s/it]\n",
      "NLL / N: 102.9759\n",
      "3it [01:21, 32.71s/it]\n",
      "NLL / N: 109.2354\n",
      "4it [01:43, 29.39s/it]\n",
      "NLL / N: 108.1581\n",
      "5it [02:08, 27.98s/it]\n",
      "NLL / N: 107.8187\n",
      "6it [02:36, 27.92s/it]\n",
      "NLL / N: 111.9054\n",
      "7it [03:08, 29.21s/it]\n",
      "NLL / N: 111.2968\n",
      "8it [03:42, 30.62s/it]\n",
      "NLL / N: 109.4089\n",
      "9it [04:14, 31.07s/it]\n",
      "NLL / N: 108.2019\n",
      "10it [04:44, 28.50s/it]\n",
      "NLL / N: 107.9419\n",
      "Purity: 0.6385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 5\n",
    "niter = 10\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,3,4,5,6,7] + (niter - 6)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.numpy() / len(ss))\n",
    "# plt.title('Mixing of DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.36000000000000004, 0.40199999999999997, 0.5175000000000001, 0.5995, 0.596, 0.6105, 0.636, 0.6365000000000001, 0.635, 0.6385000000000001]\n"
     ]
    }
   ],
   "source": [
    "print([purity(x, gt_ids) for x in r_history.argmax(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.6108+-0.0495\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.,  ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "labels[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### 4 cluster, 5 classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K4_C5')\n",
    "ss, Ts, class2idx, _ = load_data(path, maxlen=-1, ext='csv', datetime=False)\n",
    "\n",
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()\n",
    "\n",
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:39, 39.30s/it]\n",
      "NLL / N: 112.3002\n",
      "2it [00:51, 31.06s/it]\n",
      "NLL / N: 113.9484\n",
      "3it [01:03, 25.56s/it]\n",
      "NLL / N: 110.4884\n",
      "4it [01:21, 23.07s/it]\n",
      "NLL / N: 109.6833\n",
      "5it [01:41, 22.12s/it]\n",
      "NLL / N: 110.3378\n",
      "6it [02:02, 21.91s/it]\n",
      "NLL / N: 110.3131\n",
      "7it [02:28, 23.22s/it]\n",
      "NLL / N: 110.4250\n",
      "8it [02:52, 23.29s/it]\n",
      "NLL / N: 110.5777\n",
      "9it [03:15, 23.28s/it]\n",
      "NLL / N: 110.6202\n",
      "10it [03:40, 22.07s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 110.6629\n",
      "Purity: 0.7450\n",
      "1it [00:39, 39.82s/it]\n",
      "NLL / N: 114.2860\n",
      "2it [00:50, 31.12s/it]\n",
      "NLL / N: 113.1868\n",
      "3it [01:03, 25.74s/it]\n",
      "NLL / N: 107.6603\n",
      "4it [01:19, 22.85s/it]\n",
      "NLL / N: 107.9281\n",
      "5it [01:39, 21.98s/it]\n",
      "NLL / N: 111.7562\n",
      "6it [02:01, 21.98s/it]\n",
      "NLL / N: 111.9735\n",
      "7it [02:28, 23.46s/it]\n",
      "NLL / N: 111.6347\n",
      "8it [02:54, 24.12s/it]\n",
      "NLL / N: 111.5501\n",
      "9it [03:19, 24.43s/it]\n",
      "NLL / N: 111.5162\n",
      "10it [03:45, 22.51s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 111.5071\n",
      "Purity: 0.7350\n",
      "1it [00:39, 39.98s/it]\n",
      "NLL / N: 113.2184\n",
      "2it [00:51, 31.37s/it]\n",
      "NLL / N: 106.9172\n",
      "3it [01:04, 25.83s/it]\n",
      "NLL / N: 110.4727\n",
      "4it [01:21, 23.26s/it]\n",
      "NLL / N: 110.8351\n",
      "5it [01:40, 21.87s/it]\n",
      "NLL / N: 111.5347\n",
      "6it [02:00, 21.52s/it]\n",
      "NLL / N: 111.5382\n",
      "7it [02:27, 23.05s/it]\n",
      "NLL / N: 111.8132\n",
      "8it [02:52, 23.79s/it]\n",
      "NLL / N: 112.4717\n",
      "9it [03:19, 24.49s/it]\n",
      "NLL / N: 112.6958\n",
      "10it [03:45, 22.53s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 112.6143\n",
      "Purity: 0.7406\n",
      "1it [00:41, 41.13s/it]\n",
      "NLL / N: 111.1341\n",
      "2it [00:51, 31.96s/it]\n",
      "NLL / N: 114.3927\n",
      "3it [01:05, 26.50s/it]\n",
      "NLL / N: 115.2220\n",
      "4it [01:23, 23.89s/it]\n",
      "NLL / N: 114.5291\n",
      "5it [01:42, 22.37s/it]\n",
      "NLL / N: 113.5242\n",
      "6it [02:02, 21.85s/it]\n",
      "NLL / N: 112.4632\n",
      "7it [02:27, 22.87s/it]\n",
      "NLL / N: 112.9343\n",
      "8it [02:53, 23.74s/it]\n",
      "NLL / N: 113.0861\n",
      "9it [03:16, 23.60s/it]\n",
      "NLL / N: 113.1436\n",
      "10it [03:41, 22.12s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 113.1663\n",
      "Purity: 0.7925\n",
      "1it [00:40, 40.16s/it]\n",
      "NLL / N: 112.8342\n",
      "2it [00:51, 31.56s/it]\n",
      "NLL / N: 108.0740\n",
      "3it [01:05, 26.39s/it]\n",
      "NLL / N: 106.6091\n",
      "4it [01:23, 23.78s/it]\n",
      "NLL / N: 110.9723\n",
      "5it [01:41, 22.06s/it]\n",
      "NLL / N: 111.9583\n",
      "6it [02:04, 22.28s/it]\n",
      "NLL / N: 111.5154\n",
      "7it [02:30, 23.32s/it]\n",
      "NLL / N: 111.4311\n",
      "8it [02:54, 23.69s/it]\n",
      "NLL / N: 111.3201\n",
      "9it [03:18, 23.71s/it]\n",
      "NLL / N: 111.1503\n",
      "10it [03:41, 22.17s/it]\n",
      "NLL / N: 111.0750\n",
      "Purity: 0.7394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (2.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 4\n",
    "\n",
    "ntrials = 5\n",
    "niter = 10\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,3,4,5,6,7] + (niter - 6)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.7505+-0.0212\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### 3 cluster, 5 classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K3_C5')\n",
    "ss, Ts, class2idx, _ = load_data(path, maxlen=-1, ext='csv', datetime=False)\n",
    "\n",
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()\n",
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:28, 28.83s/it]\n",
      "NLL / N: 112.3995\n",
      "2it [00:36, 22.56s/it]\n",
      "NLL / N: 107.3360\n",
      "3it [00:46, 18.57s/it]\n",
      "NLL / N: 117.0898\n",
      "4it [00:58, 16.87s/it]\n",
      "NLL / N: 116.8130\n",
      "5it [01:13, 16.31s/it]\n",
      "NLL / N: 107.0087\n",
      "6it [01:31, 16.60s/it]\n",
      "NLL / N: 116.9097\n",
      "7it [01:50, 17.33s/it]\n",
      "NLL / N: 116.2267\n",
      "8it [02:09, 17.94s/it]\n",
      "NLL / N: 113.6239\n",
      "9it [02:28, 18.22s/it]\n",
      "NLL / N: 112.0471\n",
      "10it [02:47, 16.73s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 111.6934\n",
      "Purity: 0.8808\n",
      "1it [00:28, 28.66s/it]\n",
      "NLL / N: 112.1850\n",
      "2it [00:35, 22.21s/it]\n",
      "NLL / N: 106.7475\n",
      "3it [00:45, 18.50s/it]\n",
      "NLL / N: 103.8981\n",
      "4it [00:58, 16.67s/it]\n",
      "NLL / N: 102.8498\n",
      "5it [01:11, 15.81s/it]\n",
      "NLL / N: 105.6443\n",
      "6it [01:28, 16.11s/it]\n",
      "NLL / N: 111.2864\n",
      "7it [01:47, 16.82s/it]\n",
      "NLL / N: 109.3345\n",
      "8it [02:04, 17.05s/it]\n",
      "NLL / N: 110.3924\n",
      "9it [02:23, 17.43s/it]\n",
      "NLL / N: 111.2633\n",
      "10it [02:41, 16.11s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 111.3966\n",
      "Purity: 0.8392\n",
      "1it [00:28, 28.22s/it]\n",
      "NLL / N: 114.1269\n",
      "2it [00:36, 22.12s/it]\n",
      "NLL / N: 122.7714\n",
      "3it [00:46, 18.69s/it]\n",
      "NLL / N: 120.2661\n",
      "4it [00:59, 16.85s/it]\n",
      "NLL / N: 108.6169\n",
      "5it [01:14, 16.23s/it]\n",
      "NLL / N: 114.8446\n",
      "6it [01:31, 16.48s/it]\n",
      "NLL / N: 115.7843\n",
      "7it [01:49, 16.96s/it]\n",
      "NLL / N: 113.6943\n",
      "8it [02:07, 17.48s/it]\n",
      "NLL / N: 111.6440\n",
      "9it [02:26, 17.94s/it]\n",
      "NLL / N: 111.2603\n",
      "10it [02:44, 16.48s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 111.3635\n",
      "Purity: 0.9250\n",
      "1it [00:29, 29.65s/it]\n",
      "NLL / N: 117.8589\n",
      "2it [00:36, 22.96s/it]\n",
      "NLL / N: 115.1000\n",
      "3it [00:46, 18.80s/it]\n",
      "NLL / N: 115.5559\n",
      "4it [00:57, 16.44s/it]\n",
      "NLL / N: 109.6328\n",
      "5it [01:10, 15.58s/it]\n",
      "NLL / N: 107.0075\n",
      "6it [01:26, 15.71s/it]\n",
      "NLL / N: 117.1234\n",
      "7it [01:44, 16.39s/it]\n",
      "NLL / N: 116.1653\n",
      "8it [02:00, 16.18s/it]\n",
      "NLL / N: 114.0952\n",
      "9it [02:16, 16.05s/it]\n",
      "NLL / N: 112.7582\n",
      "10it [02:31, 15.16s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 112.4058\n",
      "Purity: 0.8658\n",
      "1it [00:21, 21.41s/it]\n",
      "NLL / N: 118.3565\n",
      "2it [00:26, 16.64s/it]\n",
      "NLL / N: 126.1523\n",
      "3it [00:34, 13.82s/it]\n",
      "NLL / N: 123.5397\n",
      "4it [00:46, 13.32s/it]\n",
      "NLL / N: 124.4655\n",
      "5it [01:00, 13.51s/it]\n",
      "NLL / N: 115.9161\n",
      "6it [01:17, 14.51s/it]\n",
      "NLL / N: 112.0273\n",
      "7it [01:36, 15.89s/it]\n",
      "NLL / N: 111.7175\n",
      "8it [01:54, 16.54s/it]\n",
      "NLL / N: 111.6444\n",
      "9it [02:12, 17.04s/it]\n",
      "NLL / N: 111.6271\n",
      "10it [02:29, 14.97s/it]\n",
      "NLL / N: 111.6143\n",
      "Purity: 0.8508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 3\n",
    "\n",
    "ntrials = 5\n",
    "niter = 10\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,3,4,5,6,7] + (niter - 6)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.8723+-0.0298\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}