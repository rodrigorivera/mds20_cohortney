{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from HP import PointProcessStorage, DirichletMixtureModel, EM_clustering\n",
    "from metrics import consistency, purity\n",
    "from data_utils import load_data"
   ]
  },
  {
   "source": [
    "### IPTV Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'IPTV_Data')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=300, ext='txt', datetime=True, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (2.*(k+1)**2) ) for k in range(D)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(class2idx)\n",
    "K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.65s/it]\u001b[A\n",
      "NLL / N: 537.3705\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:42, 34.08s/it]\u001b[A\n",
      "NLL / N: 596.5760\n",
      "\n",
      " 60%|██████    | 3/5 [01:36<01:07, 33.93s/it]\u001b[A\n",
      "NLL / N: 587.5982\n",
      "\n",
      " 80%|████████  | 4/5 [02:15<00:35, 35.21s/it]\u001b[A\n",
      "NLL / N: 601.1137\n",
      "\n",
      "100%|██████████| 5/5 [02:58<00:00, 35.79s/it]\n",
      "NLL / N: 645.3842\n",
      "\n",
      " 10%|█         | 1/10 [03:50<34:37, 230.82s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: nan\n",
      "\n",
      " 20%|██        | 1/5 [00:38<02:32, 38.19s/it]\u001b[A\n",
      "NLL / N: 522.6370\n",
      "\n",
      " 40%|████      | 2/5 [01:05<01:44, 34.94s/it]\u001b[A\n",
      "NLL / N: 516.6924\n",
      "\n",
      " 60%|██████    | 3/5 [01:42<01:11, 35.68s/it]\u001b[A\n",
      "NLL / N: 482.7739\n",
      "\n",
      " 80%|████████  | 4/5 [02:23<00:37, 37.17s/it]\u001b[A\n",
      "NLL / N: 487.5942\n",
      "\n",
      "100%|██████████| 5/5 [03:09<00:00, 37.82s/it]\n",
      "NLL / N: 559.7852\n",
      "\n",
      " 20%|██        | 2/10 [07:49<31:05, 233.22s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3361\n",
      "\n",
      " 20%|██        | 1/5 [00:38<02:33, 38.25s/it]\u001b[A\n",
      "NLL / N: 531.1342\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:43, 34.39s/it]\u001b[A\n",
      "NLL / N: 497.7358\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.75s/it]\u001b[A\n",
      "NLL / N: 443.5218\n",
      "\n",
      " 80%|████████  | 4/5 [02:19<00:36, 36.42s/it]\u001b[A\n",
      "NLL / N: 404.2956\n",
      "\n",
      "100%|██████████| 5/5 [03:08<00:00, 37.65s/it]\n",
      "NLL / N: 441.0808\n",
      "\n",
      " 30%|███       | 3/10 [11:47<27:21, 234.50s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.2927\n",
      "\n",
      " 20%|██        | 1/5 [00:36<02:26, 36.73s/it]\u001b[A\n",
      "NLL / N: 506.3757\n",
      "\n",
      " 40%|████      | 2/5 [01:02<01:40, 33.50s/it]\u001b[A\n",
      "NLL / N: 518.5385\n",
      "\n",
      " 60%|██████    | 3/5 [01:40<01:09, 34.88s/it]\u001b[A\n",
      "NLL / N: 527.1872\n",
      "\n",
      " 80%|████████  | 4/5 [02:22<00:36, 36.94s/it]\u001b[A\n",
      "NLL / N: 485.8402\n",
      "\n",
      "100%|██████████| 5/5 [03:09<00:00, 37.92s/it]\n",
      "NLL / N: 491.8597\n",
      "\n",
      " 40%|████      | 4/10 [15:46<23:35, 235.94s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.2970\n",
      "\n",
      " 20%|██        | 1/5 [00:39<02:36, 39.07s/it]\u001b[A\n",
      "NLL / N: 490.2220\n",
      "\n",
      " 40%|████      | 2/5 [01:07<01:47, 35.83s/it]\u001b[A\n",
      "NLL / N: 551.2139\n",
      "\n",
      " 60%|██████    | 3/5 [01:44<01:12, 36.33s/it]\u001b[A\n",
      "NLL / N: 573.0693\n",
      "\n",
      " 80%|████████  | 4/5 [02:27<00:38, 38.21s/it]\u001b[A\n",
      "NLL / N: 561.0652\n",
      "\n",
      "100%|██████████| 5/5 [03:15<00:00, 39.16s/it]\n",
      "NLL / N: 570.0848\n",
      "\n",
      " 50%|█████     | 5/10 [19:52<19:54, 238.86s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3131\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.56s/it]\u001b[A\n",
      "NLL / N: 505.1434\n",
      "\n",
      " 40%|████      | 2/5 [01:04<01:43, 34.35s/it]\u001b[A\n",
      "NLL / N: 511.3603\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.53s/it]\u001b[A\n",
      "NLL / N: 533.3947\n",
      "\n",
      " 80%|████████  | 4/5 [02:18<00:36, 36.02s/it]\u001b[A\n",
      "NLL / N: 576.7228\n",
      "\n",
      "100%|██████████| 5/5 [03:02<00:00, 36.55s/it]\n",
      "NLL / N: 595.7842\n",
      "\n",
      " 60%|██████    | 6/10 [23:42<15:44, 236.23s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3069\n",
      "\n",
      " 20%|██        | 1/5 [00:35<02:21, 35.48s/it]\u001b[A\n",
      "NLL / N: 501.6199\n",
      "\n",
      " 40%|████      | 2/5 [01:00<01:36, 32.20s/it]\u001b[A\n",
      "NLL / N: 517.6251\n",
      "\n",
      " 60%|██████    | 3/5 [01:34<01:05, 32.80s/it]\u001b[A\n",
      "NLL / N: 495.6169\n",
      "\n",
      " 80%|████████  | 4/5 [02:11<00:34, 34.25s/it]\u001b[A\n",
      "NLL / N: 488.3614\n",
      "\n",
      "100%|██████████| 5/5 [02:56<00:00, 35.21s/it]\n",
      "NLL / N: 507.6536\n",
      "\n",
      " 70%|███████   | 7/10 [27:29<11:40, 233.55s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3134\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:30, 37.69s/it]\u001b[A\n",
      "NLL / N: 558.5164\n",
      "\n",
      " 40%|████      | 2/5 [01:02<01:41, 33.90s/it]\u001b[A\n",
      "NLL / N: 552.7010\n",
      "\n",
      " 60%|██████    | 3/5 [01:39<01:09, 34.69s/it]\u001b[A\n",
      "NLL / N: 545.7552\n",
      "\n",
      " 80%|████████  | 4/5 [02:21<00:36, 36.98s/it]\u001b[A\n",
      "NLL / N: 594.5211\n",
      "\n",
      "100%|██████████| 5/5 [03:06<00:00, 37.34s/it]\n",
      "NLL / N: 602.9580\n",
      "\n",
      " 80%|████████  | 8/10 [31:24<07:47, 233.99s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3095\n",
      "\n",
      " 20%|██        | 1/5 [00:36<02:24, 36.13s/it]\u001b[A\n",
      "NLL / N: 530.7309\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:40, 33.59s/it]\u001b[A\n",
      "NLL / N: 701.2354\n",
      "\n",
      " 60%|██████    | 3/5 [01:41<01:09, 34.92s/it]\u001b[A\n",
      "NLL / N: 702.4122\n",
      "\n",
      " 80%|████████  | 4/5 [02:24<00:37, 37.29s/it]\u001b[A\n",
      "NLL / N: 629.8088\n",
      "\n",
      "100%|██████████| 5/5 [03:12<00:00, 38.45s/it]\n",
      "NLL / N: 633.1060\n",
      "\n",
      " 90%|█████████ | 9/10 [35:26<03:56, 236.40s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Consistency of clustering: 0.3068\n",
      "\n",
      " 20%|██        | 1/5 [00:37<02:28, 37.02s/it]\u001b[A\n",
      "NLL / N: 555.6172\n",
      "\n",
      " 40%|████      | 2/5 [01:03<01:41, 33.99s/it]\u001b[A\n",
      "NLL / N: 565.5540\n",
      "\n",
      " 60%|██████    | 3/5 [01:40<01:09, 34.81s/it]\u001b[A\n",
      "NLL / N: 542.0080\n",
      "\n",
      " 80%|████████  | 4/5 [02:25<00:37, 37.89s/it]\u001b[A\n",
      "NLL / N: 548.4473\n",
      "\n",
      "100%|██████████| 5/5 [03:16<00:00, 39.20s/it]\n",
      "NLL / N: 524.2672\n",
      "\n",
      "100%|██████████| 10/10 [39:32<00:00, 237.26s/it]\n",
      "Consistency of clustering: 0.3033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 10\n",
    "niter = 5\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in trange(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    train_ids = np.sort(np.random.choice(np.arange(len(ss)), size=len(ss) // 2, replace=False))\n",
    "    train_fold = [ss[i] for i in range(len(ss)) if i in train_ids]\n",
    "    train_Ts = Ts[train_ids]\n",
    "    \n",
    "    # learn\n",
    "    hp = PointProcessStorage(train_fold, train_Ts, basis_fs)\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model, n_inner=5)\n",
    "\n",
    "    _, nll_history, _ = EM.learn_hp(niter=niter, ninner=[2,4,6,7,8])\n",
    "\n",
    "    # validate\n",
    "    EM.hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "    EM.N = len(ss)\n",
    "    EM.int_g = []\n",
    "    EM.g = []\n",
    "    r = EM.e_step()\n",
    "    \n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'\\nConsistency of clustering: {consistency(labels[:i+1]).item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.mean(0).numpy() / len(train_ids))\n",
    "# plt.fill_between(np.arange(niter)+1, (nlls.mean(0).numpy() - nlls.std(0).numpy()) / len(train_ids), (nlls.mean(0).numpy() + nlls.std(0).numpy()) / len(train_ids), alpha=0.2)\n",
    "# plt.title('Mixing DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Consistency of clustering: 0.3033\n"
     ]
    }
   ],
   "source": [
    "print(f'Consistency of clustering: {consistency(labels).item():.4f}')"
   ]
  },
  {
   "source": [
    "### Synthetic data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K5_C5')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=2000, maxlen=-1, ext='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:55, 55.29s/it]\n",
      "NLL / N: 113.6334\n",
      "2it [01:07, 42.34s/it]\n",
      "NLL / N: 109.6858\n",
      "3it [01:23, 34.44s/it]\n",
      "NLL / N: 112.1539\n",
      "4it [01:39, 28.99s/it]\n",
      "NLL / N: 112.9830\n",
      "5it [02:00, 26.53s/it]\n",
      "NLL / N: 107.6991\n",
      "6it [02:21, 24.77s/it]\n",
      "NLL / N: 113.6205\n",
      "7it [02:45, 24.51s/it]\n",
      "NLL / N: 114.3848\n",
      "8it [03:05, 23.22s/it]\n",
      "NLL / N: 112.4740\n",
      "9it [03:29, 23.45s/it]\n",
      "NLL / N: 110.9315\n",
      "10it [03:56, 24.70s/it]\n",
      "NLL / N: 110.1535\n",
      "11it [04:29, 27.04s/it]\n",
      "NLL / N: 109.8683\n",
      "12it [05:01, 28.49s/it]\n",
      "NLL / N: 109.7370\n",
      "13it [05:38, 31.10s/it]\n",
      "NLL / N: 109.6369\n",
      "14it [06:15, 32.75s/it]\n",
      "NLL / N: 109.5524\n",
      "15it [06:51, 33.91s/it]\n",
      "NLL / N: 109.4811\n",
      "16it [07:28, 34.82s/it]\n",
      "NLL / N: 109.4183\n",
      "17it [08:06, 35.66s/it]\n",
      "NLL / N: 109.3717\n",
      "18it [08:42, 35.83s/it]\n",
      "NLL / N: 109.3340\n",
      "19it [09:18, 35.99s/it]\n",
      "NLL / N: 109.3059\n",
      "20it [09:55, 29.77s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.2871\n",
      "Purity: 0.6380\n",
      "1it [00:54, 54.32s/it]\n",
      "NLL / N: 111.1096\n",
      "2it [01:05, 41.51s/it]\n",
      "NLL / N: 118.6358\n",
      "3it [01:21, 33.75s/it]\n",
      "NLL / N: 120.2586\n",
      "4it [01:37, 28.34s/it]\n",
      "NLL / N: 117.3156\n",
      "5it [01:58, 26.22s/it]\n",
      "NLL / N: 110.5075\n",
      "6it [02:18, 24.48s/it]\n",
      "NLL / N: 112.4352\n",
      "7it [02:43, 24.58s/it]\n",
      "NLL / N: 112.3692\n",
      "8it [03:08, 24.70s/it]\n",
      "NLL / N: 109.8943\n",
      "9it [03:37, 25.95s/it]\n",
      "NLL / N: 108.2979\n",
      "10it [04:06, 26.81s/it]\n",
      "NLL / N: 108.0078\n",
      "11it [04:39, 28.58s/it]\n",
      "NLL / N: 107.9431\n",
      "12it [05:11, 29.85s/it]\n",
      "NLL / N: 107.8935\n",
      "13it [05:48, 31.86s/it]\n",
      "NLL / N: 107.9057\n",
      "14it [06:25, 33.28s/it]\n",
      "NLL / N: 108.3760\n",
      "15it [07:01, 34.18s/it]\n",
      "NLL / N: 109.0813\n",
      "16it [07:39, 35.45s/it]\n",
      "NLL / N: 109.3545\n",
      "17it [08:17, 36.06s/it]\n",
      "NLL / N: 109.4351\n",
      "18it [08:54, 36.44s/it]\n",
      "NLL / N: 109.4573\n",
      "19it [09:31, 36.59s/it]\n",
      "NLL / N: 109.4753\n",
      "20it [10:08, 30.45s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.4938\n",
      "Purity: 0.6300\n",
      "1it [00:54, 54.09s/it]\n",
      "NLL / N: 117.3077\n",
      "2it [01:05, 41.39s/it]\n",
      "NLL / N: 120.9852\n",
      "3it [01:22, 33.97s/it]\n",
      "NLL / N: 118.9885\n",
      "4it [01:38, 28.68s/it]\n",
      "NLL / N: 115.6046\n",
      "5it [01:59, 26.22s/it]\n",
      "NLL / N: 113.8595\n",
      "6it [02:19, 24.46s/it]\n",
      "NLL / N: 111.0919\n",
      "7it [02:44, 24.58s/it]\n",
      "NLL / N: 110.6735\n",
      "8it [03:09, 24.71s/it]\n",
      "NLL / N: 111.0245\n",
      "9it [03:38, 26.03s/it]\n",
      "NLL / N: 112.3814\n",
      "10it [04:07, 26.76s/it]\n",
      "NLL / N: 110.9709\n",
      "11it [04:39, 28.37s/it]\n",
      "NLL / N: 109.7576\n",
      "12it [05:11, 29.55s/it]\n",
      "NLL / N: 109.6388\n",
      "13it [05:48, 31.80s/it]\n",
      "NLL / N: 109.5602\n",
      "14it [06:25, 33.47s/it]\n",
      "NLL / N: 109.4811\n",
      "15it [07:04, 35.00s/it]\n",
      "NLL / N: 109.4090\n",
      "16it [07:41, 35.73s/it]\n",
      "NLL / N: 109.3520\n",
      "17it [08:19, 36.35s/it]\n",
      "NLL / N: 109.3142\n",
      "18it [08:56, 36.52s/it]\n",
      "NLL / N: 109.2957\n",
      "19it [09:33, 36.48s/it]\n",
      "NLL / N: 109.2862\n",
      "20it [10:09, 30.47s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 109.2787\n",
      "Purity: 0.6385\n",
      "1it [00:52, 52.75s/it]\n",
      "NLL / N: 110.2892\n",
      "2it [01:04, 40.36s/it]\n",
      "NLL / N: 105.6172\n",
      "3it [01:19, 32.87s/it]\n",
      "NLL / N: 102.5987\n",
      "4it [01:35, 27.65s/it]\n",
      "NLL / N: 103.8344\n",
      "5it [01:55, 25.38s/it]\n",
      "NLL / N: 103.6795\n",
      "6it [02:16, 24.06s/it]\n",
      "NLL / N: 104.6619\n",
      "7it [02:41, 24.35s/it]\n",
      "NLL / N: 108.8678\n",
      "8it [03:05, 24.25s/it]\n",
      "NLL / N: 112.0525\n",
      "9it [03:33, 25.55s/it]\n",
      "NLL / N: 108.7753\n",
      "10it [04:01, 26.32s/it]\n",
      "NLL / N: 108.4924\n",
      "11it [04:34, 28.17s/it]\n",
      "NLL / N: 108.5557\n",
      "12it [05:06, 29.41s/it]\n",
      "NLL / N: 108.5776\n",
      "13it [05:42, 31.48s/it]\n",
      "NLL / N: 108.5669\n",
      "14it [06:19, 32.85s/it]\n",
      "NLL / N: 108.5484\n",
      "15it [06:54, 33.63s/it]\n",
      "NLL / N: 108.5375\n",
      "16it [07:33, 35.16s/it]\n",
      "NLL / N: 108.5408\n",
      "17it [08:11, 35.96s/it]\n",
      "NLL / N: 108.5609\n",
      "18it [08:47, 36.22s/it]\n",
      "NLL / N: 108.5926\n",
      "19it [09:24, 36.28s/it]\n",
      "NLL / N: 108.6331\n",
      "20it [10:00, 30.05s/it]\n",
      "NLL / N: 108.6689\n",
      "Purity: 0.6735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntrials = 4\n",
    "niter = 20\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,2,3,3,4,4,5,5,6,6,7,7] + (niter - 12)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (model.A >= 0).all()\n",
    "assert (model.mu > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9, 5))\n",
    "# plt.grid()\n",
    "# plt.plot(np.arange(niter)+1, nlls.numpy() / len(ss))\n",
    "# plt.title('Mixing of DMMHP', fontsize=15)\n",
    "# plt.xlabel(r'$n$ outer iterations', fontsize=15)\n",
    "# plt.ylabel(r'$\\sim$ NLL / $N$', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.24850000000000003, 0.278, 0.314, 0.37400000000000005, 0.42700000000000005, 0.4555, 0.5265, 0.6135, 0.6325, 0.6280000000000001, 0.6335000000000001, 0.6380000000000001, 0.6380000000000001, 0.6460000000000001, 0.6540000000000001, 0.6585000000000001, 0.6635, 0.6675, 0.671, 0.6735]\n"
     ]
    }
   ],
   "source": [
    "print([purity(x, gt_ids) for x in r_history.argmax(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Purity: 0.6450+-0.0168\n"
     ]
    }
   ],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.,  ..., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 268
    }
   ],
   "source": [
    "labels[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K4_C5')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=1600, maxlen=-1, ext='csv')\n",
    "\n",
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()\n",
    "\n",
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:02, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-99fd3e26a909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichletMixtureModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mEM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_hp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36mlearn_hp\u001b[0;34m(self, niter, ninner)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# nll1 = self.hp_nll(r.sum(0) / self.N, mu, A)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mnll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_nll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36me_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mlog_rho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_lambda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvar_lambda\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me_lambda\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mint_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_int_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mint_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me_mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint_g\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mlog_rho\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mint_lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36m_get_int_g\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mTn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mint_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintegral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasis_fs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mTn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mint_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintegral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasis_fs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36mintegral\u001b[0;34m(f, left, right, npts)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mintegral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mint_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = len(ss)\n",
    "D = 5\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 4\n",
    "\n",
    "ntrials = 4\n",
    "niter = 20\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,2,3,3,4,4,5,5,6,6,7,7] + (niter - 12)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../..', 'data', 'simulated_Hawkes', 'K3_C1')\n",
    "ss, Ts, class2idx = load_data(path, nfiles=300, maxlen=-1, ext='csv')\n",
    "\n",
    "gt_ids = pd.read_csv(Path(path, 'clusters.csv'))['cluster_id'].to_numpy()\n",
    "gt_ids = torch.LongTensor(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [04:32, 272.51s/it]\n",
      "NLL / N: 821.9668\n",
      "2it [05:48, 213.68s/it]\n",
      "NLL / N: -21.0775\n",
      "3it [06:51, 168.34s/it]\n",
      "NLL / N: -25.2455\n",
      "4it [07:52, 136.04s/it]\n",
      "NLL / N: 10.4621\n",
      "5it [09:08, 118.03s/it]\n",
      "NLL / N: 11.2603\n",
      "6it [10:24, 105.58s/it]\n",
      "NLL / N: 10.7322\n",
      "7it [11:50, 99.54s/it] \n",
      "NLL / N: 10.5084\n",
      "8it [13:14, 95.13s/it]\n",
      "NLL / N: 10.4957\n",
      "9it [14:53, 96.14s/it]\n",
      "NLL / N: 10.5146\n",
      "10it [16:32, 97.00s/it]\n",
      "NLL / N: 10.4436\n",
      "11it [18:17, 99.54s/it]\n",
      "NLL / N: 10.3164\n",
      "12it [20:07, 102.40s/it]\n",
      "NLL / N: 10.7432\n",
      "13it [22:05, 107.34s/it]\n",
      "NLL / N: 10.7802\n",
      "14it [24:06, 111.20s/it]\n",
      "NLL / N: 10.5157\n",
      "15it [26:06, 113.99s/it]\n",
      "NLL / N: 10.5320\n",
      "16it [28:04, 115.03s/it]\n",
      "NLL / N: 11.0811\n",
      "17it [29:58, 114.78s/it]\n",
      "NLL / N: 10.9054\n",
      "18it [31:59, 116.58s/it]\n",
      "NLL / N: 10.1535\n",
      "19it [33:58, 117.60s/it]\n",
      "NLL / N: 10.5953\n",
      "20it [35:58, 107.94s/it]\n",
      "0it [00:00, ?it/s]\n",
      "NLL / N: 10.6457\n",
      "Purity: 0.6633\n",
      "1it [01:59, 119.20s/it]\n",
      "NLL / N: 291.6378\n",
      "2it [02:44, 96.90s/it] \n",
      "NLL / N: 16.0954\n",
      "3it [03:42, 85.38s/it]\n",
      "NLL / N: 11.6632\n",
      "4it [04:38, 76.60s/it]\n",
      "NLL / N: 10.8176\n",
      "5it [05:48, 74.57s/it]\n",
      "NLL / N: 10.3209\n",
      "5it [06:55, 83.13s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35cd4760b882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichletMixtureModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mEM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_hp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mninner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mniter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36mlearn_hp\u001b[0;34m(self, niter, ninner)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mnll2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_nll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mds2020/mds20_cohortney/src/DMHP/HP.py\u001b[0m in \u001b[0;36mm_step\u001b[0;34m(self, r, niter)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m#A_g_ = (A[cs.tolist(), cs.tolist(), :, :] * g[:, :, :, None]) # L x L x D x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mpijd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_g\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# L x L x D x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpijd\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpijd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = len(ss)\n",
    "D = 3\n",
    "basis_fs = [lambda x: torch.exp(- x**2 / (3.*(k+1)**2) ) for k in range(D)]\n",
    "\n",
    "hp = PointProcessStorage(ss, Ts, basis_fs)\n",
    "\n",
    "C = len(class2idx)\n",
    "K = 3\n",
    "\n",
    "ntrials = 4\n",
    "niter = 20\n",
    "\n",
    "labels = torch.zeros(ntrials, len(ss))\n",
    "nlls = torch.zeros(ntrials, niter)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    Sigma = torch.rand(C, C, D, K)\n",
    "    B = torch.rand(C, K)\n",
    "    alpha = 1.\n",
    "\n",
    "    model = DirichletMixtureModel(K, C, D, alpha, B, Sigma)\n",
    "    EM = EM_clustering(hp, model)\n",
    "    r, nll_history, r_history = EM.learn_hp(niter=niter, ninner=[2,2,3,3,4,4,5,5,6,6,7,7] + (niter - 12)*[8])\n",
    "\n",
    "    labels[i] = r.argmax(-1)\n",
    "    nlls[i] = torch.FloatTensor(nll_history)\n",
    "\n",
    "    print(f'Purity: {purity(labels[i], gt_ids):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur_val_mean = np.mean([purity(x, gt_ids) for x in labels])\n",
    "pur_val_std = np.std([purity(x, gt_ids) for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Purity: {pur_val_mean:.4f}+-{pur_val_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}