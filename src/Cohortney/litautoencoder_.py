# -*- coding: utf-8 -*-
"""litAutoEncoder.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_o6hnIX5yqu3spMdYwETNmydcj5o_Ofa
"""

import os
from collections import defaultdict
from typing import List, Callable
from numbers import Number
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
#import cvxpy as cp

import pytorch_lightning as pl



import torch

from pathlib import Path
from zipfile import ZipFile
import pandas as pd
import torch
import random
import numpy as np
from matplotlib import pyplot as plt
from tqdm import tqdm, trange

class LitAutoEncoder(pl.LightningModule):
    def __init__(self
                 , n_latent_features: int):
        super().__init__()
        self.out = n_latent_features
        self.encoder = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=512, kernel_size = 3),
                nn.BatchNorm1d(512),
                nn.Conv1d(in_channels=512, out_channels=256, kernel_size = 3),
                nn.BatchNorm1d(256),
                nn.Conv1d(in_channels=256, out_channels=128, kernel_size = 3),
                nn.BatchNorm1d(128),
                nn.Conv1d(in_channels=128, out_channels=64, kernel_size = 3),
                nn.BatchNorm1d(64),
                nn.Conv1d(in_channels=64, out_channels=32, kernel_size = 3),
                nn.BatchNorm1d(32),
                nn.Conv1d(in_channels=32, out_channels=self.out, kernel_size = 3)
   
                )  
        self.decoder =  nn.Sequential(
               nn.ConvTranspose1d(in_channels=self.out, out_channels=32, kernel_size = 3),
                nn.BatchNorm1d(32), 
                nn.ConvTranspose1d(in_channels=32, out_channels=64, kernel_size = 3),
                nn.BatchNorm1d(64), 
                nn.ConvTranspose1d(in_channels=64, out_channels=128, kernel_size = 3),
                nn.BatchNorm1d(128), 
                nn.ConvTranspose1d(in_channels=128, out_channels=256, kernel_size = 3),
                nn.BatchNorm1d(256), 
                nn.ConvTranspose1d(in_channels=256, out_channels=512, kernel_size = 3),
                nn.BatchNorm1d(512),
                nn.ConvTranspose1d(in_channels=512, out_channels=1, kernel_size = 3 ),
                )


    def forward(self, x):
        latent = self.encoder(x)
        return self.decoder(latent)

    def training_step(self, batch, batch_idx):
        x = batch
        x_hat = self(x)

        loss =  torch.nn.MSELoss()(x_hat, x)
        self.log('train_loss', loss)
        return loss

    def training_epoch_end(self, outputs):
        losses = torch.as_tensor([o['loss'] for o in outputs])
        self.log('avg_train_loss', losses.mean(), prog_bar=True)



    def validation_step(self, batch, batch_idx):
        x = batch
        x_hat = self(x)

        loss = torch.nn.MSELoss()(x_hat, x)


        output = {
            'val_loss': loss
            
        }
        self.log_dict(output, prog_bar=True)

        return output

    def validation_epoch_end(self, outputs):
        losses = []
        

        for o in outputs:
            losses.append(o['val_loss'])
            

        self.log_dict({
            'avg_val_loss': torch.as_tensor(losses).mean()
            
        }, prog_bar=True)

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.003)

